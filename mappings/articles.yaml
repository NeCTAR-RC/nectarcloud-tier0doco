33:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:10-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " \n Creating an SSH Keypair \n Configuring an Instance \n Create\
          \ a Security Group \n Example - launching an instance \n \n This guide describes\
          \ launching a running instance (virtual machine) with SSH login\nenabled.\
          \ \n Setting up and using the Virtual Machines requires at least some familiarity\
          \ with\nUNIX shell (often called 'BASH') commands. There are many excellent\
          \ beginner's \ntutorials to refresh your skills, such as this short, interactive\
          \ tutorial from\nCodecademy. \n Preparation - creating an SSH keypair \n\
          \ \n You need to create a public/private key pair before you can use SSH\
          \ to login to \nthe newly created instance. The public key will be stored\
          \ on the instance and\nthe private key is used on your desktop/laptop. \
          \ \n \n Keys can be created by your computer, and the public key uploaded\
          \ to Nectar, or  \n Keys can be created on the Nectar dashboard, and the\
          \ private key downloaded to your computer. \n \n 1. Create a keypair locally\
          \ \n Windows User \n On Windows computers, the program PuTTY is used as\
          \ an SSH client and a terminal emulator.\nPutty allows the windows user\
          \ to access and use the VM via the command line.\nUse PuTTYgen key generator\
          \ to generate the required key pair: \n \n \n Download PuTTYgen (puttygen.exe)\
          \ from PuTTYgen download page\n \n Launch the PuTTYgen application by double\
          \ clicking the puttygen.exe\n \n The default settings are fine for this\
          \ case, click the 'Generate' button \n Save your public key by clicking\
          \ 'Save public key' button. You should give a\n name that will help identify\
          \ the key in the future \n Save your private key by clicking 'Save private\
          \ key' button. You should give\n a sensible name for future reference. The\
          \ passphrase can provide additional\n security, though can be left empty.\
          \ \n \n \n Linux/Mac User \n On Mac and Linux computers, commands are entered\
          \ directly in the 'Terminal' application. \n ssh-keygen -t rsa -f Nectar_Key\
          \ \n \n To generate a keypair, enter the previous command in the Terminal.\
          \ \n Instead of \"Nectar_Key\", enter your preferred key name. \n By default,\
          \ key files will be generated in the directory '~/.ssh'. Check with ls ~/.ssh\n\
          \ \n You should see a private key (e.g. 'Nectar_Key') and a public key (e.g.\
          \ 'Nectar_Key.pub') \n \n Note: For the security of your private key, ensuring\
          \ only the user can read the file:\nOn you local computer, enter chmod 600\
          \ ~/.ssh/Nectar_Key. \n \n Import the Public Key to Nectar \n The public\
          \ key generated by Windows/Linux/Mac are required to be imported into\n\
          the Nectar Cloud dashboard before use. \n \n   \n \n Log into the Cloud\
          \ Dashboard\n \n Go to the 'Access and Security' tab and then to the 'Keypairs'\
          \ page \n Click 'Import Key Pair' button \n \n Type in a keypair name and\
          \ paste the contents of the public key.  \n \n \n For Windows users, open\
          \ PuTTYgen and click 'Load' button to load the related private key and copy/paste\
          \ the public key contents. \n \n For Linux/Mac user, type cat ~/.ssh/id_rsa.pub\
          \ and copy/paste the public key contents from the terminal output. \n \n\
          \ 2. Alternatively: Create Keys on the Nectar Cloud Dashboard \n \n \n Login\
          \ to the Cloud Dashboard\n \n Go to the Access and Security tab and then\
          \ to the Keypairs page \n Click the 'Create Key Pair' button \n Type in\
          \ a keypair name in the popup window and click the 'Create Key Pair'\n button.\
          \ The private key will be downloaded. \n Save the private key into a directory\
          \ on your local computer. \n \n \n Mac / Linux \n mv ~/Downloads/Nectar_Key.pem\
          \ ~/.ssh/Nectar_Key This moves the private key to \nthe '.ssh' folder (change\
          \ 'Nectar_Key' to the name of your keypair). \n Note: For the security of\
          \ your private key, ensuring only the user can read the file:\nOn you local\
          \ computer, enter chmod 600 ~/.ssh/Nectar_Key.  \n \n Windows \n The SSH\
          \ private key will need to be converted for use with PuTTY. \n \n Open PuTTYgen\
          \ \n Click 'Load' button to load the private key generated by the Cloud\
          \ Dashboard \n Click 'Export OpenSSH key' from 'Conversions' menu \n Type\
          \ a private key name and save \n \n   \n \n For more information, you can\
          \ access the detailed SSH key tutorial page. \n \n Select an Image \n You\
          \ need to select an image to be used for your instance. The image defines\
          \ what\noperating system the instance uses and thus you need to select an\
          \ image based on\nyour needs. Nectar Cloud offers a list of official images\
          \ and for\nsimplicity, these images are recommended. You can find a complete\
          \ list of\nofficial images from Nectar image catalog. You can also find\
          \ all\navailable images from the Cloud Dashboard. \n \n Login to the Cloud\
          \ Dashboard\n \n Go to the Dashboard 'Images' tab \n \n For advanced users,\
          \ you can also create your own images. Please refer to\nthe openstack documentation\
          \ for more details. \n Configure Instance \n \n Before you can launch an\
          \ instance, you need to configure the following options: \n Details \n \n\
          \ \n Instance Name: the name used by the dashboard to identify the instance\
          \ \n \n \n Flavour: the resources available for the instance. It specifies\
          \ the number of\n VCPUs, size of root disk, size of ephemeral disk and size\
          \ of RAM.\n Your allocated flavour or lesser configurations can be selected\
          \ (the\n default is m2.tiny; a 1 VCPU machine) \n \n \n Instance Count:\
          \ number of instance to launch (the default is 1) \n \n \n Instance Boot\
          \ Source: the media used to boot the instance. You can boot from\n image,\
          \ snapshot and volume (the default is boot from image) \n \n \n Boot from\
          \ image: Boot instance using an image \n \n Boot from snapshot: Boot instance\
          \ using a snapshot \n \n Boot from volume: Boot instance from volume storage\
          \ \n \n \n Image Name: the name of an Image. This option is used when the\
          \ Instance Boot\n Source is 'Boot from image' \n \n \n Access & Security\
          \ \n \n \n Key Pair: the public/private keys used to log into the instance.\
          \ See above to\n see how to create them. This can't be added or changed\
          \ after the instance is\n created. \n \n \n Security Groups: add network\
          \ access to your instances. This determines what\n services can be accessed\
          \ on the instance. You must select 'SSH' Security Groups\n to allow you\
          \ to login via SSH. If 'SSH' Security Groups is not available, you\n can\
          \ create it by going to Access & Security tab on the right hand side of\
          \ the\n Cloud Dashboard. The default Security Group (no network access at\
          \ first) is\n pre-selected \n \n \n To create a Security Group \n \n \n\
          \ Login to the Cloud Dashboard\n \n Go to the Access & Security tab \n Click\
          \ 'Create Security Group' button \n Give a name for the Security Group \n\
          \ Give a meaningful description for the Security Group \n Click 'Create\
          \ Security Group' button \n \n The newly created Security Group has no rules\
          \ added (no network access defined).\nTo add rules to a Security Group:\
          \ \n \n Go to the Access & Security tab \n Tick to select the Security Group\
          \ to add rules \n Click 'Manage Rules' button \n Click 'Add Rule' button\
          \ \n Select what type of Rule you want to create \n Select from 'Open Port'\
          \ the 'Port' option to open one single port, or 'Port Range'\n to open a\
          \ range of ports \n The 'Remote' option specifies the source of the traffic\
          \ to be allowed via this\n rule. You may do so either in the form of an\
          \ IP address block (CIDR) or via a\n source group (Security Group). \n Click\
          \ 'Add' button \n \n You can also click 'Delete Rule' button to delete a\
          \ rule \n Availability Zone \n Select the Availability Zone for your instance.\
          \ The Availability Zone is the\nlocation for your instance. By default,\
          \ the system will select an available\nlocation for you. You can also click\
          \ the 'Advanced' button to select from a\ncomplete list of available Availability\
          \ Zones \n Post-Creation \n You can execute a customization script after\
          \ you launch your instance. You can\ndo any initialization and customization\
          \ to your instance by using this and it\nis executed only once at the first\
          \ boot of your instance. You can copy/paste\nyour script by selecting 'Direct\
          \ Input' or you can upload a script file. The\nscript can be a shell script\
          \ or Cloud-init script. \n Advanced Options \n You can choose whether you\
          \ automaticly or manually create the disk partition.\nIn most cases, you\
          \ shouldn't change the default. \n Notes: The above configuration options\
          \ can be set in the 'Launch Instance' popup\nwindow. To launch the popup\
          \ window, you can go to the Instances tab and\nclick 'Launch Instance' button.\
          \ \n To get more information about the terms used, please refer to\nthe\
          \ Glossary. \n \n Example Launch of an Instance \n \n \n \n Login to the\
          \ Cloud Dashboard\n \n Go to Dashboard Instances tab \n Click 'Launch Instance'\
          \ button \n Type instance name \n Select a flavour. Flavour indicates the\
          \ specification of a instance. You can find more information in the Flavour\
          \ Details. \n Select an NeCTAR offical image (we suggest selecting an Ubuntu\
          \ image such as NeCTAR Ubuntu 14.04 (Trusty) amd64) \n \n \n \n Click Access\
          \ & Security tab \n Select a key pair created earlier \n Select security\
          \ groups to use. Tick 'ssh' and 'http' (these are pre-defined groups in\
          \ the default personal project) \n \n \n \n Click Availability Zone \n Select\
          \ the location of your instance or leave as unselected (the system will\
          \ auto select available location) \n Click launch button and the page will\
          \ change to the Instances Tab \n After a while (usually a couple of minutes),\
          \ your instance will become active\n and will have an IP address. The IP\
          \ address is available in the Instances table\n on your Nectar Dashboard.\
          \ \n \n The launch button begins Cloud provisioning and initialisation of\
          \ a running\ninstance from the selected image and your configuration options.\
          \ The instance\nwill normally pass from status \"Build\" to \"Active\".\
          \ Depending on your image\nsize and cloud activity, the length of time required\
          \ may vary. Your instance\nwill have a public IP address and be reachable\
          \ according to the\nSecurity Groups selected. \n Instructions to access\
          \ the instance are on the 'Accessing Instance' page in Cloud Basics. \n\
          \ If Launch is Unsuccessful \n You may get a message that your quota has\
          \ been exceeded or you have\ninsufficient resources. Check the table to\
          \ the right on the Launch Instance page\nfor the number of instances you\
          \ may run simultaneously, then check the\nInstances tab to see how many\
          \ Instances you already have running. You may have\nto terminate a running\
          \ Instance to free resources before you can launch another\n(see Instance\
          \ tab to Terminate). If you need more resources see the allocation\ntab\
          \ to apply for an increase. \n If the above doesn't apply to you, alternatively,\
          \ you can send an email to the\nCloud Help Desk. Please find how to lodge\
          \ a support ticket from\nNectar Support. "
        description: "<ul>\n<li><a href=\"#Keypair\">Creating an SSH Keypair</a></li>\n\
          <li><a href=\"#Configuration\">Configuring an Instance</a></li>\n<li><a\
          \ href=\"#SecurityGroup\">Create a Security Group</a></li>\n<li><a href=\"\
          #Example\">Example - launching an instance</a></li>\n</ul>\n<p>This guide\
          \ describes launching a running instance (virtual machine) with SSH login\n\
          enabled.</p>\n<p>Setting up and using the Virtual Machines requires at least\
          \ some familiarity with\nUNIX shell (often called 'BASH') commands. There\
          \ are many excellent beginner's \ntutorials to refresh your skills, such\
          \ as this short, interactive tutorial from\n<a href=\"https://www.codecademy.com/learn/learn-the-command-line\"\
          >Codecademy</a>.</p>\n<h2>Preparation - creating an SSH keypair <a name=\"\
          Keypair\"></a>\n</h2>\n<p>You need to create a public/private key pair before\
          \ you can use SSH to login to \nthe newly created instance. The public key\
          \ will be stored on the instance and\nthe private key is used on your desktop/laptop.\
          \ </p>\n<ol>\n<li>Keys can be created by your computer, and the public key\
          \ uploaded to Nectar, or </li>\n<li>Keys can be created on the Nectar dashboard,\
          \ and the private key downloaded to your computer.</li>\n</ol>\n<h2>1. Create\
          \ a keypair locally</h2>\n<h3>Windows User</h3>\n<p>On Windows computers,\
          \ the program PuTTY is used as an SSH client and a terminal emulator.\n\
          Putty allows the windows user to access and use the VM via the command line.\n\
          Use PuTTYgen key generator to generate the required key pair:</p>\n<p><img\
          \ alt=\"puttygen1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/puttygen1.png?raw=true\"\
          ></p>\n<ol>\n<li>Download PuTTYgen (<code>puttygen.exe</code>) from <a href=\"\
          http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\">PuTTYgen\
          \ download page</a>\n</li>\n<li>Launch the PuTTYgen application by double\
          \ clicking the <code>puttygen.exe</code>\n</li>\n<li>The default settings\
          \ are fine for this case, click the 'Generate' button</li>\n<li>Save your\
          \ public key by clicking 'Save public key' button. You should give a\n name\
          \ that will help identify the key in the future</li>\n<li>Save your private\
          \ key by clicking 'Save private key' button. You should give\n a sensible\
          \ name for future reference. The passphrase can provide additional\n security,\
          \ though can be left empty.</li>\n</ol>\n<hr>\n<h3>Linux/Mac User</h3>\n\
          <p>On Mac and Linux computers, commands are entered directly in the 'Terminal'\
          \ application.</p>\n<p><code>ssh-keygen -t rsa -f Nectar_Key</code></p>\n\
          <ol>\n<li>To generate a keypair, enter the previous command in the Terminal.</li>\n\
          <li>Instead of \"Nectar_Key\", enter your preferred key name.</li>\n<li>By\
          \ default, key files will be generated in the directory '~/.ssh'. Check\
          \ with <code>ls ~/.ssh</code>\n</li>\n<li>You should see a private key (e.g.\
          \ 'Nectar_Key') and a public key (e.g. 'Nectar_Key.pub')</li>\n</ol>\n<p>Note:\
          \ For the security of your private key, ensuring only the user can read\
          \ the file:\nOn you local computer, enter <code>chmod 600 ~/.ssh/Nectar_Key</code>.</p>\n\
          <hr>\n<h3>Import the Public Key to Nectar</h3>\n<p>The public key generated\
          \ by Windows/Linux/Mac are required to be imported into\nthe Nectar Cloud\
          \ dashboard before use.</p>\n<p><img alt=\"keypair\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/keypair.png?raw=true\"\
          ></p>\n<p><img alt=\"key4\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/key4.png?raw=true\"\
          > </p>\n<ol>\n<li>Log into the <a href=\"https://dashboard.rc.nectar.org.au\"\
          >Cloud Dashboard</a>\n</li>\n<li>Go to the 'Access and Security' tab and\
          \ then to the 'Keypairs' page</li>\n<li>Click 'Import Key Pair' button</li>\n\
          <li>\n<p>Type in a keypair name and paste the contents of the public key.\
          \ </p>\n</li>\n<li>\n<p>For <strong>Windows</strong> users, open PuTTYgen\
          \ and click 'Load' button to load the related private key and copy/paste\
          \ the public key contents.</p>\n</li>\n<li>For <strong>Linux/Mac</strong>\
          \ user, type <code>cat ~/.ssh/id_rsa.pub</code> and copy/paste the public\
          \ key contents from the terminal output.</li>\n</ol>\n<h2>2. Alternatively:\
          \ Create Keys on the Nectar Cloud Dashboard</h2>\n<p><img alt=\"create_keypair\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/create_keypair.png?raw=true\"\
          ></p>\n<ol>\n<li>Login to the <a href=\"https://dashboard.rc.nectar.org.au\"\
          >Cloud Dashboard</a>\n</li>\n<li>Go to the Access and Security tab and then\
          \ to the Keypairs page</li>\n<li>Click the 'Create Key Pair' button</li>\n\
          <li>Type in a keypair name in the popup window and click the 'Create Key\
          \ Pair'\n button. The private key will be downloaded.</li>\n<li>Save the\
          \ private key into a directory on your local computer.</li>\n</ol>\n<hr>\n\
          <h3>Mac / Linux</h3>\n<p><code>mv ~/Downloads/Nectar_Key.pem ~/.ssh/Nectar_Key</code>\
          \ This moves the private key to \nthe '.ssh' folder (change 'Nectar_Key'\
          \ to the name of your keypair).</p>\n<p>Note: For the security of your private\
          \ key, ensuring only the user can read the file:\nOn you local computer,\
          \ enter <code>chmod 600 ~/.ssh/Nectar_Key</code>. </p>\n<hr>\n<h3>Windows</h3>\n\
          <p>The SSH private key will need to be converted for use with PuTTY.</p>\n\
          <ol>\n<li>Open PuTTYgen</li>\n<li>Click 'Load' button to load the private\
          \ key generated by the Cloud Dashboard</li>\n<li>Click 'Export OpenSSH key'\
          \ from 'Conversions' menu</li>\n<li>Type a private key name and save</li>\n\
          </ol>\n<p><img alt=\"puttygen3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/puttygen3.png?raw=true\"\
          > </p>\n<hr>\n<p>For more information, you can access the detailed <a href=\"\
          http://training.nectar.org.au/package07/sections/createSSHKey.html\">SSH\
          \ key tutorial page</a>.</p>\n<hr>\n<h2>Select an Image</h2>\n<p>You need\
          \ to select an image to be used for your instance. The image defines what\n\
          operating system the instance uses and thus you need to select an image\
          \ based on\nyour needs. Nectar Cloud offers a list of official images and\
          \ for\nsimplicity, these images are recommended. You can find a complete\
          \ list of\nofficial images from <a href=\"https://wiki.rc.nectar.org.au/wiki/Image_Catalog\"\
          >Nectar image catalog</a>. You can also find all\navailable images from\
          \ the <a href=\"https://dashboard.rc.nectar.org.au\">Cloud Dashboard</a>.</p>\n\
          <ul>\n<li>Login to the <a href=\"https://dashboard.rc.nectar.org.au\">Cloud\
          \ Dashboard</a>\n</li>\n<li>Go to the Dashboard 'Images' tab</li>\n</ul>\n\
          <p>For advanced users, you can also create your own images. Please refer\
          \ to\nthe <a href=\"http://docs.openstack.org/image-guide/content/ch_creating_images_manually.html\"\
          >openstack documentation</a> for more details.</p>\n<h2>Configure Instance\
          \ <a name=\"Configuration\"></a>\n</h2>\n<p>Before you can launch an instance,\
          \ you need to configure the following options:</p>\n<h3>Details</h3>\n<ul>\n\
          <li>\n<p>Instance Name: the name used by the dashboard to identify the instance</p>\n\
          </li>\n<li>\n<p>Flavour: the resources available for the instance. It specifies\
          \ the number of\n VCPUs, size of root disk, size of ephemeral disk and size\
          \ of RAM.\n Your allocated flavour or lesser configurations can be selected\
          \ (the\n default is m2.tiny; a 1 VCPU machine)</p>\n</li>\n<li>\n<p>Instance\
          \ Count: number of instance to launch (the default is 1)</p>\n</li>\n<li>\n\
          <p>Instance Boot Source: the media used to boot the instance. You can boot\
          \ from\n image, snapshot and volume (the default is boot from image)</p>\n\
          </li>\n<li>\n<p>Boot from image: Boot instance using an image</p>\n</li>\n\
          <li>Boot from snapshot: Boot instance using a snapshot</li>\n<li>\n<p>Boot\
          \ from volume: Boot instance from volume storage</p>\n</li>\n<li>\n<p>Image\
          \ Name: the name of an Image. This option is used when the Instance Boot\n\
          \ Source is 'Boot from image'</p>\n</li>\n</ul>\n<h4>Access &amp; Security</h4>\n\
          <ul>\n<li>\n<p>Key Pair: the public/private keys used to log into the instance.\
          \ See above to\n see how to create them. This can't be added or changed\
          \ after the instance is\n created.</p>\n</li>\n<li>\n<p>Security Groups:\
          \ add network access to your instances. This determines what\n services\
          \ can be accessed on the instance. You must select 'SSH' Security Groups\n\
          \ to allow you to login via SSH. If 'SSH' Security Groups is not available,\
          \ you\n can create it by going to Access &amp; Security tab on the right\
          \ hand side of the\n Cloud Dashboard. The default Security Group (no network\
          \ access at first) is\n pre-selected</p>\n</li>\n</ul>\n<h4>To create a\
          \ Security Group <a name=\"SecurityGroup\"></a>\n</h4>\n<ol>\n<li>Login\
          \ to the <a href=\"https://dashboard.rc.nectar.org.au\">Cloud Dashboard</a>\n\
          </li>\n<li>Go to the Access &amp; Security tab</li>\n<li>Click 'Create Security\
          \ Group' button</li>\n<li>Give a name for the Security Group</li>\n<li>Give\
          \ a meaningful description for the Security Group</li>\n<li>Click 'Create\
          \ Security Group' button</li>\n</ol>\n<p>The newly created Security Group\
          \ has no rules added (no network access defined).\n<strong>To add rules\
          \ to a Security Group:</strong></p>\n<ol>\n<li>Go to the Access &amp; Security\
          \ tab</li>\n<li>Tick to select the Security Group to add rules</li>\n<li>Click\
          \ 'Manage Rules' button</li>\n<li>Click 'Add Rule' button</li>\n<li>Select\
          \ what type of Rule you want to create</li>\n<li>Select from 'Open Port'\
          \ the 'Port' option to open one single port, or 'Port Range'\n to open a\
          \ range of ports</li>\n<li>The 'Remote' option specifies the source of the\
          \ traffic to be allowed via this\n rule. You may do so either in the form\
          \ of an IP address block (CIDR) or via a\n source group (Security Group).</li>\n\
          <li>Click 'Add' button</li>\n</ol>\n<p>You can also click 'Delete Rule'\
          \ button to delete a rule</p>\n<h3>Availability Zone</h3>\n<p>Select the\
          \ Availability Zone for your instance. The Availability Zone is the\nlocation\
          \ for your instance. By default, the system will select an available\nlocation\
          \ for you. You can also click the 'Advanced' button to select from a\ncomplete\
          \ list of available Availability Zones</p>\n<h3>Post-Creation</h3>\n<p>You\
          \ can execute a customization script after you launch your instance. You\
          \ can\ndo any initialization and customization to your instance by using\
          \ this and it\nis executed only once at the first boot of your instance.\
          \ You can copy/paste\nyour script by selecting 'Direct Input' or you can\
          \ upload a script file. The\nscript can be a shell script or Cloud-init\
          \ script.</p>\n<h3>Advanced Options</h3>\n<p>You can choose whether you\
          \ automaticly or manually create the disk partition.\nIn most cases, you\
          \ shouldn't change the default.</p>\n<p>Notes: The above configuration options\
          \ can be set in the 'Launch Instance' popup\nwindow. To launch the popup\
          \ window, you can go to the Instances tab and\nclick 'Launch Instance' button.</p>\n\
          <p>To get more information about the terms used, please refer to\nthe Glossary.</p>\n\
          <hr>\n<h2>Example Launch of an Instance <a name=\"Example\"></a>\n</h2>\n\
          <p><img alt=\"launch\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/launch_instance.png?raw=true\"\
          ></p>\n<ol>\n<li>Login to the <a href=\"https://dashboard.rc.nectar.org.au\"\
          >Cloud Dashboard</a>\n</li>\n<li>Go to Dashboard Instances tab</li>\n<li>Click\
          \ 'Launch Instance' button</li>\n<li>Type instance name</li>\n<li>Select\
          \ a flavour. Flavour indicates the specification of a instance. You can\
          \ find more information in the Flavour Details.</li>\n<li>Select an NeCTAR\
          \ offical image (we suggest selecting an Ubuntu image such as NeCTAR Ubuntu\
          \ 14.04 (Trusty) amd64)</li>\n</ol>\n<p><img alt=\"image\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/image_name.png?raw=true\"\
          ></p>\n<ol>\n<li>Click Access &amp; Security tab</li>\n<li>Select a key\
          \ pair created earlier</li>\n<li>Select security groups to use. Tick 'ssh'\
          \ and 'http' (these are pre-defined groups in the default personal project)</li>\n\
          </ol>\n<p><img alt=\"image\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/security.png?raw=true\"\
          ></p>\n<ol>\n<li>Click Availability Zone</li>\n<li>Select the location of\
          \ your instance or leave as unselected (the system will auto select available\
          \ location)</li>\n<li>Click launch button and the page will change to the\
          \ Instances Tab</li>\n<li>After a while (usually a couple of minutes), your\
          \ instance will become active\n and will have an IP address. The IP address\
          \ is available in the Instances table\n on your Nectar Dashboard.</li>\n\
          </ol>\n<p>The launch button begins Cloud provisioning and initialisation\
          \ of a running\ninstance from the selected image and your configuration\
          \ options. The instance\nwill normally pass from status \"Build\" to \"\
          Active\". Depending on your image\nsize and cloud activity, the length of\
          \ time required may vary. Your instance\nwill have a public IP address and\
          \ be reachable according to the\nSecurity Groups selected.</p>\n<p>Instructions\
          \ to access the instance are on the 'Accessing Instance' page in Cloud Basics.</p>\n\
          <h2>If Launch is Unsuccessful</h2>\n<p>You may get a message that your quota\
          \ has been exceeded or you have\ninsufficient resources. Check the table\
          \ to the right on the Launch Instance page\nfor the number of instances\
          \ you may run simultaneously, then check the\nInstances tab to see how many\
          \ Instances you already have running. You may have\nto terminate a running\
          \ Instance to free resources before you can launch another\n(see Instance\
          \ tab to Terminate). If you need more resources see the allocation\ntab\
          \ to apply for an increase.</p>\n<p>If the above doesn't apply to you, alternatively,\
          \ you can send an email to the\nCloud Help Desk. Please find how to lodge\
          \ a support ticket from\n<a href=\"https://support.rc.nectar.org.au/docs/support\"\
          >Nectar Support</a>.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 59
        id: 6000055376
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-27T00:32:01-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000055376
        position: 4
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Launching Virtual Machines
        updated_at: '2015-10-27T00:32:01-04:00'
        user_id: 6002464727
  html: "<ul>\n<li><a href=\"#Keypair\">Creating an SSH Keypair</a></li>\n<li><a href=\"\
    #Configuration\">Configuring an Instance</a></li>\n<li><a href=\"#SecurityGroup\"\
    >Create a Security Group</a></li>\n<li><a href=\"#Example\">Example - launching\
    \ an instance</a></li>\n</ul>\n<p>This guide describes launching a running instance\
    \ (virtual machine) with SSH login\nenabled.</p>\n<p>Setting up and using the\
    \ Virtual Machines requires at least some familiarity with\nUNIX shell (often\
    \ called 'BASH') commands. There are many excellent beginner's \ntutorials to\
    \ refresh your skills, such as this short, interactive tutorial from\n<a href=\"\
    https://www.codecademy.com/learn/learn-the-command-line\">Codecademy</a>.</p>\n\
    <h2>Preparation - creating an SSH keypair <a name=\"Keypair\"></a></h2>\n<p>You\
    \ need to create a public/private key pair before you can use SSH to login to\
    \ \nthe newly created instance. The public key will be stored on the instance\
    \ and\nthe private key is used on your desktop/laptop. </p>\n<ol>\n<li>Keys can\
    \ be created by your computer, and the public key uploaded to Nectar, or </li>\n\
    <li>Keys can be created on the Nectar dashboard, and the private key downloaded\
    \ to your computer.</li>\n</ol>\n<h2>1. Create a keypair locally</h2>\n<h3>Windows\
    \ User</h3>\n<p>On Windows computers, the program PuTTY is used as an SSH client\
    \ and a terminal emulator.\nPutty allows the windows user to access and use the\
    \ VM via the command line.\nUse PuTTYgen key generator to generate the required\
    \ key pair:</p>\n<p><img alt=\"puttygen1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/puttygen1.png?raw=true\"\
    ></p>\n<ol>\n<li>Download PuTTYgen (<code>puttygen.exe</code>) from <a href=\"\
    http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\">PuTTYgen download\
    \ page</a></li>\n<li>Launch the PuTTYgen application by double clicking the <code>puttygen.exe</code></li>\n\
    <li>The default settings are fine for this case, click the 'Generate' button</li>\n\
    <li>Save your public key by clicking 'Save public key' button. You should give\
    \ a\n name that will help identify the key in the future</li>\n<li>Save your private\
    \ key by clicking 'Save private key' button. You should give\n a sensible name\
    \ for future reference. The passphrase can provide additional\n security, though\
    \ can be left empty.</li>\n</ol>\n<hr>\n<h3>Linux/Mac User</h3>\n<p>On Mac and\
    \ Linux computers, commands are entered directly in the 'Terminal' application.</p>\n\
    <p><code>ssh-keygen -t rsa -f Nectar_Key</code></p>\n<ol>\n<li>To generate a keypair,\
    \ enter the previous command in the Terminal.</li>\n<li>Instead of \"Nectar_Key\"\
    , enter your preferred key name.</li>\n<li>By default, key files will be generated\
    \ in the directory '~/.ssh'. Check with <code>ls ~/.ssh</code></li>\n<li>You should\
    \ see a private key (e.g. 'Nectar_Key') and a public key (e.g. 'Nectar_Key.pub')</li>\n\
    </ol>\n<p>Note: For the security of your private key, ensuring only the user can\
    \ read the file:\nOn you local computer, enter <code>chmod 600 ~/.ssh/Nectar_Key</code>.</p>\n\
    <hr>\n<h3>Import the Public Key to Nectar</h3>\n<p>The public key generated by\
    \ Windows/Linux/Mac are required to be imported into\nthe Nectar Cloud dashboard\
    \ before use.</p>\n<p><img alt=\"keypair\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/keypair.png?raw=true\"></p>\n\
    <p><img alt=\"key4\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/key4.png?raw=true\"> </p>\n\
    <ol>\n<li>Log into the <a href=\"https://dashboard.rc.nectar.org.au\">Cloud Dashboard</a></li>\n\
    <li>Go to the 'Access and Security' tab and then to the 'Keypairs' page</li>\n\
    <li>Click 'Import Key Pair' button</li>\n<li>\n<p>Type in a keypair name and paste\
    \ the contents of the public key. </p>\n</li>\n<li>\n<p>For <strong>Windows</strong>\
    \ users, open PuTTYgen and click 'Load' button to load the related private key\
    \ and copy/paste the public key contents.</p>\n</li>\n<li>For <strong>Linux/Mac</strong>\
    \ user, type <code>cat ~/.ssh/id_rsa.pub</code> and copy/paste the public key\
    \ contents from the terminal output.</li>\n</ol>\n<h2>2. Alternatively: Create\
    \ Keys on the Nectar Cloud Dashboard</h2>\n<p><img alt=\"create_keypair\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/create_keypair.png?raw=true\"\
    ></p>\n<ol>\n<li>Login to the <a href=\"https://dashboard.rc.nectar.org.au\">Cloud\
    \ Dashboard</a></li>\n<li>Go to the Access and Security tab and then to the Keypairs\
    \ page</li>\n<li>Click the 'Create Key Pair' button</li>\n<li>Type in a keypair\
    \ name in the popup window and click the 'Create Key Pair'\n button. The private\
    \ key will be downloaded.</li>\n<li>Save the private key into a directory on your\
    \ local computer.</li>\n</ol>\n<hr>\n<h3>Mac / Linux</h3>\n<p><code>mv ~/Downloads/Nectar_Key.pem\
    \ ~/.ssh/Nectar_Key</code> This moves the private key to \nthe '.ssh' folder (change\
    \ 'Nectar_Key' to the name of your keypair).</p>\n<p>Note: For the security of\
    \ your private key, ensuring only the user can read the file:\nOn you local computer,\
    \ enter <code>chmod 600 ~/.ssh/Nectar_Key</code>. </p>\n<hr>\n<h3>Windows</h3>\n\
    <p>The SSH private key will need to be converted for use with PuTTY.</p>\n<ol>\n\
    <li>Open PuTTYgen</li>\n<li>Click 'Load' button to load the private key generated\
    \ by the Cloud Dashboard</li>\n<li>Click 'Export OpenSSH key' from 'Conversions'\
    \ menu</li>\n<li>Type a private key name and save</li>\n</ol>\n<p><img alt=\"\
    puttygen3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/puttygen3.png?raw=true\"\
    > </p>\n<hr>\n<p>For more information, you can access the detailed <a href=\"\
    http://training.nectar.org.au/package07/sections/createSSHKey.html\">SSH key tutorial\
    \ page</a>.</p>\n<hr>\n<h2>Select an Image</h2>\n<p>You need to select an image\
    \ to be used for your instance. The image defines what\noperating system the instance\
    \ uses and thus you need to select an image based on\nyour needs. Nectar Cloud\
    \ offers a list of official images and for\nsimplicity, these images are recommended.\
    \ You can find a complete list of\nofficial images from <a href=\"https://wiki.rc.nectar.org.au/wiki/Image_Catalog\"\
    >Nectar image catalog</a>. You can also find all\navailable images from the <a\
    \ href=\"https://dashboard.rc.nectar.org.au\">Cloud Dashboard</a>.</p>\n<ul>\n\
    <li>Login to the <a href=\"https://dashboard.rc.nectar.org.au\">Cloud Dashboard</a></li>\n\
    <li>Go to the Dashboard 'Images' tab</li>\n</ul>\n<p>For advanced users, you can\
    \ also create your own images. Please refer to\nthe <a href=\"http://docs.openstack.org/image-guide/content/ch_creating_images_manually.html\"\
    >openstack documentation</a> for more details.</p>\n<h2>Configure Instance <a\
    \ name=\"Configuration\"></a></h2>\n<p>Before you can launch an instance, you\
    \ need to configure the following options:</p>\n<h3>Details</h3>\n<ul>\n<li>\n\
    <p>Instance Name: the name used by the dashboard to identify the instance</p>\n\
    </li>\n<li>\n<p>Flavour: the resources available for the instance. It specifies\
    \ the number of\n VCPUs, size of root disk, size of ephemeral disk and size of\
    \ RAM.\n Your allocated flavour or lesser configurations can be selected (the\n\
    \ default is m2.tiny; a 1 VCPU machine)</p>\n</li>\n<li>\n<p>Instance Count: number\
    \ of instance to launch (the default is 1)</p>\n</li>\n<li>\n<p>Instance Boot\
    \ Source: the media used to boot the instance. You can boot from\n image, snapshot\
    \ and volume (the default is boot from image)</p>\n</li>\n<li>\n<p>Boot from image:\
    \ Boot instance using an image</p>\n</li>\n<li>Boot from snapshot: Boot instance\
    \ using a snapshot</li>\n<li>\n<p>Boot from volume: Boot instance from volume\
    \ storage</p>\n</li>\n<li>\n<p>Image Name: the name of an Image. This option is\
    \ used when the Instance Boot\n Source is 'Boot from image'</p>\n</li>\n</ul>\n\
    <h4>Access &amp; Security</h4>\n<ul>\n<li>\n<p>Key Pair: the public/private keys\
    \ used to log into the instance. See above to\n see how to create them. This can't\
    \ be added or changed after the instance is\n created.</p>\n</li>\n<li>\n<p>Security\
    \ Groups: add network access to your instances. This determines what\n services\
    \ can be accessed on the instance. You must select 'SSH' Security Groups\n to\
    \ allow you to login via SSH. If 'SSH' Security Groups is not available, you\n\
    \ can create it by going to Access &amp; Security tab on the right hand side of\
    \ the\n Cloud Dashboard. The default Security Group (no network access at first)\
    \ is\n pre-selected</p>\n</li>\n</ul>\n<h4>To create a Security Group <a name=\"\
    SecurityGroup\"></a></h4>\n<ol>\n<li>Login to the <a href=\"https://dashboard.rc.nectar.org.au\"\
    >Cloud Dashboard</a></li>\n<li>Go to the Access &amp; Security tab</li>\n<li>Click\
    \ 'Create Security Group' button</li>\n<li>Give a name for the Security Group</li>\n\
    <li>Give a meaningful description for the Security Group</li>\n<li>Click 'Create\
    \ Security Group' button</li>\n</ol>\n<p>The newly created Security Group has\
    \ no rules added (no network access defined).\n<strong>To add rules to a Security\
    \ Group:</strong></p>\n<ol>\n<li>Go to the Access &amp; Security tab</li>\n<li>Tick\
    \ to select the Security Group to add rules</li>\n<li>Click 'Manage Rules' button</li>\n\
    <li>Click 'Add Rule' button</li>\n<li>Select what type of Rule you want to create</li>\n\
    <li>Select from 'Open Port' the 'Port' option to open one single port, or 'Port\
    \ Range'\n to open a range of ports</li>\n<li>The 'Remote' option specifies the\
    \ source of the traffic to be allowed via this\n rule. You may do so either in\
    \ the form of an IP address block (CIDR) or via a\n source group (Security Group).</li>\n\
    <li>Click 'Add' button</li>\n</ol>\n<p>You can also click 'Delete Rule' button\
    \ to delete a rule</p>\n<h3>Availability Zone</h3>\n<p>Select the Availability\
    \ Zone for your instance. The Availability Zone is the\nlocation for your instance.\
    \ By default, the system will select an available\nlocation for you. You can also\
    \ click the 'Advanced' button to select from a\ncomplete list of available Availability\
    \ Zones</p>\n<h3>Post-Creation</h3>\n<p>You can execute a customization script\
    \ after you launch your instance. You can\ndo any initialization and customization\
    \ to your instance by using this and it\nis executed only once at the first boot\
    \ of your instance. You can copy/paste\nyour script by selecting 'Direct Input'\
    \ or you can upload a script file. The\nscript can be a shell script or Cloud-init\
    \ script.</p>\n<h3>Advanced Options</h3>\n<p>You can choose whether you automaticly\
    \ or manually create the disk partition.\nIn most cases, you shouldn't change\
    \ the default.</p>\n<p>Notes: The above configuration options can be set in the\
    \ 'Launch Instance' popup\nwindow. To launch the popup window, you can go to the\
    \ Instances tab and\nclick 'Launch Instance' button.</p>\n<p>To get more information\
    \ about the terms used, please refer to\nthe Glossary.</p>\n<hr>\n<h2>Example\
    \ Launch of an Instance <a name=\"Example\"></a></h2>\n<p><img alt=\"launch\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/launch_instance.png?raw=true\"\
    ></p>\n<ol>\n<li>Login to the <a href=\"https://dashboard.rc.nectar.org.au\">Cloud\
    \ Dashboard</a></li>\n<li>Go to Dashboard Instances tab</li>\n<li>Click 'Launch\
    \ Instance' button</li>\n<li>Type instance name</li>\n<li>Select a flavour. Flavour\
    \ indicates the specification of a instance. You can find more information in\
    \ the Flavour Details.</li>\n<li>Select an NeCTAR offical image (we suggest selecting\
    \ an Ubuntu image such as NeCTAR Ubuntu 14.04 (Trusty) amd64)</li>\n</ol>\n<p><img\
    \ alt=\"image\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/image_name.png?raw=true\"\
    ></p>\n<ol>\n<li>Click Access &amp; Security tab</li>\n<li>Select a key pair created\
    \ earlier</li>\n<li>Select security groups to use. Tick 'ssh' and 'http' (these\
    \ are pre-defined groups in the default personal project)</li>\n</ol>\n<p><img\
    \ alt=\"image\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/security.png?raw=true\"\
    ></p>\n<ol>\n<li>Click Availability Zone</li>\n<li>Select the location of your\
    \ instance or leave as unselected (the system will auto select available location)</li>\n\
    <li>Click launch button and the page will change to the Instances Tab</li>\n<li>After\
    \ a while (usually a couple of minutes), your instance will become active\n and\
    \ will have an IP address. The IP address is available in the Instances table\n\
    \ on your Nectar Dashboard.</li>\n</ol>\n<p>The launch button begins Cloud provisioning\
    \ and initialisation of a running\ninstance from the selected image and your configuration\
    \ options. The instance\nwill normally pass from status \"Build\" to \"Active\"\
    . Depending on your image\nsize and cloud activity, the length of time required\
    \ may vary. Your instance\nwill have a public IP address and be reachable according\
    \ to the\nSecurity Groups selected.</p>\n<p>Instructions to access the instance\
    \ are on the 'Accessing Instance' page in Cloud Basics.</p>\n<h2>If Launch is\
    \ Unsuccessful</h2>\n<p>You may get a message that your quota has been exceeded\
    \ or you have\ninsufficient resources. Check the table to the right on the Launch\
    \ Instance page\nfor the number of instances you may run simultaneously, then\
    \ check the\nInstances tab to see how many Instances you already have running.\
    \ You may have\nto terminate a running Instance to free resources before you can\
    \ launch another\n(see Instance tab to Terminate). If you need more resources\
    \ see the allocation\ntab to apply for an increase.</p>\n<p>If the above doesn't\
    \ apply to you, alternatively, you can send an email to the\nCloud Help Desk.\
    \ Please find how to lodge a support ticket from\n<a href=\"https://support.rc.nectar.org.au/docs/support\"\
    >Nectar Support</a>.</p>"
  parent: 21
  sha1: 94a609873dcf252b5697341c6f4fc664f95c2ea5
  title: Launching Virtual Machines
34:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:12-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " If you work or study at an Australian University you will\
          \ be able to login to\nthe Nectar Cloud using your institutional credentials.\
          \ Access to the Nectar\nCloud is enabled by the Australian Access Federation\
          \ (AAF). \n AAF Authentication \n Your AAF credentials are the same as your\
          \ institutional username and password.\nTo check that your organisation\
          \ is a member of the AAF check the\ncomplete AAF member list here. \n If\
          \ your institution is not a member of the AAF, talk to your local IT team\n\
          to arrange access. \n Logging in \n Once you have obtained your AAF credentials,\
          \ you can follow these steps to\nlogin to the NeCTAR Dashboard: \n \n Click\
          \ here to go to the NeCTAR Dashboard and you will see the\n following screen:\
          \ \n \n \n \n Click 'Log In' button, then select your AAF organisation from\
          \ the menu: \n \n \n \n You will be redirected to a login page provided\
          \ by your selected institution/organization: \n \n \n \n Type in username/password\
          \ supplied by your institution/organization and click\n 'Continue' button,\
          \ if successful, you should see the NeCTAR Dashboard \n \n If you have any\
          \ issues contact the NecTAR HelpDesk. \n Login Problems \n If your login\
          \ details are rejected first\ncheck your Research Institution is a member\
          \ of the AAF. \n If your research institution is a member but you still\
          \ can't login, you can\ncontact IT Service department of your own research\
          \ institution.\nThey can provide support for issues with your login credentials.\
          \ Alternatively,\nyou can email to support@rc.nectar.org.au. "
        description: "<p>If you work or study at an Australian University you will\
          \ be able to login to\nthe Nectar Cloud using your institutional credentials.\
          \ Access to the Nectar\nCloud is enabled by the <a href=\"http://aaf.edu.au/\"\
          >Australian Access Federation (AAF)</a>.</p>\n<h2>AAF Authentication</h2>\n\
          <p>Your AAF credentials are the same as your institutional username and\
          \ password.\nTo check that your organisation is a member of the AAF check\
          \ the\n<a href=\"http://aaf.edu.au/subscribe/subscribers/\">complete AAF\
          \ member list here</a>.</p>\n<p>If your institution is not a member of the\
          \ AAF, talk to your local IT team\nto arrange access.</p>\n<h2>Logging in</h2>\n\
          <p>Once you have obtained your AAF credentials, you can follow these steps\
          \ to\nlogin to the <a href=\"https://dashboard.rc.nectar.org.au/\">NeCTAR\
          \ Dashboard</a>:</p>\n<ul>\n<li>Click <a href=\"https://dashboard.rc.nectar.org.au\"\
          >here</a> to go to the NeCTAR Dashboard and you will see the\n following\
          \ screen:</li>\n</ul>\n<p><img alt=\"aaf1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/aaf1.png?raw=true\"\
          ></p>\n<ul>\n<li>Click 'Log In' button, then select your AAF organisation\
          \ from the menu:</li>\n</ul>\n<p><img alt=\"aaf2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/aaf2.png?raw=true\"\
          ></p>\n<ul>\n<li>You will be redirected to a login page provided by your\
          \ selected institution/organization:</li>\n</ul>\n<p><img alt=\"aaf3\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/aaf3.png?raw=true\"\
          ></p>\n<ul>\n<li>Type in username/password supplied by your institution/organization\
          \ and click\n 'Continue' button, if successful, you should see the NeCTAR\
          \ Dashboard</li>\n</ul>\n<p>If you have any issues contact the NecTAR <a\
          \ href=\"https://support.nectar.org.au/support/home\">HelpDesk</a>.</p>\n\
          <h2>Login Problems</h2>\n<p>If your login details are rejected first\n<a\
          \ href=\"http://aaf.edu.au/subscribe/subscribers/\">check your Research\
          \ Institution is a member of the AAF</a>.</p>\n<p>If your research institution\
          \ is a member but you still can't login, you can\ncontact IT Service department\
          \ of your own research institution.\nThey can provide support for issues\
          \ with your login credentials. Alternatively,\nyou can email to support@rc.nectar.org.au.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 17
        id: 6000055377
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-25T23:55:34-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000055377
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Getting an account
        updated_at: '2015-10-25T23:55:34-04:00'
        user_id: 6002464727
  html: "<p>If you work or study at an Australian University you will be able to login\
    \ to\nthe Nectar Cloud using your institutional credentials. Access to the Nectar\n\
    Cloud is enabled by the <a href=\"http://aaf.edu.au/\">Australian Access Federation\
    \ (AAF)</a>.</p>\n<h2>AAF Authentication</h2>\n<p>Your AAF credentials are the\
    \ same as your institutional username and password.\nTo check that your organisation\
    \ is a member of the AAF check the\n<a href=\"http://aaf.edu.au/subscribe/subscribers/\"\
    >complete AAF member list here</a>.</p>\n<p>If your institution is not a member\
    \ of the AAF, talk to your local IT team\nto arrange access.</p>\n<h2>Logging\
    \ in</h2>\n<p>Once you have obtained your AAF credentials, you can follow these\
    \ steps to\nlogin to the <a href=\"https://dashboard.rc.nectar.org.au/\">NeCTAR\
    \ Dashboard</a>:</p>\n<ul>\n<li>Click <a href=\"https://dashboard.rc.nectar.org.au\"\
    >here</a> to go to the NeCTAR Dashboard and you will see the\n following screen:</li>\n\
    </ul>\n<p><img alt=\"aaf1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/aaf1.png?raw=true\"></p>\n\
    <ul>\n<li>Click 'Log In' button, then select your AAF organisation from the menu:</li>\n\
    </ul>\n<p><img alt=\"aaf2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/aaf2.png?raw=true\"></p>\n\
    <ul>\n<li>You will be redirected to a login page provided by your selected institution/organization:</li>\n\
    </ul>\n<p><img alt=\"aaf3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/aaf3.png?raw=true\"></p>\n\
    <ul>\n<li>Type in username/password supplied by your institution/organization\
    \ and click\n 'Continue' button, if successful, you should see the NeCTAR Dashboard</li>\n\
    </ul>\n<p>If you have any issues contact the NecTAR <a href=\"https://support.nectar.org.au/support/home\"\
    >HelpDesk</a>.</p>\n<h2>Login Problems</h2>\n<p>If your login details are rejected\
    \ first\n<a href=\"http://aaf.edu.au/subscribe/subscribers/\">check your Research\
    \ Institution is a member of the AAF</a>.</p>\n<p>If your research institution\
    \ is a member but you still can't login, you can\ncontact IT Service department\
    \ of your own research institution.\nThey can provide support for issues with\
    \ your login credentials. Alternatively,\nyou can email to support@rc.nectar.org.au.</p>"
  parent: 21
  sha1: f10da9763e9420b97a4186bd8d50fe20f34e4f82
  title: Getting an account
35:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:13-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Welcome to the Nectar Cloud knowledge base. Browse or search\
          \ our\nuser documentation, and if you can't find what you're looking\nfor\
          \ contact our support team by either raising a ticket,\nor by sending an\
          \ email to support@nectar.org.au,\nor finally, by giving us a call: 1300\
          \ 080 431. \n What is the Nectar Cloud \n Nectar (National eResearch Collaboration\
          \ Tools and Resources) is an\nAustralian Government project funded to build\
          \ new infrastructure specifically for the needs of\nAustralian researchers.\
          \ The Nectar Cloud provides supported computing infrastructure, giving\n\
          researchers access to computing resources without the need to purchase or\
          \ host their own hardware. \nAll Australian researchers have access to the\
          \ Nectar Cloud via the AAF. \n To access the cloud all users must first\
          \ login through the\nNectar Cloud dashboard:\nhttps://dashboard.rc.nectar.org.au/\
          \ \n Instances \n Instances running inside the Research Cloud are just like\
          \ real-life machines but\nin a remote location. The Research Cloud is used\
          \ to start, copy and delete\ninstances. They have an operating system (you\
          \ select it from a list), network\naccess (a real IP address & you specify\
          \ any access), and hard disk storage.\nWith no hardware to maintain you\
          \ can copy (Snapshot) and customise new\nmachines rapidly. \n Tools \n The\
          \ Nectar Cloud Dashboard \n The Dashboard provides a web interface to get\
          \ all the basic\nResearch Cloud related jobs done. \n Use the dashboard:\
          \ \n \n for basic Cloud operations: (launching, duplicating & terminating\
          \ ) instances; \n to get Credentials\n  you can use with other API clients;\
          \ \n to make an allocation request for a larger ongoing share of Research\
          \ Cloud Resources. \n \n More about instances \n If you are familiar with\
          \ connecting to remote machines already\nthe same tools and techniques apply\
          \ when connecting to running\ninstances. Your instance has a public IP address\
          \ and, if\nconfigured, can be reached and controlled with any remote\naccess\
          \ tools you wish to use. For example, SSH. \n More information about launching\
          \ and managing instances is here \n Images \n Instances originate from Images\
          \ and can be a plain \"off the\nshelf\" Operating System or include software\
          \ packages and\nconfig changes to suit a particular purpose (e.g.: serving\
          \ web pages).\nThere are publicly available images in the cloud ready for\n\
          you to use. \n To suit your specific purposes an instance may need some\n\
          customisation, configuration changes or software installation.\nIts a good\
          \ idea to make a copy of the instance if you wish to\nre-use its current\
          \ state as a starting point for new instances.\nIf you are experimenting\
          \ and making changes, a copy allows you\nto return to the copied state and\
          \ dispose of the experiment\nwithout having to undo/redo configuration changes.\
          \ \n You can create an Image from scratch, but usually its easier\nto customise\
          \ & copy a running instance that is close\nto what you need. \n Copies of\
          \ instances are called Snapshots and can be used\nlike other Images to start\
          \ new instances. Making a Snapshot\nis simple: \n \n Go to the Dashboard\
          \ \"Instances\" \n   tab; \n Click \"Create Snapshot\" for the running instance\
          \ you wish to copy. \n \n Key Pairs \n Key pairs enable you to communicate\
          \ with your instance via\nSSH. When launching an instance you specify an\
          \ existing key\npair. The public key is injected into the running\ninstance's\
          \ authorized_keys file. \n You can manage your key pairs through the Dashboard\
          \ or via\nthe nova CLI client. \n In the dashboard under the Access & Security\n\
          tab you can manage your keys. You have the option of: \n \n Importing an\
          \ existing SSH key you own; \n Creating a new SSH Key. \n \n Important:\
          \ Key pairs can only be specified on instance\ncreation, if you don't specify\
          \ a keypair on creation you will\nnot be able to add it later. \n Security\
          \ groups \n Incoming network access to your machines is usually required.\n\
          Security Groups are how to add network access. If you can't\nreach your\
          \ instance by SSH to login or by browser if it\nruns a web server additional\
          \ Security Group settings could be\nneeded. \n The OpenStack article title\
          \ \"Security Groups\"\ngives more information. \n Storage in the cloud \n\
          \ The NeCTAR Research Cloud provides instances for research\nuse. While\
          \ resources like processing cores, RAM and the\namount of storage you get\
          \ are dedicated to a particular\ninstance, other resources like the network\
          \ and the underlying\nstorage system are shared among instances. Furthermore,\
          \ not\nall storage is created equal, the Research Cloud offers: \n \n \n\
          Object storage; \n \nBlock storage; \n Transient/Ephemeral storage. \n \n\
          \ You can decide which suits your needs best by reading the OpenStack article\n\
          titled \"Storage Decisions\" "
        description: "<p>Welcome to the Nectar Cloud knowledge base. Browse or search\
          \ our\nuser documentation, and if you can't find what you're looking\nfor\
          \ contact our support team by either raising a <a href=\"https://support.nectar.org.au/support/tickets/new\"\
          >ticket</a>,\nor by sending an email to <a href=\"mailto:support@nectar.org.au\"\
          >support@nectar.org.au</a>,\nor finally, by giving us a call: <a>1300 080\
          \ 431</a>.</p>\n<h2>What is the Nectar Cloud</h2>\n<p><a href=\"http://nectar.org.au/\"\
          >Nectar</a> (National eResearch Collaboration Tools and Resources) is an\n\
          Australian Government project funded to build new infrastructure specifically\
          \ for the needs of\nAustralian researchers. The Nectar Cloud provides supported\
          \ computing infrastructure, giving\nresearchers access to computing resources\
          \ without the need to purchase or host their own hardware.<br>\nAll Australian\
          \ researchers have access to the Nectar Cloud via the <a href=\"http://support.rc.nectar.org.au/node/111\"\
          >AAF</a>.</p>\n<p>To access the cloud all users must first login through\
          \ the\nNectar Cloud dashboard:\n<a href=\"https://dashboard.rc.nectar.org.au/\"\
          >https://dashboard.rc.nectar.org.au/</a></p>\n<h2>Instances</h2>\n<p>Instances\
          \ running inside the Research Cloud are just like real-life machines but\n\
          in a remote location. The Research Cloud is used to start, copy and delete\n\
          instances. They have an operating system (you select it from a list), network\n\
          access (a real IP address &amp; you specify any access), and hard disk storage.\n\
          With no hardware to maintain you can copy (Snapshot) and customise new\n\
          machines rapidly.</p>\n<h2>Tools</h2>\n<h3>The Nectar Cloud Dashboard</h3>\n\
          <p>The Dashboard provides a web interface to get all the basic\nResearch\
          \ Cloud related jobs done.</p>\n<p>Use the dashboard:</p>\n<ul>\n<li>for\
          \ basic Cloud operations: (launching, duplicating &amp; terminating ) instances;</li>\n\
          <li>to get <a href=\"https://dashboard.rc.nectar.org.au/project/access_and_security/\"\
          >Credentials</a>\n  you can use with other <a href=\"http://docs.openstack.org/cli-reference/content/ch_cli.html\"\
          >API clients</a>;</li>\n<li>to make an allocation request for a larger ongoing\
          \ share of Research Cloud Resources.</li>\n</ul>\n<h3>More about instances</h3>\n\
          <p>If you are familiar with connecting to remote machines already\nthe same\
          \ tools and techniques apply when connecting to running\ninstances. Your\
          \ instance has a public IP address and, if\nconfigured, can be reached and\
          \ controlled with any remote\naccess tools you wish to use. For example,\
          \ <a href=\"https://en.wikipedia.org/wiki/Secure_Shell\">SSH</a>.</p>\n\
          <p>More information about launching and managing instances is <a href=\"\
          https://support.nectar.org.au/support/solutions/articles/6000073471-introduction-to-instance-management\"\
          >here</a></p>\n<h3>Images</h3>\n<p>Instances originate from Images and can\
          \ be a plain \"off the\nshelf\" Operating System or include software packages\
          \ and\nconfig changes to suit a particular purpose (e.g.: serving web pages).\n\
          There are publicly available images in the cloud ready for\nyou to use.</p>\n\
          <p>To suit your specific purposes an instance may need some\ncustomisation,\
          \ configuration changes or software installation.\nIts a good idea to make\
          \ a copy of the instance if you wish to\nre-use its current state as a starting\
          \ point for new instances.\nIf you are experimenting and making changes,\
          \ a copy allows you\nto return to the copied state and dispose of the experiment\n\
          without having to undo/redo configuration changes.</p>\n<p>You can create\
          \ an Image from scratch, but usually its easier\nto customise &amp; copy\
          \ a running instance that is close\nto what you need.</p>\n<p>Copies of\
          \ instances are called Snapshots and can be used\nlike other Images to start\
          \ new instances. Making a Snapshot\nis simple:</p>\n<ol>\n<li>Go to the\
          \ Dashboard \"<a href=\"https://dashboard.rc.nectar.org.au/project/instances/\"\
          >Instances</a>\" \n   tab;</li>\n<li>Click \"Create Snapshot\" for the running\
          \ instance you wish to copy.</li>\n</ol>\n<h2>Key Pairs</h2>\n<p>Key pairs\
          \ enable you to communicate with your instance via\nSSH. When launching\
          \ an instance you specify an existing key\npair. The public key is injected\
          \ into the running\ninstance's authorized_keys file.</p>\n<p>You can manage\
          \ your key pairs through the Dashboard or via\nthe nova CLI client.</p>\n\
          <p>In the dashboard under the <a href=\"https://dashboard.rc.nectar.org.au/project/access_and_security/\"\
          >Access &amp; Security</a>\ntab you can manage your keys. You have the option\
          \ of:</p>\n<ul>\n<li>Importing an existing SSH key you own;</li>\n<li>Creating\
          \ a new SSH Key.</li>\n</ul>\n<p><strong>Important:</strong> Key pairs can\
          \ only be specified on instance\ncreation, if you don't specify a keypair\
          \ on creation you will\nnot be able to add it later.</p>\n<h2>Security groups</h2>\n\
          <p>Incoming network access to your machines is usually required.\nSecurity\
          \ Groups are how to add network access. If you can't\nreach your instance\
          \ by SSH to login or by browser if it\nruns a web server additional Security\
          \ Group settings could be\nneeded.</p>\n<p>The OpenStack article title \"\
          <a href=\"http://docs.openstack.org/openstack-ops/content/security_groups.html\"\
          >Security Groups</a>\"\ngives more information.</p>\n<h2>Storage in the\
          \ cloud</h2>\n<p>The NeCTAR Research Cloud provides instances for research\n\
          use. While resources like processing cores, RAM and the\namount of storage\
          \ you get are dedicated to a particular\ninstance, other resources like\
          \ the network and the underlying\nstorage system are shared among instances.\
          \ Furthermore, not\nall storage is created equal, the Research Cloud offers:</p>\n\
          <ul>\n<li>\n<a href=\"https://dashboard.rc.nectar.org.au/project/containers/\"\
          >Object storage</a>;</li>\n<li>\n<a href=\"https://dashboard.rc.nectar.org.au/project/volumes/\"\
          >Block storage</a>;</li>\n<li>Transient/Ephemeral storage.</li>\n</ul>\n\
          <p>You can decide which suits your needs best by reading the OpenStack article\n\
          titled \"<a href=\"http://docs.openstack.org/openstack-ops/content/storage_decision.html\"\
          >Storage Decisions</a>\"</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 26
        id: 6000055378
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-15T20:04:35-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000055378
        position: 1
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Welcome
        updated_at: '2015-10-15T20:04:35-04:00'
        user_id: 6002464727
  html: "<p>Welcome to the Nectar Cloud knowledge base. Browse or search our\nuser\
    \ documentation, and if you can't find what you're looking\nfor contact our support\
    \ team by either raising a <a href=\"https://support.nectar.org.au/support/tickets/new\"\
    >ticket</a>,\nor by sending an email to <a href=\"mailto:support@nectar.org.au\"\
    >support@nectar.org.au</a>,\nor finally, by giving us a call: <a href=\"tel:1300\
    \ 080 431\">1300 080 431</a>.</p>\n<h2>What is the Nectar Cloud</h2>\n<p><a href=\"\
    http://nectar.org.au/\">Nectar</a> (National eResearch Collaboration Tools and\
    \ Resources) is an\nAustralian Government project funded to build new infrastructure\
    \ specifically for the needs of\nAustralian researchers. The Nectar Cloud provides\
    \ supported computing infrastructure, giving\nresearchers access to computing\
    \ resources without the need to purchase or host their own hardware.<br>\nAll\
    \ Australian researchers have access to the Nectar Cloud via the <a href=\"http://support.rc.nectar.org.au/node/111\"\
    >AAF</a>.</p>\n<p>To access the cloud all users must first login through the\n\
    Nectar Cloud dashboard:\n<a href=\"https://dashboard.rc.nectar.org.au/\">https://dashboard.rc.nectar.org.au/</a></p>\n\
    <h2>Instances</h2>\n<p>Instances running inside the Research Cloud are just like\
    \ real-life machines but\nin a remote location. The Research Cloud is used to\
    \ start, copy and delete\ninstances. They have an operating system (you select\
    \ it from a list), network\naccess (a real IP address &amp; you specify any access),\
    \ and hard disk storage.\nWith no hardware to maintain you can copy (Snapshot)\
    \ and customise new\nmachines rapidly.</p>\n<h2>Tools</h2>\n<h3>The Nectar Cloud\
    \ Dashboard</h3>\n<p>The Dashboard provides a web interface to get all the basic\n\
    Research Cloud related jobs done.</p>\n<p>Use the dashboard:</p>\n<ul>\n<li>for\
    \ basic Cloud operations: (launching, duplicating &amp; terminating ) instances;</li>\n\
    <li>to get <a href=\"https://dashboard.rc.nectar.org.au/project/access_and_security/\"\
    >Credentials</a>\n  you can use with other <a href=\"http://docs.openstack.org/cli-reference/content/ch_cli.html\"\
    >API clients</a>;</li>\n<li>to make an allocation request for a larger ongoing\
    \ share of Research Cloud Resources.</li>\n</ul>\n<h3>More about instances</h3>\n\
    <p>If you are familiar with connecting to remote machines already\nthe same tools\
    \ and techniques apply when connecting to running\ninstances. Your instance has\
    \ a public IP address and, if\nconfigured, can be reached and controlled with\
    \ any remote\naccess tools you wish to use. For example, <a href=\"https://en.wikipedia.org/wiki/Secure_Shell\"\
    >SSH</a>.</p>\n<p>More information about launching and managing instances is <a\
    \ href=\"https://support.nectar.org.au/support/solutions/articles/6000073471-introduction-to-instance-management\"\
    >here</a></p>\n<h3>Images</h3>\n<p>Instances originate from Images and can be\
    \ a plain \"off the\nshelf\" Operating System or include software packages and\n\
    config changes to suit a particular purpose (e.g.: serving web pages).\nThere\
    \ are publicly available images in the cloud ready for\nyou to use.</p>\n<p>To\
    \ suit your specific purposes an instance may need some\ncustomisation, configuration\
    \ changes or software installation.\nIts a good idea to make a copy of the instance\
    \ if you wish to\nre-use its current state as a starting point for new instances.\n\
    If you are experimenting and making changes, a copy allows you\nto return to the\
    \ copied state and dispose of the experiment\nwithout having to undo/redo configuration\
    \ changes.</p>\n<p>You can create an Image from scratch, but usually its easier\n\
    to customise &amp; copy a running instance that is close\nto what you need.</p>\n\
    <p>Copies of instances are called Snapshots and can be used\nlike other Images\
    \ to start new instances. Making a Snapshot\nis simple:</p>\n<ol>\n<li>Go to the\
    \ Dashboard \"<a href=\"https://dashboard.rc.nectar.org.au/project/instances/\"\
    >Instances</a>\" \n   tab;</li>\n<li>Click \"Create Snapshot\" for the running\
    \ instance you wish to copy.</li>\n</ol>\n<h2>Key Pairs</h2>\n<p>Key pairs enable\
    \ you to communicate with your instance via\nSSH. When launching an instance you\
    \ specify an existing key\npair. The public key is injected into the running\n\
    instance's authorized_keys file.</p>\n<p>You can manage your key pairs through\
    \ the Dashboard or via\nthe nova CLI client.</p>\n<p>In the dashboard under the\
    \ <a href=\"https://dashboard.rc.nectar.org.au/project/access_and_security/\"\
    >Access &amp; Security</a>\ntab you can manage your keys. You have the option\
    \ of:</p>\n<ul>\n<li>Importing an existing SSH key you own;</li>\n<li>Creating\
    \ a new SSH Key.</li>\n</ul>\n<p><strong>Important:</strong> Key pairs can only\
    \ be specified on instance\ncreation, if you don't specify a keypair on creation\
    \ you will\nnot be able to add it later.</p>\n<h2>Security groups</h2>\n<p>Incoming\
    \ network access to your machines is usually required.\nSecurity Groups are how\
    \ to add network access. If you can't\nreach your instance by SSH to login or\
    \ by browser if it\nruns a web server additional Security Group settings could\
    \ be\nneeded.</p>\n<p>The OpenStack article title \"<a href=\"http://docs.openstack.org/openstack-ops/content/security_groups.html\"\
    >Security Groups</a>\"\ngives more information.</p>\n<h2>Storage in the cloud</h2>\n\
    <p>The NeCTAR Research Cloud provides instances for research\nuse. While resources\
    \ like processing cores, RAM and the\namount of storage you get are dedicated\
    \ to a particular\ninstance, other resources like the network and the underlying\n\
    storage system are shared among instances. Furthermore, not\nall storage is created\
    \ equal, the Research Cloud offers:</p>\n<ul>\n<li><a href=\"https://dashboard.rc.nectar.org.au/project/containers/\"\
    >Object storage</a>;</li>\n<li><a href=\"https://dashboard.rc.nectar.org.au/project/volumes/\"\
    >Block storage</a>;</li>\n<li>Transient/Ephemeral storage.</li>\n</ul>\n<p>You\
    \ can decide which suits your needs best by reading the OpenStack article\ntitled\
    \ \"<a href=\"http://docs.openstack.org/openstack-ops/content/storage_decision.html\"\
    >Storage Decisions</a>\"</p>"
  parent: 21
  sha1: 5107317db550e4e09840ae5c0eb92ed58fde7f74
  title: Welcome
36:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:14-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Consider Security \n Security of your NeCTAR instances is\
          \ your responsibility. \n If we see evidence that an instance's security\
          \ has been comprised, we\nwill take steps to shut down and isolate it so\
          \ that it doesn't do any further\ndamage to cloud infrastructure or to other\
          \ users' assets. \n Compromised Nectar instances are a real issue. Across\
          \ the Nectar federation, we\nsee examples at least once a month. \n Apply\
          \ system patches as often as possible \n Keeping your system up to date\
          \ is one of the simplest and most effective\nways to secure your system\
          \ against unwanted intrusion. \n It is easy and more practical to configure\
          \ a recent Linux system to apply\npatches automatically.  Alternatively\
          \ If you are applying patches by hand, we\nrecommend that you do it at least\
          \ once a week. \n Understand the lifecycle of your Linux Distribution \n\
          \ Every release of a linux distribution (such as Debian Wheezy, or Ubuntu\n\
          Precise) will have a published end of life date.  Assuming you are doing\
          \ the\nright thing and applying patches regularly, once the end of life\
          \ date is\nreached, the patches will no longer be available. \n If system\
          \ patches are discontinued, you should update to a more recent version\n\
          of the operating system.  You should treat this as a matter of urgency.\
          \ \n It is trivially easy for a Bad Person(tm) to scan your machine and\
          \ determine\nexactly which attacks your instance is vulnerable to. \n Understand\
          \ SSH authentication \n It is undeniable that ssh key authentication is\
          \ the most effective way to\nsecure ssh access to your instance.  Enabling\
          \ ssh password authentication may\nseem like a good idea, but doing so opens\
          \ your machine to brute force password\nattacks.  Don't underestimate the\
          \ means and will of Bad People(tm) to exploit\nyour instance for their nefarious\
          \ purposes. \n Don't share your ssh private key with anyone, ever.   Like\
          \ giving machine guns\nto monkeys, it's a very bad idea. \n Don't use VNC,\
          \ use x2go instead \n VNC is one of those longstanding ways of getting graphical\
          \ access to your\ncomputer over a network.  While it's well known and loved,\
          \ there are in fact\nmany ways to exploit VNC and there are now better ways\
          \ to get to your graphical\ncontent. \n X2go is technically superior to\
          \ VNC and tunnels your graphical content over\nssh. \n Terminate instances\
          \ that you no longer require \n In theory, you can run an instance as long\
          \ as you like.  In practice, we would\nprefer you to promptly terminate\
          \ any instance that are not using actively, so\nthat other users can make\
          \ use of the resources. \n Currently, there is no formal Nectar mechanism\
          \ to discourage wasteful use of\nyour allocation, but this is likely to\
          \ change. \n What should I do when I am finished with an instance \n When\
          \ you are finished with an Instance, you should terminate it.  Leaving an\n\
          instance running, or in \"paused\" or \"suspended\" or \"shutdown\" states\
          \ is tying\ndown resources that other people could be using. \n Note that\
          \ terminating an instance destroys its primary and ephemeral file\nsystems.\
          \  If you want to save the primary file system (so that you can launch a\n\
          new instance), snapshot the instance before you terminate it. "
        description: '<h2>Consider Security</h2>

          <p>Security of your NeCTAR instances is your responsibility.</p>

          <p>If we see evidence that an instance''s security has been comprised, we

          will take steps to shut down and isolate it so that it doesn''t do any further

          damage to cloud infrastructure or to other users'' assets.</p>

          <p>Compromised Nectar instances are a real issue. Across the Nectar federation,
          we

          see examples at least once a month.</p>

          <h2>Apply system patches as often as possible</h2>

          <p>Keeping your system up to date is one of the simplest and most effective

          ways to secure your system against unwanted intrusion.</p>

          <p>It is easy and more practical to configure a recent Linux system to apply

          patches automatically.  Alternatively If you are applying patches by hand,
          we

          recommend that you do it at least once a week.</p>

          <h2>Understand the lifecycle of your Linux Distribution</h2>

          <p>Every release of a linux distribution (such as Debian Wheezy, or Ubuntu

          Precise) will have a published end of life date.  Assuming you are doing
          the

          right thing and applying patches regularly, once the end of life date is

          reached, the patches will no longer be available.</p>

          <p>If system patches are discontinued, you should update to a more recent
          version

          of the operating system.  You should treat this as a matter of urgency.</p>

          <p>It is trivially easy for a Bad Person(tm) to scan your machine and determine

          exactly which attacks your instance is vulnerable to.</p>

          <h2>Understand SSH authentication</h2>

          <p>It is undeniable that ssh key authentication is the most effective way
          to

          secure ssh access to your instance.  Enabling ssh password authentication
          may

          seem like a good idea, but doing so opens your machine to brute force password

          attacks.  Don''t underestimate the means and will of Bad People(tm) to exploit

          your instance for their nefarious purposes.</p>

          <p>Don''t share your ssh private key with anyone, ever.   Like giving machine
          guns

          to monkeys, it''s a very bad idea.</p>

          <h2>Don''t use VNC, use x2go instead</h2>

          <p>VNC is one of those longstanding ways of getting graphical access to
          your

          computer over a network.  While it''s well known and loved, there are in
          fact

          many ways to exploit VNC and there are now better ways to get to your graphical

          content.</p>

          <p>X2go is technically superior to VNC and tunnels your graphical content
          over

          ssh.</p>

          <h2>Terminate instances that you no longer require</h2>

          <p>In theory, you can run an instance as long as you like.  In practice,
          we would

          prefer you to promptly terminate any instance that are not using actively,
          so

          that other users can make use of the resources.</p>

          <p>Currently, there is no formal Nectar mechanism to discourage wasteful
          use of

          your allocation, but this is likely to change.</p>

          <h2>What should I do when I am finished with an instance</h2>

          <p>When you are finished with an Instance, you should terminate it.  Leaving
          an

          instance running, or in "paused" or "suspended" or "shutdown" states is
          tying

          down resources that other people could be using.</p>

          <p>Note that terminating an instance destroys its primary and ephemeral
          file

          systems.  If you want to save the primary file system (so that you can launch
          a

          new instance), snapshot the instance before you terminate it.</p>'
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 2
          updated_at: '2015-09-03T01:28:04-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 0
        id: 6000055379
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-09-03T01:28:14-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000055379
        position: 4
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Good Practices
        updated_at: '2015-09-03T01:28:14-04:00'
        user_id: 6002464727
  html: '<h2>Consider Security</h2>

    <p>Security of your NeCTAR instances is your responsibility.</p>

    <p>If we see evidence that an instance''s security has been comprised, we

    will take steps to shut down and isolate it so that it doesn''t do any further

    damage to cloud infrastructure or to other users'' assets.</p>

    <p>Compromised Nectar instances are a real issue. Across the Nectar federation,
    we

    see examples at least once a month.</p>

    <h2>Apply system patches as often as possible</h2>

    <p>Keeping your system up to date is one of the simplest and most effective

    ways to secure your system against unwanted intrusion.</p>

    <p>It is easy and more practical to configure a recent Linux system to apply

    patches automatically.  Alternatively If you are applying patches by hand, we

    recommend that you do it at least once a week.</p>

    <h2>Understand the lifecycle of your Linux Distribution</h2>

    <p>Every release of a linux distribution (such as Debian Wheezy, or Ubuntu

    Precise) will have a published end of life date.  Assuming you are doing the

    right thing and applying patches regularly, once the end of life date is

    reached, the patches will no longer be available.</p>

    <p>If system patches are discontinued, you should update to a more recent version

    of the operating system.  You should treat this as a matter of urgency.</p>

    <p>It is trivially easy for a Bad Person(tm) to scan your machine and determine

    exactly which attacks your instance is vulnerable to.</p>

    <h2>Understand SSH authentication</h2>

    <p>It is undeniable that ssh key authentication is the most effective way to

    secure ssh access to your instance.  Enabling ssh password authentication may

    seem like a good idea, but doing so opens your machine to brute force password

    attacks.  Don''t underestimate the means and will of Bad People(tm) to exploit

    your instance for their nefarious purposes.</p>

    <p>Don''t share your ssh private key with anyone, ever.   Like giving machine
    guns

    to monkeys, it''s a very bad idea.</p>

    <h2>Don''t use VNC, use x2go instead</h2>

    <p>VNC is one of those longstanding ways of getting graphical access to your

    computer over a network.  While it''s well known and loved, there are in fact

    many ways to exploit VNC and there are now better ways to get to your graphical

    content.</p>

    <p>X2go is technically superior to VNC and tunnels your graphical content over

    ssh.</p>

    <h2>Terminate instances that you no longer require</h2>

    <p>In theory, you can run an instance as long as you like.  In practice, we would

    prefer you to promptly terminate any instance that are not using actively, so

    that other users can make use of the resources.</p>

    <p>Currently, there is no formal Nectar mechanism to discourage wasteful use of

    your allocation, but this is likely to change.</p>

    <h2>What should I do when I am finished with an instance</h2>

    <p>When you are finished with an Instance, you should terminate it.  Leaving an

    instance running, or in "paused" or "suspended" or "shutdown" states is tying

    down resources that other people could be using.</p>

    <p>Note that terminating an instance destroys its primary and ephemeral file

    systems.  If you want to save the primary file system (so that you can launch
    a

    new instance), snapshot the instance before you terminate it.</p>'
  parent: 21
  sha1: 16b9cd15a0754709d46f6e8ff5dfda05615d4df6
  title: Good Practices
37:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:15-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " The Cloud \n The Nectar Cloud supports thousands of virtual\
          \ machines\nusing 20,000 VCPUs across Australia. \n Allocations: Personal\
          \ Trials and Projects \n The Nectar Cloud provides access to the cloud via\
          \ projects, each with an\nallocation of time & capacity (virtual CPUs).\
          \ \n \n All researchers initially (and without application) get a personal\n\
          \ project with 2 VCPUs for 3 Months. \n This means you can run 2 Small or\
          \ 1 Medium virtual machine for three months. \n Need more time or computing\
          \ power? Submit an allocation request. \n Multiple users can share an allocation\
          \ for a project. \n \n Instances available by size \n The resources available\
          \ to an instance are selected by different\n'flavors' when launching the\
          \ instance for the first time. \n The flavors define the number of VCPUs,\
          \ the root disk size and the\nsize of the ephemeral disk. The current flavors\
          \ use a name\npre-fixed with 'm2.' \n \n m2.tiny: 1 VCPUs, 768MB RAM, 5GB\
          \ root disk, no ephemeral disk \n m2.xsmall: 1 VCPUs, 2GB RAM, 10GB root\
          \ disk, no ephemeral disk \n m2.small: 1 VCPUs, 4GB RAM, 30GB root disk,\
          \ no ephemeral disk \n m2.medium: 2 VCPUs, 6GB RAM, 30GB root disk, no ephemeral\
          \ disk \n m2.large: 4 core, 12GB RAM, 30GB root disk, 80GB ephemeral disk\
          \ \n m2.xlarge: 12 core, 48GB RAM, 30GB root disk, 360GB ephemeral disk\
          \ \n \n Legacy flavors use a prefix of 'm1.' and have a 10G root disk. \n\
          \ \n m1.small: 1 core, 4GB RAM, 10GB root disk, 30GB secondary disk \n m1.medium:\
          \ 2 cores, 8GB RAM, 10GB root disk, 60GB secondary disk \n m1.large: 4 cores,\
          \ 16GB RAM, 10GB root disk, 120GB secondary disk \n m1.xlarge: 8 cores,\
          \ 32GB RAM, 10GB root disk, 240GB secondary disk \n m1.xxlarge: 16 cores,\
          \ 64GB RAM, 10GB root disk, 480GB secondary disk \n \n Larger instances\
          \ require more resources than available in the\npersonal project; a new\
          \ project with more resources can be requested\nvia an allocation request.\
          \ \n Internet Traffic Quotas (downloads to your instances) \n \n On-Net\
          \ Internet traffic is unlimited (check AARNET off/on net status) \n Off-Net:\
          \ 1GB of off-net traffic per core per month \n You can manage your virtual\
          \ machines and monitor your usage: see\n  NeCTAR DashBoard\n \n "
        description: "<h2>The Cloud</h2>\n<p>The Nectar Cloud supports <a href=\"\
          http://status.rc.nectar.org.au/growth/infrastructure/\">thousands of virtual\
          \ machines</a>\nusing <a href=\"http://status.rc.nectar.org.au/growth/infrastructure/\"\
          >20,000 VCPUs</a> across Australia.</p>\n<h2>Allocations: Personal Trials\
          \ and Projects</h2>\n<p>The Nectar Cloud provides access to the cloud via\
          \ projects, each with an\nallocation of time &amp; capacity (virtual CPUs).</p>\n\
          <ul>\n<li>All researchers initially (and without application) get a personal\n\
          \ project with 2 VCPUs for 3 Months.</li>\n<li>This means you can run 2\
          \ Small or 1 Medium virtual machine for three months.</li>\n<li>Need more\
          \ time or computing power? Submit an allocation request.</li>\n<li>Multiple\
          \ users can share an allocation for a project.</li>\n</ul>\n<h2>Instances\
          \ available by size</h2>\n<p>The resources available to an instance are\
          \ selected by different\n'flavors' when launching the instance for the first\
          \ time.</p>\n<p>The flavors define the number of VCPUs, the root disk size\
          \ and the\nsize of the ephemeral disk. The current flavors use a name\n\
          pre-fixed with 'm2.'</p>\n<ul>\n<li>m2.tiny: 1 VCPUs, 768MB RAM, 5GB root\
          \ disk, no ephemeral disk</li>\n<li>m2.xsmall: 1 VCPUs, 2GB RAM, 10GB root\
          \ disk, no ephemeral disk</li>\n<li>m2.small: 1 VCPUs, 4GB RAM, 30GB root\
          \ disk, no ephemeral disk</li>\n<li>m2.medium: 2 VCPUs, 6GB RAM, 30GB root\
          \ disk, no ephemeral disk</li>\n<li>m2.large: 4 core, 12GB RAM, 30GB root\
          \ disk, 80GB ephemeral disk</li>\n<li>m2.xlarge: 12 core, 48GB RAM, 30GB\
          \ root disk, 360GB ephemeral disk</li>\n</ul>\n<p>Legacy flavors use a prefix\
          \ of 'm1.' and have a 10G root disk.</p>\n<ul>\n<li>m1.small: 1 core, 4GB\
          \ RAM, 10GB root disk, 30GB secondary disk</li>\n<li>m1.medium: 2 cores,\
          \ 8GB RAM, 10GB root disk, 60GB secondary disk</li>\n<li>m1.large: 4 cores,\
          \ 16GB RAM, 10GB root disk, 120GB secondary disk</li>\n<li>m1.xlarge: 8\
          \ cores, 32GB RAM, 10GB root disk, 240GB secondary disk</li>\n<li>m1.xxlarge:\
          \ 16 cores, 64GB RAM, 10GB root disk, 480GB secondary disk</li>\n</ul>\n\
          <p>Larger instances require more resources than available in the\npersonal\
          \ project; a new project with more resources can be requested\nvia an allocation\
          \ request.</p>\n<h2>Internet Traffic Quotas (downloads to your instances)</h2>\n\
          <ul>\n<li>On-Net Internet traffic is unlimited (<a href=\"http://lg.aarnet.edu.au/cgi-bin/traffic.cgi\"\
          >check AARNET off/on net status</a>)</li>\n<li>Off-Net: 1GB of off-net traffic\
          \ per core per month</li>\n<li>You can manage your virtual machines and\
          \ monitor your usage: see\n  <a href=\"https://dashboard.rc.nectar.org.au/\"\
          >NeCTAR DashBoard</a>\n</li>\n</ul>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 2
          updated_at: '2015-09-03T01:28:04-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 0
        id: 6000055380
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-09-15T23:47:36-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000055380
        position: 5
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Resources available to you
        updated_at: '2015-09-15T23:47:36-04:00'
        user_id: 6002464727
  html: "<h2>The Cloud</h2>\n<p>The Nectar Cloud supports <a href=\"http://status.rc.nectar.org.au/growth/infrastructure/\"\
    >thousands of virtual machines</a>\nusing <a href=\"http://status.rc.nectar.org.au/growth/infrastructure/\"\
    >20,000 VCPUs</a> across Australia.</p>\n<h2>Allocations: Personal Trials and\
    \ Projects</h2>\n<p>The Nectar Cloud provides access to the cloud via projects,\
    \ each with an\nallocation of time &amp; capacity (virtual CPUs).</p>\n<ul>\n\
    <li>All researchers initially (and without application) get a personal\n project\
    \ with 2 VCPUs for 3 Months.</li>\n<li>This means you can run 2 Small or 1 Medium\
    \ virtual machine for three months.</li>\n<li>Need more time or computing power?\
    \ Submit an allocation request.</li>\n<li>Multiple users can share an allocation\
    \ for a project.</li>\n</ul>\n<h2>Instances available by size</h2>\n<p>The resources\
    \ available to an instance are selected by different\n'flavors' when launching\
    \ the instance for the first time.</p>\n<p>The flavors define the number of VCPUs,\
    \ the root disk size and the\nsize of the ephemeral disk. The current flavors\
    \ use a name\npre-fixed with 'm2.'</p>\n<ul>\n<li>m2.tiny: 1 VCPUs, 768MB RAM,\
    \ 5GB root disk, no ephemeral disk</li>\n<li>m2.xsmall: 1 VCPUs, 2GB RAM, 10GB\
    \ root disk, no ephemeral disk</li>\n<li>m2.small: 1 VCPUs, 4GB RAM, 30GB root\
    \ disk, no ephemeral disk</li>\n<li>m2.medium: 2 VCPUs, 6GB RAM, 30GB root disk,\
    \ no ephemeral disk</li>\n<li>m2.large: 4 core, 12GB RAM, 30GB root disk, 80GB\
    \ ephemeral disk</li>\n<li>m2.xlarge: 12 core, 48GB RAM, 30GB root disk, 360GB\
    \ ephemeral disk</li>\n</ul>\n<p>Legacy flavors use a prefix of 'm1.' and have\
    \ a 10G root disk.</p>\n<ul>\n<li>m1.small: 1 core, 4GB RAM, 10GB root disk, 30GB\
    \ secondary disk</li>\n<li>m1.medium: 2 cores, 8GB RAM, 10GB root disk, 60GB secondary\
    \ disk</li>\n<li>m1.large: 4 cores, 16GB RAM, 10GB root disk, 120GB secondary\
    \ disk</li>\n<li>m1.xlarge: 8 cores, 32GB RAM, 10GB root disk, 240GB secondary\
    \ disk</li>\n<li>m1.xxlarge: 16 cores, 64GB RAM, 10GB root disk, 480GB secondary\
    \ disk</li>\n</ul>\n<p>Larger instances require more resources than available\
    \ in the\npersonal project; a new project with more resources can be requested\n\
    via an allocation request.</p>\n<h2>Internet Traffic Quotas (downloads to your\
    \ instances)</h2>\n<ul>\n<li>On-Net Internet traffic is unlimited (<a href=\"\
    http://lg.aarnet.edu.au/cgi-bin/traffic.cgi\">check AARNET off/on net status</a>)</li>\n\
    <li>Off-Net: 1GB of off-net traffic per core per month</li>\n<li>You can manage\
    \ your virtual machines and monitor your usage: see\n  <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >NeCTAR DashBoard</a></li>\n</ul>"
  parent: 21
  sha1: 61c1492a41b681772259eb522df85061c526b6d9
  title: Resources available to you
38:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:16-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " The Nectar Cloud is organised in Availability Zones, that\
          \ are hosted by the\nparticipating institutions. An availability zone is\
          \ a virtual area in the\ncloud where your VM will reside. In many cloud\
          \ usage scenarios you won't need\nto worry about these: the Nectar software\
          \ will select a suitable Availability\nZone for you when you launch your\
          \ VM. In certain other scenarios, however, you\nhave to select the AZ that\
          \ is right for your purpose. \n How to select an Availability Zone at launch\
          \ \n You can select a specific Availability Zone for your VM at Launch time\
          \ in the\nLaunch Dialog's Availability Zone. The default option is \"(Any\
          \ availability\nzone)\" If you leave this selected Nectar will find a suitable\
          \ AZ for you.\n \n Scenarios \n If your VM uses persistent volume storage,\
          \ your VM and your storage must\nbe in compatible Availability Zones. You\
          \ can find more information on the Cloud Storage page. \n In some scenarios\
          \ you can use institutionally licensed software, in which\ncase you may\
          \ need to select the appropriate Availability Zone \n Some participating\
          \ institutions offer private availability zones, for which\nyou may be eligible.\
          \ You will have to contact your Node's local support. "
        description: '<p>The Nectar Cloud is organised in Availability Zones, that
          are hosted by the

          participating institutions. An availability zone is a virtual area in the

          cloud where your VM will reside. In many cloud usage scenarios you won''t
          need

          to worry about these: the Nectar software will select a suitable Availability

          Zone for you when you launch your VM. In certain other scenarios, however,
          you

          have to select the AZ that is right for your purpose.</p>

          <h2>How to select an Availability Zone at launch</h2>

          <p>You can select a specific Availability Zone for your VM at Launch time
          in the

          Launch Dialog''s Availability Zone. The default option is "(Any availability

          zone)" If you leave this selected Nectar will find a suitable AZ for you.

          <img alt="Screenshot of Launch Dialog AZ Tab" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/NeCTAR%20Fundamentals--DOCID26/images/launch_dialog_az_tab.png?raw=true"></p>

          <h2>Scenarios</h2>

          <p>If your VM uses <strong>persistent volume storage</strong>, your VM and
          your storage must

          be in compatible Availability Zones. You can find more information on the
          Cloud Storage page.</p>

          <p>In some scenarios you can use <strong>institutionally licensed software</strong>,
          in which

          case you may need to select the appropriate Availability Zone</p>

          <p>Some participating institutions offer <strong>private availability zones</strong>,
          for which

          you may be eligible. You will have to contact your Node''s local support.</p>'
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:09-04:00'
          customer_folders: []
          description: NeCTAR Fundamentals
          id: 6000190155
          is_default: false
          language_id: 6
          name: NeCTAR Fundamentals
          parent_id: 6000190155
          position: 2
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190155
        hits: 13
        id: 6000055381
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-20T21:03:34-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000055381
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 2
        thumbs_up: 0
        title: Availability Zones
        updated_at: '2015-10-20T21:03:34-04:00'
        user_id: 6002464727
  html: '<p>The Nectar Cloud is organised in Availability Zones, that are hosted by
    the

    participating institutions. An availability zone is a virtual area in the

    cloud where your VM will reside. In many cloud usage scenarios you won''t need

    to worry about these: the Nectar software will select a suitable Availability

    Zone for you when you launch your VM. In certain other scenarios, however, you

    have to select the AZ that is right for your purpose.</p>

    <h2>How to select an Availability Zone at launch</h2>

    <p>You can select a specific Availability Zone for your VM at Launch time in the

    Launch Dialog''s Availability Zone. The default option is "(Any availability

    zone)" If you leave this selected Nectar will find a suitable AZ for you.

    <img alt="Screenshot of Launch Dialog AZ Tab" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR
    Documentation--DOCID16/NeCTAR Fundamentals--DOCID26/images/launch_dialog_az_tab.png?raw=true"></p>

    <h2>Scenarios</h2>

    <p>If your VM uses <strong>persistent volume storage</strong>, your VM and your
    storage must

    be in compatible Availability Zones. You can find more information on the Cloud
    Storage page.</p>

    <p>In some scenarios you can use <strong>institutionally licensed software</strong>,
    in which

    case you may need to select the appropriate Availability Zone</p>

    <p>Some participating institutions offer <strong>private availability zones</strong>,
    for which

    you may be eligible. You will have to contact your Node''s local support.</p>'
  parent: 26
  sha1: f3833959eda87b1b543c43245a1f6c223da0f4bf
  title: Availability Zones
39:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:17-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " The NeCTAR virtual machines have many resources binded with\
          \ them in order for it\nto function properly. Among these resources, storage\
          \ is the fundamental component\nfor both the virtual machine and user to\
          \ save and use data. The amount of\nstorage your virtual machine get are\
          \ dedicated, but the underlying storage\nsystem are shared. Furthermore,\
          \ not all storage is created equal, and Research\nCloud users have a few\
          \ different types of storage available which differ\naccording to performance,\
          \ persistence and data safety. \n On Virtual Machine Storage \n Each virtual\
          \ machine in the NeCTAR Cloud comes with a certain amount of built-in\n\
          storage and theseappear as two separated hard disks\n(Root Disk and Ephemeral\
          \ Disk). These storage disks run off robust\nenterprise-grade storage hardware\
          \ on the back. However, both storage disks are not\nsuitable for long-term\
          \ persistent data as data will be lost after termination or\nrebuild of\
          \ a virtual machine. \n Root Disk \n This storage is used for the operating\
          \ system of the virtual machine, to boot it\ninto a functional state. It\
          \ has a limited 10GB in size, which is the same for every\nstandard size\
          \ of virtual machine (Small, Medium, Large, Extra Large and\nExtra Extra\
          \ Large). The size varies for non-standard virtual machines such as\ntiny,\
          \ which only has 5GB root storage. \n Data stored on the root storage are\
          \ persistent until the termination or rebuild\nof the virtual machine and\
          \ are copied during the snapshot. That means, if you\nreboot your virtual\
          \ machine, the data remains intact and when you take a\npoint-in-time snapshot\
          \ of your virtual machine, the entire root storage is\ncopied. As the root\
          \ storage comes with fixed size and is used by the operation\nsystem, caution\
          \ need to be taken as it should not be filled in full. The name of\nthis\
          \ disk as seen from the virtual machine is usually '/dev/vda'. \n Ephemeral\
          \ Disk \n This storage appears as a second hard disk in your virtual machine.\
          \ It is a raw\nand unformatted block device, that you can format and use\
          \ as you wish. It varies\nin size according to the size of virtual machine\
          \ (from 0GB to 480GB). For each\nCPU, a standard virtual machine will get\
          \ 30GB of additional ephemeral storage.\nIt varies in size for non-standard\
          \ virtual machines. The name of this device as\nseen from the instance is\
          \ usually '/dev/vdb' and some operating systems will\nautomatically format\
          \ and mount the ephemeral disk. For example, Ubuntu creates\nan ext3 partition\
          \ and mounts it at '/mnt'. For operating systems that don't do it\nautomatically,\
          \ you can format it by executing mkfs.ext4 /dev/vdb in the command line\n\
          and mount it by executing mount /dev/vdb /mnt. You need to have root\npermission\
          \ to do this. \n Data stored on ephemeral disk are only persistent until\
          \ the termination or\nrebuild of the virtual machine (like the root disk).\
          \ The only difference\nis that data on the ephemeral disk are not copied\
          \ when taking a snapshot of a virtual\nmachine, which means you cannot use\
          \ snapshot to save data stored on ephemeral\ndisk. \n NOTE: At first, you\
          \ will not be able to save information to the ephemeral disk. \nThe following\
          \ command gives permission for the user 'ubuntu' to write to the ephemeral\
          \ disk: \n sudo chown ubuntu /mnt \n Backup of Ephemeral Disk \n Data on\
          \ the ephemeral disk does not get saved in a snapshot, and requires other\n\
          techniques to make a backup. Other forms of storage can be used such as\
          \ the\nObject Store and Volume Storage within the Research Cloud or external\
          \ locations. \n Persistent Volume Storage \n Persistent volume storage can\
          \ live outside your virtual machine. It appears\nas block storage which\
          \ can be attached then accessed and even booted from. This\nis a storage\
          \ volume that you can attach to from within your virtual machine,\nread\
          \ and write data, detach it, and make it available to another virtual machine.\n\
          Your data on a persistent volume are retained even when you terminate your\n\
          virtual machine. Persistent Volumes offer a snapshot feature which can be\
          \ used\nto make convenient backups (this uses some of your overall Persistent\
          \ Volume quota). \n NOTE: Persistent Volumes are local services and only\
          \ virtual machines in the\navailability zone where the persistent Volume\
          \ has been created can access it. \n How to Get Persistent Volume Storage\
          \ \n By default, there are no persistent volume storage available to your\
          \ project.\nYou need to make an allocation request to apply for the quantity\
          \ of persistent volume\nstorage you require for your project. Follow these\
          \ steps to submit a\nrequest: \n \n \n Login to NeCTAR Cloud Dashboard \n\
          \ \n \n Go to Allocations and you can either click 'New Request' to make\
          \ a new request\n or 'My Requests' to amend an existing request \n \n \n\
          \ Under section 'Storage Quota', you select 'Resource' as volume, select\
          \ the\n Zone you want the storage to be located at (must be the same location\
          \ as the instance it will be attached to) and enter the size in GB under\
          \ 'Requested Quota'. \n \n \n Click the 'Submit' button \n \n \n NOTE: It\
          \ may take a while for your request to be approved. \n Create a persistent\
          \ volume storage \n Once your request has been approved, your project should\
          \ have volume storage\navailable. You need to create the volume storage\
          \ in the NeCTAR Cloud Dashboard \nbefore you can use it. \n \n \n Login\
          \ to the NeCTAR Cloud Dashboard \n \n \n Go to 'Volumes' \n \n \n Click\
          \ 'Create Volume' button \n \n \n Give a Volume Name and meaningful description\
          \ \n \n \n Specify a 'Volume Source' to determine how the volume will be\
          \ built. You can select\n 'No source empty volume' to create new empty volume.\
          \ You can select 'image' to\n build a volume from a image or 'Volume' to\
          \ build a volume from existing volume \n \n \n Specify the size of the volume\
          \ in GB \n \n \n Enter an 'Availability Zone' (must be the same zone as\
          \ the instance) \n \n \n Click 'Create Volume' button \n \n \n Attach a\
          \ persistent volume storage \n You can attach the volume created earlier\
          \ to a running virtual machine. See the\nbelow instruction: \n \n \n Login\
          \ to NeCTAR Cloud Dashboard \n \n \n Go to 'Volumes' \n \n \n Click the\
          \ action list of volume \n \n \n Click 'Edit Attachment' \n \n \n Click\
          \ 'Attach to Instance' drop down list to select a virtual machine to\n attach\
          \ the volume to. \n \n \n Click 'Attach Volume' button \n \n \n Use Persistent\
          \ Volume Storage in Virtual Machine \n For a standard flavor virtual machine\
          \ the persistent volume will be attached\nas '/dev/vdc'.  \n A new volume\
          \ may not have a file system (depending on how it was created) and\nyou\
          \ need to create one before mounting. \n The exact mount command syntax\
          \ is dependent on the virtual machine' operating\nsystem and the type of\
          \ file system you require. \n You can use below command to create file system\
          \ on the new volume:\nsudo mkfs.ext4 /dev/vdc \n WARNING: This can cause\
          \ data loss if a file system already exists on the target\nVolume. \n You\
          \ can use below command to mount the volume (choose any volume-name). \n\
          \ sudo mkdir /volume_name \n sudo mount /dev/vdc /volume_name -t auto \n\
          \ NOTE: At first, you will not be able to save information to the ephemeral\
          \ disk. \nThe following command gives permission for the user 'ubuntu' to\
          \ write to the ephemeral disk: \n sudo chown ubuntu /mnt \n Notes:\nVolumes\
          \ must be detached before deletion. \n Check your Storage \n Here are some\
          \ commands that can allow you to look at your mounted storage blocks\nand\
          \ keep track of their usage: \n lsblk -l  for info : man lsblk \n df -hT\
          \  for info : man df \n du -h <path/to/directory>  for info : man du \n\
          \ Object Storage \n The NeCTAR Cloud Object Storage is not a traditional\
          \ file system, but rather a\ndistributed storage system for static data\
          \ such as virtual machine images,\nphoto storage, email storage, backups\
          \ and archives. Having no central \"brain\" or\nmaster point of control\
          \ provides greater scalability, redundancy and durability.\nWhen you put\
          \ a file in the NeCTAR Cloud Object Store, 3 copies of your data are\ndistributed\
          \ to different hardware for extra data safety and performance. \n Think\
          \ about that dataset comprised of 2GB files that you read in and analyse\n\
          many times, but in general it doesn't change. Or the images you want to\
          \ use on\nthe cloud. Those are a couple examples of perfect data for Object\
          \ Storage.\nObjects are written to multiple hardware devices in the data\
          \ center to ensure\nintegrity, and great performance! \n In general, the\
          \ object store is great for data you write once and read many\ntimes, but\
          \ not suitable for applications like databases. It's the safest place\n\
          to put your data on the NeCTAR Research Cloud as multiple redundant copies\
          \ of\nyour data are made, and it has great performance. You can access the\
          \ object\nstore from anywhere on the Internet, and data from Object Storage\
          \ can be\ntransferred to and from your virtual machine with a variety of\
          \ http-capable\ntools. \n Object Storage is completely decoupled from your\
          \ virtual machine, so even if you\nreboot, delete or crash your virtual\
          \ machine, your Object Storage files will\nremain safe (unless you remove\
          \ them yourself). Object Storage persists\nindependently of the life of\
          \ an instance. \n Swift \n Swift is the component that provides object storage\
          \ for OpenStack. With your\ncredentials and via a URL you can request Swift\
          \ to reserve & create storage\n(called containers or buckets). Files (known\
          \ as objects when stored in Swift)\ncan then be uploaded and accessed similarly\
          \ by your running virtual machines. \n The NeCTAR implementation of Swift\
          \ is geodistributed across Nodes of the NeCTAR\nCloud so that availability\
          \ does not rely on any one data center or network\ninfrastructure. Each\
          \ collection of Swift nodes/hardware is known as a region,\nwhich may or\
          \ may not include a Swift proxy server (the Internet facing and\nserving\
          \ component of Swift). With some Swift clients/APIs users can explicitly\n\
          chose which proxy to connect to, this might be useful e.g. for speeding\
          \ up\nwrites to object storage by choosing the nearest proxy. Due to NeCTAR's\
          \ Swift\nhaving multiple regions (some of which are Node private) some clients/APIs\n\
          require explicit configuration of a default region, which should be \"Melbourne\"\
          \nfor most users. "
        description: "<p>The NeCTAR virtual machines have many resources binded with\
          \ them in order for it\nto function properly. Among these resources, storage\
          \ is the fundamental component\nfor both the virtual machine and user to\
          \ save and use data. The amount of\nstorage your virtual machine get are\
          \ dedicated, but the underlying storage\nsystem are shared. Furthermore,\
          \ not all storage is created equal, and Research\nCloud users have a few\
          \ different types of storage available which differ\naccording to performance,\
          \ persistence and data safety.</p>\n<h2>On Virtual Machine Storage</h2>\n\
          <p>Each virtual machine in the NeCTAR Cloud comes with a certain amount\
          \ of built-in\nstorage and theseappear as two separated hard disks\n(Root\
          \ Disk and Ephemeral Disk). These storage disks run off robust\nenterprise-grade\
          \ storage hardware on the back. However, both storage disks are not\nsuitable\
          \ for long-term persistent data as data will be lost after termination or\n\
          rebuild of a virtual machine.</p>\n<h3>Root Disk</h3>\n<p>This storage is\
          \ used for the operating system of the virtual machine, to boot it\ninto\
          \ a functional state. It has a limited 10GB in size, which is the same for\
          \ every\nstandard size of virtual machine (Small, Medium, Large, Extra Large\
          \ and\nExtra Extra Large). The size varies for non-standard virtual machines\
          \ such as\ntiny, which only has 5GB root storage.</p>\n<p>Data stored on\
          \ the root storage are persistent until the termination or rebuild\nof the\
          \ virtual machine and are copied during the snapshot. That means, if you\n\
          reboot your virtual machine, the data remains intact and when you take a\n\
          point-in-time snapshot of your virtual machine, the entire root storage\
          \ is\ncopied. As the root storage comes with fixed size and is used by the\
          \ operation\nsystem, caution need to be taken as it should not be filled\
          \ in full. The name of\nthis disk as seen from the virtual machine is usually\
          \ '/dev/vda'.</p>\n<h3>Ephemeral Disk</h3>\n<p>This storage appears as a\
          \ second hard disk in your virtual machine. It is a raw\nand unformatted\
          \ block device, that you can format and use as you wish. It varies\nin size\
          \ according to the size of virtual machine (from 0GB to 480GB). For each\n\
          CPU, a standard virtual machine will get 30GB of additional ephemeral storage.\n\
          It varies in size for non-standard virtual machines. The name of this device\
          \ as\nseen from the instance is usually '/dev/vdb' and some operating systems\
          \ will\nautomatically format and mount the ephemeral disk. For example,\
          \ Ubuntu creates\nan ext3 partition and mounts it at '/mnt'. For operating\
          \ systems that don't do it\nautomatically, you can format it by executing\
          \ <code>mkfs.ext4 /dev/vdb</code> in the command line\nand mount it by executing\
          \ <code>mount /dev/vdb /mnt</code>. You need to have root\npermission to\
          \ do this.</p>\n<p>Data stored on ephemeral disk are only persistent until\
          \ the termination or\nrebuild of the virtual machine (like the root disk).\
          \ The only difference\nis that data on the ephemeral disk are not copied\
          \ when taking a snapshot of a virtual\nmachine, which means you cannot use\
          \ snapshot to save data stored on ephemeral\ndisk.</p>\n<p>NOTE: At first,\
          \ you will not be able to save information to the ephemeral disk. \nThe\
          \ following command gives permission for the user 'ubuntu' to write to the\
          \ ephemeral disk:</p>\n<p><code>sudo chown ubuntu /mnt</code></p>\n<h4>Backup\
          \ of Ephemeral Disk</h4>\n<p>Data on the ephemeral disk does not get saved\
          \ in a snapshot, and requires other\ntechniques to make a backup. Other\
          \ forms of storage can be used such as the\nObject Store and Volume Storage\
          \ within the Research Cloud or external locations.</p>\n<h2>Persistent Volume\
          \ Storage</h2>\n<p>Persistent volume storage can live outside your virtual\
          \ machine. It appears\nas block storage which can be attached then accessed\
          \ and even booted from. This\nis a storage volume that you can attach to\
          \ from within your virtual machine,\nread and write data, detach it, and\
          \ make it available to another virtual machine.\nYour data on a persistent\
          \ volume are retained even when you terminate your\nvirtual machine. Persistent\
          \ Volumes offer a snapshot feature which can be used\nto make convenient\
          \ backups (this uses some of your overall Persistent Volume quota).</p>\n\
          <p>NOTE: Persistent Volumes are local services and only virtual machines\
          \ in the\navailability zone where the persistent Volume has been created\
          \ can access it.</p>\n<h3>How to Get Persistent Volume Storage</h3>\n<p>By\
          \ default, there are no persistent volume storage available to your project.\n\
          You need to make an allocation request to apply for the quantity of persistent\
          \ volume\nstorage you require for your project. Follow these steps to submit\
          \ a\nrequest:</p>\n<ul>\n<li>\n<p>Login to NeCTAR Cloud <a href=\"https://dashboard.rc.nectar.org.au\"\
          >Dashboard</a></p>\n</li>\n<li>\n<p>Go to Allocations and you can either\
          \ click 'New Request' to make a new request\n or 'My Requests' to amend\
          \ an existing request</p>\n</li>\n<li>\n<p>Under section 'Storage Quota',\
          \ you select 'Resource' as volume, select the\n Zone you want the storage\
          \ to be located at (must be the same location as the instance it will be\
          \ attached to) and enter the size in GB under 'Requested Quota'.</p>\n</li>\n\
          <li>\n<p>Click the 'Submit' button</p>\n</li>\n</ul>\n<p>NOTE: It may take\
          \ a while for your request to be approved.</p>\n<h3>Create a persistent\
          \ volume storage</h3>\n<p>Once your request has been approved, your project\
          \ should have volume storage\navailable. You need to create the volume storage\
          \ in the NeCTAR Cloud Dashboard \nbefore you can use it.</p>\n<ul>\n<li>\n\
          <p>Login to the NeCTAR Cloud <a href=\"https://dashboard.rc.nectar.org.au\"\
          >Dashboard</a></p>\n</li>\n<li>\n<p>Go to 'Volumes'</p>\n</li>\n<li>\n<p>Click\
          \ 'Create Volume' button</p>\n</li>\n<li>\n<p>Give a Volume Name and meaningful\
          \ description</p>\n</li>\n<li>\n<p>Specify a 'Volume Source' to determine\
          \ how the volume will be built. You can select\n 'No source empty volume'\
          \ to create new empty volume. You can select 'image' to\n build a volume\
          \ from a image or 'Volume' to build a volume from existing volume</p>\n\
          </li>\n<li>\n<p>Specify the size of the volume in GB</p>\n</li>\n<li>\n\
          <p>Enter an 'Availability Zone' (must be the same zone as the instance)</p>\n\
          </li>\n<li>\n<p>Click 'Create Volume' button</p>\n</li>\n</ul>\n<h3>Attach\
          \ a persistent volume storage</h3>\n<p>You can attach the volume created\
          \ earlier to a running virtual machine. See the\nbelow instruction:</p>\n\
          <ul>\n<li>\n<p>Login to NeCTAR Cloud <a href=\"https://dashboard.rc.nectar.org.au\"\
          >Dashboard</a></p>\n</li>\n<li>\n<p>Go to 'Volumes'</p>\n</li>\n<li>\n<p>Click\
          \ the action list of volume</p>\n</li>\n<li>\n<p>Click 'Edit Attachment'</p>\n\
          </li>\n<li>\n<p>Click 'Attach to Instance' drop down list to select a virtual\
          \ machine to\n attach the volume to.</p>\n</li>\n<li>\n<p>Click 'Attach\
          \ Volume' button</p>\n</li>\n</ul>\n<h3>Use Persistent Volume Storage in\
          \ Virtual Machine</h3>\n<p>For a standard flavor virtual machine the persistent\
          \ volume will be attached\nas '/dev/vdc'. </p>\n<p>A new volume may not\
          \ have a file system (depending on how it was created) and\nyou need to\
          \ create one before mounting.</p>\n<p>The exact mount command syntax is\
          \ dependent on the virtual machine' operating\nsystem and the type of file\
          \ system you require.</p>\n<p>You can use below command to create file system\
          \ on the new volume:\n<code>sudo mkfs.ext4 /dev/vdc</code></p>\n<p>WARNING:\
          \ This can cause data loss if a file system already exists on the target\n\
          Volume.</p>\n<p>You can use below command to mount the volume (choose any\
          \ volume-name).</p>\n<p><code>sudo mkdir /volume_name</code></p>\n<p><code>sudo\
          \ mount /dev/vdc /volume_name -t auto</code></p>\n<p>NOTE: At first, you\
          \ will not be able to save information to the ephemeral disk. \nThe following\
          \ command gives permission for the user 'ubuntu' to write to the ephemeral\
          \ disk:</p>\n<p><code>sudo chown ubuntu /mnt</code></p>\n<p>Notes:\nVolumes\
          \ must be detached before deletion.</p>\n<h2>Check your Storage</h2>\n<p>Here\
          \ are some commands that can allow you to look at your mounted storage blocks\n\
          and keep track of their usage:</p>\n<p><code>lsblk -l</code>  for info :\
          \ <code>man lsblk</code></p>\n<p><code>df -hT</code>  for info : <code>man\
          \ df</code></p>\n<p><code>du -h &lt;path/to/directory&gt;</code>  for info\
          \ : <code>man du</code></p>\n<h2>Object Storage</h2>\n<p>The NeCTAR Cloud\
          \ Object Storage is not a traditional file system, but rather a\ndistributed\
          \ storage system for static data such as virtual machine images,\nphoto\
          \ storage, email storage, backups and archives. Having no central \"brain\"\
          \ or\nmaster point of control provides greater scalability, redundancy and\
          \ durability.\nWhen you put a file in the NeCTAR Cloud Object Store, 3 copies\
          \ of your data are\ndistributed to different hardware for extra data safety\
          \ and performance.</p>\n<p>Think about that dataset comprised of 2GB files\
          \ that you read in and analyse\nmany times, but in general it doesn't change.\
          \ Or the images you want to use on\nthe cloud. Those are a couple examples\
          \ of perfect data for Object Storage.\nObjects are written to multiple hardware\
          \ devices in the data center to ensure\nintegrity, and great performance!</p>\n\
          <p>In general, the object store is great for data you write once and read\
          \ many\ntimes, but not suitable for applications like databases. It's the\
          \ safest place\nto put your data on the NeCTAR Research Cloud as multiple\
          \ redundant copies of\nyour data are made, and it has great performance.\
          \ You can access the object\nstore from anywhere on the Internet, and data\
          \ from Object Storage can be\ntransferred to and from your virtual machine\
          \ with a variety of http-capable\ntools.</p>\n<p>Object Storage is completely\
          \ decoupled from your virtual machine, so even if you\nreboot, delete or\
          \ crash your virtual machine, your Object Storage files will\nremain safe\
          \ (unless you remove them yourself). Object Storage persists\nindependently\
          \ of the life of an instance.</p>\n<h3>Swift</h3>\n<p>Swift is the component\
          \ that provides object storage for OpenStack. With your\ncredentials and\
          \ via a URL you can request Swift to reserve &amp; create storage\n(called\
          \ containers or buckets). Files (known as objects when stored in Swift)\n\
          can then be uploaded and accessed similarly by your running virtual machines.</p>\n\
          <p>The NeCTAR implementation of Swift is geodistributed across Nodes of\
          \ the NeCTAR\nCloud so that availability does not rely on any one data center\
          \ or network\ninfrastructure. Each collection of Swift nodes/hardware is\
          \ known as a region,\nwhich may or may not include a Swift proxy server\
          \ (the Internet facing and\nserving component of Swift). With some Swift\
          \ clients/APIs users can explicitly\nchose which proxy to connect to, this\
          \ might be useful e.g. for speeding up\nwrites to object storage by choosing\
          \ the nearest proxy. Due to NeCTAR's Swift\nhaving multiple regions (some\
          \ of which are Node private) some clients/APIs\nrequire explicit configuration\
          \ of a default region, which should be \"Melbourne\"\nfor most users.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 18
        id: 6000055382
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-02T18:56:03-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000055382
        position: 6
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Introduction to Cloud Storage
        updated_at: '2015-11-02T18:56:03-05:00'
        user_id: 6002464727
  html: "<p>The NeCTAR virtual machines have many resources binded with them in order\
    \ for it\nto function properly. Among these resources, storage is the fundamental\
    \ component\nfor both the virtual machine and user to save and use data. The amount\
    \ of\nstorage your virtual machine get are dedicated, but the underlying storage\n\
    system are shared. Furthermore, not all storage is created equal, and Research\n\
    Cloud users have a few different types of storage available which differ\naccording\
    \ to performance, persistence and data safety.</p>\n<h2>On Virtual Machine Storage</h2>\n\
    <p>Each virtual machine in the NeCTAR Cloud comes with a certain amount of built-in\n\
    storage and theseappear as two separated hard disks\n(Root Disk and Ephemeral\
    \ Disk). These storage disks run off robust\nenterprise-grade storage hardware\
    \ on the back. However, both storage disks are not\nsuitable for long-term persistent\
    \ data as data will be lost after termination or\nrebuild of a virtual machine.</p>\n\
    <h3>Root Disk</h3>\n<p>This storage is used for the operating system of the virtual\
    \ machine, to boot it\ninto a functional state. It has a limited 10GB in size,\
    \ which is the same for every\nstandard size of virtual machine (Small, Medium,\
    \ Large, Extra Large and\nExtra Extra Large). The size varies for non-standard\
    \ virtual machines such as\ntiny, which only has 5GB root storage.</p>\n<p>Data\
    \ stored on the root storage are persistent until the termination or rebuild\n\
    of the virtual machine and are copied during the snapshot. That means, if you\n\
    reboot your virtual machine, the data remains intact and when you take a\npoint-in-time\
    \ snapshot of your virtual machine, the entire root storage is\ncopied. As the\
    \ root storage comes with fixed size and is used by the operation\nsystem, caution\
    \ need to be taken as it should not be filled in full. The name of\nthis disk\
    \ as seen from the virtual machine is usually '/dev/vda'.</p>\n<h3>Ephemeral Disk</h3>\n\
    <p>This storage appears as a second hard disk in your virtual machine. It is a\
    \ raw\nand unformatted block device, that you can format and use as you wish.\
    \ It varies\nin size according to the size of virtual machine (from 0GB to 480GB).\
    \ For each\nCPU, a standard virtual machine will get 30GB of additional ephemeral\
    \ storage.\nIt varies in size for non-standard virtual machines. The name of this\
    \ device as\nseen from the instance is usually '/dev/vdb' and some operating systems\
    \ will\nautomatically format and mount the ephemeral disk. For example, Ubuntu\
    \ creates\nan ext3 partition and mounts it at '/mnt'. For operating systems that\
    \ don't do it\nautomatically, you can format it by executing <code>mkfs.ext4 /dev/vdb</code>\
    \ in the command line\nand mount it by executing <code>mount /dev/vdb /mnt</code>.\
    \ You need to have root\npermission to do this.</p>\n<p>Data stored on ephemeral\
    \ disk are only persistent until the termination or\nrebuild of the virtual machine\
    \ (like the root disk). The only difference\nis that data on the ephemeral disk\
    \ are not copied when taking a snapshot of a virtual\nmachine, which means you\
    \ cannot use snapshot to save data stored on ephemeral\ndisk.</p>\n<p>NOTE: At\
    \ first, you will not be able to save information to the ephemeral disk. \nThe\
    \ following command gives permission for the user 'ubuntu' to write to the ephemeral\
    \ disk:</p>\n<p><code>sudo chown ubuntu /mnt</code></p>\n<h4>Backup of Ephemeral\
    \ Disk</h4>\n<p>Data on the ephemeral disk does not get saved in a snapshot, and\
    \ requires other\ntechniques to make a backup. Other forms of storage can be used\
    \ such as the\nObject Store and Volume Storage within the Research Cloud or external\
    \ locations.</p>\n<h2>Persistent Volume Storage</h2>\n<p>Persistent volume storage\
    \ can live outside your virtual machine. It appears\nas block storage which can\
    \ be attached then accessed and even booted from. This\nis a storage volume that\
    \ you can attach to from within your virtual machine,\nread and write data, detach\
    \ it, and make it available to another virtual machine.\nYour data on a persistent\
    \ volume are retained even when you terminate your\nvirtual machine. Persistent\
    \ Volumes offer a snapshot feature which can be used\nto make convenient backups\
    \ (this uses some of your overall Persistent Volume quota).</p>\n<p>NOTE: Persistent\
    \ Volumes are local services and only virtual machines in the\navailability zone\
    \ where the persistent Volume has been created can access it.</p>\n<h3>How to\
    \ Get Persistent Volume Storage</h3>\n<p>By default, there are no persistent volume\
    \ storage available to your project.\nYou need to make an allocation request to\
    \ apply for the quantity of persistent volume\nstorage you require for your project.\
    \ Follow these steps to submit a\nrequest:</p>\n<ul>\n<li>\n<p>Login to NeCTAR\
    \ Cloud <a href=\"https://dashboard.rc.nectar.org.au\">Dashboard</a></p>\n</li>\n\
    <li>\n<p>Go to Allocations and you can either click 'New Request' to make a new\
    \ request\n or 'My Requests' to amend an existing request</p>\n</li>\n<li>\n<p>Under\
    \ section 'Storage Quota', you select 'Resource' as volume, select the\n Zone\
    \ you want the storage to be located at (must be the same location as the instance\
    \ it will be attached to) and enter the size in GB under 'Requested Quota'.</p>\n\
    </li>\n<li>\n<p>Click the 'Submit' button</p>\n</li>\n</ul>\n<p>NOTE: It may take\
    \ a while for your request to be approved.</p>\n<h3>Create a persistent volume\
    \ storage</h3>\n<p>Once your request has been approved, your project should have\
    \ volume storage\navailable. You need to create the volume storage in the NeCTAR\
    \ Cloud Dashboard \nbefore you can use it.</p>\n<ul>\n<li>\n<p>Login to the NeCTAR\
    \ Cloud <a href=\"https://dashboard.rc.nectar.org.au\">Dashboard</a></p>\n</li>\n\
    <li>\n<p>Go to 'Volumes'</p>\n</li>\n<li>\n<p>Click 'Create Volume' button</p>\n\
    </li>\n<li>\n<p>Give a Volume Name and meaningful description</p>\n</li>\n<li>\n\
    <p>Specify a 'Volume Source' to determine how the volume will be built. You can\
    \ select\n 'No source empty volume' to create new empty volume. You can select\
    \ 'image' to\n build a volume from a image or 'Volume' to build a volume from\
    \ existing volume</p>\n</li>\n<li>\n<p>Specify the size of the volume in GB</p>\n\
    </li>\n<li>\n<p>Enter an 'Availability Zone' (must be the same zone as the instance)</p>\n\
    </li>\n<li>\n<p>Click 'Create Volume' button</p>\n</li>\n</ul>\n<h3>Attach a persistent\
    \ volume storage</h3>\n<p>You can attach the volume created earlier to a running\
    \ virtual machine. See the\nbelow instruction:</p>\n<ul>\n<li>\n<p>Login to NeCTAR\
    \ Cloud <a href=\"https://dashboard.rc.nectar.org.au\">Dashboard</a></p>\n</li>\n\
    <li>\n<p>Go to 'Volumes'</p>\n</li>\n<li>\n<p>Click the action list of volume</p>\n\
    </li>\n<li>\n<p>Click 'Edit Attachment'</p>\n</li>\n<li>\n<p>Click 'Attach to\
    \ Instance' drop down list to select a virtual machine to\n attach the volume\
    \ to.</p>\n</li>\n<li>\n<p>Click 'Attach Volume' button</p>\n</li>\n</ul>\n<h3>Use\
    \ Persistent Volume Storage in Virtual Machine</h3>\n<p>For a standard flavor\
    \ virtual machine the persistent volume will be attached\nas '/dev/vdc'. </p>\n\
    <p>A new volume may not have a file system (depending on how it was created) and\n\
    you need to create one before mounting.</p>\n<p>The exact mount command syntax\
    \ is dependent on the virtual machine' operating\nsystem and the type of file\
    \ system you require.</p>\n<p>You can use below command to create file system\
    \ on the new volume:\n<code>sudo mkfs.ext4 /dev/vdc</code></p>\n<p>WARNING: This\
    \ can cause data loss if a file system already exists on the target\nVolume.</p>\n\
    <p>You can use below command to mount the volume (choose any volume-name).</p>\n\
    <p><code>sudo mkdir /volume_name</code></p>\n<p><code>sudo mount /dev/vdc /volume_name\
    \ -t auto</code></p>\n<p>NOTE: At first, you will not be able to save information\
    \ to the ephemeral disk. \nThe following command gives permission for the user\
    \ 'ubuntu' to write to the ephemeral disk:</p>\n<p><code>sudo chown ubuntu /mnt</code></p>\n\
    <p>Notes:\nVolumes must be detached before deletion.</p>\n<h2>Check your Storage</h2>\n\
    <p>Here are some commands that can allow you to look at your mounted storage blocks\n\
    and keep track of their usage:</p>\n<p><code>lsblk -l</code>  for info : <code>man\
    \ lsblk</code></p>\n<p><code>df -hT</code>  for info : <code>man df</code></p>\n\
    <p><code>du -h &lt;path/to/directory&gt;</code>  for info : <code>man du</code></p>\n\
    <h2>Object Storage</h2>\n<p>The NeCTAR Cloud Object Storage is not a traditional\
    \ file system, but rather a\ndistributed storage system for static data such as\
    \ virtual machine images,\nphoto storage, email storage, backups and archives.\
    \ Having no central \"brain\" or\nmaster point of control provides greater scalability,\
    \ redundancy and durability.\nWhen you put a file in the NeCTAR Cloud Object Store,\
    \ 3 copies of your data are\ndistributed to different hardware for extra data\
    \ safety and performance.</p>\n<p>Think about that dataset comprised of 2GB files\
    \ that you read in and analyse\nmany times, but in general it doesn't change.\
    \ Or the images you want to use on\nthe cloud. Those are a couple examples of\
    \ perfect data for Object Storage.\nObjects are written to multiple hardware devices\
    \ in the data center to ensure\nintegrity, and great performance!</p>\n<p>In general,\
    \ the object store is great for data you write once and read many\ntimes, but\
    \ not suitable for applications like databases. It's the safest place\nto put\
    \ your data on the NeCTAR Research Cloud as multiple redundant copies of\nyour\
    \ data are made, and it has great performance. You can access the object\nstore\
    \ from anywhere on the Internet, and data from Object Storage can be\ntransferred\
    \ to and from your virtual machine with a variety of http-capable\ntools.</p>\n\
    <p>Object Storage is completely decoupled from your virtual machine, so even if\
    \ you\nreboot, delete or crash your virtual machine, your Object Storage files\
    \ will\nremain safe (unless you remove them yourself). Object Storage persists\n\
    independently of the life of an instance.</p>\n<h3>Swift</h3>\n<p>Swift is the\
    \ component that provides object storage for OpenStack. With your\ncredentials\
    \ and via a URL you can request Swift to reserve &amp; create storage\n(called\
    \ containers or buckets). Files (known as objects when stored in Swift)\ncan then\
    \ be uploaded and accessed similarly by your running virtual machines.</p>\n<p>The\
    \ NeCTAR implementation of Swift is geodistributed across Nodes of the NeCTAR\n\
    Cloud so that availability does not rely on any one data center or network\ninfrastructure.\
    \ Each collection of Swift nodes/hardware is known as a region,\nwhich may or\
    \ may not include a Swift proxy server (the Internet facing and\nserving component\
    \ of Swift). With some Swift clients/APIs users can explicitly\nchose which proxy\
    \ to connect to, this might be useful e.g. for speeding up\nwrites to object storage\
    \ by choosing the nearest proxy. Due to NeCTAR's Swift\nhaving multiple regions\
    \ (some of which are Node private) some clients/APIs\nrequire explicit configuration\
    \ of a default region, which should be \"Melbourne\"\nfor most users.</p>"
  parent: 21
  sha1: cefb5447304e6dde5e59187590e25598103cc923
  title: Introduction to Cloud Storage
46:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:19-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " \n Heat \n Heat is a template driven service that automates\
          \ the management of the entire\nlifecycle of your application on the NeCTAR\
          \ cloud. \n A 'template driven service' simply means that you define your\
          \ application's\nrequirements in a human readable text file - the template.\
          \ In this file you to\ndescribe both the infrastructure and its relationships\
          \ that your application\nwill need to run on the NeCTAR cloud. \n Heat then\
          \ uses this template to provision the required infrastructure and\nmanage\
          \ the lifecycle of your application from start to finish. This template,\n\
          and the infrastructure that it has created, is termed a 'stack'. \n As part\
          \ of the life cycle management, the Heat service supports both scaling on\n\
          demand and the freeing up of infrastructure once the application is finished.\
          \ \n Heat integrates well with configuration management tools, such as Chef\
          \ and\nPuppet. Thus the Heat service offers executable documentation of\
          \ your\napplication's deployment and lifecycle, making your deployments\
          \ repeatable and\nreliable. The net effect is to limit human error and to\
          \ save you time. Thus\nsaving you money. \n The stack template format(s)\
          \ \n Heat is modelled after Amazon's CloudFormation\nservice, and endeavours\
          \ to maintain some degree of compatibility with this\nservice. Hence Heat\
          \ supports two different template formats. \n \n The first is a JSON based\
          \ implementation that\n  mimics the Amazon specification. \n The second\
          \ is a YAML based native OpenStack\n  implementation termed 'HOT'. \n \n\
          \ We strongly recommend that you use the HOT format. \n The stack lifecycle\
          \ \n A template is created, using a standard text editor (such as Brackets).\n\
          It is then uploaded into the OpenStack Heat service, either by means of\
          \ the\nHeat command line client, or the Horizon dashboard. \n If uploaded\
          \ via the command line client, the engine expects any mandatory\nparameters\
          \ to be provided as arguments added at the point the template was\nuploaded.\
          \ \n If, however, uploaded via the dashboard, then the dashboard will create\
          \ an\ninput wizard that will step the person who uploaded the template through\
          \ the\nprocess of entering the required parameter values. \n Once all the\
          \ required data has been gathered the stack is then provisioned and\nlaunched.\
          \ \n The template and its associated parameters will remain in the Heat\
          \ database\nuntil such time as the engine is instructed to destroy the stack.\
          \ \n At that point all the provisioned infrastructure will be destroyed,\
          \ its\nresources released, and then the template and its parameters will\
          \ be removed\nfrom the Heat database \n For more on Heat, read the other\
          \ articles on this site. "
        description: "<h1>\n<img alt=\"flame logo\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/glossy_flame.png?raw=true\"\
          > Heat</h1>\n<p>Heat is a template driven service that automates the management\
          \ of the entire\nlifecycle of your application on the NeCTAR cloud.</p>\n\
          <p>A 'template driven service' simply means that you define your application's\n\
          requirements in a human readable text file - the template. In this file\
          \ you to\ndescribe both the infrastructure and its relationships that your\
          \ application\nwill need to run on the NeCTAR cloud.</p>\n<p>Heat then uses\
          \ this template to provision the required infrastructure and\nmanage the\
          \ lifecycle of your application from start to finish. This template,\nand\
          \ the infrastructure that it has created, is termed a 'stack'.</p>\n<p>As\
          \ part of the life cycle management, the Heat service supports both scaling\
          \ on\ndemand and the freeing up of infrastructure once the application is\
          \ finished.</p>\n<p>Heat integrates well with configuration management tools,\
          \ such as Chef and\nPuppet. Thus the Heat service offers executable documentation\
          \ of your\napplication's deployment and lifecycle, making your deployments\
          \ repeatable and\nreliable. The net effect is to limit human error and to\
          \ save you time. Thus\nsaving you money.</p>\n<h2>The stack template format(s)</h2>\n\
          <p>Heat is modelled after Amazon's <a href=\"http://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/Welcome.html\"\
          >CloudFormation</a>\nservice, and endeavours to maintain some degree of\
          \ compatibility with this\nservice. Hence Heat supports two different template\
          \ formats.</p>\n<ul>\n<li>The first is a <a href=\"http://www.json.org/\"\
          >JSON</a> based implementation that\n  mimics the Amazon specification.</li>\n\
          <li>The second is a <a href=\"http://www.yaml.org/\">YAML</a> based native\
          \ OpenStack\n  implementation termed 'HOT'.</li>\n</ul>\n<p>We strongly\
          \ recommend that you use the HOT format.</p>\n<h2>The stack lifecycle</h2>\n\
          <p>A template is created, using a standard text editor (such as <a href=\"\
          http://brackets.io/\">Brackets</a>).\nIt is then uploaded into the OpenStack\
          \ Heat service, either by means of the\nHeat command line client, or the\
          \ Horizon dashboard.</p>\n<p>If uploaded via the command line client, the\
          \ engine expects any mandatory\nparameters to be provided as arguments added\
          \ at the point the template was\nuploaded.</p>\n<p>If, however, uploaded\
          \ via the dashboard, then the dashboard will create an\ninput wizard that\
          \ will step the person who uploaded the template through the\nprocess of\
          \ entering the required parameter values.</p>\n<p>Once all the required\
          \ data has been gathered the stack is then provisioned and\nlaunched.</p>\n\
          <p>The template and its associated parameters will remain in the Heat database\n\
          until such time as the engine is instructed to destroy the stack.</p>\n\
          <p>At that point all the provisioned infrastructure will be destroyed, its\n\
          resources released, and then the template and its parameters will be removed\n\
          from the Heat database</p>\n<p>For more on Heat, read the other articles\
          \ on this site.</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:02-04:00'
          customer_folders: []
          description: Heat
          id: 6000190148
          is_default: false
          language_id: 6
          name: Heat
          parent_id: 6000190148
          position: 4
          updated_at: '2015-09-03T01:28:02-04:00'
          visibility: 1
        folder_id: 6000190148
        hits: 12
        id: 6000055383
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-14T20:46:31-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000055383
        position: 1
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Introduction to HEAT
        updated_at: '2015-10-14T20:46:31-04:00'
        user_id: 6002464727
  html: "<h1><img alt=\"flame logo\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/glossy_flame.png?raw=true\"> Heat</h1>\n\
    <p>Heat is a template driven service that automates the management of the entire\n\
    lifecycle of your application on the NeCTAR cloud.</p>\n<p>A 'template driven\
    \ service' simply means that you define your application's\nrequirements in a\
    \ human readable text file - the template. In this file you to\ndescribe both\
    \ the infrastructure and its relationships that your application\nwill need to\
    \ run on the NeCTAR cloud.</p>\n<p>Heat then uses this template to provision the\
    \ required infrastructure and\nmanage the lifecycle of your application from start\
    \ to finish. This template,\nand the infrastructure that it has created, is termed\
    \ a 'stack'.</p>\n<p>As part of the life cycle management, the Heat service supports\
    \ both scaling on\ndemand and the freeing up of infrastructure once the application\
    \ is finished.</p>\n<p>Heat integrates well with configuration management tools,\
    \ such as Chef and\nPuppet. Thus the Heat service offers executable documentation\
    \ of your\napplication's deployment and lifecycle, making your deployments repeatable\
    \ and\nreliable. The net effect is to limit human error and to save you time.\
    \ Thus\nsaving you money.</p>\n<h2>The stack template format(s)</h2>\n<p>Heat\
    \ is modelled after Amazon's <a href=\"http://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/Welcome.html\"\
    >CloudFormation</a>\nservice, and endeavours to maintain some degree of compatibility\
    \ with this\nservice. Hence Heat supports two different template formats.</p>\n\
    <ul>\n<li>The first is a <a href=\"http://www.json.org/\">JSON</a> based implementation\
    \ that\n  mimics the Amazon specification.</li>\n<li>The second is a <a href=\"\
    http://www.yaml.org/\">YAML</a> based native OpenStack\n  implementation termed\
    \ 'HOT'.</li>\n</ul>\n<p>We strongly recommend that you use the HOT format.</p>\n\
    <h2>The stack lifecycle</h2>\n<p>A template is created, using a standard text\
    \ editor (such as <a href=\"http://brackets.io/\">Brackets</a>).\nIt is then uploaded\
    \ into the OpenStack Heat service, either by means of the\nHeat command line client,\
    \ or the Horizon dashboard.</p>\n<p>If uploaded via the command line client, the\
    \ engine expects any mandatory\nparameters to be provided as arguments added at\
    \ the point the template was\nuploaded.</p>\n<p>If, however, uploaded via the\
    \ dashboard, then the dashboard will create an\ninput wizard that will step the\
    \ person who uploaded the template through the\nprocess of entering the required\
    \ parameter values.</p>\n<p>Once all the required data has been gathered the stack\
    \ is then provisioned and\nlaunched.</p>\n<p>The template and its associated parameters\
    \ will remain in the Heat database\nuntil such time as the engine is instructed\
    \ to destroy the stack.</p>\n<p>At that point all the provisioned infrastructure\
    \ will be destroyed, its\nresources released, and then the template and its parameters\
    \ will be removed\nfrom the Heat database</p>\n<p>For more on Heat, read the other\
    \ articles on this site.</p>"
  parent: 42
  sha1: 988556590c11d69c9e0bcb5f54dc6ae2aa14f0b1
  title: Introduction to HEAT
47:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:20-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Walk through of a YAML template \n Template sections \n A\
          \ Heat template is divided into several sections. These are the sections\
          \ that\nwill typically appear in a Heat template: \n \n \nheat_template_version\
          \ - A field that allows you to specify which version\n   of Heat the template\
          \ was written for (optional) \n \ndescription - A field that allows you\
          \ to describe the intent of the template\n  to a human audience (optional)\
          \ \n \nparameters - The specification of any arguments that the user might\
          \ be\n  required to provide (optional) \n \nresources - The specification\
          \ of the OpenStack resources that are to be\n  created (mandatory) \n \n\
          outputs - Any expected values that are to be returned once the template\n\
          \  has been processed (optional). \n \n The following table contains a guided\
          \ tour of a template\nin the NeCTAR sample template repository\nthat will\
          \ install the Apache web server on a single Ubuntu instance. \n\n\n\nSection\n\
          Template content\n\n\n\n\nVersion indicator\n\n\n\n\n The first line of\
          \ a YAML template should list a version indicator.\nIf present Heat will\
          \ parse the file  appropriately. If not present then\nHeat will assume that\
          \ the file adheres to the most recent specification. \n\n\n\nSection\nTemplate\
          \ content\n\n\n\n\nDescription\n\n\n\n\n Description is optional section\
          \ that allows you to provide a description of\nthe template. \n\n\n\nSection\n\
          Template content\n\n\n\n\nParameters\n\n\n\n\n Parameters is an optional\
          \ section that allows you to specify any input\nparameters that might be\
          \ required when the configuration described in the\ntemplate is built. \n\
          \n\n\nSection\nTemplate content\n\n\n\n\nParameters\n\n\n\n\n Each parameter\
          \ is in its own nested block, with the name appearing in\nthe first line,\
          \ and its attributes as further nested elements. \n\n\n\nSection\nTemplate\
          \ content\n\n\n\n\nParameters\n\n\n\n\n \n \ntype is a mandatory element\
          \ for a parameter that can be one of:\n  string, number, json or comma_delimited_list\n\
          \ \n \ndescription is an optional attribute that provided guidance to people\n\
          \  using the template. \n \n\n\n\nSection\nTemplate content\n\n\n\n\nParameters\n\
          \n\n\n\n \n \ndefault is an optional attribute that provides a default value\
          \ for\n  the parameter. \n Constraints on the user entered value can also\
          \ be set. \n \n\n\n\nSection\nTemplate content\n\n\n\n\nResources\n\n\n\n\
          \n Resources is a mandatory section that defines the resources that the\n\
          application will need. \n\n\n\nSection\nTemplate content\n\n\n\n\nResources\n\
          \n\n\n\n Each resource is in its own nested block, with the name appearing\
          \ in the\nfirst line, and attributes as  further nested elements \n Type\
          \ defines the OpenStack resource to be built. The complete list\nsupported\
          \ can be found in the template guide\nThis resource type will build a security\
          \ group. \n Each resource has its own attribute set. These are documented\
          \ in the\ntemplate guide - e.g.: for the AWS::EC2::SecurityGroup \n\n\n\n\
          Section\nTemplate content\n\n\n\n\nResources\n\n\n\n\n This resource type\
          \ builds an instance with apache installed. \n The AWS::CloudFormation::Init\
          \ section provides instructions as to what\nshould be done on the instance\
          \ once it has booted. \n Fn::Select is a function that will select an item\
          \ from a list. \n get_param is a function that returns the value of the\
          \ named parameter\nthat was set by the user. \n The Heat manual contains\
          \ a complete list of built in functions\nCurrently NeCTAR supports releases\
          \ up to Juno. \n UserData is a mechanism by which information can be passed\
          \ to an instance at\nlaunch time. Typically this will be either a a shell\
          \ script or a configuration\nfile. \n Note that the chosen image for the\
          \ instance must have the cloudinit\npackaged installed for AWS::CloudFormation::Init\
          \ to work. \n\n\n\nSection\nTemplate content\n\n\n\n\nResources\n\n\n\n\n\
          \ These resource types will notify the heat engine when the software is\n\
          fully installed on the instance. \n\n\n\nSection\nTemplate content\n\n\n\
          \n\nOutputs\n\n\n\n\n The outputs will show once the heat engine has finished\
          \ building the template. "
        description: "<h1>Walk through of a YAML template</h1>\n<h2>Template sections</h2>\n\
          <p>A Heat template is divided into several sections. These are the sections\
          \ that\nwill typically appear in a Heat template:</p>\n<ul>\n<li>\n<code>heat_template_version</code>\
          \ - A field that allows you to specify which version\n   of Heat the template\
          \ was written for (optional)</li>\n<li>\n<code>description</code> - A field\
          \ that allows you to describe the intent of the template\n  to a human audience\
          \ (optional)</li>\n<li>\n<code>parameters</code> - The specification of\
          \ any arguments that the user might be\n  required to provide (optional)</li>\n\
          <li>\n<code>resources</code> - The specification of the OpenStack resources\
          \ that are to be\n  created (mandatory)</li>\n<li>\n<code>outputs</code>\
          \ - Any expected values that are to be returned once the template\n  has\
          \ been processed (optional).</li>\n</ul>\n<p>The following table contains\
          \ a guided tour of a <a href=\"https://raw.githubusercontent.com/NeCTAR-RC/heat-templates/master/juno/Ubuntu/apache_single_instance_aws.yaml\"\
          >template</a>\nin the <a href=\"https://github.com/NeCTAR-RC/heat-templates\"\
          >NeCTAR sample template repository</a>\nthat will install the Apache web\
          \ server on a single Ubuntu instance.</p>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n\
          <th>Template content</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Version indicator</td>\n\
          <td><img alt=\"version info\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_template_version.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<p>The first line of a YAML template\
          \ should list a version indicator.\nIf present Heat will parse the file\
          \  appropriately. If not present then\nHeat will assume that the file adheres\
          \ to the most recent specification.</p>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n\
          <th>Template content</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Description</td>\n\
          <td><img alt=\"description\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_description.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<p>Description is optional section that\
          \ allows you to provide a description of\nthe template.</p>\n<table>\n<thead>\n\
          <tr>\n<th>Section</th>\n<th>Template content</th>\n</tr>\n</thead>\n<tbody>\n\
          <tr>\n<td>Parameters</td>\n<td><img alt=\"parameters\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_parameters.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<p>Parameters is an optional section\
          \ that allows you to specify any input\nparameters that might be required\
          \ when the configuration described in the\ntemplate is built.</p>\n<table>\n\
          <thead>\n<tr>\n<th>Section</th>\n<th>Template content</th>\n</tr>\n</thead>\n\
          <tbody>\n<tr>\n<td>Parameters</td>\n<td><img alt=\"key name\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_key_name.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<p>Each parameter is in its own nested\
          \ block, with the name appearing in\nthe first line, and its attributes\
          \ as further nested elements.</p>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n\
          <th>Template content</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Parameters</td>\n\
          <td><img alt=\"instance type\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_instance_type.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>\n<code>type</code> is a mandatory\
          \ element for a parameter that can be one of:\n  <code>string</code>, <code>number</code>,\
          \ <code>json</code> or <code>comma_delimited_list</code>\n</li>\n<li>\n\
          <code>description</code> is an optional attribute that provided guidance\
          \ to people\n  using the template.</li>\n</ul>\n<table>\n<thead>\n<tr>\n\
          <th>Section</th>\n<th>Template content</th>\n</tr>\n</thead>\n<tbody>\n\
          <tr>\n<td>Parameters</td>\n<td><img alt=\"image name\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_image_name.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>\n<code>default</code> is an\
          \ optional attribute that provides a default value for\n  the parameter.</li>\n\
          <li>Constraints on the user entered value can also be set.</li>\n</ul>\n\
          <table>\n<thead>\n<tr>\n<th>Section</th>\n<th>Template content</th>\n</tr>\n\
          </thead>\n<tbody>\n<tr>\n<td>Resources</td>\n<td><img alt=\"resources\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_resources.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<p>Resources is a mandatory section that\
          \ defines the resources that the\napplication will need.</p>\n<table>\n\
          <thead>\n<tr>\n<th>Section</th>\n<th>Template content</th>\n</tr>\n</thead>\n\
          <tbody>\n<tr>\n<td>Resources</td>\n<td><img alt=\"web security group\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_web_security_group.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<p>Each resource is in its own nested\
          \ block, with the name appearing in the\nfirst line, and attributes as \
          \ further nested elements</p>\n<p>Type defines the OpenStack resource to\
          \ be built. The complete list\nsupported can be found in the <a href=\"\
          http://docs.openstack.org/developer/heat/template_guide/\">template guide</a>\n\
          This resource type will build a security group.</p>\n<p>Each resource has\
          \ its own attribute set. These are documented in the\ntemplate guide - e.g.:\
          \ for the <a href=\"http://docs.openstack.org/developer/heat/template_guide/cfn.html#AWS::EC2::SecurityGroup\"\
          ><code>AWS::EC2::SecurityGroup</code></a></p>\n<table>\n<thead>\n<tr>\n\
          <th>Section</th>\n<th>Template content</th>\n</tr>\n</thead>\n<tbody>\n\
          <tr>\n<td>Resources</td>\n<td><img alt=\"apache server\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_apache_server.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<p>This resource type builds an instance\
          \ with apache installed.</p>\n<p>The <code>AWS::CloudFormation::Init</code>\
          \ section provides instructions as to what\nshould be done on the instance\
          \ once it has booted.</p>\n<p><code>Fn::Select</code> is a function that\
          \ will select an item from a list.</p>\n<p><code>get_param</code> is a function\
          \ that returns the value of the named parameter\nthat was set by the user.</p>\n\
          <p>The Heat manual contains a complete list of <a href=\"http://docs.openstack.org/developer/heat/template_guide/hot_spec.html\"\
          >built in functions</a>\nCurrently NeCTAR supports releases up to Juno.</p>\n\
          <p>UserData is a mechanism by which information can be passed to an instance\
          \ at\nlaunch time. Typically this will be either a a shell script or a configuration\n\
          file.</p>\n<p>Note that the chosen image for the instance must have the\
          \ <code>cloudinit</code>\npackaged installed for <code>AWS::CloudFormation::Init</code>\
          \ to work.</p>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n<th>Template content</th>\n\
          </tr>\n</thead>\n<tbody>\n<tr>\n<td>Resources</td>\n<td><img alt=\"apache\
          \ server\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_wait_handle.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<p>These resource types will notify the\
          \ heat engine when the software is\nfully installed on the instance.</p>\n\
          <table>\n<thead>\n<tr>\n<th>Section</th>\n<th>Template content</th>\n</tr>\n\
          </thead>\n<tbody>\n<tr>\n<td>Outputs</td>\n<td><img alt=\"apache server\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_outputs.png?raw=true\"\
          ></td>\n</tr>\n</tbody>\n</table>\n<p>The outputs will show once the heat\
          \ engine has finished building the template.</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:02-04:00'
          customer_folders: []
          description: Heat
          id: 6000190148
          is_default: false
          language_id: 6
          name: Heat
          parent_id: 6000190148
          position: 5
          updated_at: '2015-09-03T01:28:02-04:00'
          visibility: 1
        folder_id: 6000190148
        hits: 0
        id: 6000055384
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-09-03T01:28:20-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000055384
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Heat Template Walk Through
        updated_at: '2015-09-03T01:28:20-04:00'
        user_id: 6002464727
  html: "<h1>Walk through of a YAML template</h1>\n<h2>Template sections</h2>\n<p>A\
    \ Heat template is divided into several sections. These are the sections that\n\
    will typically appear in a Heat template:</p>\n<ul>\n<li><code>heat_template_version</code>\
    \ - A field that allows you to specify which version\n   of Heat the template\
    \ was written for (optional)</li>\n<li><code>description</code> - A field that\
    \ allows you to describe the intent of the template\n  to a human audience (optional)</li>\n\
    <li><code>parameters</code> - The specification of any arguments that the user\
    \ might be\n  required to provide (optional)</li>\n<li><code>resources</code>\
    \ - The specification of the OpenStack resources that are to be\n  created (mandatory)</li>\n\
    <li><code>outputs</code> - Any expected values that are to be returned once the\
    \ template\n  has been processed (optional).</li>\n</ul>\n<p>The following table\
    \ contains a guided tour of a <a href=\"https://raw.githubusercontent.com/NeCTAR-RC/heat-templates/master/juno/Ubuntu/apache_single_instance_aws.yaml\"\
    >template</a>\nin the <a href=\"https://github.com/NeCTAR-RC/heat-templates\"\
    >NeCTAR sample template repository</a>\nthat will install the Apache web server\
    \ on a single Ubuntu instance.</p>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n\
    <th>Template content</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Version indicator</td>\n\
    <td><img alt=\"version info\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_template_version.png?raw=true\"></td>\n\
    </tr>\n</tbody>\n</table>\n<p>The first line of a YAML template should list a\
    \ version indicator.\nIf present Heat will parse the file  appropriately. If not\
    \ present then\nHeat will assume that the file adheres to the most recent specification.</p>\n\
    <table>\n<thead>\n<tr>\n<th>Section</th>\n<th>Template content</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td>Description</td>\n<td><img alt=\"description\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_description.png?raw=true\"></td>\n\
    </tr>\n</tbody>\n</table>\n<p>Description is optional section that allows you\
    \ to provide a description of\nthe template.</p>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n\
    <th>Template content</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Parameters</td>\n\
    <td><img alt=\"parameters\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_parameters.png?raw=true\"></td>\n\
    </tr>\n</tbody>\n</table>\n<p>Parameters is an optional section that allows you\
    \ to specify any input\nparameters that might be required when the configuration\
    \ described in the\ntemplate is built.</p>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n\
    <th>Template content</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Parameters</td>\n\
    <td><img alt=\"key name\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_key_name.png?raw=true\"></td>\n</tr>\n\
    </tbody>\n</table>\n<p>Each parameter is in its own nested block, with the name\
    \ appearing in\nthe first line, and its attributes as further nested elements.</p>\n\
    <table>\n<thead>\n<tr>\n<th>Section</th>\n<th>Template content</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td>Parameters</td>\n<td><img alt=\"instance type\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_instance_type.png?raw=true\"></td>\n\
    </tr>\n</tbody>\n</table>\n<ul>\n<li><code>type</code> is a mandatory element\
    \ for a parameter that can be one of:\n  <code>string</code>, <code>number</code>,\
    \ <code>json</code> or <code>comma_delimited_list</code></li>\n<li><code>description</code>\
    \ is an optional attribute that provided guidance to people\n  using the template.</li>\n\
    </ul>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n<th>Template content</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>Parameters</td>\n<td><img alt=\"image name\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_image_name.png?raw=true\"></td>\n\
    </tr>\n</tbody>\n</table>\n<ul>\n<li><code>default</code> is an optional attribute\
    \ that provides a default value for\n  the parameter.</li>\n<li>Constraints on\
    \ the user entered value can also be set.</li>\n</ul>\n<table>\n<thead>\n<tr>\n\
    <th>Section</th>\n<th>Template content</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>Resources</td>\n<td><img alt=\"resources\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_resources.png?raw=true\"></td>\n</tr>\n\
    </tbody>\n</table>\n<p>Resources is a mandatory section that defines the resources\
    \ that the\napplication will need.</p>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n\
    <th>Template content</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Resources</td>\n\
    <td><img alt=\"web security group\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_web_security_group.png?raw=true\"\
    ></td>\n</tr>\n</tbody>\n</table>\n<p>Each resource is in its own nested block,\
    \ with the name appearing in the\nfirst line, and attributes as  further nested\
    \ elements</p>\n<p>Type defines the OpenStack resource to be built. The complete\
    \ list\nsupported can be found in the <a href=\"http://docs.openstack.org/developer/heat/template_guide/\"\
    >template guide</a>\nThis resource type will build a security group.</p>\n<p>Each\
    \ resource has its own attribute set. These are documented in the\ntemplate guide\
    \ - e.g.: for the <a href=\"http://docs.openstack.org/developer/heat/template_guide/cfn.html#AWS::EC2::SecurityGroup\"\
    ><code>AWS::EC2::SecurityGroup</code></a></p>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n\
    <th>Template content</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Resources</td>\n\
    <td><img alt=\"apache server\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_apache_server.png?raw=true\"></td>\n\
    </tr>\n</tbody>\n</table>\n<p>This resource type builds an instance with apache\
    \ installed.</p>\n<p>The <code>AWS::CloudFormation::Init</code> section provides\
    \ instructions as to what\nshould be done on the instance once it has booted.</p>\n\
    <p><code>Fn::Select</code> is a function that will select an item from a list.</p>\n\
    <p><code>get_param</code> is a function that returns the value of the named parameter\n\
    that was set by the user.</p>\n<p>The Heat manual contains a complete list of\
    \ <a href=\"http://docs.openstack.org/developer/heat/template_guide/hot_spec.html\"\
    >built in functions</a>\nCurrently NeCTAR supports releases up to Juno.</p>\n\
    <p>UserData is a mechanism by which information can be passed to an instance at\n\
    launch time. Typically this will be either a a shell script or a configuration\n\
    file.</p>\n<p>Note that the chosen image for the instance must have the <code>cloudinit</code>\n\
    packaged installed for <code>AWS::CloudFormation::Init</code> to work.</p>\n<table>\n\
    <thead>\n<tr>\n<th>Section</th>\n<th>Template content</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td>Resources</td>\n<td><img alt=\"apache server\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_wait_handle.png?raw=true\"></td>\n\
    </tr>\n</tbody>\n</table>\n<p>These resource types will notify the heat engine\
    \ when the software is\nfully installed on the instance.</p>\n<table>\n<thead>\n\
    <tr>\n<th>Section</th>\n<th>Template content</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td>Outputs</td>\n<td><img alt=\"apache server\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_outputs.png?raw=true\"></td>\n</tr>\n\
    </tbody>\n</table>\n<p>The outputs will show once the heat engine has finished\
    \ building the template.</p>"
  parent: 42
  sha1: 6be381c7cebba06fe61e16c46dcc06ecdf5ebc69
  title: Heat Template Walk Through
48:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:21-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Just enough YAML to read a template \n Heat templates are\
          \ written in a format named 'YAML'. This\nis a short guide that will, hopefully,\
          \ give you enough background to be able\nto work with heat templates. \n\
          \ YAML \n YAML is a human readable data format. \n It's not a markup language:\
          \ the format of the content gives the meaning. There\nare no embedded tags!\
          \ Hence indentation and justification are important. \n Comments are preceded\
          \ by a hash. A hash can appear anywhere on a line, and will\nmark everything\
          \ to the end of the line as being part of the comment. \n # this is a comment,\
          \ it won't be read as YAML input, but is useful for people reading the YAML\
          \ document \n Data is stored in key value maps, with the key value pairs\
          \ separated by a colon. \n date: 2014-01-14 \n String values can be indicated\
          \ by no quotes, single quotes, or double quotes. \n ``` \n first-name: 'Verity'\
          \ \n surname: \"Stobs\" \n publication: The Register \n ``` \n Hashes in\
          \ string values demarcated by quotes are not seen as the start of a comment.\
          \ \n example:   \"# this is not a comment\"    # but this is \n Double quoted\
          \ strings can contain escaped characters, such as '\\n' (newline). \n example:\
          \ \"This is \\n a new line\" \n '>' Indicates that the following block of\
          \ lines is a string value that will\nhave each line break folded into a\
          \ space. \n ``` \n example: > \n This\n\nhas a value # and it is 'This has\
          \ a value'\n \n ``` \n '|' (vertical bar) indicates that the following block\
          \ of lines is a string value \nthat will have the line breaks preserved.\
          \ \n ``` \n example: | \n This\n\nhas a value # and it is 'This\\nhas a\
          \ value'\n \n ```` \n The value associated with a key can be another map\
          \ of key value pairs. \n If this is the case then don't provide a value:\
          \ simply indent the new set of\nkey value pairs on the following lines.\
          \ So all lines prefixed by more space\nthan the parent key are contained\
          \ inside the parent key as a map of key value\npairs. \n All lines in the\
          \ same map have to have the same level of indentation. \n ``` \n name: \n\
          \ first: Verity\n\nlast: Stob\n \n ``` \n Key value pairs have an alternate\
          \ compact syntax: {key: value, key: value, ...} \n name: {first: Verity,\
          \ last: Stob} \n Lists are simply collections of ordered values: hence the\
          \ values in a list have\nno key. But the parent list must belong to a key.\
          \ \n List elements are indicated by a '-'. \n ``` \n publications: \n -\
          \ '.EXE'\n\n- 'Dr. Dobb's Journal'\n\n- 'The Register'\n \n ``` \n Lists\
          \ have an alternate compact syntax: [value, value, value,...]. \n publications:\
          \ ['.EXE', 'Dr. Dobb's Journal', 'The Register'] \n Lists and Maps can be\
          \ nested in any order. \n ``` \n name: \n first: Verity\n\nlast: Stob\n\n\
          publications:\n\n    - '.EXE'\n\n    - 'Dr. Dobb's Journal'\n\n    - 'The\
          \ Register'\n \n ``` "
        description: "<h1>Just enough YAML to read a template</h1>\n<p>Heat templates\
          \ are written in a format named '<a href=\"http://yaml.org/\">YAML</a>'.\
          \ This\nis a short guide that will, hopefully, give you enough background\
          \ to be able\nto work with heat templates.</p>\n<h2>YAML</h2>\n<p>YAML is\
          \ a human readable data format.</p>\n<p>It's not a markup language: the\
          \ format of the content gives the meaning. There\nare no embedded tags!\
          \ Hence indentation and justification are important.</p>\n<p>Comments are\
          \ preceded by a hash. A hash can appear anywhere on a line, and will\nmark\
          \ everything to the end of the line as being part of the comment.</p>\n\
          <p><code># this is a comment, it won't be read as YAML input, but is useful\
          \ for people reading the YAML document</code></p>\n<p>Data is stored in\
          \ key value maps, with the key value pairs separated by a colon.</p>\n<p><code>date:\
          \ 2014-01-14</code></p>\n<p>String values can be indicated by no quotes,\
          \ single quotes, or double quotes.</p>\n<p>```</p>\n<p>first-name: 'Verity'</p>\n\
          <p>surname: \"Stobs\"</p>\n<p>publication: The Register</p>\n<p>```</p>\n\
          <p>Hashes in string values demarcated by quotes are not seen as the start\
          \ of a comment.</p>\n<p><code>example:   \"# this is not a comment\"   \
          \ # but this is</code></p>\n<p>Double quoted strings can contain escaped\
          \ characters, such as <code>'\\n'</code> (newline).</p>\n<p><code>example:\
          \ \"This is \\n a new line\"</code></p>\n<p><code>'&gt;'</code> Indicates\
          \ that the following block of lines is a string value that will\nhave each\
          \ line break folded into a space.</p>\n<p>```</p>\n<p>example: &gt;</p>\n\
          <pre><code>This\n\nhas a value # and it is 'This has a value'\n</code></pre>\n\
          <p>```</p>\n<p><code>'|'</code> (vertical bar) indicates that the following\
          \ block of lines is a string value \nthat will have the line breaks preserved.</p>\n\
          <p>```</p>\n<p>example: |</p>\n<pre><code>This\n\nhas a value # and it is\
          \ 'This\\nhas a value'\n</code></pre>\n<p>````</p>\n<p>The value associated\
          \ with a key can be another map of key value pairs.</p>\n<p>If this is the\
          \ case then don't provide a value: simply indent the new set of\nkey value\
          \ pairs on the following lines. So all lines prefixed by more space\nthan\
          \ the parent key are contained inside the parent key as a map of key value\n\
          pairs.</p>\n<p>All lines in the same map have to have the same level of\
          \ indentation.</p>\n<p>```</p>\n<p>name:</p>\n<pre><code>first: Verity\n\
          \nlast: Stob\n</code></pre>\n<p>```</p>\n<p>Key value pairs have an alternate\
          \ compact syntax: <code>{key: value, key: value, ...}</code></p>\n<p><code>name:\
          \ {first: Verity, last: Stob}</code></p>\n<p>Lists are simply collections\
          \ of ordered values: hence the values in a list have\nno key. But the parent\
          \ list must belong to a key.</p>\n<p>List elements are indicated by a <code>'-'</code>.</p>\n\
          <p>```</p>\n<p>publications:</p>\n<pre><code>- '.EXE'\n\n- 'Dr. Dobb's Journal'\n\
          \n- 'The Register'\n</code></pre>\n<p>```</p>\n<p>Lists have an alternate\
          \ compact syntax: <code>[value, value, value,...]</code>.</p>\n<p><code>publications:\
          \ ['.EXE', 'Dr. Dobb's Journal', 'The Register']</code></p>\n<p>Lists and\
          \ Maps can be nested in any order.</p>\n<p>```</p>\n<p>name:</p>\n<pre><code>first:\
          \ Verity\n\nlast: Stob\n\npublications:\n\n    - '.EXE'\n\n    - 'Dr. Dobb's\
          \ Journal'\n\n    - 'The Register'\n</code></pre>\n<p>```</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:02-04:00'
          customer_folders: []
          description: Heat
          id: 6000190148
          is_default: false
          language_id: 6
          name: Heat
          parent_id: 6000190148
          position: 4
          updated_at: '2015-09-03T01:28:02-04:00'
          visibility: 1
        folder_id: 6000190148
        hits: 9
        id: 6000055385
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T22:50:52-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000055385
        position: 5
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Introduction to YAML
        updated_at: '2015-11-01T22:50:52-05:00'
        user_id: 6002464727
  html: "<h1>Just enough YAML to read a template</h1>\n<p>Heat templates are written\
    \ in a format named '<a href=\"http://yaml.org/\">YAML</a>'. This\nis a short\
    \ guide that will, hopefully, give you enough background to be able\nto work with\
    \ heat templates.</p>\n<h2>YAML</h2>\n<p>YAML is a human readable data format.</p>\n\
    <p>It's not a markup language: the format of the content gives the meaning. There\n\
    are no embedded tags! Hence indentation and justification are important.</p>\n\
    <p>Comments are preceded by a hash. A hash can appear anywhere on a line, and\
    \ will\nmark everything to the end of the line as being part of the comment.</p>\n\
    <p><code># this is a comment, it won't be read as YAML input, but is useful for\
    \ people reading the YAML document</code></p>\n<p>Data is stored in key value\
    \ maps, with the key value pairs separated by a colon.</p>\n<p><code>date: 2014-01-14</code></p>\n\
    <p>String values can be indicated by no quotes, single quotes, or double quotes.</p>\n\
    <p>```</p>\n<p>first-name: 'Verity'</p>\n<p>surname: \"Stobs\"</p>\n<p>publication:\
    \ The Register</p>\n<p>```</p>\n<p>Hashes in string values demarcated by quotes\
    \ are not seen as the start of a comment.</p>\n<p><code>example:   \"# this is\
    \ not a comment\"    # but this is</code></p>\n<p>Double quoted strings can contain\
    \ escaped characters, such as <code>'\\n'</code> (newline).</p>\n<p><code>example:\
    \ \"This is \\n a new line\"</code></p>\n<p><code>'&gt;'</code> Indicates that\
    \ the following block of lines is a string value that will\nhave each line break\
    \ folded into a space.</p>\n<p>```</p>\n<p>example: &gt;</p>\n<pre><code>This\n\
    \nhas a value # and it is 'This has a value'\n</code></pre>\n<p>```</p>\n<p><code>'|'</code>\
    \ (vertical bar) indicates that the following block of lines is a string value\
    \ \nthat will have the line breaks preserved.</p>\n<p>```</p>\n<p>example: |</p>\n\
    <pre><code>This\n\nhas a value # and it is 'This\\nhas a value'\n</code></pre>\n\
    <p>````</p>\n<p>The value associated with a key can be another map of key value\
    \ pairs.</p>\n<p>If this is the case then don't provide a value: simply indent\
    \ the new set of\nkey value pairs on the following lines. So all lines prefixed\
    \ by more space\nthan the parent key are contained inside the parent key as a\
    \ map of key value\npairs.</p>\n<p>All lines in the same map have to have the\
    \ same level of indentation.</p>\n<p>```</p>\n<p>name:</p>\n<pre><code>first:\
    \ Verity\n\nlast: Stob\n</code></pre>\n<p>```</p>\n<p>Key value pairs have an\
    \ alternate compact syntax: <code>{key: value, key: value, ...}</code></p>\n<p><code>name:\
    \ {first: Verity, last: Stob}</code></p>\n<p>Lists are simply collections of ordered\
    \ values: hence the values in a list have\nno key. But the parent list must belong\
    \ to a key.</p>\n<p>List elements are indicated by a <code>'-'</code>.</p>\n<p>```</p>\n\
    <p>publications:</p>\n<pre><code>- '.EXE'\n\n- 'Dr. Dobb's Journal'\n\n- 'The\
    \ Register'\n</code></pre>\n<p>```</p>\n<p>Lists have an alternate compact syntax:\
    \ <code>[value, value, value,...]</code>.</p>\n<p><code>publications: ['.EXE',\
    \ 'Dr. Dobb's Journal', 'The Register']</code></p>\n<p>Lists and Maps can be nested\
    \ in any order.</p>\n<p>```</p>\n<p>name:</p>\n<pre><code>first: Verity\n\nlast:\
    \ Stob\n\npublications:\n\n    - '.EXE'\n\n    - 'Dr. Dobb's Journal'\n\n    -\
    \ 'The Register'\n</code></pre>\n<p>```</p>"
  parent: 42
  sha1: ecd3e2fb4506878099b3828936b5fd6455e1cdd9
  title: Introduction to YAML
50:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T01:28:24-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Incoming network access to your machines is usually required.\
          \ Security Groups\nare how to add network access. If you can't reach your\
          \ instance by SSH to login\nor by browser if it runs a Webserver, additional\
          \ Security Group settings could\nbe needed. \n Adding Network Access \n\
          \ The default Security Group is empty and no incoming access is configured\
          \ until\nyou add rules to specify: \n \n which ports are available for connection\
          \ to your instance and... \n from which addresses your instance will accept\
          \ inbound traffic to the\n  open ports \n \n \n NOTE: If you do not specify\
          \ a security group at boot, the default security\ngroup will be applied\
          \ \n \n \n Each rule adds further access; it never cancels or overrides\
          \ another rule. \n Rules can have overlapping ranges and addresses. \n Rules\
          \ for the same ports and addresses can be added to more than one\n  Security\
          \ Group \n \n Removing Network Access \n To remove access to a port or from\
          \ an address, locate all security groups with\nrules relating to that port\
          \ or address, then \n \n remove or edit each applicable rule, OR \n do not\
          \ apply those Security Groups that contain the applicable rule(s) \n \n\
          \ Pre-Defined and Default Security Groups \n For Project Trials (pt-xxxx)\
          \ there are pre-defined security groups for\nconvenience. \n \n SSH opens\
          \ tcp port 22 to traffic from all sources (for logging via ssh) \n HTTP\
          \ opens tcp ports 80 and 443 to traffic from all sources (for\n  web servers)\
          \ \n ICMP opens all ICMP traffic from all sources (etc. to allow pinging\
          \ your\n  VMs IP address) \n \n For all other shared projects that are created\
          \ after an allocation request,\nthere is only the empty 'default' security\
          \ group at first. These Projects\nshare their security groups so all changes\
          \ should be made with caution as\nthey may affect instances by other users\
          \ sharing your Project. \n Managing Security Groups \n Sometimes it can\
          \ be convenient to organise rules into multiple Security\nGroups,\nfor example\
          \ \n \n apply only some or all groups depending on a instances purpose.\
          \ \n users experimenting with network access can remove groups and re-apply\n\
          \  them without re-creating rules each time \n testing rules on a temporary\
          \ security group and test Instance before\n  adding the same rules to Security\
          \ Groups already in use.\n  Rules can appear in more than one Security Group\
          \ \n \n Applying Security Groups \n Security Groups are most conveniently\
          \ applied before Launching your\ninstance. Multiple security groups can\
          \ be selected.\nSecurity Groups can also be added or removed on running\
          \ instances. \n Click 'Launch' then click the 'Security Groups' field. The\
          \ default group is\npre-selected. \n Outgoing traffic \n Outgoing traffic\
          \ is not blocked on any port:  connections that originate\nfrom your instance\
          \ to the outside world are not blocked by Nectar\nOpenStack configuration\
          \ \n \n Security Note \n Using the Research Cloud creates a publicly accessible\
          \ server (depending on\nSecurity Groups) and therefore that machine can\
          \ be exploited. All users must\nread & follow our Security Guidelines. \n\
          \ "
        description: "<p>Incoming network access to your machines is usually required.\
          \ Security Groups\nare how to add network access. If you can't reach your\
          \ instance by SSH to login\nor by browser if it runs a Webserver, additional\
          \ Security Group settings could\nbe needed.</p>\n<h2>Adding Network Access</h2>\n\
          <p>The default Security Group is empty and no incoming access is configured\
          \ until\nyou add rules to specify:</p>\n<ul>\n<li>which ports are available\
          \ for connection to your instance and...</li>\n<li>from which addresses\
          \ your instance will accept inbound traffic to the\n  open ports</li>\n\
          </ul>\n<blockquote>\n<p>NOTE: If you do not specify a security group at\
          \ boot, the default security\ngroup will be applied</p>\n</blockquote>\n\
          <ul>\n<li>Each rule adds further access; it never cancels or overrides another\
          \ rule.</li>\n<li>Rules can have overlapping ranges and addresses.</li>\n\
          <li>Rules for the same ports and addresses can be added to more than one\n\
          \  Security Group</li>\n</ul>\n<h2>Removing Network Access</h2>\n<p>To remove\
          \ access to a port or from an address, locate all security groups with\n\
          rules relating to that port or address, then</p>\n<ul>\n<li>remove or edit\
          \ each applicable rule, OR</li>\n<li>do not apply those Security Groups\
          \ that contain the applicable rule(s)</li>\n</ul>\n<h2>Pre-Defined and Default\
          \ Security Groups</h2>\n<p>For Project Trials (pt-xxxx) there are pre-defined\
          \ security groups for\nconvenience.</p>\n<ul>\n<li>SSH opens tcp port 22\
          \ to traffic from all sources (for logging via ssh)</li>\n<li>HTTP opens\
          \ tcp ports 80 and 443 to traffic from all sources (for\n  web servers)</li>\n\
          <li>ICMP opens all ICMP traffic from all sources (etc. to allow pinging\
          \ your\n  VMs IP address)</li>\n</ul>\n<p>For all other shared projects\
          \ that are created after an allocation request,\nthere is only the empty\
          \ 'default' security group at first. These Projects\nshare their security\
          \ groups so all changes should be made with caution as\nthey may affect\
          \ instances by other users sharing your Project.</p>\n<h2>Managing Security\
          \ Groups</h2>\n<p>Sometimes it can be convenient to organise rules into\
          \ multiple Security\nGroups,\nfor example</p>\n<ul>\n<li>apply only some\
          \ or all groups depending on a instances purpose.</li>\n<li>users experimenting\
          \ with network access can remove groups and re-apply\n  them without re-creating\
          \ rules each time</li>\n<li>testing rules on a temporary security group\
          \ and test Instance before\n  adding the same rules to Security Groups already\
          \ in use.\n  Rules can appear in more than one Security Group</li>\n</ul>\n\
          <h2>Applying Security Groups</h2>\n<p>Security Groups are most conveniently\
          \ applied before Launching your\ninstance. Multiple security groups can\
          \ be selected.\nSecurity Groups can also be added or removed on running\
          \ instances.</p>\n<p>Click 'Launch' then click the 'Security Groups' field.\
          \ The default group is\npre-selected.</p>\n<h2>Outgoing traffic</h2>\n<p>Outgoing\
          \ traffic is not blocked on any port:  connections that originate\nfrom\
          \ your instance to the outside world are not blocked by Nectar\nOpenStack\
          \ configuration</p>\n<blockquote>\n<p>Security Note</p>\n<p>Using the Research\
          \ Cloud creates a publicly accessible server (depending on\nSecurity Groups)\
          \ and therefore that machine can be exploited. All users must\nread &amp;\
          \ follow our Security Guidelines.</p>\n</blockquote>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:09-04:00'
          customer_folders: []
          description: NeCTAR Fundamentals
          id: 6000190155
          is_default: false
          language_id: 6
          name: NeCTAR Fundamentals
          parent_id: 6000190155
          position: 2
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190155
        hits: 6
        id: 6000055387
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-20T21:03:52-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000055387
        position: 3
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Security Groups
        updated_at: '2015-10-20T21:03:52-04:00'
        user_id: 6002464727
  html: "<p>Incoming network access to your machines is usually required. Security\
    \ Groups\nare how to add network access. If you can't reach your instance by SSH\
    \ to login\nor by browser if it runs a Webserver, additional Security Group settings\
    \ could\nbe needed.</p>\n<h2>Adding Network Access</h2>\n<p>The default Security\
    \ Group is empty and no incoming access is configured until\nyou add rules to\
    \ specify:</p>\n<ul>\n<li>which ports are available for connection to your instance\
    \ and...</li>\n<li>from which addresses your instance will accept inbound traffic\
    \ to the\n  open ports</li>\n</ul>\n<blockquote>\n<p>NOTE: If you do not specify\
    \ a security group at boot, the default security\ngroup will be applied</p>\n\
    </blockquote>\n<ul>\n<li>Each rule adds further access; it never cancels or overrides\
    \ another rule.</li>\n<li>Rules can have overlapping ranges and addresses.</li>\n\
    <li>Rules for the same ports and addresses can be added to more than one\n  Security\
    \ Group</li>\n</ul>\n<h2>Removing Network Access</h2>\n<p>To remove access to\
    \ a port or from an address, locate all security groups with\nrules relating to\
    \ that port or address, then</p>\n<ul>\n<li>remove or edit each applicable rule,\
    \ OR</li>\n<li>do not apply those Security Groups that contain the applicable\
    \ rule(s)</li>\n</ul>\n<h2>Pre-Defined and Default Security Groups</h2>\n<p>For\
    \ Project Trials (pt-xxxx) there are pre-defined security groups for\nconvenience.</p>\n\
    <ul>\n<li>SSH opens tcp port 22 to traffic from all sources (for logging via ssh)</li>\n\
    <li>HTTP opens tcp ports 80 and 443 to traffic from all sources (for\n  web servers)</li>\n\
    <li>ICMP opens all ICMP traffic from all sources (etc. to allow pinging your\n\
    \  VMs IP address)</li>\n</ul>\n<p>For all other shared projects that are created\
    \ after an allocation request,\nthere is only the empty 'default' security group\
    \ at first. These Projects\nshare their security groups so all changes should\
    \ be made with caution as\nthey may affect instances by other users sharing your\
    \ Project.</p>\n<h2>Managing Security Groups</h2>\n<p>Sometimes it can be convenient\
    \ to organise rules into multiple Security\nGroups,\nfor example</p>\n<ul>\n<li>apply\
    \ only some or all groups depending on a instances purpose.</li>\n<li>users experimenting\
    \ with network access can remove groups and re-apply\n  them without re-creating\
    \ rules each time</li>\n<li>testing rules on a temporary security group and test\
    \ Instance before\n  adding the same rules to Security Groups already in use.\n\
    \  Rules can appear in more than one Security Group</li>\n</ul>\n<h2>Applying\
    \ Security Groups</h2>\n<p>Security Groups are most conveniently applied before\
    \ Launching your\ninstance. Multiple security groups can be selected.\nSecurity\
    \ Groups can also be added or removed on running instances.</p>\n<p>Click 'Launch'\
    \ then click the 'Security Groups' field. The default group is\npre-selected.</p>\n\
    <h2>Outgoing traffic</h2>\n<p>Outgoing traffic is not blocked on any port:  connections\
    \ that originate\nfrom your instance to the outside world are not blocked by Nectar\n\
    OpenStack configuration</p>\n<blockquote>\n<p>Security Note</p>\n<p>Using the\
    \ Research Cloud creates a publicly accessible server (depending on\nSecurity\
    \ Groups) and therefore that machine can be exploited. All users must\nread &amp;\
    \ follow our Security Guidelines.</p>\n</blockquote>"
  parent: 26
  sha1: 1e7bfd723d5df5568137a1694554ae952820aa86
  title: Security Groups
52:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T02:45:31-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " This content is heavily sourced from the excellent eSpaces\
          \ glossary\nproduced by Steve Crawley at QCIF. \n The full glossary of OpenStack\
          \ terms can be found at: http://docs.openstack.org/glossary/content/glossary.html\
          \ \n The terms \n A \n AAF  - The Australian Access Federation. A\nShibboleth-based\
          \ federated authentication service for the Australian academic community.\n\
          Also the name of the organization that runs the AAF service. \n AARNET -\
          \ Australia's Academic & Research Network - the organization that runs the\n\
          networks connecting Australia's Universities and Research Organizations.\
          \ \n Access Control  - The process of determining if an (authenticated)\
          \ agent is\npermitted to perform some action.  Synonym: Authorization. \n\
          \ Access Group - OpenStack terminology that is a synonym for Security Group.\
          \ \n Access Rule  - An access rule allow network access to an\ninstance\
          \ from other hosts with a specified combination of protocol family (e.g.\
          \ TCP, UDP, UCMP),\nport number and address range. \n Account - OpenStack\
          \ terminology. A synonym for \"project\" and \"tenant\". \n Active Directory\
          \ (AD) - Microsoft's directory service product; essentially LDAP enhanced\
          \ with\nKerberos. Most Microsoft Windows environments will use AD to centrally\
          \ control\nauthentication. \n AMD - Advanced Micro Devices Inc. A manufacturer\
          \ of x86 and x86_64 compatible\nmicroprocessors. A direct competitor to\
          \ Intel. \n API - Application Programming Interface - an interface that\
          \ that is designed for\nprograms to use (As distinct from a user interface,\
          \ which is designed for\npeople to use). \n API Endpoint  - See Service\
          \ endpoint. \n apt  - The package manager used by the Debian\nfamily (Debian/Ubuntu/Mint)\
          \ of Linux distributions. \n Aspera - \"Aspera High-speed File Transfer\
          \ Software that moves the world's data at maximum\nspeed, regardless of\
          \ file size, transfer distance or network conditions\". \n Attach - An OpenStack\
          \ volume can be attached to an OpenStack instance to provide it with\nadditional\
          \ disk storage. \n Authentication - The process of establishing that an\
          \ agent (i.e. a person, or other entity) in a\ncomputer system is who they\
          \ say they are.  The simple username and password\nis the most familiar\
          \ means of authentication. \n Authorization - See Access Control. \n Availability\
          \ Zone (AZ) - a logical grouping of compute nodes within a region. \n AWS\
          \ - Amazon Web Services. \n Azure - Microsoft's commercial cloud computing\
          \ platform / service. \n B \n BCCVL - The Biodiversity and Climate Change\
          \ Virtual Laboratory. \n Boot - The boot (or \"bootstrap\") process is the\
          \ means by which the computer starts\nitself up after the power button is\
          \ pressed.  Ultimately booting is the process\nin which a computer goes\
          \ from having empty memory to having the operating\nsystem loaded and running.\
          \ \n Bricked - Colloquialism: describes a system that has been damaged in\
          \ a way that\npermanently locks out some or all functionality.  It's usually\
          \ the consequence\nof some kind of firmware update that fails to run properly,\
          \ or at all, meaning\nfurther remedial firmware updates are not possible.\
          \  The device is bricked when\nit can't be fixed and is effectively an expensive\
          \ square shaped \"brick\". \n C \n Canonical - Canonical Ltd. is a UK-based\
          \ privately held computer software company founded\n(and funded) by South\
          \ African entrepreneur Mark Shuttleworth to market\ncommercial support and\
          \ services for Ubuntu and related projects. \n CDS - RDSI terminology for\
          \ Collection Development Storage. \n Ceilometer - The OpenStack Ceilometer\
          \ project aims to deliver a unique point of\ncontact for billing systems\
          \ to acquire all of the measurements they need to\nestablish customer billing,\
          \ across all current OpenStack core components. \n It is also a means by\
          \ which to gather performance related metrics useful for the\ngeneral management\
          \ of the OpenStack environment in general. \n Cell - Cells are a means by\
          \ which to partition an OpenStack compute cloud into groups. \n At NeCTAR\
          \ each site runs a different configuration, as a resource cells in an\n\
          OpenStack Compute cells setup. This allows the NeCTAR nodes to do different\n\
          things such as span multiple data centers, or run off compute node storage\n\
          with a shared file system, or use on compute node storage with a non-shared\
          \ file\nsystem.  It's also a way to partition tenants and accounts. \n CentOS\
          \ - A community-based rebadging of RHEL distribution.  The result is \"\
          for free\", but with\n no support. \n Ceph - \"Ceph is a unified, distributed\
          \ storage system designed for excellent\nperformance, reliability and scalability.\"\
          \  Volume and object storage\nare typically implemented using Ceph. \n CephFS\
          \ - A project aimed and making Ceph work akin to a traditional filesystem\n\
          ala ext4 or xfs.  It is still considered experimental at this stage. \n\
          \ Chef - A recipe based system configuration framework. A main competitor\
          \ to Puppet, but\nalso now to other such systems such as Ansible and Salt.\
          \ \n CIDR Notation - Classless Internet Domain Routing notation - a concise\
          \ notation for writing IPv4\n or IPv6 network address ranges. \n Cinder\
          \ - The OpenStack Volume Storage management service. \n The \"Cloud\" -\
          \ A network of servers used to store, manage, and process data to achieve\n\
          efficiencies of scale in completing various computational tasks. \n CloudStor\
          \ - A free cloud-based file transfer service provided by AARNET. Allows\
          \ researchers\n to send and receive large files (up to 100Gb) or the big\
          \ brother CloudStor+\nwhich is an enhanced version of CloudStor that supports\
          \ secure long-term file\nstorage. \n Cluster-as-a-service - Implementing\
          \ HPC-style compute facilities on top of cloud computing\ninfrastructure.\
          \ \n Collection - RDSI Collection - Large data collection, usually formalised\
          \ with metadata and\nmade discoverable and accessible. Stored as part of\
          \ a data storage investment\nproject called RDSI (Research Data Storage\
          \ Infrastructure). Operators of the\ninfrastructure from RDSI project are\
          \ called RDSI nodes and may still refer to\ntheir storage facilities or\
          \ collections as 'RDSI storage' or 'RDSI collection'. \n Collection VM -\
          \ RDSI collections in QRIScloud are exposed via virtual machines that run\
          \ access\nservices; e.g. scp, sftp, rsync, WebDAV & GridFTP. \n Compute\
          \ Node   - OpenStack terminology for a physical computer\nused to run virtual\
          \ machines. It will typically have multiple CPUs and shared memory, and\n\
          one or more network interfaces.  It may also have on-node disc storage.\
          \ \n Container - General Computing - a means by which to run multiple \"\
          things\" inside a given\ncomputer and have those things isolated from each\
          \ other and the computer itself.\nSimilar in concept to Virtualisation,\
          \ however not as broadly applicable because\nthe containers must be the\
          \ same operating system as the host itself. \n Copyleft - A form of software\
          \ licensing that uses Copyright Law as the legal basis for\ngranting and\
          \ enforcing license terms. \n Creative Commons - A family of licenses originally\
          \ designed for creative (non-software) works,\nthat is often used for published\
          \ scientific data. \n CVL - Characterization Virtual Laboratory - A NeCTAR\
          \ Virtual Laboratory project. \n D \n DaRIS (Distributed and Reflective\
          \ Informatics System) - DaRIS\nis a subject-oriented informatics framework\
          \ and capability developed\nprimarily at the University of Melbourne. It\
          \ is built with the commercial\nMediaflux data operating system. DaRIS is\
          \ mainly used to supply a repository to\nmanage bio-medical imaging data.\
          \ \n Dashboard - The NeCTAR Dashboard is the main web-based interface for\
          \ managing NeCTAR\nvirtuals. The OpenStack component service for the dashboard\
          \ is called Horizon. \n Data Centre - A place where a large collection of\
          \ shared computing equipment is housed.\nThese expensive and high security\
          \ installations are often hot and noisy and\nconsume hard drives for breakfast.\
          \ \n Data Repository - A system or service that provides systematic data\
          \ management services. More\nthan just \"a shared fileserver\". \n .deb\
          \ - The Debian standard package format. See apt. \n Debian Family - Debian,\
          \ Ubuntu, Mint and many lesser known but similar linux distributions. \n\
          \ Distribution (Linux) - Refers to a (ideally) homoginized release of the\
          \ Linux Kernel and a\ncompendium of utilities, services and applications\
          \ that are nominally modified\nand tested to run well together, then given\
          \ an odd name like \"Mandriva\" or\n\"Suse\" or \"Debian\".  May inherit\
          \ concepts, frameworks and software\nfrom other distributions with or without\
          \ attribution or other reciprocal\ncontribution.  Typically distributions\
          \ attract a zealous user base\nwho will willingly fight each other to the\
          \ bitter death over not much at all.\nSome are funded by corporations, others\
          \ by well meaning techno hippies or not\nby anyone at all. \n Distro - A\
          \ contraction of \"Distribution\". \n DMF - DMF is a\nHierarchical Storage\
          \ Management (HSM) system by SGI designed for\nthe bulk storage of data.\
          \ The basic premise is that fast storage is expensive so\nwouldn't it be\
          \ cool if we could put only the data we actually use on the fast\nstorage,\
          \ and the rest can kind of trickle through less expensive storage layers.\n\
          So the hierarchy is in fact a sandwich of storage technologies (usually\
          \ ssd,\nhdd, tape) at each of which the storage cost per gigabyte decreases.\
          \  As data\nages through the layers the usual trade off is speed, so ideally\
          \ frequently used\ndata stays on the faster storage layer.  Conversely,\
          \ data which is seldom\naccessed is often archived off to tape where the\
          \ cost per gigabyte is very low.\nMagical filesystems ideally make all of\
          \ this invisible to users and\napplications.  Usually highly expensive and\
          \ complicated, it's pretty awesome\nwhen it works. \n Docker - A tool that\
          \ helps automate the deployment of applications\ninside software containers.\
          \ \n DropBox - A company that offers cloud storage that is easily used for\
          \ file sharing\nand collaboration. \n Drupal - A popular open source website\
          \ / content management system. \n DSpace - An open source application used\
          \ to create open access repositories\nfor digital content. \n DuraSpace\
          \ - The not-for-profit organization that manages the DSpace and Fedora Repository\n\
          projects. \n E \n EC2 - Amazon's \"Elastic Compute\" offering. \n EC2 Credentials\
          \ - One of the kinds of credentials you can obtain from the NeCTAR Dashboard.\n\
          It allows software written to work with the Amazon cloud to be used with\
          \ the OpenStack cloud. \n Elastic Computing  - Cloud computing resources\
          \ that can be\nadded to or removed from. \n Ephemeral Storage - Disk storage\
          \ associated with a NeCTAR instance that goes away when the\ninstance is\
          \ terminated. \n ERSA - eResearch SA runs the South Australian node of the\
          \ NeCTAR research cloud. \n eSpace - The UQ library managed system for UQ\
          \ research publications. \n eSpaces - A web-based collaboration system for\
          \ the Australian academic community. \n F \n FAQ - A Frequently Asked Question.\
          \ A software project or an IT support organization\nwill often create an\
          \ online FAQ document consisting of a number of such\nquestions, and their\
          \ answers. \n Fedora - RedHat's \"bleeding edge\" Linux distro (It was called\
          \ Fedora Core in early\nreleases). \n Fedora Repository -  The Flexible\
          \ Extensible Digital Object Repository Architecture\nwas developed for storing,\
          \ managing, and accessing digital content in the form of digital\nobjects.\
          \ The Fedora Repository Project (i.e., Fedora) implements the Fedora abstractions\n\
          in a open source software system. \n Fez - A front-end and administration\
          \ tool for the Fedora Repository. \n Flashlight - An RCC / QCIF HPC system\
          \ designed for data intensive computation. \n Flavor - An OpenStack term\
          \ for an instance sizing specification. Gives the amount of\nmemory, number\
          \ of VCPUs and ephemeral disc size. \n G \n Galaxy - A web based platform\
          \ for biomedical research. \n Ganglia - A distributed monitoring system.\
          \ \n Git - A popular distributed version control system. \n Github - A popular\
          \ free open-source project hosting site. \n Glance - OpenStack's Image store\
          \ service. \n Globus GridFTP - A data transfer protocol for high bandwidth\
          \ wide area networks. \n Gnocchi - Gnocchi is an OpenStack project that\
          \ provides a TDBaaS \n(Time Series Database as a Service). \n GNU - Stands\
          \ for \"GNU is Not Unix\".  Originally a project that aimed to provide a\n\
          complete open-source replacement for the (proprietary) AT&T Unix operating\n\
          system.  GNU now focus mostly on things \"above the kernel\". \n Google\
          \ Drive - A cloud storage service by Google that is easily used for file\n\
          sharing and collaboration. \n GPGPU - General Purpose computing using GPUs.\
          \ \n GPL - The GNU Public License. One of the most important open source\
          \ software\nlicenses. In fact there are a number of variants of GPL currently\
          \ in use:\nGPL2, GPL3, LGPL, Affero. \n GPU - Graphics Processing Unit -\
          \ primarily designed for high-speed graphics process\n(e.g. on a video card),\
          \ GPUs can also be exploited for certain kinds of\nparallel computation.\
          \ \n Grizzly - The name of an OpenStack release. \n Grizzly - A scalable\
          \ web server framework implemented in Java (not servlet based). \n GVL -\
          \ The Genomics Virtual Laboratory - A NeCTAR virtual laboratory project.\
          \ \n H \n Hard Reboot - A reboot in which no attempt is made to shut down\
          \ cleanly prior\nto booting. This has an increased risk of damage to file\
          \ systems or application\ndata on the instance. \n Havana - The name of\
          \ an OpenStack release. \n Heat - The orchestration service for OpenStack.\
          \ It is designed to launch multiple\ncomposite cloud applications based\
          \ on templates in the form of text files that\ncan be treated like code.\
          \ \n HFS - Hierarchical File Storage (usually) or Hierarchical File System.\
          \ \n HPC - High Performance Computing systems - typically refers to \"high\
          \ end\" computing\nhardware designed for doing \"large\" computational tasks.\
          \ \n HOW-TO - A document written for users that tries to explain \"how to\"\
          \ do a specific task. \n Hyper-V - Microsoft's main virtualization technology\
          \ offering. \n Hypervisor - The software that performs the core management\
          \ of virtual machines in a\nvirtualized computing system. \n I \n IaaS -\
          \ Infrastructure as a service (IaaS) is a type of cloud computing in which\
          \ a\nthird-party provider hosts virtualized computing resources over the\
          \ Internet. \n Icehouse - The name of an OpenStack release. \n Image - A\
          \ starting state for a new \"clean\" virtual machine.  Typical consists\
          \ of an\nimage of a file system with freshly installed operating system\
          \ and applications. \n Image Store - The place where OpenStack images are\
          \ held. \n Instance - OpenStack terminology for a virtual machine. \n Intel\
          \ - An American multinational that is one of the world's largest semiconductor\
          \ chip manufacturers. \n Intersect - An eResearch support agency based in\
          \ New South Wales. \n Internet - The Internet is a global system of interconnected\
          \ computer networks that use the Internet protocol\nsuite (TCP/IP) to link\
          \ to each other. \n IP - The Internet Protocol (IP) is the principal communications\
          \ protocol in the\nInternet protocol suite for relaying datagrams (also\
          \ knows as messages or\npackets) across network boundaries. Transmission\
          \ and the routing of IP packets\nare what makes the Internet work. \n IPv4\
          \ - The (currently) dominant version of IP in use at the moment.  IPv4 is\
          \ limited\nby its design to 232 distinct addresses. The IPv4 address space\
          \ is \"full\" in\nmost regions, and networking providers are rolling out\
          \ support of the next\ngeneration (IPv6). \n IPv6 - The successor version\
          \ of IP, which supports 264 addresses. \n iSCSI - Internet Small Computer\
          \ System Interface, an IP-based storage networking\nstandard for linking\
          \ data storage facilities. \n Issue Tracking System - An issue tracker is\
          \ a system that is used to record \"issues\" in a software\nproduct, and\
          \ track their resolution. Issues can include bugs, requested\nenhancements\
          \ or planned features. \n iVEC - iVEC used to be a high performance computing\
          \ facility located in Perth, but it was rebranded to the\nPawsey Supercomputing\
          \ Centre. \n J \n JSON - A light weight data-interchange format based on\
          \ a subset of the JavaScript programming language. \n Juju - An orchestration\
          \ framework from Ubuntu. \n Juno - The name of an OpenStack release. \n\
          \ K \n Kerberos - An authentication protocol used over networks. \n Kepler\
          \ - A computational workflow engine. \n Key Pair - A matching pair of public\
          \ and private keys; see public key encryption. \n Keystone - Keystone is\
          \ an OpenStack service that provides Identity, Token, Catalog and\nPolicy\
          \ services for use specifically by projects in the OpenStack family. \n\
          \ Kilo - The name of an OpenStack release. \n KVM - Kernel-based Virtual\
          \ Machine - a virtualization framework supported by\nmodern Linux kernels.\
          \ \n L \n Launch - OpenStack terminology for creating a new virtual machine.\
          \  There are\nmultiple steps in the launch process; e.g. \"scheduling\"\
          \ where the system\ndecides which cell, aggregate & compute node to put\
          \ the instance on, \"building\"\nwhich creates the virtual machines, allocates\
          \ network addresses, etcetera, and\n\"booting\" where the virtual machine\
          \ is started up. \n LDAP - The Lightweight Directory Access Protocol. A\
          \ distributed directory service. \n Liberty - The name of an OpenStack release\
          \ \n Linux - The leading open-source operating system, originally developed\
          \ by Linus\nTorsvalds.  (What we normally call Linux is better labelled\
          \ GNU / Linux,\nreflecting the fact that the core user libraries and utilities\
          \ are provided\nby GNU projects.) Linux is \"Unix-like\", but contains no\
          \ Unix code. \n LiveArc - Another name for Mediaflux. \n LTS - Long Term\
          \ Support - Ubuntu LTS releases have 5 years of support. Non-LTS releases\
          \ will have only 9 months\nof support. \n M \n Manila - An OpenStack project\
          \ that provides a shared file system service. \n MariaDB - A fork of MySQL\
          \ that is managed by the original MySQL founder and developers. \n MASSIVE\
          \ - Australian Sciences Imaging and Visualisation Environment. A GPU-based\
          \ HPC\nsystem run by Monash. \n MATLAB - Matrix Laboratory is a proprietary\
          \ numerical computing programming language. \n Mediaflux - An engine to\
          \ manage both data and metadata amongst distributed groups of people. \n\
          \ Memcache - A general purpose distributed memory caching system. \n Mint\
          \ - An Ubuntu based Linux distribution. \n Mitaka (\u4E09\u9DF9) - The name\
          \ of an OpenStack release \n MPI - Message Passing Interface - a standard\
          \ API for passing message in a parallel\ncomputing system. \n MySQL - An\
          \ open source SQL database system. Currently owned by Oracle Inc. \n MyTardis\
          \ - A program that allows users to store large datasets and to share them\
          \ with collaborators. \n N \n Nagios - Monitoring software. \n NCI - National\
          \ Computing Infrastructure and typically refers to one of the NCI systems.\
          \ \n NeCTAR - National eResearch Collaboration Tools and Resources project.\
          \ \n NeCTAR RC - The NeCTAR Research Cloud. \n NeCTAR VLs - The NeCTAR Virtual\
          \ Laboratory (VL) projects fund the development of\ncomputational science\
          \ facilities in the NeCTAR RC to support particular research\n domains.\
          \ \n Neutron - OpenStack \"networking as a service\". Neutron manages the\
          \ network interface\ndevices (e.g., vNICs) used by other Openstack instances.\
          \ Neutron supersedes the\n\"nova network\". \n NFS - \"Network File System\"\
          \ - a standard network protocol for making a file system on\n one machine\
          \ available on another across the network. \n Nimrod - Distributed computing\
          \ middleware. \n Node - NeCTAR terminology - a Node (or cloud node) is one\
          \ of the \"data centre\naggregations\" that comprise the NeCTAR research\
          \ cloud. \n The term \"node\" can also refer to a compute node. \n Node\
          \ Zero - The term once used to describe the NeCTAR node managed by the University\
          \ of Melbourne.\nIt is no longer used. \n Nova - The OpenStack cloud compute\
          \ service. \n Nova Cells - When this functionality is enabled, the hosts\
          \ in an OpenStack Compute cloud\nare partitioned into groups called cells.\
          \ \n Nova Network - The component that manages networking in Nova. It is\
          \ no longer in use at NeCTAR. \n NSP - Nectar Servers Program - provides\
          \ managed servers for eResearch projects. \n O \n Object - OpenStack terminology\
          \ for the unit of storage in object storage. \n Object Storage - OpenStack\
          \ terminology for a kind of data storage where \"objects\" are\nsaved and\
          \ retrieved using a RESTful API. Object Storage is typically replicated\n\
          with copies held at (at least) 3 locations. \n Object Store - A storage\
          \ architecture that manages data in terms of objects. \n Omero - An application\
          \ the visualization, management and analysis of biological\nmicroscope images.\
          \ \n Open Source - Open source refers to a computer program in which the\
          \ source code is available\nto the general public for use and/or modification\
          \ from its original design. \n OpenStack - \"..OpenStack is a free and open-source\
          \ cloud computing software platform. Users\nprimarily deploy it as an infrastructure\
          \ as a service (IaaS) solution. The\ntechnology consists of a series of\
          \ interrelated projects that control pools of\nprocessing, storage, and\
          \ networking resources throughout a data center which\nusers manage through\
          \ a web-based dashboard, command-line tools, or a RESTful\nAPI...\" Wikipedia.\
          \ \n OpenStack Clients - These are tools that you can install on a system\n\
          (e.g. your desktop or laptop) for interacting with the OpenStack services.\
          \ \n OpenSUSE - A Linux distribution. \n ORM - Object-Relational Mapping\
          \ - a mapping from a conventional (table-based)\ndatabase to object-oriented\
          \ programming. \n OS - A contraction of Operating System. \n Overcommit\
          \ - A way of dealing with resource shortages in a virtual computing framework.\n\
          Many virtual machines do not use all of the resources allocated to them\
          \ all of the\ntime, so when overcommitting more virtual resources are allocated\
          \ than the physical resources\ncan actually support. \n P \n Package manager\
          \  - A simple and elegant way to install software\non your Linux servers.\
          \ Conceptually remote \"repositories\" contain massive amounts of software\n\
          (called \"packages\") and by using the package manager, you can download\
          \ and install any of it\nusing a simple command. The package manager maintains\
          \ a local database that tracks which\npackages you have installed and manages\
          \ the additional packages your original package\ndepends on (the \"dependencies\"\
          ). Before package managers, managing dependencies was a\ndifficult and manual\
          \ process. \n Panasas - A company that builds network attached storage.\
          \ \n Password - A secret (e.g. known to the user) that is used for authentication\
          \ purposes. \n Passphrase - A longer secret that is typically used to secure\
          \ a private key. \n Pausey - The Pausey Centre runs the Western Australian\
          \ node of the NeCTAR research\ncloud. \n Plone - A popular website / content\
          \ management / wiki system.  Espaces is implemented\n on top of Plone. \n\
          \ Polaris - The tier 3 data center that houses the second stage QRIScloud\
          \ infrastructure. \n pQERN - The predecessor of QERN.  Now decommissioned.\
          \ \n Prentice - The first stage QRISCloud infrastructure was housed in the\
          \ UQ Prentice\nbuilding. \n Private Key - See key pair, public key encryption.\
          \ \n Project - The NeCTAR term for a \"resource container\"; i.e. what you\
          \ get when you are\ngranted a NeCTAR allocation. A project \"owns\" virtual\
          \ machine instances,\nsnapshots and various kinds of storage, and may be\
          \ shared by multiple users. \n Public Key - See key pair, public key encryption.\
          \ \n Public Key Encryption - A kind of encryption system based on \"one-way\
          \ functions\".\nThese systems depend on a public / private key pair, where\
          \ the public key is for\nencryption and the private key is for a decryption.\
          \ Knowledge of one key does\nnot allow you to determine the other one. \n\
          \ Puppet - An open source configuration tool. \n Putty  - A widely used\
          \ Windows tool for accessing a command shell on a remote\nUnix/Linux system.\
          \  Putty supports SSH. \n Python - A programming language. OpenStack is\
          \ largely implemented in Python. \n Q \n QCIF - Queensland Cyber Infrastructure\
          \ Foundation. \n Qcloud - The previous name for QRIScloud \n QERN - The\
          \ predecessor of Qcloud / QRIScloud implemented by QCIF.  (Decommissioned)\
          \ \n QRIScloud - The overall name for the QCIF's cloud computing systems.\
          \ \n QRIScompute - The \"compute\" component of QRIScloud. This includes\
          \ the QRIScloud NeCTAR\nresearch cloud facilities, special compute, elastic\
          \ compute and Kepler / Nimrod based\nservices. \n QRISdata - The \"data\"\
          \ component of QRIScloud. This includes QCIF's RDSI storage and data\n access\
          \ services. \n Quota - Operational limits defined in OpenStack to prevent\
          \ system capacity from\nbeing exhausted. \n R \n R - A programming language\
          \ \n RAID - Redundant Array of Independent Discs. A way of putting together\
          \ disc storage\nthat provides a degree of recoverability in the event of\
          \ the loss of disc media. \n RDA - Research Data Australia - A project of\
          \ ANDS. \n RDP -    Microsoft's Remote Desktop Protocol. \n RDSI - Research\
          \ Data Storage Infrastructure - A organization / project funding the\nprovision\
          \ of storage for \"research data collections\" to the Australian academic\n\
          community. \n Reboot - The act of restarting a computer. \n Rebuild - To\
          \ wipe and reinstall all of the software on a computer. \n ReDBox - An application\
          \ used to describe and share information about research data\ncollections.\
          \ \n Redhat Inc - A leading open source software vendor that produces RHEL\
          \ and Fedora, as\nwell as other software products. \n ReDS - RDSI terminology\
          \ - Research Data Storage. \n Replica - A copy of (say) a file or collection.\
          \ \n Replication - A process for creating or updating a replica. \n Rescue\
          \ - As system administration terminology: a procedure for recovering a\n\
          system that won't boot properly. \n Research Data Management - The topic\
          \ / problem-space of storing and curating\nthe data outputs of (academic)\
          \ research.  Aspects include safe storage, metadata,\ndata publication,\
          \ data discovery, access control & ethical considerations,\nprovenance &\
          \ audit, and long term archival considerations. \n Resize - The act of changing\
          \ a VM's flavor, thus allowing it to match the\ncurrent needs. \n REST /\
          \ RESTful  - Representational state transfer (REST)\nis an architectural\
          \ style for implementing web-based system. RESTful APIs\nare designed to\
          \ be easy to use by both web browsers (e.g. from Javascript)\nand from stand-alone\
          \ clients and servers. OpenStack APIs are RESTful. \n RESTful Service -\
          \ A service that exposes RESTful APIs. \n RHEL - Redhat Enterprise Linux.\
          \  The flagship product of RedHat Inc. \nRHEL distributions are \"paid-for-support\"\
          \ Linux aimed at the \"enterprise\ncomputing\" market. \n RHEL Family -\
          \ RHEL, CentOS and Scientific Linux (Amazon Linux is pretty similar). \n\
          \ RPM - The name of the package manager used by the Red Hat\nfamily of Linux\
          \ distribution. \n rsync - A standard Unix / Linux utility for incrementally\
          \ copying changes between\nfile trees; i.e. \"synchronizing\" them. \n S\
          \ \n S3 - S3 is an abbreviation for Simple Storage Solution, Amazon's Object\
          \ Store\noffering. \n SaaS - Software as a Service. \n Salt - A configuration\
          \ management tool written in the Python programming language. \n Samba -\
          \ An open source reimplementation of the Windows file server technology;\
          \ \ne.g. it can store Windows \"shares\" on Linux systems. \n SAML - Security\
          \ Assertion Markup Language (SAML, pronounced sam-el) is an\nXML-based data\
          \ format for exchanging authentication and authorization data between\n\
          parties. \n Scientific Linux / SL Scientific Linux - a rebadging of RHEL\
          \ produced by CERN.\nThe goal is to support \"scientific computing\". SL\
          \ is \"for free\", but with no support. \n scp - A Unix/Linux command for\
          \ copying files and file trees over SSH. \n Security Group  - A set of Access\
          \ Rules that\nmay be applied to one or more instances. \n At NeCTAR by the\
          \ default Security Group applied to new instances does not\ncontain an access\
          \ rule for SSH.  Meaning that new users often find their new\nvirtual machines\
          \ inaccessible via SSH until they add the appropriate access\nrule. \n Service\
          \ - In the software world, set of related functionalities that can be used\
          \ by different clients. \n Service Endpoint  - Typically a web URL that\
          \ can be used by an\napplication to access a service. Synonym: API endpoint.\
          \ \n sftp - Secure File Transfer Protocol is a protocol packaged with SSH\
          \ that\nallows you to transfer files between instances. \n Shared Memory\
          \ - Computer memory regions that can be accessed by different processors\n\
          (or processes) in computer system. \n Shibboleth - A the federated identity\
          \ solution on which the AAF is based. \n Shutdown - A shutdown VM is gracefully\
          \ powered off, but its disk remains on the host\nmachine, ready to be restarted\
          \ from there. \n SLES - SUSE Linux Enterprise Server - a paid-for Linux\
          \ distro. \n SMB - The Windows network file system protocol. \n Snapshot\
          \ - OpenStack terminology for an image produced from an active (typically\
          \ not\n\"clean\") virtual instance. \n SSH  - A protocol and tools for establishing\
          \ secure \"shell\" sessions\nover the network.  SSH encrypts the data transferred,\
          \ and supports user authentication\nusing public/private keys.  See also:\
          \ Putty. \n Solaris - A proprietary Unix system produced by Sun Microsystems,\
          \ and now Oracle. \n Subversion (SVN) - A widely used non-distributed version\
          \ control system. \n Suspend - A suspended VM has its state written to the\
          \ host machines disk,\nready to be resumed from there. \n Swift - The OpenStack\
          \ object storage API, and associated command-line tool. \n T \n tar - The\
          \ standard file archive utility (and format) for Unix, Linux and\nrelated\
          \ platforms.  (Analogous to ZIP files on Windows.) \n Telemetry An integrated\
          \ project that provides metering and measuring facilities for \nOpenStack.\
          \ The project name of Telemetry is ceilometer. \n Tenant - Openstack terminology\
          \ for \"isolated resource containers forming the\nprincipal organizational\
          \ structure within the Compute service\". Note: NeCTAR uses /\nprefers the\
          \ term \"project\". \n Terminate - OpenStack terminology for permanently\
          \ destroy an Instance and its\nephemeral storage. \n TERN - The Terrestrial\
          \ Ecosystem Research Network connects ecosystem scientists\nand enables\
          \ them to collect, contribute, store, share and integrate data across\n\
          disciplines. \n Ticket - Synonym for support ticket. \n Tier n Support -\
          \ IT support terminology: support functions are typically classified\nby\
          \ the 4 tiers below. The 'n' references the fact that are multiple tiers.\
          \ \n \n Tier 0 is user self-help - e.g. using online help, reading user\
          \ guides, HOW-TOs\n  and FAQs, and \"googling\". \n Tier 1 is non-technical\
          \ support - e.g. problem triage, providing solutions for\n  common mistakes,\
          \ and answering simple questions. \n Tier 2 is technical support - e.g.\
          \ initial diagnosis of more complicated problems,\n  solving some of them,\
          \ and answering technical problems. \n Tier 3 is deep technical support\
          \ - e.g. things that the other tiers can answer. \n \n Tiered Storage -\
          \  Different categories of data are assigned to different types\nof storage\
          \ media. This is ordinarily done to reduce storage costs. \n TPAC - The\
          \ Tasmanian Partnership for Advanced Computing. \n TurnKey Linux - A Debian\
          \ Linux based virtual appliance library. \n U \n Ubuntu - A Debian based\
          \ Linux distribution produced by Canonical, originally aimed\nat the desktop\
          \ computing market. But now widely used in the cloud. Ubuntu is for-free,\n\
          though paid support is available. \n Unix - A proprietary operating system\
          \ for \"minicomputers\" originally written by Bell\nLabs / AT&T in the 1970s.\
          \  Many versions of Unix have been produced by many\ncompanies over the\
          \ years. \n URI / URL - Universal Resource Identifier / Universal Resource\
          \ Locator. \n V \n V3 Alliance* - An eResearch support agency based in Victoria.\
          \ \n Vagrant - A desktop virtualization framework aimed at supporting transient\
          \ virtual\nmachine instances. \n VCPU - OpenStack terminology for a Virtual\
          \ CPU. \n VCPU Hours - The number of VCPU's in an instance multiplied by\
          \ the hours used. \n VicNode - A service to all Victorian researchers and\
          \ their collaborators to store\nand share research data. \n Virtual Barrine\
          \ - A project to use \"cluster as a service\" technology to build a cluster\
          \ in\nQRIScloud. \n Virtual Machine (VM) - A \"computational element\" that\
          \ \"thinks\" it is a real\ncomputer with control of its own (virtual) resources,\
          \ but is actually running under\nthe control of something else.  In the\
          \ cloud computing context, virtual machines\nrun directly on real computer\
          \ hardware (i.e. they execute native instructions at\nnormal clock speed),\
          \ but access to system resources is \"mediated\". \n Virtual Memory - A\
          \ memory management technique that maps the memory addresses\nused by a\
          \ program to physical memory. \n VM - A contraction of \"virtual machine\"\
          . \n VMware - A commercial virtualization company, and the name of their\
          \ main\nproduct line. \n VNC - Virtual Network Computing is a system to\
          \ share graphical desktops across\nmachines. \n Volume - A volume is a storage\
          \ area with a single file system on it. \n W \n Wiki - A website that supports\
          \ the collaborative modification of its content via\na web browser. \n Windows\
          \ - A generic name for the Microsoft operating systems. \n WinSCP - A popular\
          \ open source file transfer tool for Windows. \n Workflow - An orchestrated\
          \ pattern of activity that can both be communicated\nand repeatedly run.\
          \ \n X \n X11 - A graphical user interface that can be used on NeCTAR instances.\
          \ \n x86 - The most common instruction set architecture for 32 bit computers.\
          \ \n x86-64 - The 64bit version of x86. \n XML - Stands for eXtensible Markup\
          \ Language: a way to markup text in a way\nthat is readable by both humans\
          \ and computers. \n Xen - A virtualization framework supported by modern\
          \ Linux kernels. \n Y \n Yum - A package manager used on RHEL family and\
          \ Fedora\ndistributions. \n Z \n Zope A framework for building web applications\
          \ based on Python. "
        description: "<p>This content is heavily sourced from the excellent <a href=\"\
          https://espaces.edu.au/vwrangler/nectar-openstack-glossary\">eSpaces glossary</a>\n\
          produced by Steve Crawley at QCIF.</p>\n<p>The full glossary of OpenStack\
          \ terms can be found at: <a href=\"http://docs.openstack.org/glossary/content/glossary.html\"\
          >http://docs.openstack.org/glossary/content/glossary.html</a></p>\n<h2>The\
          \ terms</h2>\n<h3>A</h3>\n<p><strong>AAF</strong> <a name=\"AAF\"></a> -\
          \ The <a href=\"http://aaf.edu.au/\">Australian Access Federation</a>. A\n\
          Shibboleth-based federated authentication service for the Australian academic\
          \ community.\nAlso the name of the organization that runs the AAF service.</p>\n\
          <p><strong>AARNET</strong> - Australia's Academic &amp; Research Network\
          \ - the organization that runs the\nnetworks connecting Australia's Universities\
          \ and Research Organizations.</p>\n<p><strong>Access Control</strong> <a\
          \ name=\"AccessControl\"></a> - The process of determining if an (authenticated)\
          \ agent is\npermitted to perform some action.  Synonym: Authorization.</p>\n\
          <p><strong>Access Group</strong> - OpenStack terminology that is a synonym\
          \ for <a href=\"#SecurityGroup\">Security Group</a>.</p>\n<p><strong>Access\
          \ Rule</strong> <a name=\"AccessRule\"></a> - An access rule allow network\
          \ access to an\ninstance from other hosts with a specified combination of\
          \ protocol family (e.g. TCP, UDP, UCMP),\nport number and address range.</p>\n\
          <p><strong>Account</strong> - OpenStack terminology. A synonym for \"project\"\
          \ and \"tenant\".</p>\n<p><strong>Active Directory (AD)</strong> - Microsoft's\
          \ directory service product; essentially LDAP enhanced with\nKerberos. Most\
          \ Microsoft Windows environments will use AD to centrally control\nauthentication.</p>\n\
          <p><strong>AMD</strong> - Advanced Micro Devices Inc. A manufacturer of\
          \ x86 and x86_64 compatible\nmicroprocessors. A direct competitor to Intel.</p>\n\
          <p><strong>API</strong> - Application Programming Interface - an interface\
          \ that that is designed for\nprograms to use (As distinct from a user interface,\
          \ which is designed for\npeople to use).</p>\n<p><strong>API Endpoint</strong>\
          \ <a name=\"ApiEndpoint\"></a> - See <a href=\"#ServiceEndpoint\">Service\
          \ endpoint</a>.</p>\n<p><strong><code>apt</code></strong> <a name=\"apt\"\
          ></a> - The <a href=\"#PackageManager\">package manager</a> used by the\
          \ Debian\nfamily (Debian/Ubuntu/Mint) of Linux distributions.</p>\n<p><strong>Aspera</strong>\
          \ - \"Aspera High-speed File Transfer Software that moves the world's data\
          \ at maximum\nspeed, regardless of file size, transfer distance or network\
          \ conditions\".</p>\n<p><strong>Attach</strong> - An OpenStack volume can\
          \ be attached to an OpenStack instance to provide it with\nadditional disk\
          \ storage.</p>\n<p><strong>Authentication</strong> - The process of establishing\
          \ that an agent (i.e. a person, or other entity) in a\ncomputer system is\
          \ who they say they are.  The simple username and password\nis the most\
          \ familiar means of authentication.</p>\n<p><strong>Authorization</strong>\
          \ - See <a href=\"#AccessControl\">Access Control</a>.</p>\n<p><strong>Availability\
          \ Zone (AZ)</strong> - a logical grouping of compute nodes within a region.</p>\n\
          <p><strong>AWS</strong> - Amazon Web Services.</p>\n<p><strong>Azure</strong>\
          \ - Microsoft's commercial cloud computing platform / service.</p>\n<h3>B</h3>\n\
          <p><strong>BCCVL</strong> - The Biodiversity and Climate Change Virtual\
          \ Laboratory.</p>\n<p><strong>Boot</strong> - The boot (or \"bootstrap\"\
          ) process is the means by which the computer starts\nitself up after the\
          \ power button is pressed.  Ultimately booting is the process\nin which\
          \ a computer goes from having empty memory to having the operating\nsystem\
          \ loaded and running.</p>\n<p><strong>Bricked</strong> - Colloquialism:\
          \ describes a system that has been damaged in a way that\npermanently locks\
          \ out some or all functionality.  It's usually the consequence\nof some\
          \ kind of firmware update that fails to run properly, or at all, meaning\n\
          further remedial firmware updates are not possible.  The device is bricked\
          \ when\nit can't be fixed and is effectively an expensive square shaped\
          \ \"brick\".</p>\n<h3>C</h3>\n<p><strong>Canonical</strong> - Canonical\
          \ Ltd. is a UK-based privately held computer software company founded\n\
          (and funded) by South African entrepreneur Mark Shuttleworth to market\n\
          commercial support and services for Ubuntu and related projects.</p>\n<p><strong>CDS</strong>\
          \ - RDSI terminology for Collection Development Storage.</p>\n<p><strong>Ceilometer</strong>\
          \ - The OpenStack Ceilometer project aims to deliver a unique point of\n\
          contact for billing systems to acquire all of the measurements they need\
          \ to\nestablish customer billing, across all current OpenStack core components.</p>\n\
          <p>It is also a means by which to gather performance related metrics useful\
          \ for the\ngeneral management of the OpenStack environment in general.</p>\n\
          <p><strong>Cell</strong> - Cells are a means by which to partition an OpenStack\
          \ compute cloud into groups.</p>\n<p>At NeCTAR each site runs a different\
          \ configuration, as a resource cells in an\nOpenStack Compute cells setup.\
          \ This allows the NeCTAR nodes to do different\nthings such as span multiple\
          \ data centers, or run off <a href=\"#ComputeNode\">compute node</a> storage\n\
          with a shared file system, or use on compute node storage with a non-shared\
          \ file\nsystem.  It's also a way to partition tenants and accounts.</p>\n\
          <p><strong>CentOS</strong> - A community-based rebadging of RHEL distribution.\
          \  The result is \"for free\", but with\n no support.</p>\n<p><strong>Ceph</strong>\
          \ - \"Ceph is a unified, distributed storage system designed for excellent\n\
          performance, reliability and scalability.\"  Volume and object storage\n\
          are typically implemented using Ceph.</p>\n<p><strong>CephFS</strong> -\
          \ A project aimed and making Ceph work akin to a traditional filesystem\n\
          ala ext4 or xfs.  It is still considered experimental at this stage.</p>\n\
          <p><strong>Chef</strong> - A recipe based system configuration framework.\
          \ A main competitor to Puppet, but\nalso now to other such systems such\
          \ as Ansible and Salt.</p>\n<p><strong>CIDR Notation</strong> - Classless\
          \ Internet Domain Routing notation - a concise notation for writing IPv4\n\
          \ or IPv6 network address ranges.</p>\n<p><strong>Cinder</strong> - The\
          \ OpenStack Volume Storage management service.</p>\n<p><strong>The \"Cloud\"\
          </strong> - A network of servers used to store, manage, and process data\
          \ to achieve\nefficiencies of scale in completing various computational\
          \ tasks.</p>\n<p><strong>CloudStor</strong> - A free cloud-based file transfer\
          \ service provided by AARNET. Allows researchers\n to send and receive large\
          \ files (up to 100Gb) or the big brother CloudStor+\nwhich is an enhanced\
          \ version of CloudStor that supports secure long-term file\nstorage.</p>\n\
          <p><strong>Cluster-as-a-service</strong> - Implementing HPC-style compute\
          \ facilities on top of cloud computing\ninfrastructure.</p>\n<p><strong>Collection</strong>\
          \ - RDSI Collection - Large data collection, usually formalised with metadata\
          \ and\nmade discoverable and accessible. Stored as part of a data storage\
          \ investment\nproject called RDSI (Research Data Storage Infrastructure).\
          \ Operators of the\ninfrastructure from RDSI project are called RDSI nodes\
          \ and may still refer to\ntheir storage facilities or collections as 'RDSI\
          \ storage' or 'RDSI collection'.</p>\n<p><strong>Collection VM</strong>\
          \ - RDSI collections in QRIScloud are exposed via virtual machines that\
          \ run access\nservices; e.g. scp, sftp, rsync, WebDAV &amp; GridFTP.</p>\n\
          <p><strong>Compute Node</strong>  <a name=\"ComputeNode\"></a> - OpenStack\
          \ terminology for a physical computer\nused to run virtual machines. It\
          \ will typically have multiple CPUs and shared memory, and\none or more\
          \ network interfaces.  It may also have on-node disc storage.</p>\n<p><strong>Container</strong>\
          \ - General Computing - a means by which to run multiple \"things\" inside\
          \ a given\ncomputer and have those things isolated from each other and the\
          \ computer itself.\nSimilar in concept to Virtualisation, however not as\
          \ broadly applicable because\nthe containers must be the same operating\
          \ system as the host itself.</p>\n<p><strong>Copyleft</strong> - A form\
          \ of software licensing that uses Copyright Law as the legal basis for\n\
          granting and enforcing license terms.</p>\n<p><strong>Creative Commons</strong>\
          \ - A family of licenses originally designed for creative (non-software)\
          \ works,\nthat is often used for published scientific data.</p>\n<p><strong>CVL</strong>\
          \ - Characterization Virtual Laboratory - A NeCTAR Virtual Laboratory project.</p>\n\
          <h3>D</h3>\n<p><strong>DaRIS (Distributed and Reflective Informatics System)</strong>\
          \ - <a href=\"http://nsp.nectar.org.au/wiki-its-r/doku.php?id=data_management:daris:about\"\
          >DaRIS</a>\nis a subject-oriented informatics framework and capability developed\n\
          primarily at the University of Melbourne. It is built with the commercial\n\
          Mediaflux data operating system. DaRIS is mainly used to supply a repository\
          \ to\nmanage bio-medical imaging data.</p>\n<p><strong>Dashboard</strong>\
          \ - The NeCTAR Dashboard is the main web-based interface for managing NeCTAR\n\
          virtuals. The OpenStack component service for the dashboard is called Horizon.</p>\n\
          <p><strong>Data Centre</strong> - A place where a large collection of shared\
          \ computing equipment is housed.\nThese expensive and high security installations\
          \ are often hot and noisy and\nconsume hard drives for breakfast.</p>\n\
          <p><strong>Data Repository</strong> - A system or service that provides\
          \ systematic data management services. More\nthan just \"a shared fileserver\"\
          .</p>\n<p><strong><code>.deb</code></strong> - The Debian standard package\
          \ format. See <a href=\"#apt\">apt</a>.</p>\n<p><strong>Debian Family</strong>\
          \ - Debian, Ubuntu, Mint and many lesser known but similar linux distributions.</p>\n\
          <p><strong>Distribution (Linux)</strong> - Refers to a (ideally) homoginized\
          \ release of the Linux Kernel and a\ncompendium of utilities, services and\
          \ applications that are nominally modified\nand tested to run well together,\
          \ then given an odd name like \"Mandriva\" or\n\"Suse\" or \"Debian\". \
          \ May inherit concepts, frameworks and software\nfrom other distributions\
          \ with or without attribution or other reciprocal\ncontribution.  Typically\
          \ distributions attract a zealous user base\nwho will willingly fight each\
          \ other to the bitter death over not much at all.\nSome are funded by corporations,\
          \ others by well meaning techno hippies or not\nby anyone at all.</p>\n\
          <p><strong>Distro</strong> - A contraction of \"Distribution\".</p>\n<p><strong>DMF</strong>\
          \ - <a href=\"https://www.sgi.com/products/storage/idm/dmf.html\">DMF</a>\
          \ is a\nHierarchical Storage Management (HSM) system by SGI designed for\n\
          the bulk storage of data. The basic premise is that fast storage is expensive\
          \ so\nwouldn't it be cool if we could put only the data we actually use\
          \ on the fast\nstorage, and the rest can kind of trickle through less expensive\
          \ storage layers.\nSo the hierarchy is in fact a sandwich of storage technologies\
          \ (usually ssd,\nhdd, tape) at each of which the storage cost per gigabyte\
          \ decreases.  As data\nages through the layers the usual trade off is speed,\
          \ so ideally frequently used\ndata stays on the faster storage layer.  Conversely,\
          \ data which is seldom\naccessed is often archived off to tape where the\
          \ cost per gigabyte is very low.\nMagical filesystems ideally make all of\
          \ this invisible to users and\napplications.  Usually highly expensive and\
          \ complicated, it's pretty awesome\nwhen it works.</p>\n<p><strong>Docker</strong>\
          \ - A tool that helps automate the deployment of applications\ninside software\
          \ containers.</p>\n<p><strong>DropBox</strong> - A company that offers cloud\
          \ storage that is easily used for file sharing\nand collaboration.</p>\n\
          <p><strong>Drupal</strong> - A popular open source website / content management\
          \ system.</p>\n<p><strong>DSpace</strong> - An open source application used\
          \ to create open access repositories\nfor digital content.</p>\n<p><strong>DuraSpace</strong>\
          \ - The not-for-profit organization that manages the DSpace and Fedora Repository\n\
          projects.</p>\n<h3>E</h3>\n<p><strong>EC2</strong> - Amazon's \"<a href=\"\
          #ElasticComputing\">Elastic Compute</a>\" offering.</p>\n<p><strong>EC2\
          \ Credentials</strong> - One of the kinds of credentials you can obtain\
          \ from the NeCTAR Dashboard.\nIt allows software written to work with the\
          \ Amazon cloud to be used with the OpenStack cloud.</p>\n<p><strong>Elastic\
          \ Computing</strong> <a name=\"ElasticComputing\"></a> - Cloud computing\
          \ resources that can be\nadded to or removed from.</p>\n<p><strong>Ephemeral\
          \ Storage</strong> - Disk storage associated with a NeCTAR instance that\
          \ goes away when the\ninstance is terminated.</p>\n<p><strong>ERSA</strong>\
          \ - eResearch SA runs the South Australian node of the NeCTAR research cloud.</p>\n\
          <p><strong>eSpace</strong> - The UQ library managed system for UQ research\
          \ publications.</p>\n<p><strong>eSpaces</strong> - A web-based collaboration\
          \ system for the Australian academic community.</p>\n<h3>F</h3>\n<p><strong>FAQ</strong>\
          \ - A Frequently Asked Question. A software project or an IT support organization\n\
          will often create an online FAQ document consisting of a number of such\n\
          questions, and their answers.</p>\n<p><strong>Fedora</strong> - RedHat's\
          \ \"bleeding edge\" Linux distro (It was called Fedora Core in early\nreleases).</p>\n\
          <p><strong>Fedora Repository</strong> -  The Flexible Extensible Digital\
          \ Object Repository Architecture\nwas developed for storing, managing, and\
          \ accessing digital content in the form of digital\nobjects. The Fedora\
          \ Repository Project (i.e., Fedora) implements the Fedora abstractions\n\
          in a open source software system.</p>\n<p><strong>Fez</strong> - A front-end\
          \ and administration tool for the Fedora Repository.</p>\n<p><strong>Flashlight</strong>\
          \ - An RCC / QCIF HPC system designed for data intensive computation.</p>\n\
          <p><strong>Flavor</strong> - An OpenStack term for an instance sizing specification.\
          \ Gives the amount of\nmemory, number of VCPUs and ephemeral disc size.</p>\n\
          <h3>G</h3>\n<p><strong>Galaxy</strong> - A web based platform for biomedical\
          \ research.</p>\n<p><strong>Ganglia</strong> - A distributed monitoring\
          \ system.</p>\n<p><strong>Git</strong> - A popular distributed version control\
          \ system.</p>\n<p><strong>Github</strong> - A popular free open-source project\
          \ hosting site.</p>\n<p><strong>Glance</strong> - OpenStack's Image store\
          \ service.</p>\n<p><strong>Globus GridFTP</strong> - A data transfer protocol\
          \ for high bandwidth wide area networks.</p>\n<p><strong>Gnocchi</strong>\
          \ - Gnocchi is an OpenStack project that provides a TDBaaS \n(Time Series\
          \ Database as a Service).</p>\n<p><strong>GNU</strong> - Stands for \"GNU\
          \ is Not Unix\".  Originally a project that aimed to provide a\ncomplete\
          \ open-source replacement for the (proprietary) AT&amp;T Unix operating\n\
          system.  GNU now focus mostly on things \"above the kernel\".</p>\n<p><strong>Google\
          \ Drive</strong> - A cloud storage service by Google that is easily used\
          \ for file\nsharing and collaboration.</p>\n<p><strong>GPGPU</strong> -\
          \ General Purpose computing using GPUs.</p>\n<p><strong>GPL</strong> - The\
          \ GNU Public License. One of the most important open source software\nlicenses.\
          \ In fact there are a number of variants of GPL currently in use:\nGPL2,\
          \ GPL3, LGPL, Affero.</p>\n<p><strong>GPU</strong> - Graphics Processing\
          \ Unit - primarily designed for high-speed graphics process\n(e.g. on a\
          \ video card), GPUs can also be exploited for certain kinds of\nparallel\
          \ computation.</p>\n<p><strong>Grizzly</strong> - The name of an OpenStack\
          \ release.</p>\n<p><strong>Grizzly</strong> - A scalable web server framework\
          \ implemented in Java (not servlet based).</p>\n<p><strong>GVL</strong>\
          \ - The Genomics Virtual Laboratory - A NeCTAR virtual laboratory project.</p>\n\
          <h3>H</h3>\n<p><strong>Hard Reboot</strong> - A reboot in which no attempt\
          \ is made to shut down cleanly prior\nto booting. This has an increased\
          \ risk of damage to file systems or application\ndata on the instance.</p>\n\
          <p><strong>Havana</strong> - The name of an OpenStack release.</p>\n<p><strong>Heat</strong>\
          \ - The orchestration service for OpenStack. It is designed to launch multiple\n\
          composite cloud applications based on templates in the form of text files\
          \ that\ncan be treated like code.</p>\n<p><strong>HFS</strong> - Hierarchical\
          \ File Storage (usually) or Hierarchical File System.</p>\n<p><strong>HPC</strong>\
          \ - High Performance Computing systems - typically refers to \"high end\"\
          \ computing\nhardware designed for doing \"large\" computational tasks.</p>\n\
          <p><strong>HOW-TO</strong> - A document written for users that tries to\
          \ explain \"how to\" do a specific task.</p>\n<p><strong>Hyper-V</strong>\
          \ - Microsoft's main virtualization technology offering.</p>\n<p><strong>Hypervisor</strong>\
          \ - The software that performs the core management of virtual machines in\
          \ a\nvirtualized computing system.</p>\n<h3>I</h3>\n<p><strong>IaaS</strong>\
          \ - Infrastructure as a service (IaaS) is a type of cloud computing in which\
          \ a\nthird-party provider hosts virtualized computing resources over the\
          \ Internet.</p>\n<p><strong>Icehouse</strong> - The name of an OpenStack\
          \ release.</p>\n<p><strong>Image</strong> - A starting state for a new \"\
          clean\" virtual machine.  Typical consists of an\nimage of a file system\
          \ with freshly installed operating system and applications.</p>\n<p><strong>Image\
          \ Store</strong> - The place where OpenStack images are held.</p>\n<p><strong>Instance</strong>\
          \ - OpenStack terminology for a virtual machine.</p>\n<p><strong>Intel</strong>\
          \ - An American multinational that is one of the world's largest semiconductor\
          \ chip manufacturers.</p>\n<p><strong>Intersect</strong> - An eResearch\
          \ support agency based in New South Wales.</p>\n<p><strong>Internet</strong>\
          \ - The Internet is a global system of interconnected computer networks\
          \ that use the Internet protocol\nsuite (TCP/IP) to link to each other.</p>\n\
          <p><strong>IP</strong> - The Internet Protocol (IP) is the principal communications\
          \ protocol in the\nInternet protocol suite for relaying datagrams (also\
          \ knows as messages or\npackets) across network boundaries. Transmission\
          \ and the routing of IP packets\nare what makes the Internet work.</p>\n\
          <p><strong>IPv4</strong> - The (currently) dominant version of IP in use\
          \ at the moment.  IPv4 is limited\nby its design to 2<sup>32</sup> distinct\
          \ addresses. The IPv4 address space is \"full\" in\nmost regions, and networking\
          \ providers are rolling out support of the next\ngeneration (IPv6).</p>\n\
          <p><strong>IPv6</strong> - The successor version of IP, which supports 2<sup>64</sup>\
          \ addresses.</p>\n<p><strong>iSCSI</strong> - Internet Small Computer System\
          \ Interface, an IP-based storage networking\nstandard for linking data storage\
          \ facilities.</p>\n<p><strong>Issue Tracking System</strong> - An issue\
          \ tracker is a system that is used to record \"issues\" in a software\n\
          product, and track their resolution. Issues can include bugs, requested\n\
          enhancements or planned features.</p>\n<p><strong>iVEC</strong> - iVEC used\
          \ to be a high performance computing facility located in Perth, but it was\
          \ rebranded to the\nPawsey Supercomputing Centre.</p>\n<h3>J</h3>\n<p><strong>JSON</strong>\
          \ - A light weight data-interchange format based on a subset of the JavaScript\
          \ programming language.</p>\n<p><strong>Juju</strong> - An orchestration\
          \ framework from Ubuntu.</p>\n<p><strong>Juno</strong> - The name of an\
          \ OpenStack release.</p>\n<h3>K</h3>\n<p><strong>Kerberos</strong> - An\
          \ authentication protocol used over networks.</p>\n<p><strong>Kepler</strong>\
          \ - A computational workflow engine.</p>\n<p><strong>Key Pair</strong> -\
          \ A matching pair of public and private keys; see public key encryption.</p>\n\
          <p><strong>Keystone</strong> - Keystone is an OpenStack service that provides\
          \ Identity, Token, Catalog and\nPolicy services for use specifically by\
          \ projects in the OpenStack family.</p>\n<p><strong>Kilo</strong> - The\
          \ name of an OpenStack release.</p>\n<p><strong>KVM</strong> - Kernel-based\
          \ Virtual Machine - a virtualization framework supported by\nmodern Linux\
          \ kernels.</p>\n<h3>L</h3>\n<p><strong>Launch</strong> - OpenStack terminology\
          \ for creating a new virtual machine.  There are\nmultiple steps in the\
          \ launch process; e.g. \"scheduling\" where the system\ndecides which cell,\
          \ aggregate &amp; <a href=\"#ComputeNode\">compute node</a> to put the instance\
          \ on, \"building\"\nwhich creates the virtual machines, allocates network\
          \ addresses, etcetera, and\n\"booting\" where the virtual machine is started\
          \ up.</p>\n<p><strong>LDAP</strong> - The Lightweight Directory Access Protocol.\
          \ A distributed directory service.</p>\n<p><strong>Liberty</strong> - The\
          \ name of an OpenStack release</p>\n<p><strong>Linux</strong> - The leading\
          \ open-source operating system, originally developed by Linus\nTorsvalds.\
          \  (What we normally call Linux is better labelled GNU / Linux,\nreflecting\
          \ the fact that the core user libraries and utilities are provided\nby GNU\
          \ projects.) Linux is \"Unix-like\", but contains no Unix code.</p>\n<p><strong>LiveArc</strong>\
          \ - Another name for Mediaflux.</p>\n<p><strong>LTS</strong> - Long Term\
          \ Support - Ubuntu LTS releases have 5 years of support. Non-LTS releases\
          \ will have only 9 months\nof support.</p>\n<h3>M</h3>\n<p><strong>Manila</strong>\
          \ - An OpenStack project that provides a shared file system service.</p>\n\
          <p><strong>MariaDB</strong> - A fork of MySQL that is managed by the original\
          \ MySQL founder and developers.</p>\n<p><strong>MASSIVE</strong> - Australian\
          \ Sciences Imaging and Visualisation Environment. A GPU-based HPC\nsystem\
          \ run by Monash.</p>\n<p><strong>MATLAB</strong> - Matrix Laboratory is\
          \ a proprietary numerical computing programming language.</p>\n<p><strong>Mediaflux</strong>\
          \ - An engine to manage both data and metadata amongst distributed groups\
          \ of people.</p>\n<p><strong>Memcache</strong> - A general purpose distributed\
          \ memory caching system.</p>\n<p><strong>Mint</strong> - An Ubuntu based\
          \ Linux distribution.</p>\n<p><strong>Mitaka (\u4E09\u9DF9)</strong> - The\
          \ name of an OpenStack release</p>\n<p><strong>MPI</strong> - Message Passing\
          \ Interface - a standard API for passing message in a parallel\ncomputing\
          \ system.</p>\n<p><strong>MySQL</strong> - An open source SQL database system.\
          \ Currently owned by Oracle Inc.</p>\n<p><strong>MyTardis</strong> - A program\
          \ that allows users to store large datasets and to share them with collaborators.</p>\n\
          <h3>N</h3>\n<p><strong>Nagios</strong> - Monitoring software.</p>\n<p><strong>NCI</strong>\
          \ - National Computing Infrastructure and typically refers to one of the\
          \ NCI systems.</p>\n<p><strong>NeCTAR</strong> - National eResearch Collaboration\
          \ Tools and Resources project.</p>\n<p><strong>NeCTAR RC</strong> - The\
          \ NeCTAR Research Cloud.</p>\n<p><strong>NeCTAR VLs</strong> - The NeCTAR\
          \ Virtual Laboratory (VL) projects fund the development of\ncomputational\
          \ science facilities in the NeCTAR RC to support particular research\n domains.</p>\n\
          <p><strong>Neutron</strong> - OpenStack \"networking as a service\". Neutron\
          \ manages the network interface\ndevices (e.g., vNICs) used by other Openstack\
          \ instances. Neutron supersedes the\n\"nova network\".</p>\n<p><strong>NFS</strong>\
          \ - \"Network File System\" - a standard network protocol for making a file\
          \ system on\n one machine available on another across the network.</p>\n\
          <p><strong>Nimrod</strong> - Distributed computing middleware.</p>\n<p><strong>Node</strong>\
          \ - NeCTAR terminology - a Node (or cloud node) is one of the \"data centre\n\
          aggregations\" that comprise the NeCTAR research cloud.</p>\n<p>The term\
          \ \"node\" can also refer to a <a href=\"#ComputeNode\">compute node</a>.</p>\n\
          <p><strong>Node Zero</strong> - The term once used to describe the NeCTAR\
          \ node managed by the University of Melbourne.\nIt is no longer used.</p>\n\
          <p><strong>Nova</strong> - The OpenStack cloud compute service.</p>\n<p><strong>Nova\
          \ Cells</strong> - When this functionality is enabled, the hosts in an OpenStack\
          \ Compute cloud\nare partitioned into groups called cells.</p>\n<p><strong>Nova\
          \ Network</strong> - The component that manages networking in Nova. It is\
          \ no longer in use at NeCTAR.</p>\n<p><strong>NSP</strong> - Nectar Servers\
          \ Program - provides managed servers for eResearch projects.</p>\n<h3>O</h3>\n\
          <p><strong>Object</strong> - OpenStack terminology for the unit of storage\
          \ in object storage.</p>\n<p><strong>Object Storage</strong> - OpenStack\
          \ terminology for a kind of data storage where \"objects\" are\nsaved and\
          \ retrieved using a <a href=\"#REST\">RESTful</a> API. Object Storage is\
          \ typically replicated\nwith copies held at (at least) 3 locations.</p>\n\
          <p><strong>Object Store</strong> - A storage architecture that manages data\
          \ in terms of objects.</p>\n<p><strong>Omero</strong> - An application the\
          \ visualization, management and analysis of biological\nmicroscope images.</p>\n\
          <p><strong>Open Source</strong> - Open source refers to a computer program\
          \ in which the source code is available\nto the general public for use and/or\
          \ modification from its original design.</p>\n<p><strong>OpenStack</strong>\
          \ - \"..OpenStack is a free and open-source cloud computing software platform.\
          \ Users\nprimarily deploy it as an infrastructure as a service (IaaS) solution.\
          \ The\ntechnology consists of a series of interrelated projects that control\
          \ pools of\nprocessing, storage, and networking resources throughout a data\
          \ center which\nusers manage through a web-based dashboard, command-line\
          \ tools, or a <a href=\"#REST\">RESTful</a>\nAPI...\" <a href=\"https://en.wikipedia.org/wiki/OpenStack\"\
          >Wikipedia</a>.</p>\n<p><strong>OpenStack Clients</strong> - These are tools\
          \ that you can install on a system\n(e.g. your desktop or laptop) for interacting\
          \ with the OpenStack services.</p>\n<p><strong>OpenSUSE</strong> - A Linux\
          \ distribution.</p>\n<p><strong>ORM</strong> - Object-Relational Mapping\
          \ - a mapping from a conventional (table-based)\ndatabase to object-oriented\
          \ programming.</p>\n<p><strong>OS</strong> - A contraction of Operating\
          \ System.</p>\n<p><strong>Overcommit</strong> - A way of dealing with resource\
          \ shortages in a virtual computing framework.\nMany virtual machines do\
          \ not use all of the resources allocated to them all of the\ntime, so when\
          \ overcommitting more virtual resources are allocated than the physical\
          \ resources\ncan actually support.</p>\n<h3>P</h3>\n<p><strong>Package manager</strong>\
          \ <a name=\"PackageManager\"></a> - A simple and elegant way to install\
          \ software\non your Linux servers. Conceptually remote \"repositories\"\
          \ contain massive amounts of software\n(called \"packages\") and by using\
          \ the package manager, you can download and install any of it\nusing a simple\
          \ command. The package manager maintains a local database that tracks which\n\
          packages you have installed and manages the additional packages your original\
          \ package\ndepends on (the \"dependencies\"). Before package managers, managing\
          \ dependencies was a\ndifficult and manual process.</p>\n<p><strong>Panasas</strong>\
          \ - A company that builds network attached storage.</p>\n<p><strong>Password</strong>\
          \ - A secret (e.g. known to the user) that is used for authentication purposes.</p>\n\
          <p><strong>Passphrase</strong> - A longer secret that is typically used\
          \ to secure a private key.</p>\n<p><strong>Pausey</strong> - The Pausey\
          \ Centre runs the Western Australian node of the NeCTAR research\ncloud.</p>\n\
          <p><strong>Plone</strong> - A popular website / content management / wiki\
          \ system.  Espaces is implemented\n on top of Plone.</p>\n<p><strong>Polaris</strong>\
          \ - The tier 3 data center that houses the second stage QRIScloud infrastructure.</p>\n\
          <p><strong>pQERN</strong> - The predecessor of QERN.  Now decommissioned.</p>\n\
          <p><strong>Prentice</strong> - The first stage QRISCloud infrastructure\
          \ was housed in the UQ Prentice\nbuilding.</p>\n<p><strong>Private Key</strong>\
          \ - See key pair, public key encryption.</p>\n<p><strong>Project</strong>\
          \ - The NeCTAR term for a \"resource container\"; i.e. what you get when\
          \ you are\ngranted a NeCTAR allocation. A project \"owns\" virtual machine\
          \ instances,\nsnapshots and various kinds of storage, and may be shared\
          \ by multiple users.</p>\n<p><strong>Public Key</strong> - See key pair,\
          \ public key encryption.</p>\n<p><strong>Public Key Encryption</strong>\
          \ - A kind of encryption system based on \"one-way functions\".\nThese systems\
          \ depend on a public / private key pair, where the public key is for\nencryption\
          \ and the private key is for a decryption. Knowledge of one key does\nnot\
          \ allow you to determine the other one.</p>\n<p><strong>Puppet</strong>\
          \ - An open source configuration tool.</p>\n<p><strong>Putty</strong> <a\
          \ name=\"Putty\"></a> - A widely used Windows tool for accessing a command\
          \ shell on a remote\nUnix/Linux system.  Putty supports <a href=\"#SSH\"\
          >SSH</a>.</p>\n<p><strong>Python</strong> - A programming language. OpenStack\
          \ is largely implemented in Python.</p>\n<h3>Q</h3>\n<p><strong>QCIF</strong>\
          \ - Queensland Cyber Infrastructure Foundation.</p>\n<p><strong>Qcloud</strong>\
          \ - The previous name for QRIScloud</p>\n<p><strong>QERN</strong> - The\
          \ predecessor of Qcloud / QRIScloud implemented by QCIF.  (Decommissioned)</p>\n\
          <p><strong>QRIScloud</strong> - The overall name for the QCIF's cloud computing\
          \ systems.</p>\n<p><strong>QRIScompute</strong> - The \"compute\" component\
          \ of QRIScloud. This includes the QRIScloud NeCTAR\nresearch cloud facilities,\
          \ special compute, elastic compute and Kepler / Nimrod based\nservices.</p>\n\
          <p><strong>QRISdata</strong> - The \"data\" component of QRIScloud. This\
          \ includes QCIF's RDSI storage and data\n access services.</p>\n<p><strong>Quota</strong>\
          \ - Operational limits defined in OpenStack to prevent system capacity from\n\
          being exhausted.</p>\n<h3>R</h3>\n<p><strong>R</strong> - A programming\
          \ language</p>\n<p><strong>RAID</strong> - Redundant Array of Independent\
          \ Discs. A way of putting together disc storage\nthat provides a degree\
          \ of recoverability in the event of the loss of disc media.</p>\n<p><strong>RDA</strong>\
          \ - Research Data Australia - A project of ANDS.</p>\n<p><strong>RDP</strong>\
          \ -    Microsoft's Remote Desktop Protocol.</p>\n<p><strong>RDSI</strong>\
          \ - Research Data Storage Infrastructure - A organization / project funding\
          \ the\nprovision of storage for \"research data collections\" to the Australian\
          \ academic\ncommunity.</p>\n<p><strong>Reboot</strong> - The act of restarting\
          \ a computer.</p>\n<p><strong>Rebuild</strong> - To wipe and reinstall all\
          \ of the software on a computer.</p>\n<p><strong>ReDBox</strong> - An application\
          \ used to describe and share information about research data\ncollections.</p>\n\
          <p><strong>Redhat Inc</strong> - A leading open source software vendor that\
          \ produces RHEL and Fedora, as\nwell as other software products.</p>\n<p><strong>ReDS</strong>\
          \ - RDSI terminology - Research Data Storage.</p>\n<p><strong>Replica</strong>\
          \ - A copy of (say) a file or collection.</p>\n<p><strong>Replication</strong>\
          \ - A process for creating or updating a replica.</p>\n<p><strong>Rescue</strong>\
          \ - As system administration terminology: a procedure for recovering a\n\
          system that won't boot properly.</p>\n<p><strong>Research Data Management</strong>\
          \ - The topic / problem-space of storing and curating\nthe data outputs\
          \ of (academic) research.  Aspects include safe storage, metadata,\ndata\
          \ publication, data discovery, access control &amp; ethical considerations,\n\
          provenance &amp; audit, and long term archival considerations.</p>\n<p><strong>Resize</strong>\
          \ - The act of changing a VM's flavor, thus allowing it to match the\ncurrent\
          \ needs.</p>\n<p><strong>REST / RESTful</strong> <a name=\"REST\"></a> -\
          \ Representational state transfer (REST)\nis an architectural style for\
          \ implementing web-based system. RESTful APIs\nare designed to be easy to\
          \ use by both web browsers (e.g. from Javascript)\nand from stand-alone\
          \ clients and servers. OpenStack APIs are RESTful.</p>\n<p><strong>RESTful\
          \ Service</strong> - A service that exposes <a href=\"#REST\">RESTful</a>\
          \ APIs.</p>\n<p><strong>RHEL</strong> - Redhat Enterprise Linux.  The flagship\
          \ product of RedHat Inc. \nRHEL distributions are \"paid-for-support\" Linux\
          \ aimed at the \"enterprise\ncomputing\" market.</p>\n<p><strong>RHEL Family</strong>\
          \ - RHEL, CentOS and Scientific Linux (Amazon Linux is pretty similar).</p>\n\
          <p><strong>RPM</strong> - The name of the <a href=\"#PackageManager\">package\
          \ manager</a> used by the Red Hat\nfamily of Linux distribution.</p>\n<p><strong><code>rsync</code></strong>\
          \ - A standard Unix / Linux utility for incrementally copying changes between\n\
          file trees; i.e. \"synchronizing\" them.</p>\n<h3>S</h3>\n<p><strong>S3</strong>\
          \ - S3 is an abbreviation for Simple Storage Solution, Amazon's Object Store\n\
          offering.</p>\n<p><strong>SaaS</strong> - Software as a Service.</p>\n<p><strong>Salt</strong>\
          \ - A configuration management tool written in the Python programming language.</p>\n\
          <p><strong>Samba</strong> - An open source reimplementation of the Windows\
          \ file server technology; \ne.g. it can store Windows \"shares\" on Linux\
          \ systems.</p>\n<p><strong>SAML</strong> - Security Assertion Markup Language\
          \ (SAML, pronounced sam-el) is an\nXML-based data format for exchanging\
          \ authentication and authorization data between\nparties.</p>\n<p><strong>Scientific\
          \ Linux / SL Scientific Linux</strong> - a rebadging of RHEL produced by\
          \ CERN.\nThe goal is to support \"scientific computing\". SL is \"for free\"\
          , but with no support.</p>\n<p><strong><code>scp</code></strong> - A Unix/Linux\
          \ command for copying files and file trees over <a href=\"#SSH\">SSH</a>.</p>\n\
          <p><strong>Security Group</strong> <a name=\"SecurityGroup\"></a> - A set\
          \ of <a href=\"#AccessRule\">Access Rules</a> that\nmay be applied to one\
          \ or more instances.</p>\n<p>At NeCTAR by the default Security Group applied\
          \ to new instances does not\ncontain an access rule for <a href=\"#SSH\"\
          >SSH</a>.  Meaning that new users often find their new\nvirtual machines\
          \ inaccessible via SSH until they add the appropriate access\nrule.</p>\n\
          <p><strong>Service</strong> - In the software world, set of related functionalities\
          \ that can be used by different clients.</p>\n<p><strong>Service Endpoint</strong>\
          \ <a name=\"ServiceEndpoint\"></a> - Typically a web URL that can be used\
          \ by an\napplication to access a service. Synonym: <a href=\"#ApiEndpoint\"\
          >API endpoint</a>.</p>\n<p><strong><code>sftp</code></strong> - Secure File\
          \ Transfer Protocol is a protocol packaged with <a href=\"#SSH\">SSH</a>\
          \ that\nallows you to transfer files between instances.</p>\n<p><strong>Shared\
          \ Memory</strong> - Computer memory regions that can be accessed by different\
          \ processors\n(or processes) in computer system.</p>\n<p><strong>Shibboleth</strong>\
          \ - A the federated identity solution on which the <a href=\"#AAF\">AAF</a>\
          \ is based.</p>\n<p><strong>Shutdown</strong> - A shutdown VM is gracefully\
          \ powered off, but its disk remains on the host\nmachine, ready to be restarted\
          \ from there.</p>\n<p><strong>SLES</strong> - SUSE Linux Enterprise Server\
          \ - a paid-for Linux distro.</p>\n<p><strong>SMB</strong> - The Windows\
          \ network file system protocol.</p>\n<p><strong>Snapshot</strong> - OpenStack\
          \ terminology for an image produced from an active (typically not\n\"clean\"\
          ) virtual instance.</p>\n<p><strong>SSH</strong> <a name=\"SSH\"></a> -\
          \ A protocol and tools for establishing secure \"shell\" sessions\nover\
          \ the network.  SSH encrypts the data transferred, and supports user authentication\n\
          using public/private keys.  See also: <a href=\"#Putty\">Putty</a>.</p>\n\
          <p><strong>Solaris</strong> - A proprietary Unix system produced by Sun\
          \ Microsystems, and now Oracle.</p>\n<p><strong>Subversion (SVN)</strong>\
          \ - A widely used non-distributed version control system.</p>\n<p><strong>Suspend</strong>\
          \ - A suspended VM has its state written to the host machines disk,\nready\
          \ to be resumed from there.</p>\n<p><strong>Swift</strong> - The OpenStack\
          \ object storage API, and associated command-line tool.</p>\n<h3>T</h3>\n\
          <p><strong><code>tar</code></strong> - The standard file archive utility\
          \ (and format) for Unix, Linux and\nrelated platforms.  (Analogous to ZIP\
          \ files on Windows.)</p>\n<p><strong>Telemetry</strong> An integrated project\
          \ that provides metering and measuring facilities for \nOpenStack. The project\
          \ name of Telemetry is ceilometer.</p>\n<p><strong>Tenant</strong> - Openstack\
          \ terminology for \"isolated resource containers forming the\nprincipal\
          \ organizational structure within the Compute service\". Note: NeCTAR uses\
          \ /\nprefers the term \"project\".</p>\n<p><strong>Terminate</strong> -\
          \ OpenStack terminology for permanently destroy an Instance and its\nephemeral\
          \ storage.</p>\n<p><strong>TERN</strong> - The Terrestrial Ecosystem Research\
          \ Network connects ecosystem scientists\nand enables them to collect, contribute,\
          \ store, share and integrate data across\ndisciplines.</p>\n<p><strong>Ticket</strong>\
          \ - Synonym for support ticket.</p>\n<p><strong>Tier n Support</strong>\
          \ - IT support terminology: support functions are typically classified\n\
          by the 4 tiers below. The 'n' references the fact that are multiple tiers.</p>\n\
          <ul>\n<li>Tier 0 is user self-help - e.g. using online help, reading user\
          \ guides, HOW-TOs\n  and FAQs, and \"googling\".</li>\n<li>Tier 1 is non-technical\
          \ support - e.g. problem triage, providing solutions for\n  common mistakes,\
          \ and answering simple questions.</li>\n<li>Tier 2 is technical support\
          \ - e.g. initial diagnosis of more complicated problems,\n  solving some\
          \ of them, and answering technical problems.</li>\n<li>Tier 3 is deep technical\
          \ support - e.g. things that the other tiers can answer.</li>\n</ul>\n<p><strong>Tiered\
          \ Storage</strong> -  Different categories of data are assigned to different\
          \ types\nof storage media. This is ordinarily done to reduce storage costs.</p>\n\
          <p><strong>TPAC</strong> - The Tasmanian Partnership for Advanced Computing.</p>\n\
          <p><strong>TurnKey Linux</strong> - A Debian Linux based virtual appliance\
          \ library.</p>\n<h3>U</h3>\n<p><strong>Ubuntu</strong> - A Debian based\
          \ Linux distribution produced by Canonical, originally aimed\nat the desktop\
          \ computing market. But now widely used in the cloud. Ubuntu is for-free,\n\
          though paid support is available.</p>\n<p><strong>Unix</strong> - A proprietary\
          \ operating system for \"minicomputers\" originally written by Bell\nLabs\
          \ / AT&amp;T in the 1970s.  Many versions of Unix have been produced by\
          \ many\ncompanies over the years.</p>\n<p><strong>URI / URL</strong> - Universal\
          \ Resource Identifier / Universal Resource Locator.</p>\n<h3>V</h3>\n<p><em>V3\
          \ Alliance</em>* - An eResearch support agency based in Victoria.</p>\n\
          <p><strong>Vagrant</strong> - A desktop virtualization framework aimed at\
          \ supporting transient virtual\nmachine instances.</p>\n<p><strong>VCPU</strong>\
          \ - OpenStack terminology for a Virtual CPU.</p>\n<p><strong>VCPU Hours</strong>\
          \ - The number of VCPU's in an instance multiplied by the hours used.</p>\n\
          <p><strong>VicNode</strong> - A service to all Victorian researchers and\
          \ their collaborators to store\nand share research data.</p>\n<p><strong>Virtual\
          \ Barrine</strong> - A project to use \"cluster as a service\" technology\
          \ to build a cluster in\nQRIScloud.</p>\n<p><strong>Virtual Machine (VM)</strong>\
          \ - A \"computational element\" that \"thinks\" it is a real\ncomputer with\
          \ control of its own (virtual) resources, but is actually running under\n\
          the control of something else.  In the cloud computing context, virtual\
          \ machines\nrun directly on real computer hardware (i.e. they execute native\
          \ instructions at\nnormal clock speed), but access to system resources is\
          \ \"mediated\".</p>\n<p><strong>Virtual Memory</strong> - A memory management\
          \ technique that maps the memory addresses\nused by a program to physical\
          \ memory.</p>\n<p><strong>VM</strong> - A contraction of \"virtual machine\"\
          .</p>\n<p><strong>VMware</strong> - A commercial virtualization company,\
          \ and the name of their main\nproduct line.</p>\n<p><strong>VNC</strong>\
          \ - Virtual Network Computing is a system to share graphical desktops across\n\
          machines.</p>\n<p><strong>Volume</strong> - A volume is a storage area with\
          \ a single file system on it.</p>\n<h3>W</h3>\n<p><strong>Wiki</strong>\
          \ - A website that supports the collaborative modification of its content\
          \ via\na web browser.</p>\n<p><strong>Windows</strong> - A generic name\
          \ for the Microsoft operating systems.</p>\n<p><strong>WinSCP</strong> -\
          \ A popular open source file transfer tool for Windows.</p>\n<p><strong>Workflow</strong>\
          \ - An orchestrated pattern of activity that can both be communicated\n\
          and repeatedly run.</p>\n<h3>X</h3>\n<p><strong>X11</strong> - A graphical\
          \ user interface that can be used on NeCTAR instances.</p>\n<p><strong>x86</strong>\
          \ - The most common instruction set architecture for 32 bit computers.</p>\n\
          <p><strong>x86-64</strong> - The 64bit version of x86.</p>\n<p><strong>XML</strong>\
          \ - Stands for eXtensible Markup Language: a way to markup text in a way\n\
          that is readable by both humans and computers.</p>\n<p><strong>Xen</strong>\
          \ - A virtualization framework supported by modern Linux kernels.</p>\n\
          <h3>Y</h3>\n<p><strong>Yum</strong> - A <a href=\"#PackageManager\">package\
          \ manager</a> used on RHEL family and Fedora\ndistributions.</p>\n<h3>Z</h3>\n\
          <p><strong>Zope</strong> A framework for building web applications based\
          \ on Python.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 54
        id: 6000055445
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-06T23:28:04-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000055445
        position: 8
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Glossary
        updated_at: '2015-12-06T23:28:04-05:00'
        user_id: 6002464727
  html: "<p>This content is heavily sourced from the excellent <a href=\"https://espaces.edu.au/vwrangler/nectar-openstack-glossary\"\
    >eSpaces glossary</a>\nproduced by Steve Crawley at QCIF.</p>\n<p>The full glossary\
    \ of OpenStack terms can be found at: <a href=\"http://docs.openstack.org/glossary/content/glossary.html\"\
    >http://docs.openstack.org/glossary/content/glossary.html</a></p>\n<h2>The terms</h2>\n\
    <h3>A</h3>\n<p><strong>AAF</strong> <a name=\"AAF\"></a> - The <a href=\"http://aaf.edu.au/\"\
    >Australian Access Federation</a>. A\nShibboleth-based federated authentication\
    \ service for the Australian academic community.\nAlso the name of the organization\
    \ that runs the AAF service.</p>\n<p><strong>AARNET</strong> - Australia's Academic\
    \ &amp; Research Network - the organization that runs the\nnetworks connecting\
    \ Australia's Universities and Research Organizations.</p>\n<p><strong>Access\
    \ Control</strong> <a name=\"AccessControl\"></a> - The process of determining\
    \ if an (authenticated) agent is\npermitted to perform some action.  Synonym:\
    \ Authorization.</p>\n<p><strong>Access Group</strong> - OpenStack terminology\
    \ that is a synonym for <a href=\"#SecurityGroup\">Security Group</a>.</p>\n<p><strong>Access\
    \ Rule</strong> <a name=\"AccessRule\"></a> - An access rule allow network access\
    \ to an\ninstance from other hosts with a specified combination of protocol family\
    \ (e.g. TCP, UDP, UCMP),\nport number and address range.</p>\n<p><strong>Account</strong>\
    \ - OpenStack terminology. A synonym for \"project\" and \"tenant\".</p>\n<p><strong>Active\
    \ Directory (AD)</strong> - Microsoft's directory service product; essentially\
    \ LDAP enhanced with\nKerberos. Most Microsoft Windows environments will use AD\
    \ to centrally control\nauthentication.</p>\n<p><strong>AMD</strong> - Advanced\
    \ Micro Devices Inc. A manufacturer of x86 and x86_64 compatible\nmicroprocessors.\
    \ A direct competitor to Intel.</p>\n<p><strong>API</strong> - Application Programming\
    \ Interface - an interface that that is designed for\nprograms to use (As distinct\
    \ from a user interface, which is designed for\npeople to use).</p>\n<p><strong>API\
    \ Endpoint</strong> <a name=\"ApiEndpoint\"></a> - See <a href=\"#ServiceEndpoint\"\
    >Service endpoint</a>.</p>\n<p><strong><code>apt</code></strong> <a name=\"apt\"\
    ></a> - The <a href=\"#PackageManager\">package manager</a> used by the Debian\n\
    family (Debian/Ubuntu/Mint) of Linux distributions.</p>\n<p><strong>Aspera</strong>\
    \ - \"Aspera High-speed File Transfer Software that moves the world's data at\
    \ maximum\nspeed, regardless of file size, transfer distance or network conditions\"\
    .</p>\n<p><strong>Attach</strong> - An OpenStack volume can be attached to an\
    \ OpenStack instance to provide it with\nadditional disk storage.</p>\n<p><strong>Authentication</strong>\
    \ - The process of establishing that an agent (i.e. a person, or other entity)\
    \ in a\ncomputer system is who they say they are.  The simple username and password\n\
    is the most familiar means of authentication.</p>\n<p><strong>Authorization</strong>\
    \ - See <a href=\"#AccessControl\">Access Control</a>.</p>\n<p><strong>Availability\
    \ Zone (AZ)</strong> - a logical grouping of compute nodes within a region.</p>\n\
    <p><strong>AWS</strong> - Amazon Web Services.</p>\n<p><strong>Azure</strong>\
    \ - Microsoft's commercial cloud computing platform / service.</p>\n<h3>B</h3>\n\
    <p><strong>BCCVL</strong> - The Biodiversity and Climate Change Virtual Laboratory.</p>\n\
    <p><strong>Boot</strong> - The boot (or \"bootstrap\") process is the means by\
    \ which the computer starts\nitself up after the power button is pressed.  Ultimately\
    \ booting is the process\nin which a computer goes from having empty memory to\
    \ having the operating\nsystem loaded and running.</p>\n<p><strong>Bricked</strong>\
    \ - Colloquialism: describes a system that has been damaged in a way that\npermanently\
    \ locks out some or all functionality.  It's usually the consequence\nof some\
    \ kind of firmware update that fails to run properly, or at all, meaning\nfurther\
    \ remedial firmware updates are not possible.  The device is bricked when\nit\
    \ can't be fixed and is effectively an expensive square shaped \"brick\".</p>\n\
    <h3>C</h3>\n<p><strong>Canonical</strong> - Canonical Ltd. is a UK-based privately\
    \ held computer software company founded\n(and funded) by South African entrepreneur\
    \ Mark Shuttleworth to market\ncommercial support and services for Ubuntu and\
    \ related projects.</p>\n<p><strong>CDS</strong> - RDSI terminology for Collection\
    \ Development Storage.</p>\n<p><strong>Ceilometer</strong> - The OpenStack Ceilometer\
    \ project aims to deliver a unique point of\ncontact for billing systems to acquire\
    \ all of the measurements they need to\nestablish customer billing, across all\
    \ current OpenStack core components.</p>\n<p>It is also a means by which to gather\
    \ performance related metrics useful for the\ngeneral management of the OpenStack\
    \ environment in general.</p>\n<p><strong>Cell</strong> - Cells are a means by\
    \ which to partition an OpenStack compute cloud into groups.</p>\n<p>At NeCTAR\
    \ each site runs a different configuration, as a resource cells in an\nOpenStack\
    \ Compute cells setup. This allows the NeCTAR nodes to do different\nthings such\
    \ as span multiple data centers, or run off <a href=\"#ComputeNode\">compute node</a>\
    \ storage\nwith a shared file system, or use on compute node storage with a non-shared\
    \ file\nsystem.  It's also a way to partition tenants and accounts.</p>\n<p><strong>CentOS</strong>\
    \ - A community-based rebadging of RHEL distribution.  The result is \"for free\"\
    , but with\n no support.</p>\n<p><strong>Ceph</strong> - \"Ceph is a unified,\
    \ distributed storage system designed for excellent\nperformance, reliability\
    \ and scalability.\"  Volume and object storage\nare typically implemented using\
    \ Ceph.</p>\n<p><strong>CephFS</strong> - A project aimed and making Ceph work\
    \ akin to a traditional filesystem\nala ext4 or xfs.  It is still considered experimental\
    \ at this stage.</p>\n<p><strong>Chef</strong> - A recipe based system configuration\
    \ framework. A main competitor to Puppet, but\nalso now to other such systems\
    \ such as Ansible and Salt.</p>\n<p><strong>CIDR Notation</strong> - Classless\
    \ Internet Domain Routing notation - a concise notation for writing IPv4\n or\
    \ IPv6 network address ranges.</p>\n<p><strong>Cinder</strong> - The OpenStack\
    \ Volume Storage management service.</p>\n<p><strong>The \"Cloud\"</strong> -\
    \ A network of servers used to store, manage, and process data to achieve\nefficiencies\
    \ of scale in completing various computational tasks.</p>\n<p><strong>CloudStor</strong>\
    \ - A free cloud-based file transfer service provided by AARNET. Allows researchers\n\
    \ to send and receive large files (up to 100Gb) or the big brother CloudStor+\n\
    which is an enhanced version of CloudStor that supports secure long-term file\n\
    storage.</p>\n<p><strong>Cluster-as-a-service</strong> - Implementing HPC-style\
    \ compute facilities on top of cloud computing\ninfrastructure.</p>\n<p><strong>Collection</strong>\
    \ - RDSI Collection - Large data collection, usually formalised with metadata\
    \ and\nmade discoverable and accessible. Stored as part of a data storage investment\n\
    project called RDSI (Research Data Storage Infrastructure). Operators of the\n\
    infrastructure from RDSI project are called RDSI nodes and may still refer to\n\
    their storage facilities or collections as 'RDSI storage' or 'RDSI collection'.</p>\n\
    <p><strong>Collection VM</strong> - RDSI collections in QRIScloud are exposed\
    \ via virtual machines that run access\nservices; e.g. scp, sftp, rsync, WebDAV\
    \ &amp; GridFTP.</p>\n<p><strong>Compute Node</strong>  <a name=\"ComputeNode\"\
    ></a> - OpenStack terminology for a physical computer\nused to run virtual machines.\
    \ It will typically have multiple CPUs and shared memory, and\none or more network\
    \ interfaces.  It may also have on-node disc storage.</p>\n<p><strong>Container</strong>\
    \ - General Computing - a means by which to run multiple \"things\" inside a given\n\
    computer and have those things isolated from each other and the computer itself.\n\
    Similar in concept to Virtualisation, however not as broadly applicable because\n\
    the containers must be the same operating system as the host itself.</p>\n<p><strong>Copyleft</strong>\
    \ - A form of software licensing that uses Copyright Law as the legal basis for\n\
    granting and enforcing license terms.</p>\n<p><strong>Creative Commons</strong>\
    \ - A family of licenses originally designed for creative (non-software) works,\n\
    that is often used for published scientific data.</p>\n<p><strong>CVL</strong>\
    \ - Characterization Virtual Laboratory - A NeCTAR Virtual Laboratory project.</p>\n\
    <h3>D</h3>\n<p><strong>DaRIS (Distributed and Reflective Informatics System)</strong>\
    \ - <a href=\"http://nsp.nectar.org.au/wiki-its-r/doku.php?id=data_management:daris:about\"\
    >DaRIS</a>\nis a subject-oriented informatics framework and capability developed\n\
    primarily at the University of Melbourne. It is built with the commercial\nMediaflux\
    \ data operating system. DaRIS is mainly used to supply a repository to\nmanage\
    \ bio-medical imaging data.</p>\n<p><strong>Dashboard</strong> - The NeCTAR Dashboard\
    \ is the main web-based interface for managing NeCTAR\nvirtuals. The OpenStack\
    \ component service for the dashboard is called Horizon.</p>\n<p><strong>Data\
    \ Centre</strong> - A place where a large collection of shared computing equipment\
    \ is housed.\nThese expensive and high security installations are often hot and\
    \ noisy and\nconsume hard drives for breakfast.</p>\n<p><strong>Data Repository</strong>\
    \ - A system or service that provides systematic data management services. More\n\
    than just \"a shared fileserver\".</p>\n<p><strong><code>.deb</code></strong>\
    \ - The Debian standard package format. See <a href=\"#apt\">apt</a>.</p>\n<p><strong>Debian\
    \ Family</strong> - Debian, Ubuntu, Mint and many lesser known but similar linux\
    \ distributions.</p>\n<p><strong>Distribution (Linux)</strong> - Refers to a (ideally)\
    \ homoginized release of the Linux Kernel and a\ncompendium of utilities, services\
    \ and applications that are nominally modified\nand tested to run well together,\
    \ then given an odd name like \"Mandriva\" or\n\"Suse\" or \"Debian\".  May inherit\
    \ concepts, frameworks and software\nfrom other distributions with or without\
    \ attribution or other reciprocal\ncontribution.  Typically distributions attract\
    \ a zealous user base\nwho will willingly fight each other to the bitter death\
    \ over not much at all.\nSome are funded by corporations, others by well meaning\
    \ techno hippies or not\nby anyone at all.</p>\n<p><strong>Distro</strong> - A\
    \ contraction of \"Distribution\".</p>\n<p><strong>DMF</strong> - <a href=\"https://www.sgi.com/products/storage/idm/dmf.html\"\
    >DMF</a> is a\nHierarchical Storage Management (HSM) system by SGI designed for\n\
    the bulk storage of data. The basic premise is that fast storage is expensive\
    \ so\nwouldn't it be cool if we could put only the data we actually use on the\
    \ fast\nstorage, and the rest can kind of trickle through less expensive storage\
    \ layers.\nSo the hierarchy is in fact a sandwich of storage technologies (usually\
    \ ssd,\nhdd, tape) at each of which the storage cost per gigabyte decreases. \
    \ As data\nages through the layers the usual trade off is speed, so ideally frequently\
    \ used\ndata stays on the faster storage layer.  Conversely, data which is seldom\n\
    accessed is often archived off to tape where the cost per gigabyte is very low.\n\
    Magical filesystems ideally make all of this invisible to users and\napplications.\
    \  Usually highly expensive and complicated, it's pretty awesome\nwhen it works.</p>\n\
    <p><strong>Docker</strong> - A tool that helps automate the deployment of applications\n\
    inside software containers.</p>\n<p><strong>DropBox</strong> - A company that\
    \ offers cloud storage that is easily used for file sharing\nand collaboration.</p>\n\
    <p><strong>Drupal</strong> - A popular open source website / content management\
    \ system.</p>\n<p><strong>DSpace</strong> - An open source application used to\
    \ create open access repositories\nfor digital content.</p>\n<p><strong>DuraSpace</strong>\
    \ - The not-for-profit organization that manages the DSpace and Fedora Repository\n\
    projects.</p>\n<h3>E</h3>\n<p><strong>EC2</strong> - Amazon's \"<a href=\"#ElasticComputing\"\
    >Elastic Compute</a>\" offering.</p>\n<p><strong>EC2 Credentials</strong> - One\
    \ of the kinds of credentials you can obtain from the NeCTAR Dashboard.\nIt allows\
    \ software written to work with the Amazon cloud to be used with the OpenStack\
    \ cloud.</p>\n<p><strong>Elastic Computing</strong> <a name=\"ElasticComputing\"\
    ></a> - Cloud computing resources that can be\nadded to or removed from.</p>\n\
    <p><strong>Ephemeral Storage</strong> - Disk storage associated with a NeCTAR\
    \ instance that goes away when the\ninstance is terminated.</p>\n<p><strong>ERSA</strong>\
    \ - eResearch SA runs the South Australian node of the NeCTAR research cloud.</p>\n\
    <p><strong>eSpace</strong> - The UQ library managed system for UQ research publications.</p>\n\
    <p><strong>eSpaces</strong> - A web-based collaboration system for the Australian\
    \ academic community.</p>\n<h3>F</h3>\n<p><strong>FAQ</strong> - A Frequently\
    \ Asked Question. A software project or an IT support organization\nwill often\
    \ create an online FAQ document consisting of a number of such\nquestions, and\
    \ their answers.</p>\n<p><strong>Fedora</strong> - RedHat's \"bleeding edge\"\
    \ Linux distro (It was called Fedora Core in early\nreleases).</p>\n<p><strong>Fedora\
    \ Repository</strong> -  The Flexible Extensible Digital Object Repository Architecture\n\
    was developed for storing, managing, and accessing digital content in the form\
    \ of digital\nobjects. The Fedora Repository Project (i.e., Fedora) implements\
    \ the Fedora abstractions\nin a open source software system.</p>\n<p><strong>Fez</strong>\
    \ - A front-end and administration tool for the Fedora Repository.</p>\n<p><strong>Flashlight</strong>\
    \ - An RCC / QCIF HPC system designed for data intensive computation.</p>\n<p><strong>Flavor</strong>\
    \ - An OpenStack term for an instance sizing specification. Gives the amount of\n\
    memory, number of VCPUs and ephemeral disc size.</p>\n<h3>G</h3>\n<p><strong>Galaxy</strong>\
    \ - A web based platform for biomedical research.</p>\n<p><strong>Ganglia</strong>\
    \ - A distributed monitoring system.</p>\n<p><strong>Git</strong> - A popular\
    \ distributed version control system.</p>\n<p><strong>Github</strong> - A popular\
    \ free open-source project hosting site.</p>\n<p><strong>Glance</strong> - OpenStack's\
    \ Image store service.</p>\n<p><strong>Globus GridFTP</strong> - A data transfer\
    \ protocol for high bandwidth wide area networks.</p>\n<p><strong>Gnocchi</strong>\
    \ - Gnocchi is an OpenStack project that provides a TDBaaS \n(Time Series Database\
    \ as a Service).</p>\n<p><strong>GNU</strong> - Stands for \"GNU is Not Unix\"\
    .  Originally a project that aimed to provide a\ncomplete open-source replacement\
    \ for the (proprietary) AT&amp;T Unix operating\nsystem.  GNU now focus mostly\
    \ on things \"above the kernel\".</p>\n<p><strong>Google Drive</strong> - A cloud\
    \ storage service by Google that is easily used for file\nsharing and collaboration.</p>\n\
    <p><strong>GPGPU</strong> - General Purpose computing using GPUs.</p>\n<p><strong>GPL</strong>\
    \ - The GNU Public License. One of the most important open source software\nlicenses.\
    \ In fact there are a number of variants of GPL currently in use:\nGPL2, GPL3,\
    \ LGPL, Affero.</p>\n<p><strong>GPU</strong> - Graphics Processing Unit - primarily\
    \ designed for high-speed graphics process\n(e.g. on a video card), GPUs can also\
    \ be exploited for certain kinds of\nparallel computation.</p>\n<p><strong>Grizzly</strong>\
    \ - The name of an OpenStack release.</p>\n<p><strong>Grizzly</strong> - A scalable\
    \ web server framework implemented in Java (not servlet based).</p>\n<p><strong>GVL</strong>\
    \ - The Genomics Virtual Laboratory - A NeCTAR virtual laboratory project.</p>\n\
    <h3>H</h3>\n<p><strong>Hard Reboot</strong> - A reboot in which no attempt is\
    \ made to shut down cleanly prior\nto booting. This has an increased risk of damage\
    \ to file systems or application\ndata on the instance.</p>\n<p><strong>Havana</strong>\
    \ - The name of an OpenStack release.</p>\n<p><strong>Heat</strong> - The orchestration\
    \ service for OpenStack. It is designed to launch multiple\ncomposite cloud applications\
    \ based on templates in the form of text files that\ncan be treated like code.</p>\n\
    <p><strong>HFS</strong> - Hierarchical File Storage (usually) or Hierarchical\
    \ File System.</p>\n<p><strong>HPC</strong> - High Performance Computing systems\
    \ - typically refers to \"high end\" computing\nhardware designed for doing \"\
    large\" computational tasks.</p>\n<p><strong>HOW-TO</strong> - A document written\
    \ for users that tries to explain \"how to\" do a specific task.</p>\n<p><strong>Hyper-V</strong>\
    \ - Microsoft's main virtualization technology offering.</p>\n<p><strong>Hypervisor</strong>\
    \ - The software that performs the core management of virtual machines in a\n\
    virtualized computing system.</p>\n<h3>I</h3>\n<p><strong>IaaS</strong> - Infrastructure\
    \ as a service (IaaS) is a type of cloud computing in which a\nthird-party provider\
    \ hosts virtualized computing resources over the Internet.</p>\n<p><strong>Icehouse</strong>\
    \ - The name of an OpenStack release.</p>\n<p><strong>Image</strong> - A starting\
    \ state for a new \"clean\" virtual machine.  Typical consists of an\nimage of\
    \ a file system with freshly installed operating system and applications.</p>\n\
    <p><strong>Image Store</strong> - The place where OpenStack images are held.</p>\n\
    <p><strong>Instance</strong> - OpenStack terminology for a virtual machine.</p>\n\
    <p><strong>Intel</strong> - An American multinational that is one of the world's\
    \ largest semiconductor chip manufacturers.</p>\n<p><strong>Intersect</strong>\
    \ - An eResearch support agency based in New South Wales.</p>\n<p><strong>Internet</strong>\
    \ - The Internet is a global system of interconnected computer networks that use\
    \ the Internet protocol\nsuite (TCP/IP) to link to each other.</p>\n<p><strong>IP</strong>\
    \ - The Internet Protocol (IP) is the principal communications protocol in the\n\
    Internet protocol suite for relaying datagrams (also knows as messages or\npackets)\
    \ across network boundaries. Transmission and the routing of IP packets\nare what\
    \ makes the Internet work.</p>\n<p><strong>IPv4</strong> - The (currently) dominant\
    \ version of IP in use at the moment.  IPv4 is limited\nby its design to 2<sup>32</sup>\
    \ distinct addresses. The IPv4 address space is \"full\" in\nmost regions, and\
    \ networking providers are rolling out support of the next\ngeneration (IPv6).</p>\n\
    <p><strong>IPv6</strong> - The successor version of IP, which supports 2<sup>64</sup>\
    \ addresses.</p>\n<p><strong>iSCSI</strong> - Internet Small Computer System Interface,\
    \ an IP-based storage networking\nstandard for linking data storage facilities.</p>\n\
    <p><strong>Issue Tracking System</strong> - An issue tracker is a system that\
    \ is used to record \"issues\" in a software\nproduct, and track their resolution.\
    \ Issues can include bugs, requested\nenhancements or planned features.</p>\n\
    <p><strong>iVEC</strong> - iVEC used to be a high performance computing facility\
    \ located in Perth, but it was rebranded to the\nPawsey Supercomputing Centre.</p>\n\
    <h3>J</h3>\n<p><strong>JSON</strong> - A light weight data-interchange format\
    \ based on a subset of the JavaScript programming language.</p>\n<p><strong>Juju</strong>\
    \ - An orchestration framework from Ubuntu.</p>\n<p><strong>Juno</strong> - The\
    \ name of an OpenStack release.</p>\n<h3>K</h3>\n<p><strong>Kerberos</strong>\
    \ - An authentication protocol used over networks.</p>\n<p><strong>Kepler</strong>\
    \ - A computational workflow engine.</p>\n<p><strong>Key Pair</strong> - A matching\
    \ pair of public and private keys; see public key encryption.</p>\n<p><strong>Keystone</strong>\
    \ - Keystone is an OpenStack service that provides Identity, Token, Catalog and\n\
    Policy services for use specifically by projects in the OpenStack family.</p>\n\
    <p><strong>Kilo</strong> - The name of an OpenStack release.</p>\n<p><strong>KVM</strong>\
    \ - Kernel-based Virtual Machine - a virtualization framework supported by\nmodern\
    \ Linux kernels.</p>\n<h3>L</h3>\n<p><strong>Launch</strong> - OpenStack terminology\
    \ for creating a new virtual machine.  There are\nmultiple steps in the launch\
    \ process; e.g. \"scheduling\" where the system\ndecides which cell, aggregate\
    \ &amp; <a href=\"#ComputeNode\">compute node</a> to put the instance on, \"building\"\
    \nwhich creates the virtual machines, allocates network addresses, etcetera, and\n\
    \"booting\" where the virtual machine is started up.</p>\n<p><strong>LDAP</strong>\
    \ - The Lightweight Directory Access Protocol. A distributed directory service.</p>\n\
    <p><strong>Liberty</strong> - The name of an OpenStack release</p>\n<p><strong>Linux</strong>\
    \ - The leading open-source operating system, originally developed by Linus\n\
    Torsvalds.  (What we normally call Linux is better labelled GNU / Linux,\nreflecting\
    \ the fact that the core user libraries and utilities are provided\nby GNU projects.)\
    \ Linux is \"Unix-like\", but contains no Unix code.</p>\n<p><strong>LiveArc</strong>\
    \ - Another name for Mediaflux.</p>\n<p><strong>LTS</strong> - Long Term Support\
    \ - Ubuntu LTS releases have 5 years of support. Non-LTS releases will have only\
    \ 9 months\nof support.</p>\n<h3>M</h3>\n<p><strong>Manila</strong> - An OpenStack\
    \ project that provides a shared file system service.</p>\n<p><strong>MariaDB</strong>\
    \ - A fork of MySQL that is managed by the original MySQL founder and developers.</p>\n\
    <p><strong>MASSIVE</strong> - Australian Sciences Imaging and Visualisation Environment.\
    \ A GPU-based HPC\nsystem run by Monash.</p>\n<p><strong>MATLAB</strong> - Matrix\
    \ Laboratory is a proprietary numerical computing programming language.</p>\n\
    <p><strong>Mediaflux</strong> - An engine to manage both data and metadata amongst\
    \ distributed groups of people.</p>\n<p><strong>Memcache</strong> - A general\
    \ purpose distributed memory caching system.</p>\n<p><strong>Mint</strong> - An\
    \ Ubuntu based Linux distribution.</p>\n<p><strong>Mitaka (\u4E09\u9DF9)</strong>\
    \ - The name of an OpenStack release</p>\n<p><strong>MPI</strong> - Message Passing\
    \ Interface - a standard API for passing message in a parallel\ncomputing system.</p>\n\
    <p><strong>MySQL</strong> - An open source SQL database system. Currently owned\
    \ by Oracle Inc.</p>\n<p><strong>MyTardis</strong> - A program that allows users\
    \ to store large datasets and to share them with collaborators.</p>\n<h3>N</h3>\n\
    <p><strong>Nagios</strong> - Monitoring software.</p>\n<p><strong>NCI</strong>\
    \ - National Computing Infrastructure and typically refers to one of the NCI systems.</p>\n\
    <p><strong>NeCTAR</strong> - National eResearch Collaboration Tools and Resources\
    \ project.</p>\n<p><strong>NeCTAR RC</strong> - The NeCTAR Research Cloud.</p>\n\
    <p><strong>NeCTAR VLs</strong> - The NeCTAR Virtual Laboratory (VL) projects fund\
    \ the development of\ncomputational science facilities in the NeCTAR RC to support\
    \ particular research\n domains.</p>\n<p><strong>Neutron</strong> - OpenStack\
    \ \"networking as a service\". Neutron manages the network interface\ndevices\
    \ (e.g., vNICs) used by other Openstack instances. Neutron supersedes the\n\"\
    nova network\".</p>\n<p><strong>NFS</strong> - \"Network File System\" - a standard\
    \ network protocol for making a file system on\n one machine available on another\
    \ across the network.</p>\n<p><strong>Nimrod</strong> - Distributed computing\
    \ middleware.</p>\n<p><strong>Node</strong> - NeCTAR terminology - a Node (or\
    \ cloud node) is one of the \"data centre\naggregations\" that comprise the NeCTAR\
    \ research cloud.</p>\n<p>The term \"node\" can also refer to a <a href=\"#ComputeNode\"\
    >compute node</a>.</p>\n<p><strong>Node Zero</strong> - The term once used to\
    \ describe the NeCTAR node managed by the University of Melbourne.\nIt is no longer\
    \ used.</p>\n<p><strong>Nova</strong> - The OpenStack cloud compute service.</p>\n\
    <p><strong>Nova Cells</strong> - When this functionality is enabled, the hosts\
    \ in an OpenStack Compute cloud\nare partitioned into groups called cells.</p>\n\
    <p><strong>Nova Network</strong> - The component that manages networking in Nova.\
    \ It is no longer in use at NeCTAR.</p>\n<p><strong>NSP</strong> - Nectar Servers\
    \ Program - provides managed servers for eResearch projects.</p>\n<h3>O</h3>\n\
    <p><strong>Object</strong> - OpenStack terminology for the unit of storage in\
    \ object storage.</p>\n<p><strong>Object Storage</strong> - OpenStack terminology\
    \ for a kind of data storage where \"objects\" are\nsaved and retrieved using\
    \ a <a href=\"#REST\">RESTful</a> API. Object Storage is typically replicated\n\
    with copies held at (at least) 3 locations.</p>\n<p><strong>Object Store</strong>\
    \ - A storage architecture that manages data in terms of objects.</p>\n<p><strong>Omero</strong>\
    \ - An application the visualization, management and analysis of biological\n\
    microscope images.</p>\n<p><strong>Open Source</strong> - Open source refers to\
    \ a computer program in which the source code is available\nto the general public\
    \ for use and/or modification from its original design.</p>\n<p><strong>OpenStack</strong>\
    \ - \"..OpenStack is a free and open-source cloud computing software platform.\
    \ Users\nprimarily deploy it as an infrastructure as a service (IaaS) solution.\
    \ The\ntechnology consists of a series of interrelated projects that control pools\
    \ of\nprocessing, storage, and networking resources throughout a data center which\n\
    users manage through a web-based dashboard, command-line tools, or a <a href=\"\
    #REST\">RESTful</a>\nAPI...\" <a href=\"https://en.wikipedia.org/wiki/OpenStack\"\
    >Wikipedia</a>.</p>\n<p><strong>OpenStack Clients</strong> - These are tools that\
    \ you can install on a system\n(e.g. your desktop or laptop) for interacting with\
    \ the OpenStack services.</p>\n<p><strong>OpenSUSE</strong> - A Linux distribution.</p>\n\
    <p><strong>ORM</strong> - Object-Relational Mapping - a mapping from a conventional\
    \ (table-based)\ndatabase to object-oriented programming.</p>\n<p><strong>OS</strong>\
    \ - A contraction of Operating System.</p>\n<p><strong>Overcommit</strong> - A\
    \ way of dealing with resource shortages in a virtual computing framework.\nMany\
    \ virtual machines do not use all of the resources allocated to them all of the\n\
    time, so when overcommitting more virtual resources are allocated than the physical\
    \ resources\ncan actually support.</p>\n<h3>P</h3>\n<p><strong>Package manager</strong>\
    \ <a name=\"PackageManager\"></a> - A simple and elegant way to install software\n\
    on your Linux servers. Conceptually remote \"repositories\" contain massive amounts\
    \ of software\n(called \"packages\") and by using the package manager, you can\
    \ download and install any of it\nusing a simple command. The package manager\
    \ maintains a local database that tracks which\npackages you have installed and\
    \ manages the additional packages your original package\ndepends on (the \"dependencies\"\
    ). Before package managers, managing dependencies was a\ndifficult and manual\
    \ process.</p>\n<p><strong>Panasas</strong> - A company that builds network attached\
    \ storage.</p>\n<p><strong>Password</strong> - A secret (e.g. known to the user)\
    \ that is used for authentication purposes.</p>\n<p><strong>Passphrase</strong>\
    \ - A longer secret that is typically used to secure a private key.</p>\n<p><strong>Pausey</strong>\
    \ - The Pausey Centre runs the Western Australian node of the NeCTAR research\n\
    cloud.</p>\n<p><strong>Plone</strong> - A popular website / content management\
    \ / wiki system.  Espaces is implemented\n on top of Plone.</p>\n<p><strong>Polaris</strong>\
    \ - The tier 3 data center that houses the second stage QRIScloud infrastructure.</p>\n\
    <p><strong>pQERN</strong> - The predecessor of QERN.  Now decommissioned.</p>\n\
    <p><strong>Prentice</strong> - The first stage QRISCloud infrastructure was housed\
    \ in the UQ Prentice\nbuilding.</p>\n<p><strong>Private Key</strong> - See key\
    \ pair, public key encryption.</p>\n<p><strong>Project</strong> - The NeCTAR term\
    \ for a \"resource container\"; i.e. what you get when you are\ngranted a NeCTAR\
    \ allocation. A project \"owns\" virtual machine instances,\nsnapshots and various\
    \ kinds of storage, and may be shared by multiple users.</p>\n<p><strong>Public\
    \ Key</strong> - See key pair, public key encryption.</p>\n<p><strong>Public Key\
    \ Encryption</strong> - A kind of encryption system based on \"one-way functions\"\
    .\nThese systems depend on a public / private key pair, where the public key is\
    \ for\nencryption and the private key is for a decryption. Knowledge of one key\
    \ does\nnot allow you to determine the other one.</p>\n<p><strong>Puppet</strong>\
    \ - An open source configuration tool.</p>\n<p><strong>Putty</strong> <a name=\"\
    Putty\"></a> - A widely used Windows tool for accessing a command shell on a remote\n\
    Unix/Linux system.  Putty supports <a href=\"#SSH\">SSH</a>.</p>\n<p><strong>Python</strong>\
    \ - A programming language. OpenStack is largely implemented in Python.</p>\n\
    <h3>Q</h3>\n<p><strong>QCIF</strong> - Queensland Cyber Infrastructure Foundation.</p>\n\
    <p><strong>Qcloud</strong> - The previous name for QRIScloud</p>\n<p><strong>QERN</strong>\
    \ - The predecessor of Qcloud / QRIScloud implemented by QCIF.  (Decommissioned)</p>\n\
    <p><strong>QRIScloud</strong> - The overall name for the QCIF's cloud computing\
    \ systems.</p>\n<p><strong>QRIScompute</strong> - The \"compute\" component of\
    \ QRIScloud. This includes the QRIScloud NeCTAR\nresearch cloud facilities, special\
    \ compute, elastic compute and Kepler / Nimrod based\nservices.</p>\n<p><strong>QRISdata</strong>\
    \ - The \"data\" component of QRIScloud. This includes QCIF's RDSI storage and\
    \ data\n access services.</p>\n<p><strong>Quota</strong> - Operational limits\
    \ defined in OpenStack to prevent system capacity from\nbeing exhausted.</p>\n\
    <h3>R</h3>\n<p><strong>R</strong> - A programming language</p>\n<p><strong>RAID</strong>\
    \ - Redundant Array of Independent Discs. A way of putting together disc storage\n\
    that provides a degree of recoverability in the event of the loss of disc media.</p>\n\
    <p><strong>RDA</strong> - Research Data Australia - A project of ANDS.</p>\n<p><strong>RDP</strong>\
    \ -    Microsoft's Remote Desktop Protocol.</p>\n<p><strong>RDSI</strong> - Research\
    \ Data Storage Infrastructure - A organization / project funding the\nprovision\
    \ of storage for \"research data collections\" to the Australian academic\ncommunity.</p>\n\
    <p><strong>Reboot</strong> - The act of restarting a computer.</p>\n<p><strong>Rebuild</strong>\
    \ - To wipe and reinstall all of the software on a computer.</p>\n<p><strong>ReDBox</strong>\
    \ - An application used to describe and share information about research data\n\
    collections.</p>\n<p><strong>Redhat Inc</strong> - A leading open source software\
    \ vendor that produces RHEL and Fedora, as\nwell as other software products.</p>\n\
    <p><strong>ReDS</strong> - RDSI terminology - Research Data Storage.</p>\n<p><strong>Replica</strong>\
    \ - A copy of (say) a file or collection.</p>\n<p><strong>Replication</strong>\
    \ - A process for creating or updating a replica.</p>\n<p><strong>Rescue</strong>\
    \ - As system administration terminology: a procedure for recovering a\nsystem\
    \ that won't boot properly.</p>\n<p><strong>Research Data Management</strong>\
    \ - The topic / problem-space of storing and curating\nthe data outputs of (academic)\
    \ research.  Aspects include safe storage, metadata,\ndata publication, data discovery,\
    \ access control &amp; ethical considerations,\nprovenance &amp; audit, and long\
    \ term archival considerations.</p>\n<p><strong>Resize</strong> - The act of changing\
    \ a VM's flavor, thus allowing it to match the\ncurrent needs.</p>\n<p><strong>REST\
    \ / RESTful</strong> <a name=\"REST\"></a> - Representational state transfer (REST)\n\
    is an architectural style for implementing web-based system. RESTful APIs\nare\
    \ designed to be easy to use by both web browsers (e.g. from Javascript)\nand\
    \ from stand-alone clients and servers. OpenStack APIs are RESTful.</p>\n<p><strong>RESTful\
    \ Service</strong> - A service that exposes <a href=\"#REST\">RESTful</a> APIs.</p>\n\
    <p><strong>RHEL</strong> - Redhat Enterprise Linux.  The flagship product of RedHat\
    \ Inc. \nRHEL distributions are \"paid-for-support\" Linux aimed at the \"enterprise\n\
    computing\" market.</p>\n<p><strong>RHEL Family</strong> - RHEL, CentOS and Scientific\
    \ Linux (Amazon Linux is pretty similar).</p>\n<p><strong>RPM</strong> - The name\
    \ of the <a href=\"#PackageManager\">package manager</a> used by the Red Hat\n\
    family of Linux distribution.</p>\n<p><strong><code>rsync</code></strong> - A\
    \ standard Unix / Linux utility for incrementally copying changes between\nfile\
    \ trees; i.e. \"synchronizing\" them.</p>\n<h3>S</h3>\n<p><strong>S3</strong>\
    \ - S3 is an abbreviation for Simple Storage Solution, Amazon's Object Store\n\
    offering.</p>\n<p><strong>SaaS</strong> - Software as a Service.</p>\n<p><strong>Salt</strong>\
    \ - A configuration management tool written in the Python programming language.</p>\n\
    <p><strong>Samba</strong> - An open source reimplementation of the Windows file\
    \ server technology; \ne.g. it can store Windows \"shares\" on Linux systems.</p>\n\
    <p><strong>SAML</strong> - Security Assertion Markup Language (SAML, pronounced\
    \ sam-el) is an\nXML-based data format for exchanging authentication and authorization\
    \ data between\nparties.</p>\n<p><strong>Scientific Linux / SL Scientific Linux</strong>\
    \ - a rebadging of RHEL produced by CERN.\nThe goal is to support \"scientific\
    \ computing\". SL is \"for free\", but with no support.</p>\n<p><strong><code>scp</code></strong>\
    \ - A Unix/Linux command for copying files and file trees over <a href=\"#SSH\"\
    >SSH</a>.</p>\n<p><strong>Security Group</strong> <a name=\"SecurityGroup\"></a>\
    \ - A set of <a href=\"#AccessRule\">Access Rules</a> that\nmay be applied to\
    \ one or more instances.</p>\n<p>At NeCTAR by the default Security Group applied\
    \ to new instances does not\ncontain an access rule for <a href=\"#SSH\">SSH</a>.\
    \  Meaning that new users often find their new\nvirtual machines inaccessible\
    \ via SSH until they add the appropriate access\nrule.</p>\n<p><strong>Service</strong>\
    \ - In the software world, set of related functionalities that can be used by\
    \ different clients.</p>\n<p><strong>Service Endpoint</strong> <a name=\"ServiceEndpoint\"\
    ></a> - Typically a web URL that can be used by an\napplication to access a service.\
    \ Synonym: <a href=\"#ApiEndpoint\">API endpoint</a>.</p>\n<p><strong><code>sftp</code></strong>\
    \ - Secure File Transfer Protocol is a protocol packaged with <a href=\"#SSH\"\
    >SSH</a> that\nallows you to transfer files between instances.</p>\n<p><strong>Shared\
    \ Memory</strong> - Computer memory regions that can be accessed by different\
    \ processors\n(or processes) in computer system.</p>\n<p><strong>Shibboleth</strong>\
    \ - A the federated identity solution on which the <a href=\"#AAF\">AAF</a> is\
    \ based.</p>\n<p><strong>Shutdown</strong> - A shutdown VM is gracefully powered\
    \ off, but its disk remains on the host\nmachine, ready to be restarted from there.</p>\n\
    <p><strong>SLES</strong> - SUSE Linux Enterprise Server - a paid-for Linux distro.</p>\n\
    <p><strong>SMB</strong> - The Windows network file system protocol.</p>\n<p><strong>Snapshot</strong>\
    \ - OpenStack terminology for an image produced from an active (typically not\n\
    \"clean\") virtual instance.</p>\n<p><strong>SSH</strong> <a name=\"SSH\"></a>\
    \ - A protocol and tools for establishing secure \"shell\" sessions\nover the\
    \ network.  SSH encrypts the data transferred, and supports user authentication\n\
    using public/private keys.  See also: <a href=\"#Putty\">Putty</a>.</p>\n<p><strong>Solaris</strong>\
    \ - A proprietary Unix system produced by Sun Microsystems, and now Oracle.</p>\n\
    <p><strong>Subversion (SVN)</strong> - A widely used non-distributed version control\
    \ system.</p>\n<p><strong>Suspend</strong> - A suspended VM has its state written\
    \ to the host machines disk,\nready to be resumed from there.</p>\n<p><strong>Swift</strong>\
    \ - The OpenStack object storage API, and associated command-line tool.</p>\n\
    <h3>T</h3>\n<p><strong><code>tar</code></strong> - The standard file archive utility\
    \ (and format) for Unix, Linux and\nrelated platforms.  (Analogous to ZIP files\
    \ on Windows.)</p>\n<p><strong>Telemetry</strong> An integrated project that provides\
    \ metering and measuring facilities for \nOpenStack. The project name of Telemetry\
    \ is ceilometer.</p>\n<p><strong>Tenant</strong> - Openstack terminology for \"\
    isolated resource containers forming the\nprincipal organizational structure within\
    \ the Compute service\". Note: NeCTAR uses /\nprefers the term \"project\".</p>\n\
    <p><strong>Terminate</strong> - OpenStack terminology for permanently destroy\
    \ an Instance and its\nephemeral storage.</p>\n<p><strong>TERN</strong> - The\
    \ Terrestrial Ecosystem Research Network connects ecosystem scientists\nand enables\
    \ them to collect, contribute, store, share and integrate data across\ndisciplines.</p>\n\
    <p><strong>Ticket</strong> - Synonym for support ticket.</p>\n<p><strong>Tier\
    \ n Support</strong> - IT support terminology: support functions are typically\
    \ classified\nby the 4 tiers below. The 'n' references the fact that are multiple\
    \ tiers.</p>\n<ul>\n<li>Tier 0 is user self-help - e.g. using online help, reading\
    \ user guides, HOW-TOs\n  and FAQs, and \"googling\".</li>\n<li>Tier 1 is non-technical\
    \ support - e.g. problem triage, providing solutions for\n  common mistakes, and\
    \ answering simple questions.</li>\n<li>Tier 2 is technical support - e.g. initial\
    \ diagnosis of more complicated problems,\n  solving some of them, and answering\
    \ technical problems.</li>\n<li>Tier 3 is deep technical support - e.g. things\
    \ that the other tiers can answer.</li>\n</ul>\n<p><strong>Tiered Storage</strong>\
    \ -  Different categories of data are assigned to different types\nof storage\
    \ media. This is ordinarily done to reduce storage costs.</p>\n<p><strong>TPAC</strong>\
    \ - The Tasmanian Partnership for Advanced Computing.</p>\n<p><strong>TurnKey\
    \ Linux</strong> - A Debian Linux based virtual appliance library.</p>\n<h3>U</h3>\n\
    <p><strong>Ubuntu</strong> - A Debian based Linux distribution produced by Canonical,\
    \ originally aimed\nat the desktop computing market. But now widely used in the\
    \ cloud. Ubuntu is for-free,\nthough paid support is available.</p>\n<p><strong>Unix</strong>\
    \ - A proprietary operating system for \"minicomputers\" originally written by\
    \ Bell\nLabs / AT&amp;T in the 1970s.  Many versions of Unix have been produced\
    \ by many\ncompanies over the years.</p>\n<p><strong>URI / URL</strong> - Universal\
    \ Resource Identifier / Universal Resource Locator.</p>\n<h3>V</h3>\n<p><em>V3\
    \ Alliance</em>* - An eResearch support agency based in Victoria.</p>\n<p><strong>Vagrant</strong>\
    \ - A desktop virtualization framework aimed at supporting transient virtual\n\
    machine instances.</p>\n<p><strong>VCPU</strong> - OpenStack terminology for a\
    \ Virtual CPU.</p>\n<p><strong>VCPU Hours</strong> - The number of VCPU's in an\
    \ instance multiplied by the hours used.</p>\n<p><strong>VicNode</strong> - A\
    \ service to all Victorian researchers and their collaborators to store\nand share\
    \ research data.</p>\n<p><strong>Virtual Barrine</strong> - A project to use \"\
    cluster as a service\" technology to build a cluster in\nQRIScloud.</p>\n<p><strong>Virtual\
    \ Machine (VM)</strong> - A \"computational element\" that \"thinks\" it is a\
    \ real\ncomputer with control of its own (virtual) resources, but is actually\
    \ running under\nthe control of something else.  In the cloud computing context,\
    \ virtual machines\nrun directly on real computer hardware (i.e. they execute\
    \ native instructions at\nnormal clock speed), but access to system resources\
    \ is \"mediated\".</p>\n<p><strong>Virtual Memory</strong> - A memory management\
    \ technique that maps the memory addresses\nused by a program to physical memory.</p>\n\
    <p><strong>VM</strong> - A contraction of \"virtual machine\".</p>\n<p><strong>VMware</strong>\
    \ - A commercial virtualization company, and the name of their main\nproduct line.</p>\n\
    <p><strong>VNC</strong> - Virtual Network Computing is a system to share graphical\
    \ desktops across\nmachines.</p>\n<p><strong>Volume</strong> - A volume is a storage\
    \ area with a single file system on it.</p>\n<h3>W</h3>\n<p><strong>Wiki</strong>\
    \ - A website that supports the collaborative modification of its content via\n\
    a web browser.</p>\n<p><strong>Windows</strong> - A generic name for the Microsoft\
    \ operating systems.</p>\n<p><strong>WinSCP</strong> - A popular open source file\
    \ transfer tool for Windows.</p>\n<p><strong>Workflow</strong> - An orchestrated\
    \ pattern of activity that can both be communicated\nand repeatedly run.</p>\n\
    <h3>X</h3>\n<p><strong>X11</strong> - A graphical user interface that can be used\
    \ on NeCTAR instances.</p>\n<p><strong>x86</strong> - The most common instruction\
    \ set architecture for 32 bit computers.</p>\n<p><strong>x86-64</strong> - The\
    \ 64bit version of x86.</p>\n<p><strong>XML</strong> - Stands for eXtensible Markup\
    \ Language: a way to markup text in a way\nthat is readable by both humans and\
    \ computers.</p>\n<p><strong>Xen</strong> - A virtualization framework supported\
    \ by modern Linux kernels.</p>\n<h3>Y</h3>\n<p><strong>Yum</strong> - A <a href=\"\
    #PackageManager\">package manager</a> used on RHEL family and Fedora\ndistributions.</p>\n\
    <h3>Z</h3>\n<p><strong>Zope</strong> A framework for building web applications\
    \ based on Python.</p>"
  parent: 21
  sha1: b671b92fbc951047324add2fdd5192c9a3030128
  title: Glossary
53:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-03T02:45:33-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " \n Windows User \n Mac / Linux User \n Access via web browser\
          \ \n \n This section enables you to access the virtual machine (VM) created\
          \ earlier.\nThis will give you a console for entering Shell commands to\
          \ your Linux VM.\nLater sections will help you start to use your VM. \n\
          \ IP Address \n You can use an SSH client to log into the virtual machine\
          \ created earlier.\nTo do this you will need to enter the IP Address of\
          \ the VM. \n \n Log on to the Nectar Dashboard\n \n Click the 'Instances'\
          \ tab \n Select and copy the IP Address of the instance you want to access\
          \ \n \n \n \n Windows User \n \n \n Download PuTTY(putty.exe) from PuTTY\
          \ download page\n \n Double click putty.exe \n \n \n \n Copy/paste the IP\
          \ address to 'Host Name' \n Under 'Connection' on the right side, expand\
          \ 'SSH' and click 'Auth' \n \n \n \n Click the Browse button and select\
          \ the private key created earlier \n Click 'Session' on the right side Category\
          \ \n Click 'Open' button \n Type username 'ubuntu' for Ubuntu image and\
          \ 'root' for other images \n \n \n Linux/Mac User \n \n Type the following\
          \ command into the console: \n ssh -i Nectar_Key ubuntu@XX.XX.XX.XX \n \n\
          \ Replace 'Nectar_Key' with the created private key name earlier. You may\
          \ also\n need to specify the full path for the private key (usually '~/.ssh/Nectar_Key')\
          \ \n Replace 'ubuntu' with 'root' if you are not using an Ubuntu image \n\
          \ Replace XX.XX.XX.XX with the IP address \n \n \n Access through your web\
          \ browser \n \n Your VM console can also be accessed via the NeCTAR dashboard\
          \ in your web browser.\nThis console is not as user-friendly as the SSH\
          \ clients, but has the advantage of \nbeing accessible from any computer,\
          \ without needing the private key to be saved on it. \n Set a user password\
          \ \n \n First, you need to get SSH access to the VM command line in order\
          \ to set a password. \n In PuTTY or Terminal, enter sudo passwd ubuntu (or\
          \ 'root' if your OS isn't Ubuntu) \n Enter a password, that you will use\
          \ to access the VM through a browser. \n \n Log on through the dashboard\
          \ \n \n Log on to the NeCTAR dashboard\n \n Click on the name of the Instance\
          \ you want to access \n Click on the 'Console' tab at the top of the screen\
          \ \n Log on with the username 'ubuntu' (or 'root') and the password you\
          \ set \n \n \n \n NOTE:\nIf you later choose to install a desktop environment\
          \ on your instance, the remote\ndesktop will appear in your browser instead\
          \ of the commandline console. "
        description: "<ul>\n<li><a href=\"#Windows\">Windows User</a></li>\n<li><a\
          \ href=\"#unix\">Mac / Linux User</a></li>\n<li><a href=\"#password\">Access\
          \ via web browser</a></li>\n</ul>\n<p>This section enables you to access\
          \ the virtual machine (VM) created earlier.\nThis will give you a console\
          \ for entering Shell commands to your Linux VM.\nLater sections will help\
          \ you start to use your VM.</p>\n<h2>IP Address</h2>\n<p>You can use an\
          \ SSH client to log into the virtual machine created earlier.\nTo do this\
          \ you will need to enter the IP Address of the VM.</p>\n<ol>\n<li>Log on\
          \ to the Nectar <a href=\"https://dashboard.rc.nectar.org.au/\">Dashboard</a>\n\
          </li>\n<li>Click the 'Instances' tab</li>\n<li>Select and copy the IP Address\
          \ of the instance you want to access</li>\n</ol>\n<p><img alt=\"ipaddress\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/ipaddress.png?raw=true\"\
          ></p>\n<hr>\n<h2>Windows User <a name=\"Windows\"></a>\n</h2>\n<ul>\n<li>Download\
          \ PuTTY(putty.exe) from <a href=\"http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\"\
          >PuTTY download page</a>\n</li>\n<li>Double click putty.exe</li>\n</ul>\n\
          <p><img alt=\"putty1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/putty1.png?raw=true\"\
          ></p>\n<ul>\n<li>Copy/paste the IP address to 'Host Name'</li>\n<li>Under\
          \ 'Connection' on the right side, expand 'SSH' and click 'Auth'</li>\n</ul>\n\
          <p><img alt=\"putty2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/putty2.png?raw=true\"\
          ></p>\n<ul>\n<li>Click the Browse button and select the private key created\
          \ earlier</li>\n<li>Click 'Session' on the right side Category</li>\n<li>Click\
          \ 'Open' button</li>\n<li>Type username 'ubuntu' for Ubuntu image and 'root'\
          \ for other images</li>\n</ul>\n<hr>\n<h2>Linux/Mac User <a name=\"unix\"\
          ></a>\n</h2>\n<p>Type the following command into the console:</p>\n<p><code>ssh\
          \ -i Nectar_Key ubuntu@XX.XX.XX.XX</code></p>\n<ul>\n<li>Replace 'Nectar_Key'\
          \ with the created private key name earlier. You may also\n need to specify\
          \ the full path for the private key (usually '~/.ssh/Nectar_Key')</li>\n\
          <li>Replace 'ubuntu' with 'root' if you are not using an Ubuntu image</li>\n\
          <li>Replace XX.XX.XX.XX with the IP address</li>\n</ul>\n<hr>\n<h2>Access\
          \ through your web browser <a name=\"password\"></a>\n</h2>\n<p>Your VM\
          \ console can also be accessed via the NeCTAR dashboard in your web browser.\n\
          This console is not as user-friendly as the SSH clients, but has the advantage\
          \ of \nbeing accessible from any computer, without needing the private key\
          \ to be saved on it.</p>\n<h3>Set a user password</h3>\n<ol>\n<li>First,\
          \ you need to get SSH access to the VM command line in order to set a password.</li>\n\
          <li>In PuTTY or Terminal, enter <code>sudo passwd ubuntu</code> (or 'root'\
          \ if your OS isn't Ubuntu)</li>\n<li>Enter a password, that you will use\
          \ to access the VM through a browser.</li>\n</ol>\n<h3>Log on through the\
          \ dashboard</h3>\n<ol>\n<li>Log on to the NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/\"\
          >dashboard</a>\n</li>\n<li>Click on the name of the Instance you want to\
          \ access</li>\n<li>Click on the 'Console' tab at the top of the screen</li>\n\
          <li>Log on with the username 'ubuntu' (or 'root') and the password you set</li>\n\
          </ol>\n<p><img alt=\"click\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/click_console.png?raw=true\"\
          ></p>\n<p><img alt=\"login\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/console_login.png?raw=true\"\
          ></p>\n<p>NOTE:\nIf you later choose to install a <a href=\"http://training.nectar.org.au/package07/sections/remoteDesktop.html\"\
          >desktop environment</a> on your instance, the remote\ndesktop will appear\
          \ in your browser instead of the commandline console.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 19
        id: 6000055446
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-02T17:53:32-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000055446
        position: 5
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Accessing Instances
        updated_at: '2015-11-02T17:53:32-05:00'
        user_id: 6002464727
  html: "<ul>\n<li><a href=\"#Windows\">Windows User</a></li>\n<li><a href=\"#unix\"\
    >Mac / Linux User</a></li>\n<li><a href=\"#password\">Access via web browser</a></li>\n\
    </ul>\n<p>This section enables you to access the virtual machine (VM) created\
    \ earlier.\nThis will give you a console for entering Shell commands to your Linux\
    \ VM.\nLater sections will help you start to use your VM.</p>\n<h2>IP Address</h2>\n\
    <p>You can use an SSH client to log into the virtual machine created earlier.\n\
    To do this you will need to enter the IP Address of the VM.</p>\n<ol>\n<li>Log\
    \ on to the Nectar <a href=\"https://dashboard.rc.nectar.org.au/\">Dashboard</a></li>\n\
    <li>Click the 'Instances' tab</li>\n<li>Select and copy the IP Address of the\
    \ instance you want to access</li>\n</ol>\n<p><img alt=\"ipaddress\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/ipaddress.png?raw=true\"\
    ></p>\n<hr>\n<h2>Windows User <a name=\"Windows\"></a></h2>\n<ul>\n<li>Download\
    \ PuTTY(putty.exe) from <a href=\"http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\"\
    >PuTTY download page</a></li>\n<li>Double click putty.exe</li>\n</ul>\n<p><img\
    \ alt=\"putty1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/putty1.png?raw=true\"></p>\n\
    <ul>\n<li>Copy/paste the IP address to 'Host Name'</li>\n<li>Under 'Connection'\
    \ on the right side, expand 'SSH' and click 'Auth'</li>\n</ul>\n<p><img alt=\"\
    putty2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/putty2.png?raw=true\"></p>\n\
    <ul>\n<li>Click the Browse button and select the private key created earlier</li>\n\
    <li>Click 'Session' on the right side Category</li>\n<li>Click 'Open' button</li>\n\
    <li>Type username 'ubuntu' for Ubuntu image and 'root' for other images</li>\n\
    </ul>\n<hr>\n<h2>Linux/Mac User <a name=\"unix\"></a></h2>\n<p>Type the following\
    \ command into the console:</p>\n<p><code>ssh -i Nectar_Key ubuntu@XX.XX.XX.XX</code></p>\n\
    <ul>\n<li>Replace 'Nectar_Key' with the created private key name earlier. You\
    \ may also\n need to specify the full path for the private key (usually '~/.ssh/Nectar_Key')</li>\n\
    <li>Replace 'ubuntu' with 'root' if you are not using an Ubuntu image</li>\n<li>Replace\
    \ XX.XX.XX.XX with the IP address</li>\n</ul>\n<hr>\n<h2>Access through your web\
    \ browser <a name=\"password\"></a></h2>\n<p>Your VM console can also be accessed\
    \ via the NeCTAR dashboard in your web browser.\nThis console is not as user-friendly\
    \ as the SSH clients, but has the advantage of \nbeing accessible from any computer,\
    \ without needing the private key to be saved on it.</p>\n<h3>Set a user password</h3>\n\
    <ol>\n<li>First, you need to get SSH access to the VM command line in order to\
    \ set a password.</li>\n<li>In PuTTY or Terminal, enter <code>sudo passwd ubuntu</code>\
    \ (or 'root' if your OS isn't Ubuntu)</li>\n<li>Enter a password, that you will\
    \ use to access the VM through a browser.</li>\n</ol>\n<h3>Log on through the\
    \ dashboard</h3>\n<ol>\n<li>Log on to the NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >dashboard</a></li>\n<li>Click on the name of the Instance you want to access</li>\n\
    <li>Click on the 'Console' tab at the top of the screen</li>\n<li>Log on with\
    \ the username 'ubuntu' (or 'root') and the password you set</li>\n</ol>\n<p><img\
    \ alt=\"click\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/click_console.png?raw=true\"\
    ></p>\n<p><img alt=\"login\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/console_login.png?raw=true\"\
    ></p>\n<p>NOTE:\nIf you later choose to install a <a href=\"http://training.nectar.org.au/package07/sections/remoteDesktop.html\"\
    >desktop environment</a> on your instance, the remote\ndesktop will appear in\
    \ your browser instead of the commandline console.</p>"
  parent: 21
  sha1: 654c8267329e977abc6512e5ba453d3807613354
  title: Accessing Instances
54:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-15T23:43:00-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Installation \n You can use pip to install the python-swift\
          \ API and the swfit command line API. \n See below for the instructions:\
          \ \n OS X \n ``` \n sudo easy_install pip \n sudo pip install --upgrade\
          \ setuptools \n sudo pip install python-swiftclient \n ``` \n Ubuntu \n\
          \ ``` \n sudo aptitude install python-pip \n sudo pip install python-swiftclient\
          \ \n ``` \n RHEL, CentOS, or Fedora \n ``` \n sudo yum install python-setuptools\
          \ \n sudo easy_install pip \n sudo pip install --upgrade setuptools \n sudo\
          \ pip install python-swiftclient \n ``` \n Windows \n See pip windows for\
          \ instructions on installing pip for Windows. \n pip install python-swiftclient\
          \ \n Configuration \n Before you can use the python swift client and command\
          \ line API you need to be\nauthenticated to the NeCTAR cloud. The below\
          \ shows the instructions of how to\nget username/password and get authenticated.\
          \ \n \n Login to NeCTAR Cloud Dashboard\n \n Click 'Access & Security' \n\
          \ On the 'Access & Security' page, click tab 'API Access' \n Click button\
          \ \"Download OpenStack RC File\" \n Save the file into a directory \n Click\
          \ the drop down list with your email on the right top of page, then click\
          \ 'Settings' \n Click 'Reset Password' and save the password appeared on\
          \ the screen \n \n API normally requires 4 environment variables to be set\
          \ for authentication: \n \n auth URL \n username \n project id or name (most\
          \ clients can handle either) \n password \n \n When using the script file\
          \ you downloaded from NeCTAR Dashboard, these\nvarilabels are set by the\
          \ script file and you can see these variables\nif you open the file. Example:\
          \ \n \n OS_AUTH_URL: https://keystone.rc.nectar.org.au:5000/v2.0/ \n OS_TENANT_NAME=my_science_project\
          \ \n OS_TENANT_ID=sdfsdfsfwrwewer \n OS_USERNAME=clouduser@example.edu.au\
          \ \n OS_PASSWORD=XXXXXX \n \n Authentication for Command Line API \n The\
          \ following instruction assume you use Linux operating system. \n Once you\
          \ have obtained the authentication script and password, you can execute\n\
          the script suing source file-name.sh. and type in the password you\nobtained\
          \ from Dashboard. \n Authentication for python swift API \n You can use\
          \ the below sample code to get authenticated.  \n ``` \n from swiftclient\
          \ import client \n swift = client.Connection(authurl=url, user=username,\
          \ key=password,\ntenant_name=project_name, auth_version='2') \n ``` \n You\
          \ can get authurl, user, key and tenant_name from the above .sh file obtained\n\
          from the NeCTAR Dashboard. \n How to use \n Once the client is authenticated,\
          \ you can start to use them. See below for how\nto get started. \n Command\
          \ Line API \n You can use swift command to manage your objects storage,\
          \ you can type: \n swift --help to find out all the available options. \n\
          \ Python Swift API \n You can also use Python Swift API in your python code\
          \ to access object storage. \n See below for a sample code: \n ``` \n from\
          \ swiftclient import client \n swift = client.Connection(authurl=url, user=username,\
          \ key=password,\ntenant_name=project_name, auth_version='2') \n container_name=\"\
          \" \n swift.get_container(container_name) \n ``` \n You can find more information\
          \ in the Object Storage API section.  "
        description: '<h2>Installation</h2>

          <p>You can use pip to install the python-swift API and the swfit command
          line API.</p>

          <p>See below for the instructions:</p>

          <p>OS X</p>

          <p>```</p>

          <p>sudo easy_install pip</p>

          <p>sudo pip install --upgrade setuptools</p>

          <p>sudo pip install python-swiftclient</p>

          <p>```</p>

          <p>Ubuntu</p>

          <p>```</p>

          <p>sudo aptitude install python-pip</p>

          <p>sudo pip install python-swiftclient</p>

          <p>```</p>

          <p>RHEL, CentOS, or Fedora</p>

          <p>```</p>

          <p>sudo yum install python-setuptools</p>

          <p>sudo easy_install pip</p>

          <p>sudo pip install --upgrade setuptools</p>

          <p>sudo pip install python-swiftclient</p>

          <p>```</p>

          <p>Windows</p>

          <p>See <a href="http://docs.python-guide.org/en/latest/starting/install/win.html#distribute-pip">pip
          windows</a> for instructions on installing pip for Windows.</p>

          <p><code>pip install python-swiftclient</code></p>

          <h2>Configuration</h2>

          <p>Before you can use the python swift client and command line API you need
          to be

          authenticated to the NeCTAR cloud. The below shows the instructions of how
          to

          get username/password and get authenticated.</p>

          <ol>

          <li>Login to NeCTAR Cloud <a href="https://dashboard.rc.nectar.org.au">Dashboard</a>

          </li>

          <li>Click ''Access &amp; Security''</li>

          <li>On the ''Access &amp; Security'' page, click tab ''API Access''</li>

          <li>Click button "Download OpenStack RC File"</li>

          <li>Save the file into a directory</li>

          <li>Click the drop down list with your email on the right top of page, then
          click ''Settings''</li>

          <li>Click ''Reset Password'' and save the password appeared on the screen</li>

          </ol>

          <p>API normally requires 4 environment variables to be set for authentication:</p>

          <ul>

          <li>auth URL</li>

          <li>username</li>

          <li>project id or name (most clients can handle either)</li>

          <li>password</li>

          </ul>

          <p>When using the script file you downloaded from NeCTAR Dashboard, these

          varilabels are set by the script file and you can see these variables

          if you open the file. Example:</p>

          <blockquote>

          <p>OS_AUTH_URL: https://keystone.rc.nectar.org.au:5000/v2.0/</p>

          <p>OS_TENANT_NAME=my_science_project</p>

          <p>OS_TENANT_ID=sdfsdfsfwrwewer</p>

          <p>OS_USERNAME=clouduser@example.edu.au</p>

          <p>OS_PASSWORD=XXXXXX</p>

          </blockquote>

          <h2>Authentication for Command Line API</h2>

          <p>The following instruction assume you use Linux operating system.</p>

          <p>Once you have obtained the authentication script and password, you can
          execute

          the script suing <code>source file-name.sh</code>. and type in the password
          you

          obtained from Dashboard.</p>

          <h3>Authentication for python swift API</h3>

          <p>You can use the below sample code to get authenticated. </p>

          <p>```</p>

          <p>from swiftclient import client</p>

          <p>swift = client.Connection(authurl=url, user=username, key=password,

          tenant_name=project_name, auth_version=''2'')</p>

          <p>```</p>

          <p>You can get authurl, user, key and tenant_name from the above .sh file
          obtained

          from the NeCTAR Dashboard.</p>

          <h2>How to use</h2>

          <p>Once the client is authenticated, you can start to use them. See below
          for how

          to get started.</p>

          <h3>Command Line API</h3>

          <p>You can use swift command to manage your objects storage, you can type:</p>

          <p><code>swift --help</code> to find out all the available options.</p>

          <h3>Python Swift API</h3>

          <p>You can also use Python Swift API in your python code to access object
          storage.</p>

          <p>See below for a sample code:</p>

          <p>```</p>

          <p>from swiftclient import client</p>

          <p>swift = client.Connection(authurl=url, user=username, key=password,

          tenant_name=project_name, auth_version=''2'')</p>

          <p>container_name=""</p>

          <p>swift.get_container(container_name)</p>

          <p>```</p>

          <p>You can find more information in the Object Storage API section. </p>'
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:00-04:00'
          customer_folders: []
          description: Object Storage
          id: 6000190146
          is_default: false
          language_id: 6
          name: Object Storage
          parent_id: 6000190146
          position: 2
          updated_at: '2015-09-03T01:28:00-04:00'
          visibility: 1
        folder_id: 6000190146
        hits: 26
        id: 6000061931
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T21:14:59-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000061931
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Getting Started
        updated_at: '2015-11-01T21:14:59-05:00'
        user_id: 6002464727
  html: '<h2>Installation</h2>

    <p>You can use pip to install the python-swift API and the swfit command line
    API.</p>

    <p>See below for the instructions:</p>

    <p>OS X</p>

    <p>```</p>

    <p>sudo easy_install pip</p>

    <p>sudo pip install --upgrade setuptools</p>

    <p>sudo pip install python-swiftclient</p>

    <p>```</p>

    <p>Ubuntu</p>

    <p>```</p>

    <p>sudo aptitude install python-pip</p>

    <p>sudo pip install python-swiftclient</p>

    <p>```</p>

    <p>RHEL, CentOS, or Fedora</p>

    <p>```</p>

    <p>sudo yum install python-setuptools</p>

    <p>sudo easy_install pip</p>

    <p>sudo pip install --upgrade setuptools</p>

    <p>sudo pip install python-swiftclient</p>

    <p>```</p>

    <p>Windows</p>

    <p>See <a href="http://docs.python-guide.org/en/latest/starting/install/win.html#distribute-pip">pip
    windows</a> for instructions on installing pip for Windows.</p>

    <p><code>pip install python-swiftclient</code></p>

    <h2>Configuration</h2>

    <p>Before you can use the python swift client and command line API you need to
    be

    authenticated to the NeCTAR cloud. The below shows the instructions of how to

    get username/password and get authenticated.</p>

    <ol>

    <li>Login to NeCTAR Cloud <a href="https://dashboard.rc.nectar.org.au">Dashboard</a></li>

    <li>Click ''Access &amp; Security''</li>

    <li>On the ''Access &amp; Security'' page, click tab ''API Access''</li>

    <li>Click button "Download OpenStack RC File"</li>

    <li>Save the file into a directory</li>

    <li>Click the drop down list with your email on the right top of page, then click
    ''Settings''</li>

    <li>Click ''Reset Password'' and save the password appeared on the screen</li>

    </ol>

    <p>API normally requires 4 environment variables to be set for authentication:</p>

    <ul>

    <li>auth URL</li>

    <li>username</li>

    <li>project id or name (most clients can handle either)</li>

    <li>password</li>

    </ul>

    <p>When using the script file you downloaded from NeCTAR Dashboard, these

    varilabels are set by the script file and you can see these variables

    if you open the file. Example:</p>

    <blockquote>

    <p>OS_AUTH_URL: https://keystone.rc.nectar.org.au:5000/v2.0/</p>

    <p>OS_TENANT_NAME=my_science_project</p>

    <p>OS_TENANT_ID=sdfsdfsfwrwewer</p>

    <p>OS_USERNAME=clouduser@example.edu.au</p>

    <p>OS_PASSWORD=XXXXXX</p>

    </blockquote>

    <h2>Authentication for Command Line API</h2>

    <p>The following instruction assume you use Linux operating system.</p>

    <p>Once you have obtained the authentication script and password, you can execute

    the script suing <code>source file-name.sh</code>. and type in the password you

    obtained from Dashboard.</p>

    <h3>Authentication for python swift API</h3>

    <p>You can use the below sample code to get authenticated. </p>

    <p>```</p>

    <p>from swiftclient import client</p>

    <p>swift = client.Connection(authurl=url, user=username, key=password,

    tenant_name=project_name, auth_version=''2'')</p>

    <p>```</p>

    <p>You can get authurl, user, key and tenant_name from the above .sh file obtained

    from the NeCTAR Dashboard.</p>

    <h2>How to use</h2>

    <p>Once the client is authenticated, you can start to use them. See below for
    how

    to get started.</p>

    <h3>Command Line API</h3>

    <p>You can use swift command to manage your objects storage, you can type:</p>

    <p><code>swift --help</code> to find out all the available options.</p>

    <h3>Python Swift API</h3>

    <p>You can also use Python Swift API in your python code to access object storage.</p>

    <p>See below for a sample code:</p>

    <p>```</p>

    <p>from swiftclient import client</p>

    <p>swift = client.Connection(authurl=url, user=username, key=password,

    tenant_name=project_name, auth_version=''2'')</p>

    <p>container_name=""</p>

    <p>swift.get_container(container_name)</p>

    <p>```</p>

    <p>You can find more information in the Object Storage API section. </p>'
  parent: 40
  sha1: c05dabd105fa47fb3ba200a7edcc90bb6fc3a078
  title: Getting Started
55:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-15T23:44:29-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Object Storage \n Object Storage is not a traditional file-system\
          \ or real-time data storage system.\nIt's designed for mostly static data\
          \ that can be retrieved, leveraged, and then\nupdated if necessary. It is\
          \ independent of a particular Virtual Machine and can\nbe updated and used\
          \ without having any Virtual Machine running. It is designed\nto be redundant\
          \ and scalable. \n Concept \n Think about that dataset comprised of 2GB\
          \ files that you read in and analyze\nmany times, but in general it doesn't\
          \ change. Or the images you want to use on\nthe cloud. Those are a couple\
          \ examples of what's perfect for Object Storage.\nObjects are written to\
          \ multiple hardware devices in the data center to ensure\nintegrity, and\
          \ great performance! \n In general, the object store is great for data you\
          \ write once and read many\ntimes, but not suitable for applications like\
          \ databases. It's the safest place\nto put your data on the NeCTAR Research\
          \ Cloud as multiple redundant copies of\nyour data are made, and it has\
          \ great performance. You can access the object\nstore from anywhere on the\
          \ Internet, and data from Object Storage can be\ntransferred to and from\
          \ your Virtual Machine with a variety of http-capable\ntools. \n Object\
          \ Storage has the following features which are quite different from the\n\
          traditional file systems: \n \n \n Access via API at application-level,\
          \ rather than via OS at file-system-level.\n  This means, byte-level interaction\
          \ is not possible and interaction can occur\n  via a single API end point.\
          \ \n \n \n No directory tree: object storage uses a flat structure and objects\
          \ are stored\n  in containers. \n \n \n Metadata lives directly with object.\
          \ \n \n \n Scalability: Object storage systems can scale very well when\
          \ data reaches\n  hundreds of TB and moves into the PB range and beyond.\
          \ \n \n \n Durability: Object Storage systems have mechanisms to check file\
          \ consistency,\n  and handle failed drives, bit-rot, server and cabinet\
          \ failures, etc. These\n  features allow the system to automatically replicate\
          \ data as needed to retain\n  the desired number of replicas, which results\
          \ in extremely high durability\n  and availability of data. \n \n \n Cost:\
          \ Object storage systems are designed to run on commodity hardware, it is\n\
          \  cheaper compared to block or file storage. \n \n \n Swift \n Swift is\
          \ the component that provides object storage for OpenStack. With your\n\
          credentials and via a URL you can request Swift to reserve & create storage\n\
          (called containers or buckets). Files (known as objects when stored in Swift)\n\
          can then be uploaded and accessed similarly by your running Virtual Machines.\
          \ \n The NeCTAR implementation of Swift is geodistributed across Nodes of\
          \ the\nResearch Cloud so that availability is not reliant on any one datacentre\
          \ or\nnetwork infrastructure. Each collection of Swift nodes/hardware is\
          \ known as a\nregion, which may or may not include a Swift proxy server\
          \ (the Internet facing\nand serving component of Swift). With some Swift\
          \ clients/APIs users can\nexplicitly chose which proxy to connect to, this\
          \ might be useful e.g. for\nspeeding up writes to object storage by choosing\
          \ the nearest proxy. Due to\nNeCTAR's Swift having multiple regions (some\
          \ of which are Node private) some\nclients/APIs require explicit configuration\
          \ of a default region, which should\nbe \"Melbourne\" for most users. \n\
          \ Swift does not provide encryption of the data it stores. If you have sensitive\n\
          data that requires encryption you must encrypt the data files before upload. "
        description: "<h2>Object Storage</h2>\n<p>Object Storage is not a traditional\
          \ file-system or real-time data storage system.\nIt's designed for mostly\
          \ static data that can be retrieved, leveraged, and then\nupdated if necessary.\
          \ It is independent of a particular Virtual Machine and can\nbe updated\
          \ and used without having any Virtual Machine running. It is designed\n\
          to be redundant and scalable.</p>\n<h2>Concept</h2>\n<p>Think about that\
          \ dataset comprised of 2GB files that you read in and analyze\nmany times,\
          \ but in general it doesn't change. Or the images you want to use on\nthe\
          \ cloud. Those are a couple examples of what's perfect for Object Storage.\n\
          Objects are written to multiple hardware devices in the data center to ensure\n\
          integrity, and great performance!</p>\n<p>In general, the object store is\
          \ great for data you write once and read many\ntimes, but not suitable for\
          \ applications like databases. It's the safest place\nto put your data on\
          \ the NeCTAR Research Cloud as multiple redundant copies of\nyour data are\
          \ made, and it has great performance. You can access the object\nstore from\
          \ anywhere on the Internet, and data from Object Storage can be\ntransferred\
          \ to and from your Virtual Machine with a variety of http-capable\ntools.</p>\n\
          <p>Object Storage has the following features which are quite different from\
          \ the\ntraditional file systems:</p>\n<ul>\n<li>\n<p><strong>Access via\
          \ API</strong> at application-level, rather than via OS at file-system-level.\n\
          \  This means, byte-level interaction is not possible and interaction can\
          \ occur\n  via a single API end point.</p>\n</li>\n<li>\n<p><strong>No directory\
          \ tree:</strong> object storage uses a flat structure and objects are stored\n\
          \  in containers.</p>\n</li>\n<li>\n<p><strong>Metadata</strong> lives directly\
          \ with object.</p>\n</li>\n<li>\n<p><strong>Scalability:</strong> Object\
          \ storage systems can scale very well when data reaches\n  hundreds of TB\
          \ and moves into the PB range and beyond.</p>\n</li>\n<li>\n<p><strong>Durability:</strong>\
          \ Object Storage systems have mechanisms to check file consistency,\n  and\
          \ handle failed drives, bit-rot, server and cabinet failures, etc. These\n\
          \  features allow the system to automatically replicate data as needed to\
          \ retain\n  the desired number of replicas, which results in extremely high\
          \ durability\n  and availability of data.</p>\n</li>\n<li>\n<p><strong>Cost:</strong>\
          \ Object storage systems are designed to run on commodity hardware, it is\n\
          \  cheaper compared to block or file storage.</p>\n</li>\n</ul>\n<h2>Swift</h2>\n\
          <p>Swift is the component that provides object storage for OpenStack. With\
          \ your\ncredentials and via a URL you can request Swift to reserve &amp;\
          \ create storage\n(called containers or buckets). Files (known as objects\
          \ when stored in Swift)\ncan then be uploaded and accessed similarly by\
          \ your running Virtual Machines.</p>\n<p>The NeCTAR implementation of Swift\
          \ is geodistributed across Nodes of the\nResearch Cloud so that availability\
          \ is not reliant on any one datacentre or\nnetwork infrastructure. Each\
          \ collection of Swift nodes/hardware is known as a\nregion, which may or\
          \ may not include a Swift proxy server (the Internet facing\nand serving\
          \ component of Swift). With some Swift clients/APIs users can\nexplicitly\
          \ chose which proxy to connect to, this might be useful e.g. for\nspeeding\
          \ up writes to object storage by choosing the nearest proxy. Due to\nNeCTAR's\
          \ Swift having multiple regions (some of which are Node private) some\n\
          clients/APIs require explicit configuration of a default region, which should\n\
          be \"Melbourne\" for most users.</p>\n<p>Swift does not provide encryption\
          \ of the data it stores. If you have sensitive\ndata that requires encryption\
          \ you must encrypt the data files before upload.</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:00-04:00'
          customer_folders: []
          description: Object Storage
          id: 6000190146
          is_default: false
          language_id: 6
          name: Object Storage
          parent_id: 6000190146
          position: 2
          updated_at: '2015-09-03T01:28:00-04:00'
          visibility: 1
        folder_id: 6000190146
        hits: 14
        id: 6000061932
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T21:14:01-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000061932
        position: 1
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 1
        thumbs_up: 0
        title: Introduction to Object Storage
        updated_at: '2015-11-01T21:14:01-05:00'
        user_id: 6002464727
  html: "<h2>Object Storage</h2>\n<p>Object Storage is not a traditional file-system\
    \ or real-time data storage system.\nIt's designed for mostly static data that\
    \ can be retrieved, leveraged, and then\nupdated if necessary. It is independent\
    \ of a particular Virtual Machine and can\nbe updated and used without having\
    \ any Virtual Machine running. It is designed\nto be redundant and scalable.</p>\n\
    <h2>Concept</h2>\n<p>Think about that dataset comprised of 2GB files that you\
    \ read in and analyze\nmany times, but in general it doesn't change. Or the images\
    \ you want to use on\nthe cloud. Those are a couple examples of what's perfect\
    \ for Object Storage.\nObjects are written to multiple hardware devices in the\
    \ data center to ensure\nintegrity, and great performance!</p>\n<p>In general,\
    \ the object store is great for data you write once and read many\ntimes, but\
    \ not suitable for applications like databases. It's the safest place\nto put\
    \ your data on the NeCTAR Research Cloud as multiple redundant copies of\nyour\
    \ data are made, and it has great performance. You can access the object\nstore\
    \ from anywhere on the Internet, and data from Object Storage can be\ntransferred\
    \ to and from your Virtual Machine with a variety of http-capable\ntools.</p>\n\
    <p>Object Storage has the following features which are quite different from the\n\
    traditional file systems:</p>\n<ul>\n<li>\n<p><strong>Access via API</strong>\
    \ at application-level, rather than via OS at file-system-level.\n  This means,\
    \ byte-level interaction is not possible and interaction can occur\n  via a single\
    \ API end point.</p>\n</li>\n<li>\n<p><strong>No directory tree:</strong> object\
    \ storage uses a flat structure and objects are stored\n  in containers.</p>\n\
    </li>\n<li>\n<p><strong>Metadata</strong> lives directly with object.</p>\n</li>\n\
    <li>\n<p><strong>Scalability:</strong> Object storage systems can scale very well\
    \ when data reaches\n  hundreds of TB and moves into the PB range and beyond.</p>\n\
    </li>\n<li>\n<p><strong>Durability:</strong> Object Storage systems have mechanisms\
    \ to check file consistency,\n  and handle failed drives, bit-rot, server and\
    \ cabinet failures, etc. These\n  features allow the system to automatically replicate\
    \ data as needed to retain\n  the desired number of replicas, which results in\
    \ extremely high durability\n  and availability of data.</p>\n</li>\n<li>\n<p><strong>Cost:</strong>\
    \ Object storage systems are designed to run on commodity hardware, it is\n  cheaper\
    \ compared to block or file storage.</p>\n</li>\n</ul>\n<h2>Swift</h2>\n<p>Swift\
    \ is the component that provides object storage for OpenStack. With your\ncredentials\
    \ and via a URL you can request Swift to reserve &amp; create storage\n(called\
    \ containers or buckets). Files (known as objects when stored in Swift)\ncan then\
    \ be uploaded and accessed similarly by your running Virtual Machines.</p>\n<p>The\
    \ NeCTAR implementation of Swift is geodistributed across Nodes of the\nResearch\
    \ Cloud so that availability is not reliant on any one datacentre or\nnetwork\
    \ infrastructure. Each collection of Swift nodes/hardware is known as a\nregion,\
    \ which may or may not include a Swift proxy server (the Internet facing\nand\
    \ serving component of Swift). With some Swift clients/APIs users can\nexplicitly\
    \ chose which proxy to connect to, this might be useful e.g. for\nspeeding up\
    \ writes to object storage by choosing the nearest proxy. Due to\nNeCTAR's Swift\
    \ having multiple regions (some of which are Node private) some\nclients/APIs\
    \ require explicit configuration of a default region, which should\nbe \"Melbourne\"\
    \ for most users.</p>\n<p>Swift does not provide encryption of the data it stores.\
    \ If you have sensitive\ndata that requires encryption you must encrypt the data\
    \ files before upload.</p>"
  parent: 40
  sha1: 4fb51710944a71beb2c2efeb135fb867663e309c
  title: Introduction to Object Storage
56:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-15T23:45:20-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Swift Command Line Client \n The swift client is the command-line\
          \ interface (CLI) for the OpenStack Object\nStorage API and its extensions.\
          \ \n It is same as nova client and cinder client, you need to authenticate\
          \ before you\ncan use it. Please refer the getting started to see how to\
          \ get authenticated. \n Please also refer getting started for how to install\
          \ the swift client. \n\n\n\nShell Command\nAction\n\n\n\n\nswift list\n\
          list all containers\n\n\nswift list <container>\nlist all objects in a container\n\
          \n\nswift post <container>\ncreate a container\n\n\nswift delete <container>\
          \ [object/s]\ndelete a container, or objects within a container\n\n\nswift\
          \ upload <container> <file/s_or_directory>\nupload data to the container\n\
          \n\nswift download <container> <object/s>\ndownload objects from a container\n\
          \n\n\n You can execute swift to see what commands are avaiable and\nrun\
          \ swift <command> -h find out more information about a command. \n Client\
          \ python API \n You can also use swift python API to access and manage the\
          \ object storage.\nSample Python code: \n ``` \n from swiftclient import\
          \ client \n swift = client.Connection(authurl=url, user=username, key=password,\n\
          tenant_name=project_name, auth_version='2') \n container_name=\"\" \n swift.get_container(container_name)\
          \ \n container_name=\"first container\" \n swift.put_container(container_name)\
          \ \n swift.delete_container(container_name) \n container_name = \"container\"\
          \ \n object_name = \"object\" \n swift.get_object(container_name, object_name)\
          \ \n swift.put_object(container_name, object) \n ``` \n Please refer to\
          \ above instruction about how to obtain authurl, user, password and\ntenant_name.\
          \ \n\n\n\nPython Command\nAction\n\n\n\n\nswift.get_container\nlist all\
          \ containers\n\n\nswift.get_container(container_name)\nlist all objects\
          \ in a container\n\n\nswift.post_container(container_name)\ncreate a container\n\
          \n\nswift.delete_container(container_name)\ndelete a container\n\n\nswift.put_object(container_name,\
          \ file_name)\nupload data to the container\n\n\nswift.get_object(container_name,\
          \ object_name)\ndownload objects from a container\n\n\n\n Please refer to\
          \ the swift python client document for more\ninformation. "
        description: '<h2>Swift Command Line Client</h2>

          <p>The swift client is the command-line interface (CLI) for the OpenStack
          Object

          Storage API and its extensions.</p>

          <p>It is same as nova client and cinder client, you need to authenticate
          before you

          can use it. Please refer the getting started to see how to get authenticated.</p>

          <p>Please also refer getting started for how to install the swift client.</p>

          <table>

          <thead>

          <tr>

          <th>Shell Command</th>

          <th>Action</th>

          </tr>

          </thead>

          <tbody>

          <tr>

          <td><code>swift list</code></td>

          <td>list all containers</td>

          </tr>

          <tr>

          <td><code>swift list &lt;container&gt;</code></td>

          <td>list all objects in a container</td>

          </tr>

          <tr>

          <td><code>swift post &lt;container&gt;</code></td>

          <td>create a container</td>

          </tr>

          <tr>

          <td><code>swift delete &lt;container&gt; [object/s]</code></td>

          <td>delete a container, or objects within a container</td>

          </tr>

          <tr>

          <td><code>swift upload &lt;container&gt; &lt;file/s_or_directory&gt;</code></td>

          <td>upload data to the container</td>

          </tr>

          <tr>

          <td><code>swift download &lt;container&gt; &lt;object/s&gt;</code></td>

          <td>download objects from a container</td>

          </tr>

          </tbody>

          </table>

          <p>You can execute <code>swift</code> to see what commands are avaiable
          and

          run <code>swift &lt;command&gt; -h</code> find out more information about
          a command.</p>

          <h2>Client python API</h2>

          <p>You can also use swift python API to access and manage the object storage.

          <strong>Sample Python code:</strong></p>

          <p>```</p>

          <p>from swiftclient import client</p>

          <p>swift = client.Connection(authurl=url, user=username, key=password,

          tenant_name=project_name, auth_version=''2'')</p>

          <p>container_name=""</p>

          <p>swift.get_container(container_name)</p>

          <p>container_name="first container"</p>

          <p>swift.put_container(container_name)</p>

          <p>swift.delete_container(container_name)</p>

          <p>container_name = "container"</p>

          <p>object_name = "object"</p>

          <p>swift.get_object(container_name, object_name)</p>

          <p>swift.put_object(container_name, object)</p>

          <p>```</p>

          <p>Please refer to above instruction about how to obtain authurl, user,
          password and

          tenant_name.</p>

          <table>

          <thead>

          <tr>

          <th>Python Command</th>

          <th>Action</th>

          </tr>

          </thead>

          <tbody>

          <tr>

          <td><code>swift.get_container</code></td>

          <td>list all containers</td>

          </tr>

          <tr>

          <td><code>swift.get_container(container_name)</code></td>

          <td>list all objects in a container</td>

          </tr>

          <tr>

          <td><code>swift.post_container(container_name)</code></td>

          <td>create a container</td>

          </tr>

          <tr>

          <td><code>swift.delete_container(container_name)</code></td>

          <td>delete a container</td>

          </tr>

          <tr>

          <td><code>swift.put_object(container_name, file_name)</code></td>

          <td>upload data to the container</td>

          </tr>

          <tr>

          <td><code>swift.get_object(container_name, object_name)</code></td>

          <td>download objects from a container</td>

          </tr>

          </tbody>

          </table>

          <p>Please refer to the <a href="http://docs.openstack.org/developer/python-swiftclient/index.html">swift
          python client document</a> for more

          information.</p>'
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:00-04:00'
          customer_folders: []
          description: Object Storage
          id: 6000190146
          is_default: false
          language_id: 6
          name: Object Storage
          parent_id: 6000190146
          position: 2
          updated_at: '2015-09-03T01:28:00-04:00'
          visibility: 1
        folder_id: 6000190146
        hits: 23
        id: 6000061933
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T22:23:43-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000061933
        position: 3
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: API
        updated_at: '2015-11-01T22:23:43-05:00'
        user_id: 6002464727
  html: '<h2>Swift Command Line Client</h2>

    <p>The swift client is the command-line interface (CLI) for the OpenStack Object

    Storage API and its extensions.</p>

    <p>It is same as nova client and cinder client, you need to authenticate before
    you

    can use it. Please refer the getting started to see how to get authenticated.</p>

    <p>Please also refer getting started for how to install the swift client.</p>

    <table>

    <thead>

    <tr>

    <th>Shell Command</th>

    <th>Action</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>swift list</code></td>

    <td>list all containers</td>

    </tr>

    <tr>

    <td><code>swift list &lt;container&gt;</code></td>

    <td>list all objects in a container</td>

    </tr>

    <tr>

    <td><code>swift post &lt;container&gt;</code></td>

    <td>create a container</td>

    </tr>

    <tr>

    <td><code>swift delete &lt;container&gt; [object/s]</code></td>

    <td>delete a container, or objects within a container</td>

    </tr>

    <tr>

    <td><code>swift upload &lt;container&gt; &lt;file/s_or_directory&gt;</code></td>

    <td>upload data to the container</td>

    </tr>

    <tr>

    <td><code>swift download &lt;container&gt; &lt;object/s&gt;</code></td>

    <td>download objects from a container</td>

    </tr>

    </tbody>

    </table>

    <p>You can execute <code>swift</code> to see what commands are avaiable and

    run <code>swift &lt;command&gt; -h</code> find out more information about a command.</p>

    <h2>Client python API</h2>

    <p>You can also use swift python API to access and manage the object storage.

    <strong>Sample Python code:</strong></p>

    <p>```</p>

    <p>from swiftclient import client</p>

    <p>swift = client.Connection(authurl=url, user=username, key=password,

    tenant_name=project_name, auth_version=''2'')</p>

    <p>container_name=""</p>

    <p>swift.get_container(container_name)</p>

    <p>container_name="first container"</p>

    <p>swift.put_container(container_name)</p>

    <p>swift.delete_container(container_name)</p>

    <p>container_name = "container"</p>

    <p>object_name = "object"</p>

    <p>swift.get_object(container_name, object_name)</p>

    <p>swift.put_object(container_name, object)</p>

    <p>```</p>

    <p>Please refer to above instruction about how to obtain authurl, user, password
    and

    tenant_name.</p>

    <table>

    <thead>

    <tr>

    <th>Python Command</th>

    <th>Action</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>swift.get_container</code></td>

    <td>list all containers</td>

    </tr>

    <tr>

    <td><code>swift.get_container(container_name)</code></td>

    <td>list all objects in a container</td>

    </tr>

    <tr>

    <td><code>swift.post_container(container_name)</code></td>

    <td>create a container</td>

    </tr>

    <tr>

    <td><code>swift.delete_container(container_name)</code></td>

    <td>delete a container</td>

    </tr>

    <tr>

    <td><code>swift.put_object(container_name, file_name)</code></td>

    <td>upload data to the container</td>

    </tr>

    <tr>

    <td><code>swift.get_object(container_name, object_name)</code></td>

    <td>download objects from a container</td>

    </tr>

    </tbody>

    </table>

    <p>Please refer to the <a href="http://docs.openstack.org/developer/python-swiftclient/index.html">swift
    python client document</a> for more

    information.</p>'
  parent: 40
  sha1: 26cc67a2fa8c966ea904e5b79206fa9e765c9ac2
  title: API
57:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-28T20:44:47-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Trouble shooting Heat \n Beyond the OpenStack tips\nwe have\
          \ the following heuristics. \n There are four possible locations in which\
          \ defects can be found: \n \n In the template(s) \n In the automated installation\
          \ of software \n Infrastructure problems \n Incorrect usage of resources\
          \ \n \n We believe that the command line client gives far better feedback\
          \ than\nthe dashboard. Thus preference it when developing your templates.\
          \ \n If the stack fails at start up first check that you don't have a template\n\
          formatting error. \n If you get a YAML error ('Template not in valid format'),\
          \ an online YAML parser\nsuch as the ones at YAML Lint or the Online Yaml\
          \ Parser\ncan be useful in finding the syntax error. \n To convert from\
          \ JSON to YAML, an online converter such as the one at\nConvert JSON to\
          \ YAML Online\ncan be useful in porting between the two formats. \n To debug\
          \ JSON syntax errors the following command set is useful: \n cat template.json\
          \ | python -m json.tool \n Where template.json is the name of your template.\
          \ The command simply pipes the\nfile into python, which in turn will invoke\
          \ the json module that finally will\nvalidate and pretty print the file.\
          \ \n Similarly, if you have the pyaml module installed\nyou can validate\
          \ yaml files: \n cat template.yaml | python -m pyaml \n Where template.yaml\
          \ is the name of your template. \n The form of the command in both of the\
          \ above is useful, in that you can\nverify remote files: \n curl -s https://raw.githubusercontent.com/NeCTAR-RC/heat-templates/master/json/Fedora/WordPress_2_Instances.json\
          \ | python -m json.tool \n If the stack launches, and reports no error,\
          \ suspicion falls on\nthe automated installation of software. \n In this\
          \ scenario turn to on instances log files and scripts. \n On the newly launched\
          \ image: \n \n Heat writes the scripts to the /var/lib/cloud/ directory;\
          \ \n The cloud init log can be found in /var/log/cloud-init.log; \n The\
          \ output of your code run by cloud init can be found in /var/log/cloud-init-output.log;\
          \ \n The output of the cfn init output is found in /var/log/cfn-init.log;\
          \ \n The log showing the parts produced by heat can be found in /var/log/part-handler.log;\
          \ \n The log showing the output of users scripts run can be found in /var/log/heat-provisioning.log.\
          \ \n \n If the stack state does reveal an error start by trying to understand\
          \ the\ncommand line client error messages. \n If you have nested templates,\
          \ you can find the ones that failed to launch with\nthe following command:\
          \ \n heat stack-list --show-nested -f \"status=FAILED\" \n For a given template,\
          \ you can see the list of events associated with the\ntemplate: \n heat\
          \ event-list <template id> \n You can then drill down into the events for\
          \ a given resource: \n heat event-list -r <resource name> <template id>\
          \ \n And then examine a specific event for more detail: \n heat event-show\
          \ <template id> <resource name> <event id> "
        description: '<h1>Trouble shooting Heat</h1>

          <p>Beyond the OpenStack <a href="https://wiki.openstack.org/wiki/Heat/TroubleShooting">tips</a>

          we have the following heuristics.</p>

          <p>There are four possible locations in which defects can be found:</p>

          <ul>

          <li>In the template(s)</li>

          <li>In the automated installation of software</li>

          <li>Infrastructure problems</li>

          <li>Incorrect usage of resources</li>

          </ul>

          <p>We believe that the command line client gives far better feedback than

          the dashboard. Thus preference it when developing your templates.</p>

          <p>If the stack fails at start up first check that you don''t have a template

          formatting error.</p>

          <p>If you get a YAML error (''Template not in valid format''), an online
          YAML parser

          such as the ones at <a href="http://yamllint.com/">YAML Lint</a> or the
          <a href="http://yaml-online-parser.appspot.com/">Online Yaml Parser</a>

          can be useful in finding the syntax error.</p>

          <p>To convert from JSON to YAML, an online converter such as the one at

          <a href="http://jsontoyaml.com/">Convert JSON to YAML Online</a>

          can be useful in porting between the two formats.</p>

          <p>To debug JSON syntax errors the following command set is useful:</p>

          <p><code>cat template.json | python -m json.tool</code></p>

          <p>Where <code>template.json</code> is the name of your template. The command
          simply pipes the

          file into python, which in turn will invoke the json module that finally
          will

          validate and pretty print the file.</p>

          <p>Similarly, if you have the <a href="https://pypi.python.org/pypi/pyaml/">pyaml</a>
          module installed

          you can validate yaml files:</p>

          <p><code>cat template.yaml | python -m pyaml</code></p>

          <p>Where <code>template.yaml</code> is the name of your template.</p>

          <p>The form of the command in both of the above is useful, in that you can

          verify remote files:</p>

          <p><code>curl -s https://raw.githubusercontent.com/NeCTAR-RC/heat-templates/master/json/Fedora/WordPress_2_Instances.json
          | python -m json.tool</code></p>

          <p>If the stack launches, and reports no error, suspicion falls on

          the automated installation of software.</p>

          <p>In this scenario turn to on instances log files and scripts.</p>

          <p>On the newly launched image:</p>

          <ul>

          <li>Heat writes the scripts to the <code>/var/lib/cloud/</code> directory;</li>

          <li>The cloud init log can be found in <code>/var/log/cloud-init.log</code>;</li>

          <li>The output of your code run by cloud init can be found in <code>/var/log/cloud-init-output.log</code>;</li>

          <li>The output of the cfn init output is found in <code>/var/log/cfn-init.log</code>;</li>

          <li>The log showing the parts produced by heat can be found in <code>/var/log/part-handler.log</code>;</li>

          <li>The log showing the output of users scripts run can be found in <code>/var/log/heat-provisioning.log</code>.</li>

          </ul>

          <p>If the stack state does reveal an error start by trying to understand
          the

          command line client error messages.</p>

          <p>If you have nested templates, you can find the ones that failed to launch
          with

          the following command:</p>

          <p><code>heat stack-list --show-nested -f "status=FAILED"</code></p>

          <p>For a given template, you can see the list of events associated with
          the

          template:</p>

          <p><code>heat event-list &lt;template id&gt;</code></p>

          <p>You can then drill down into the events for a given resource:</p>

          <p><code>heat event-list -r &lt;resource name&gt; &lt;template id&gt;</code></p>

          <p>And then examine a specific event for more detail:</p>

          <p><code>heat event-show &lt;template id&gt; &lt;resource name&gt; &lt;event
          id&gt;</code></p>'
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:02-04:00'
          customer_folders: []
          description: Heat
          id: 6000190148
          is_default: false
          language_id: 6
          name: Heat
          parent_id: 6000190148
          position: 4
          updated_at: '2015-09-03T01:28:02-04:00'
          visibility: 1
        folder_id: 6000190148
        hits: 5
        id: 6000068002
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-22T00:56:55-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000068002
        position: 7
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Trouble Shooting
        updated_at: '2015-10-22T00:56:55-04:00'
        user_id: 6002464727
  html: '<h1>Trouble shooting Heat</h1>

    <p>Beyond the OpenStack <a href="https://wiki.openstack.org/wiki/Heat/TroubleShooting">tips</a>

    we have the following heuristics.</p>

    <p>There are four possible locations in which defects can be found:</p>

    <ul>

    <li>In the template(s)</li>

    <li>In the automated installation of software</li>

    <li>Infrastructure problems</li>

    <li>Incorrect usage of resources</li>

    </ul>

    <p>We believe that the command line client gives far better feedback than

    the dashboard. Thus preference it when developing your templates.</p>

    <p>If the stack fails at start up first check that you don''t have a template

    formatting error.</p>

    <p>If you get a YAML error (''Template not in valid format''), an online YAML
    parser

    such as the ones at <a href="http://yamllint.com/">YAML Lint</a> or the <a href="http://yaml-online-parser.appspot.com/">Online
    Yaml Parser</a>

    can be useful in finding the syntax error.</p>

    <p>To convert from JSON to YAML, an online converter such as the one at

    <a href="http://jsontoyaml.com/">Convert JSON to YAML Online</a>

    can be useful in porting between the two formats.</p>

    <p>To debug JSON syntax errors the following command set is useful:</p>

    <p><code>cat template.json | python -m json.tool</code></p>

    <p>Where <code>template.json</code> is the name of your template. The command
    simply pipes the

    file into python, which in turn will invoke the json module that finally will

    validate and pretty print the file.</p>

    <p>Similarly, if you have the <a href="https://pypi.python.org/pypi/pyaml/">pyaml</a>
    module installed

    you can validate yaml files:</p>

    <p><code>cat template.yaml | python -m pyaml</code></p>

    <p>Where <code>template.yaml</code> is the name of your template.</p>

    <p>The form of the command in both of the above is useful, in that you can

    verify remote files:</p>

    <p><code>curl -s https://raw.githubusercontent.com/NeCTAR-RC/heat-templates/master/json/Fedora/WordPress_2_Instances.json
    | python -m json.tool</code></p>

    <p>If the stack launches, and reports no error, suspicion falls on

    the automated installation of software.</p>

    <p>In this scenario turn to on instances log files and scripts.</p>

    <p>On the newly launched image:</p>

    <ul>

    <li>Heat writes the scripts to the <code>/var/lib/cloud/</code> directory;</li>

    <li>The cloud init log can be found in <code>/var/log/cloud-init.log</code>;</li>

    <li>The output of your code run by cloud init can be found in <code>/var/log/cloud-init-output.log</code>;</li>

    <li>The output of the cfn init output is found in <code>/var/log/cfn-init.log</code>;</li>

    <li>The log showing the parts produced by heat can be found in <code>/var/log/part-handler.log</code>;</li>

    <li>The log showing the output of users scripts run can be found in <code>/var/log/heat-provisioning.log</code>.</li>

    </ul>

    <p>If the stack state does reveal an error start by trying to understand the

    command line client error messages.</p>

    <p>If you have nested templates, you can find the ones that failed to launch with

    the following command:</p>

    <p><code>heat stack-list --show-nested -f "status=FAILED"</code></p>

    <p>For a given template, you can see the list of events associated with the

    template:</p>

    <p><code>heat event-list &lt;template id&gt;</code></p>

    <p>You can then drill down into the events for a given resource:</p>

    <p><code>heat event-list -r &lt;resource name&gt; &lt;template id&gt;</code></p>

    <p>And then examine a specific event for more detail:</p>

    <p><code>heat event-show &lt;template id&gt; &lt;resource name&gt; &lt;event id&gt;</code></p>'
  parent: 42
  sha1: 49018f63c2365519bbb102f7706503b28c97870e
  title: Trouble Shooting
58:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-09-29T00:02:03-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Requesting resources on the Research Cloud \n You can run\
          \ instances of various sizes on the cloud, from one to 16 cores, and\nfrom\
          \ one instance to hundreds. \n Project Trials (Automatic, no application\
          \ required) \n When you log into the cloud for the first time, you are automatically\
          \ granted a\nProject Trial Research Allocation of two cores for three months.\
          \ Project Trials\nhave names like pt-2061. \n Within your default allocation\
          \ you can run: \n \n a medium (two core) instance, or \n two small (single\
          \ core) instances. \n As you get near the end of Project Trial, submit a\
          \ request for more resources. \n \n Before submitting a request, increased\
          \ access via your local node \n If you are associated with one of the cloud\
          \ nodes you may be eligible for\naccess to a local allocation of cloud resource.\
          \  Speak to your local node about\nthis prior to submitting a resource request.\
          \ \n Otherwise, your request will be reviewed by the NeCTAR Allocation Committee.\
          \ \n Submit a Request for more resources \n Use the Allocation Request form\
          \ from the left hand side menu of the dashboard. \n \n Allocations New Request\
          \ creates a new project \n Allocations: My Requests adds resources to an\
          \ existing project (you will see\n  your previous requests here) \n \n As\
          \ a rule of thumb, the more resources you ask for, the more detail we require\n\
          about your research. Requesting a few cores won\u2019t be scrutinised as\
          \ much as\nrequesting tens or hundreds of cores. \n What happens after you\
          \ submit a request \n When you submit the request, you will receive a confirmation\
          \ email with all\nyour details.  View or edit your request by clicking on\
          \ the \u2018My Requests\u2019 tab\nat the dashboard. \n Your request will\
          \ be reviewed by the your local node (if any) or the NeCTAR\nAllocation\
          \ Committee.  This can take up to four weeks to process. \n If there are\
          \ any issues with your request, we will get in touch with you.  You\nmay\
          \ be asked to provide more detail about your research or to clarify your\n\
          technical requirements. \n Approved requests become \"Projects\" \n We create\
          \ a Research Cloud Project using your project name, for example \u2018QCIF\n\
          DNA Sequencing Project\u2019.  You will receive an email confirming everything\
          \ is\nready to go. \n As a user, you can be a member of more than one project.\
          \  You select the\ncurrent project to access at the dashboard using a drop\
          \ down menu on the left\nhand side. \n Managing an approved Project (Add\
          \ / remove users) \n Users can be members of multiple Projects sharing each\
          \ Projects resources with\nits members.  To add other users as members of\
          \ your Project(s) see Managing a\nProject \n How do I increase my existing\
          \ Projects' resources \n You can make changes to your request at any time\
          \ by clicking on \u2018My Requests\u2019\nat the dashboard.  This will show\
          \ the requests you have made and you can update\nthem. \n If you change\
          \ and resubmit the request, it will go through the review process\nas outlined\
          \ earlier. "
        description: "<h1>Requesting resources on the Research Cloud</h1>\n<p>You\
          \ can run instances of various sizes on the cloud, from one to 16 cores,\
          \ and\nfrom one instance to hundreds.</p>\n<h2>Project Trials (Automatic,\
          \ no application required)</h2>\n<p>When you log into the cloud for the\
          \ first time, you are automatically granted a\nProject Trial Research Allocation\
          \ of two cores for three months. Project Trials\nhave names like pt-2061.</p>\n\
          <p>Within your default allocation you can run:</p>\n<ul>\n<li>a medium (two\
          \ core) instance, or</li>\n<li>two small (single core) instances.</li>\n\
          <li>As you get near the end of Project Trial, submit a request for more\
          \ resources.</li>\n</ul>\n<h2>Before submitting a request, increased access\
          \ via your local node</h2>\n<p>If you are associated with one of the cloud\
          \ nodes you may be eligible for\naccess to a local allocation of cloud resource.\
          \  Speak to your local node about\nthis prior to submitting a resource request.</p>\n\
          <p>Otherwise, your request will be reviewed by the NeCTAR Allocation Committee.</p>\n\
          <h2>Submit a Request for more resources</h2>\n<p>Use the Allocation Request\
          \ form from the left hand side menu of the dashboard.</p>\n<ul>\n<li>Allocations\
          \ New Request creates a new project</li>\n<li>Allocations: My Requests adds\
          \ resources to an existing project (you will see\n  your previous requests\
          \ here)</li>\n</ul>\n<p>As a rule of thumb, the more resources you ask for,\
          \ the more detail we require\nabout your research. Requesting a few cores\
          \ won\u2019t be scrutinised as much as\nrequesting tens or hundreds of cores.</p>\n\
          <h2>What happens after you submit a request</h2>\n<p>When you submit the\
          \ request, you will receive a confirmation email with all\nyour details.\
          \  View or edit your request by clicking on the \u2018My Requests\u2019\
          \ tab\nat the dashboard.</p>\n<p>Your request will be reviewed by the your\
          \ local node (if any) or the NeCTAR\nAllocation Committee.  This can take\
          \ up to four weeks to process.</p>\n<p>If there are any issues with your\
          \ request, we will get in touch with you.  You\nmay be asked to provide\
          \ more detail about your research or to clarify your\ntechnical requirements.</p>\n\
          <h2>Approved requests become \"Projects\"</h2>\n<p>We create a Research\
          \ Cloud Project using your project name, for example \u2018QCIF\nDNA Sequencing\
          \ Project\u2019.  You will receive an email confirming everything is\nready\
          \ to go.</p>\n<p>As a user, you can be a member of more than one project.\
          \  You select the\ncurrent project to access at the dashboard using a drop\
          \ down menu on the left\nhand side.</p>\n<h2>Managing an approved Project\
          \ (Add / remove users)</h2>\n<p>Users can be members of multiple Projects\
          \ sharing each Projects resources with\nits members.  To add other users\
          \ as members of your Project(s) see Managing a\nProject</p>\n<h2>How do\
          \ I increase my existing Projects' resources</h2>\n<p>You can make changes\
          \ to your request at any time by clicking on \u2018My Requests\u2019\nat\
          \ the dashboard.  This will show the requests you have made and you can\
          \ update\nthem.</p>\n<p>If you change and resubmit the request, it will\
          \ go through the review process\nas outlined earlier.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:09-04:00'
          customer_folders: []
          description: NeCTAR Fundamentals
          id: 6000190155
          is_default: false
          language_id: 6
          name: NeCTAR Fundamentals
          parent_id: 6000190155
          position: 7
          updated_at: '2015-09-03T01:28:09-04:00'
          visibility: 1
        folder_id: 6000190155
        hits: 0
        id: 6000068044
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-09-29T00:02:03-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000068044
        position: 3
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Managing An Allocation
        updated_at: '2015-09-29T00:02:03-04:00'
        user_id: 6002464727
  html: "<h1>Requesting resources on the Research Cloud</h1>\n<p>You can run instances\
    \ of various sizes on the cloud, from one to 16 cores, and\nfrom one instance\
    \ to hundreds.</p>\n<h2>Project Trials (Automatic, no application required)</h2>\n\
    <p>When you log into the cloud for the first time, you are automatically granted\
    \ a\nProject Trial Research Allocation of two cores for three months. Project\
    \ Trials\nhave names like pt-2061.</p>\n<p>Within your default allocation you\
    \ can run:</p>\n<ul>\n<li>a medium (two core) instance, or</li>\n<li>two small\
    \ (single core) instances.</li>\n<li>As you get near the end of Project Trial,\
    \ submit a request for more resources.</li>\n</ul>\n<h2>Before submitting a request,\
    \ increased access via your local node</h2>\n<p>If you are associated with one\
    \ of the cloud nodes you may be eligible for\naccess to a local allocation of\
    \ cloud resource.  Speak to your local node about\nthis prior to submitting a\
    \ resource request.</p>\n<p>Otherwise, your request will be reviewed by the NeCTAR\
    \ Allocation Committee.</p>\n<h2>Submit a Request for more resources</h2>\n<p>Use\
    \ the Allocation Request form from the left hand side menu of the dashboard.</p>\n\
    <ul>\n<li>Allocations New Request creates a new project</li>\n<li>Allocations:\
    \ My Requests adds resources to an existing project (you will see\n  your previous\
    \ requests here)</li>\n</ul>\n<p>As a rule of thumb, the more resources you ask\
    \ for, the more detail we require\nabout your research. Requesting a few cores\
    \ won\u2019t be scrutinised as much as\nrequesting tens or hundreds of cores.</p>\n\
    <h2>What happens after you submit a request</h2>\n<p>When you submit the request,\
    \ you will receive a confirmation email with all\nyour details.  View or edit\
    \ your request by clicking on the \u2018My Requests\u2019 tab\nat the dashboard.</p>\n\
    <p>Your request will be reviewed by the your local node (if any) or the NeCTAR\n\
    Allocation Committee.  This can take up to four weeks to process.</p>\n<p>If there\
    \ are any issues with your request, we will get in touch with you.  You\nmay be\
    \ asked to provide more detail about your research or to clarify your\ntechnical\
    \ requirements.</p>\n<h2>Approved requests become \"Projects\"</h2>\n<p>We create\
    \ a Research Cloud Project using your project name, for example \u2018QCIF\nDNA\
    \ Sequencing Project\u2019.  You will receive an email confirming everything is\n\
    ready to go.</p>\n<p>As a user, you can be a member of more than one project.\
    \  You select the\ncurrent project to access at the dashboard using a drop down\
    \ menu on the left\nhand side.</p>\n<h2>Managing an approved Project (Add / remove\
    \ users)</h2>\n<p>Users can be members of multiple Projects sharing each Projects\
    \ resources with\nits members.  To add other users as members of your Project(s)\
    \ see Managing a\nProject</p>\n<h2>How do I increase my existing Projects' resources</h2>\n\
    <p>You can make changes to your request at any time by clicking on \u2018My Requests\u2019\
    \nat the dashboard.  This will show the requests you have made and you can update\n\
    them.</p>\n<p>If you change and resubmit the request, it will go through the review\
    \ process\nas outlined earlier.</p>"
  parent: 26
  sha1: bba65138cc3ac626e863e69f7a0c6ee103e4a792
  title: Managing An Allocation
59:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-01T22:28:24-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Introduction \n Security should be one of the foremost thoughts\
          \ at all stages of setting up your\nVirtual Machines. It requires good knowledge\
          \ of the fundamentals of Operating\nSystem on your Virtual Machines to implement\
          \ a good security policy. \n What is security?  Security is a set of appropriate\
          \ procedures to protect your\nresources (your data, your account, your services\
          \ and your reputation) against\nrisks. \n The NeCTAR cloud is a public Cloud\
          \ environment. Thus your virtual machines are\nconnected to the rest of\
          \ the world and there are many potential risks associated\nwith that. You\
          \ should always consider your Virtual Machines are vulnerable and\nsome\
          \ security policy and procedures must be implemented. \n Security is a big\
          \ topic and there many complete books on the subject. This\nguide provides\
          \ some basic introduction to security and how the techniques, and\ntools\
          \ can be used to provide additional security on a Virtual Machine. \n Security\
          \ requirements \n Before you implement security policy, you should consider\
          \ the aspects of\nsecurity that are required. The main security requirements\
          \ are:  \n \n \n Confidentiality (don't let anybody else know your password\
          \ confidential data) \n \n \n Authorization (Only allow these that need\
          \ to access data) \n \n \n Integrity (Ensure that the data has not been\
          \ modified) \n \n \n Availability (Ensure that system can perform its required\
          \ functions) \n \n \n Type of Attackers \n It is important to know the type\
          \ of attackers to the Virtual Machine. The types\nof attackers are listed\
          \ below: \n \n \n Crackers, there are people that gain unauthorized access\
          \ to a computer \n \n \n Hackers, any individual who illegally breaks into\
          \ computer systems to damage, \n steal information or perform some malicious\
          \ functions using the systems. \n \n \n Types of attacks against virtual\
          \ machines \n There are many different types of attacks and are different\
          \ depending upon the\noperating system, the service and type of attackers.\
          \ The below list only\nprovides some common types of attack and aims to\
          \ provide an idea of what areas to\nfocus on. \n \n \n Reading data: typically\
          \ associated with steal important information such as\n confidential data,\
          \ account information, passwords, etc. \n \n \n Changing data: potentially\
          \ to gain sufficient access to be able to update data \n \n \n Access to\
          \ virtual machine: get access to your virtual machine and use it to\n attach\
          \ other computer systems. The attackers might setup a service to send email\n\
          \ spam using your virtual machines \n \n \n Denial of service: attacker\
          \ disables or makes unusable the services provided\n by the system  \n \n\
          \ \n Common Methods of Attacking A Virtual machine \n The below shows some\
          \ techniques used to gain access and it only provides an idea\nof methods\
          \ used and doesn't include all available methods. \n \n \n Password guessing:\
          \ where attacks try to guess your system account password and\n in the hope\
          \ they will be lucky and find an easily guessed password. \n \n \n Social\
          \ engineering: attackers pretend to be someone you trust and gain\n information\
          \ (e.g. password) from you. \n \n \n Trojan horses: these are programs planted\
          \ in a virtual machine which appear to be\n harmless. When a trigger is\
          \ activated, the attacker can gain access to the \n virtual machine and\
          \ run certain commands. There are various ways these programs\n get onto\
          \ your virtual machines, such as by installing untrusted software\n packages.\
          \ \n \n \n virus: a virus is a program designed to damage the system. \n\
          \ \n \n software bugs: a software bug can lead to a security exposure. \n\
          \ \n \n address spoofing: this is to change the IP address of the computer,\
          \ to pretend \n it is a trusted system and gain access.  \n \n \n Security\
          \ Policy \n If you already have a security policy in place, you need to\
          \ follow these steps\nto secure your virtual machines. If you don't have\
          \ one, there are a number of\nfactors you need to consider when you are\
          \ creating a security policy. \n You need to make sure you have covered\
          \ each of the issues: Authorization, Authentication,\nConfidentiality, Integrity\
          \ and Availability. You also need to consider how the\npolicy is going to\
          \ be implemented as people might make mistakes. You should\nalways consider\
          \ how this can be enforced and audited.  "
        description: "<h2>Introduction</h2>\n<p>Security should be one of the foremost\
          \ thoughts at all stages of setting up your\nVirtual Machines. It requires\
          \ good knowledge of the fundamentals of Operating\nSystem on your Virtual\
          \ Machines to implement a good security policy.</p>\n<p>What is security?\
          \  Security is a set of appropriate procedures to protect your\nresources\
          \ (your data, your account, your services and your reputation) against\n\
          risks.</p>\n<p>The NeCTAR cloud is a public Cloud environment. Thus your\
          \ virtual machines are\nconnected to the rest of the world and there are\
          \ many potential risks associated\nwith that. You should always consider\
          \ your Virtual Machines are vulnerable and\nsome security policy and procedures\
          \ must be implemented.</p>\n<p>Security is a big topic and there many complete\
          \ books on the subject. This\nguide provides some basic introduction to\
          \ security and how the techniques, and\ntools can be used to provide additional\
          \ security on a Virtual Machine.</p>\n<h2>Security requirements</h2>\n<p>Before\
          \ you implement security policy, you should consider the aspects of\nsecurity\
          \ that are required. The main security requirements are: </p>\n<ul>\n<li>\n\
          <p>Confidentiality (don't let anybody else know your password confidential\
          \ data)</p>\n</li>\n<li>\n<p>Authorization (Only allow these that need to\
          \ access data)</p>\n</li>\n<li>\n<p>Integrity (Ensure that the data has\
          \ not been modified)</p>\n</li>\n<li>\n<p>Availability (Ensure that system\
          \ can perform its required functions)</p>\n</li>\n</ul>\n<h2>Type of Attackers</h2>\n\
          <p>It is important to know the type of attackers to the Virtual Machine.\
          \ The types\nof attackers are listed below:</p>\n<ul>\n<li>\n<p>Crackers,\
          \ there are people that gain unauthorized access to a computer</p>\n</li>\n\
          <li>\n<p>Hackers, any individual who illegally breaks into computer systems\
          \ to damage, \n steal information or perform some malicious functions using\
          \ the systems.</p>\n</li>\n</ul>\n<h2>Types of attacks against virtual machines</h2>\n\
          <p>There are many different types of attacks and are different depending\
          \ upon the\noperating system, the service and type of attackers. The below\
          \ list only\nprovides some common types of attack and aims to provide an\
          \ idea of what areas to\nfocus on.</p>\n<ul>\n<li>\n<p>Reading data: typically\
          \ associated with steal important information such as\n confidential data,\
          \ account information, passwords, etc.</p>\n</li>\n<li>\n<p>Changing data:\
          \ potentially to gain sufficient access to be able to update data</p>\n\
          </li>\n<li>\n<p>Access to virtual machine: get access to your virtual machine\
          \ and use it to\n attach other computer systems. The attackers might setup\
          \ a service to send email\n spam using your virtual machines</p>\n</li>\n\
          <li>\n<p>Denial of service: attacker disables or makes unusable the services\
          \ provided\n by the system </p>\n</li>\n</ul>\n<h2>Common Methods of Attacking\
          \ A Virtual machine</h2>\n<p>The below shows some techniques used to gain\
          \ access and it only provides an idea\nof methods used and doesn't include\
          \ all available methods.</p>\n<ul>\n<li>\n<p>Password guessing: where attacks\
          \ try to guess your system account password and\n in the hope they will\
          \ be lucky and find an easily guessed password.</p>\n</li>\n<li>\n<p>Social\
          \ engineering: attackers pretend to be someone you trust and gain\n information\
          \ (e.g. password) from you.</p>\n</li>\n<li>\n<p>Trojan horses: these are\
          \ programs planted in a virtual machine which appear to be\n harmless. When\
          \ a trigger is activated, the attacker can gain access to the \n virtual\
          \ machine and run certain commands. There are various ways these programs\n\
          \ get onto your virtual machines, such as by installing untrusted software\n\
          \ packages.</p>\n</li>\n<li>\n<p>virus: a virus is a program designed to\
          \ damage the system.</p>\n</li>\n<li>\n<p>software bugs: a software bug\
          \ can lead to a security exposure.</p>\n</li>\n<li>\n<p>address spoofing:\
          \ this is to change the IP address of the computer, to pretend \n it is\
          \ a trusted system and gain access. </p>\n</li>\n</ul>\n<h2>Security Policy</h2>\n\
          <p>If you already have a security policy in place, you need to follow these\
          \ steps\nto secure your virtual machines. If you don't have one, there are\
          \ a number of\nfactors you need to consider when you are creating a security\
          \ policy.</p>\n<p>You need to make sure you have covered each of the issues:\
          \ Authorization, Authentication,\nConfidentiality, Integrity and Availability.\
          \ You also need to consider how the\npolicy is going to be implemented as\
          \ people might make mistakes. You should\nalways consider how this can be\
          \ enforced and audited. </p>"
        folder:
          category_id: 6000122279
          created_at: '2015-10-01T22:28:23-04:00'
          customer_folders: []
          description: Security Guidelines
          id: 6000203455
          is_default: false
          language_id: 6
          name: Security Guidelines
          parent_id: 6000203455
          position: 5
          updated_at: '2015-10-01T22:28:23-04:00'
          visibility: 1
        folder_id: 6000203455
        hits: 9
        id: 6000070469
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-20T21:02:57-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000070469
        position: 1
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Introduction
        updated_at: '2015-10-20T21:02:57-04:00'
        user_id: 6002464727
  html: "<h2>Introduction</h2>\n<p>Security should be one of the foremost thoughts\
    \ at all stages of setting up your\nVirtual Machines. It requires good knowledge\
    \ of the fundamentals of Operating\nSystem on your Virtual Machines to implement\
    \ a good security policy.</p>\n<p>What is security?  Security is a set of appropriate\
    \ procedures to protect your\nresources (your data, your account, your services\
    \ and your reputation) against\nrisks.</p>\n<p>The NeCTAR cloud is a public Cloud\
    \ environment. Thus your virtual machines are\nconnected to the rest of the world\
    \ and there are many potential risks associated\nwith that. You should always\
    \ consider your Virtual Machines are vulnerable and\nsome security policy and\
    \ procedures must be implemented.</p>\n<p>Security is a big topic and there many\
    \ complete books on the subject. This\nguide provides some basic introduction\
    \ to security and how the techniques, and\ntools can be used to provide additional\
    \ security on a Virtual Machine.</p>\n<h2>Security requirements</h2>\n<p>Before\
    \ you implement security policy, you should consider the aspects of\nsecurity\
    \ that are required. The main security requirements are: </p>\n<ul>\n<li>\n<p>Confidentiality\
    \ (don't let anybody else know your password confidential data)</p>\n</li>\n<li>\n\
    <p>Authorization (Only allow these that need to access data)</p>\n</li>\n<li>\n\
    <p>Integrity (Ensure that the data has not been modified)</p>\n</li>\n<li>\n<p>Availability\
    \ (Ensure that system can perform its required functions)</p>\n</li>\n</ul>\n\
    <h2>Type of Attackers</h2>\n<p>It is important to know the type of attackers to\
    \ the Virtual Machine. The types\nof attackers are listed below:</p>\n<ul>\n<li>\n\
    <p>Crackers, there are people that gain unauthorized access to a computer</p>\n\
    </li>\n<li>\n<p>Hackers, any individual who illegally breaks into computer systems\
    \ to damage, \n steal information or perform some malicious functions using the\
    \ systems.</p>\n</li>\n</ul>\n<h2>Types of attacks against virtual machines</h2>\n\
    <p>There are many different types of attacks and are different depending upon\
    \ the\noperating system, the service and type of attackers. The below list only\n\
    provides some common types of attack and aims to provide an idea of what areas\
    \ to\nfocus on.</p>\n<ul>\n<li>\n<p>Reading data: typically associated with steal\
    \ important information such as\n confidential data, account information, passwords,\
    \ etc.</p>\n</li>\n<li>\n<p>Changing data: potentially to gain sufficient access\
    \ to be able to update data</p>\n</li>\n<li>\n<p>Access to virtual machine: get\
    \ access to your virtual machine and use it to\n attach other computer systems.\
    \ The attackers might setup a service to send email\n spam using your virtual\
    \ machines</p>\n</li>\n<li>\n<p>Denial of service: attacker disables or makes\
    \ unusable the services provided\n by the system </p>\n</li>\n</ul>\n<h2>Common\
    \ Methods of Attacking A Virtual machine</h2>\n<p>The below shows some techniques\
    \ used to gain access and it only provides an idea\nof methods used and doesn't\
    \ include all available methods.</p>\n<ul>\n<li>\n<p>Password guessing: where\
    \ attacks try to guess your system account password and\n in the hope they will\
    \ be lucky and find an easily guessed password.</p>\n</li>\n<li>\n<p>Social engineering:\
    \ attackers pretend to be someone you trust and gain\n information (e.g. password)\
    \ from you.</p>\n</li>\n<li>\n<p>Trojan horses: these are programs planted in\
    \ a virtual machine which appear to be\n harmless. When a trigger is activated,\
    \ the attacker can gain access to the \n virtual machine and run certain commands.\
    \ There are various ways these programs\n get onto your virtual machines, such\
    \ as by installing untrusted software\n packages.</p>\n</li>\n<li>\n<p>virus:\
    \ a virus is a program designed to damage the system.</p>\n</li>\n<li>\n<p>software\
    \ bugs: a software bug can lead to a security exposure.</p>\n</li>\n<li>\n<p>address\
    \ spoofing: this is to change the IP address of the computer, to pretend \n it\
    \ is a trusted system and gain access. </p>\n</li>\n</ul>\n<h2>Security Policy</h2>\n\
    <p>If you already have a security policy in place, you need to follow these steps\n\
    to secure your virtual machines. If you don't have one, there are a number of\n\
    factors you need to consider when you are creating a security policy.</p>\n<p>You\
    \ need to make sure you have covered each of the issues: Authorization, Authentication,\n\
    Confidentiality, Integrity and Availability. You also need to consider how the\n\
    policy is going to be implemented as people might make mistakes. You should\n\
    always consider how this can be enforced and audited. </p>"
  parent: 43
  sha1: c401b0c4754bf55fc6819040848b0c9d78e5e4c8
  title: Introduction
60:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-05T18:20:25-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Getting Started \n Security is an complex topic and it is\
          \ impossible to address everything. This\ndocument lists a number of security\
          \ recommendations to help ensure the safe\nrunning of your instances on\
          \ the cloud. Security is important, so please\nfollow these. \n The NecTAR\
          \ team conduct routine and random audits to determine the integrity\nof\
          \ machine images and running instances. If you have discovered a critical\n\
          security flaw, or believe your machine has been compromised, please email\n\
          security@rc.nectar.org.au; or for non-urgent security questions go to NeCTAR\n\
          support to lodge a ticket. \n Mail Servers \n If you run a mail server,\
          \ make sure it only listens on the localhost IP\naddress (127.0.0.1). For\
          \ many clients, if you don't specify an SMTP server\nwhen sending email,\
          \ it will use the recipients SMTP server automatically. This\nis probably\
          \ what you want. Some nodes (Qld) disallow this and require you to\nuse\
          \ their SMTP server for outgoing mail. \n Enable Automatic Updates \n All\
          \ operating systems have the ability to apply updates automatically, and\
          \ its\neasy to turn this on. Please do so, and ask us if you need help.\
          \ \n Upgrade your kernel \n Some updates, such as a kernel upgrade, require\
          \ a reboot of the instance. Please\nschedule this into your regular maintenance.\
          \ \n No open recursive name servers \n If you are running a DNS server,\
          \ please ensure you only allow recursion from\ntrusted hosts. \n Control\
          \ or disable access to your NTP server \n If you run an NTP server, limit\
          \ which systems can access it. Disable the\n'monlist' command as this can\
          \ be used as a denial of service vector on your\nsystem. For info about\
          \ DDoS by NTP, see\nthis article on Cloudflare \n Subscribe to security\
          \ announcements for your OS \n If there is a security problem with your\
          \ Operating System, you need to find\nout as soon as possible. Find the\
          \ appropriate mailing list and keep an eye\nout for anything that requires\
          \ urgent action. As soon as new security bugs are\ndetected, you need to\
          \ execute security upgrade immediately.  \n Run a restrictive firewall \n\
          \ Your instances should be configured so they allow the minimum access required\n\
          to run their service. Please use a host-based firewall, in conjunction with\n\
          the cloud-provided firewall to manage access. \n Disable/Remove unneeded\
          \ accounts \n Keep an eye on the user accounts enabled on your system. Some\
          \ applications\ncreate default accounts which are insecure. You may also\
          \ open a temporary user\naccount to allow quick login for a task and leave\
          \ it forever. This may lead to\nsecurity issue later, and you need to regular\
          \ check and delete these user\naccounts. \n Disable SSH password login -\
          \ use keys \n With enough time and compute power it is possible for passwords\
          \ to be brute\nforce attacked. The average SSH server deals with thousands\
          \ of such attacks\nevery week, so use ssh keys. Ubuntu provides some good\
          \ documentation for it. \n Don't store keys on the image \n The cloud provides\
          \ a metadata service so you can download keys on boot, so\nyou don't need\
          \ to copy keys manually. This ensures that if your key is\ncompromised,\
          \ not all running instances of that image are compromised. \n Install SSH\
          \ attack banning tools \n Install a tools like fail2ban or denyhosts, which\
          \ checks log files for\nattempted breaches and then blocks malicious IP\
          \ addresses. \n Disable unneeded services \n Know what services run on your\
          \ image, and disable the unneeded ones before\nyou upload it. This reduces\
          \ the attack surface. \n Use Encrypted Communications \n Wherever possible,\
          \ use encrypted communications to avoid attacks which\nintercept data. \n\
          \ Use best-practices for logging \n Make sure that services are logging\
          \ to a secure location, that is as\ntamperproof as possible. If logging\
          \ remotely, ensure that it is done over\na secure channel so that eavesdroppers\
          \ cannot monitor what is happening on\nyour instance. \n Only open ports\
          \ for required services \n By default, virtual machines in NeCTAR has closed\
          \ all ports, so in order to make\nservices available to public, you need\
          \ to open certain ports for it. Before you\nopen a open, you need to think\
          \ carefully about what service associated with it\nand what is the intention.\
          \ Never open ports for non-service binded to it. \n Only grant sufficient\
          \ permission to user account \n When creating user account, make sure only\
          \ permission sufficient for its use \nis granted. Never grant extra permission\
          \ if it is not needed. \n Disable root access from SSH and use sudo if possible\
          \ \n Disable root user SSH login and setup user account with sudo permission\
          \ to\nperform administrator tasks. \n Use other port for SSH \n The SSH\
          \ service on the virtual machine uses port 22 by default. This port is \n\
          well-known and can attract many attackers. Use a custom ssh port other than\
          \ 22\nwill improve security. Be noted, the port number below 1024 is well\
          \ reserved and\nshouldn't be used for SSH. \n Read security guide for service\
          \ installed \n Before and after you install a new service on your virtual\
          \ machine, you need to\ncheck the service security guide to perform any\
          \ required steps to harden the\nservice security. "
        description: "<h2>Getting Started</h2>\n<p>Security is an complex topic and\
          \ it is impossible to address everything. This\ndocument lists a number\
          \ of security recommendations to help ensure the safe\nrunning of your instances\
          \ on the cloud. Security is important, so please\nfollow these.</p>\n<p>The\
          \ NecTAR team conduct routine and random audits to determine the integrity\n\
          of machine images and running instances. If you have discovered a critical\n\
          security flaw, or believe your machine has been compromised, please email\n\
          <a href=\"mailto:security@rc.nectar.org.au\">security@rc.nectar.org.au</a>;\
          \ or for non-urgent security questions go to NeCTAR\n<a href=\"https://support.nectar.org.au/support/home\"\
          >support</a> to lodge a ticket.</p>\n<h2>Mail Servers</h2>\n<p>If you run\
          \ a mail server, make sure it only listens on the localhost IP\naddress\
          \ (127.0.0.1). For many clients, if you don't specify an SMTP server\nwhen\
          \ sending email, it will use the recipients SMTP server automatically. This\n\
          is probably what you want. Some nodes (Qld) disallow this and require you\
          \ to\nuse their SMTP server for outgoing mail.</p>\n<h2>Enable Automatic\
          \ Updates</h2>\n<p>All operating systems have the ability to apply updates\
          \ automatically, and its\neasy to turn this on. Please do so, and ask us\
          \ if you need help.</p>\n<h2>Upgrade your kernel</h2>\n<p>Some updates,\
          \ such as a kernel upgrade, require a reboot of the instance. Please\nschedule\
          \ this into your regular maintenance.</p>\n<h2>No open recursive name servers</h2>\n\
          <p>If you are running a DNS server, please ensure you only allow recursion\
          \ from\ntrusted hosts.</p>\n<h2>Control or disable access to your NTP server</h2>\n\
          <p>If you run an NTP server, limit which systems can access it. Disable\
          \ the\n'monlist' command as this can be used as a denial of service vector\
          \ on your\nsystem. For info about DDoS by NTP, see\n<a href=\"https://blog.cloudflare.com/understanding-and-mitigating-ntp-based-ddos-attacks/\"\
          \ title=\"Cloudflare Understanding NTP DDoS\">this article on Cloudflare</a></p>\n\
          <h2>Subscribe to security announcements for your OS</h2>\n<p>If there is\
          \ a security problem with your Operating System, you need to find\nout as\
          \ soon as possible. Find the appropriate mailing list and keep an eye\n\
          out for anything that requires urgent action. As soon as new security bugs\
          \ are\ndetected, you need to execute security upgrade immediately. </p>\n\
          <h2>Run a restrictive firewall</h2>\n<p>Your instances should be configured\
          \ so they allow the minimum access required\nto run their service. Please\
          \ use a host-based firewall, in conjunction with\nthe cloud-provided firewall\
          \ to manage access.</p>\n<h2>Disable/Remove unneeded accounts</h2>\n<p>Keep\
          \ an eye on the user accounts enabled on your system. Some applications\n\
          create default accounts which are insecure. You may also open a temporary\
          \ user\naccount to allow quick login for a task and leave it forever. This\
          \ may lead to\nsecurity issue later, and you need to regular check and delete\
          \ these user\naccounts.</p>\n<h2>Disable SSH password login - use keys</h2>\n\
          <p>With enough time and compute power it is possible for passwords to be\
          \ brute\nforce attacked. The average SSH server deals with thousands of\
          \ such attacks\nevery week, so use ssh keys. Ubuntu provides some good documentation\
          \ for it.</p>\n<h2>Don't store keys on the image</h2>\n<p>The cloud provides\
          \ a metadata service so you can download keys on boot, so\nyou don't need\
          \ to copy keys manually. This ensures that if your key is\ncompromised,\
          \ not all running instances of that image are compromised.</p>\n<h2>Install\
          \ SSH attack banning tools</h2>\n<p>Install a tools like fail2ban or denyhosts,\
          \ which checks log files for\nattempted breaches and then blocks malicious\
          \ IP addresses.</p>\n<h2>Disable unneeded services</h2>\n<p>Know what services\
          \ run on your image, and disable the unneeded ones before\nyou upload it.\
          \ This reduces the attack surface.</p>\n<h2>Use Encrypted Communications</h2>\n\
          <p>Wherever possible, use encrypted communications to avoid attacks which\n\
          intercept data.</p>\n<h2>Use best-practices for logging</h2>\n<p>Make sure\
          \ that services are logging to a secure location, that is as\ntamperproof\
          \ as possible. If logging remotely, ensure that it is done over\na secure\
          \ channel so that eavesdroppers cannot monitor what is happening on\nyour\
          \ instance.</p>\n<h2>Only open ports for required services</h2>\n<p>By default,\
          \ virtual machines in NeCTAR has closed all ports, so in order to make\n\
          services available to public, you need to open certain ports for it. Before\
          \ you\nopen a open, you need to think carefully about what service associated\
          \ with it\nand what is the intention. Never open ports for non-service binded\
          \ to it.</p>\n<h2>Only grant sufficient permission to user account</h2>\n\
          <p>When creating user account, make sure only permission sufficient for\
          \ its use \nis granted. Never grant extra permission if it is not needed.</p>\n\
          <h2>Disable root access from SSH and use sudo if possible</h2>\n<p>Disable\
          \ root user SSH login and setup user account with sudo permission to\nperform\
          \ administrator tasks.</p>\n<h2>Use other port for SSH</h2>\n<p>The SSH\
          \ service on the virtual machine uses port 22 by default. This port is \n\
          well-known and can attract many attackers. Use a custom ssh port other than\
          \ 22\nwill improve security. Be noted, the port number below 1024 is well\
          \ reserved and\nshouldn't be used for SSH.</p>\n<h2>Read security guide\
          \ for service installed</h2>\n<p>Before and after you install a new service\
          \ on your virtual machine, you need to\ncheck the service security guide\
          \ to perform any required steps to harden the\nservice security.</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-10-01T22:28:23-04:00'
          customer_folders: []
          description: Security Guidelines
          id: 6000203455
          is_default: false
          language_id: 6
          name: Security Guidelines
          parent_id: 6000203455
          position: 5
          updated_at: '2015-10-01T22:28:23-04:00'
          visibility: 1
        folder_id: 6000203455
        hits: 3
        id: 6000073462
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-20T21:02:59-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000073462
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Getting Started
        updated_at: '2015-10-20T21:02:59-04:00'
        user_id: 6002464727
  html: "<h2>Getting Started</h2>\n<p>Security is an complex topic and it is impossible\
    \ to address everything. This\ndocument lists a number of security recommendations\
    \ to help ensure the safe\nrunning of your instances on the cloud. Security is\
    \ important, so please\nfollow these.</p>\n<p>The NecTAR team conduct routine\
    \ and random audits to determine the integrity\nof machine images and running\
    \ instances. If you have discovered a critical\nsecurity flaw, or believe your\
    \ machine has been compromised, please email\n<a href=\"&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#115;&#101;&#99;&#117;&#114;&#105;&#116;&#121;&#64;&#114;&#99;&#46;&#110;&#101;&#99;&#116;&#97;&#114;&#46;&#111;&#114;&#103;&#46;&#97;&#117;\"\
    >&#115;&#101;&#99;&#117;&#114;&#105;&#116;&#121;&#64;&#114;&#99;&#46;&#110;&#101;&#99;&#116;&#97;&#114;&#46;&#111;&#114;&#103;&#46;&#97;&#117;</a>;\
    \ or for non-urgent security questions go to NeCTAR\n<a href=\"https://support.nectar.org.au/support/home\"\
    >support</a> to lodge a ticket.</p>\n<h2>Mail Servers</h2>\n<p>If you run a mail\
    \ server, make sure it only listens on the localhost IP\naddress (127.0.0.1).\
    \ For many clients, if you don't specify an SMTP server\nwhen sending email, it\
    \ will use the recipients SMTP server automatically. This\nis probably what you\
    \ want. Some nodes (Qld) disallow this and require you to\nuse their SMTP server\
    \ for outgoing mail.</p>\n<h2>Enable Automatic Updates</h2>\n<p>All operating\
    \ systems have the ability to apply updates automatically, and its\neasy to turn\
    \ this on. Please do so, and ask us if you need help.</p>\n<h2>Upgrade your kernel</h2>\n\
    <p>Some updates, such as a kernel upgrade, require a reboot of the instance. Please\n\
    schedule this into your regular maintenance.</p>\n<h2>No open recursive name servers</h2>\n\
    <p>If you are running a DNS server, please ensure you only allow recursion from\n\
    trusted hosts.</p>\n<h2>Control or disable access to your NTP server</h2>\n<p>If\
    \ you run an NTP server, limit which systems can access it. Disable the\n'monlist'\
    \ command as this can be used as a denial of service vector on your\nsystem. For\
    \ info about DDoS by NTP, see\n<a href=\"https://blog.cloudflare.com/understanding-and-mitigating-ntp-based-ddos-attacks/\"\
    \ title=\"Cloudflare Understanding NTP DDoS\">this article on Cloudflare</a></p>\n\
    <h2>Subscribe to security announcements for your OS</h2>\n<p>If there is a security\
    \ problem with your Operating System, you need to find\nout as soon as possible.\
    \ Find the appropriate mailing list and keep an eye\nout for anything that requires\
    \ urgent action. As soon as new security bugs are\ndetected, you need to execute\
    \ security upgrade immediately. </p>\n<h2>Run a restrictive firewall</h2>\n<p>Your\
    \ instances should be configured so they allow the minimum access required\nto\
    \ run their service. Please use a host-based firewall, in conjunction with\nthe\
    \ cloud-provided firewall to manage access.</p>\n<h2>Disable/Remove unneeded accounts</h2>\n\
    <p>Keep an eye on the user accounts enabled on your system. Some applications\n\
    create default accounts which are insecure. You may also open a temporary user\n\
    account to allow quick login for a task and leave it forever. This may lead to\n\
    security issue later, and you need to regular check and delete these user\naccounts.</p>\n\
    <h2>Disable SSH password login - use keys</h2>\n<p>With enough time and compute\
    \ power it is possible for passwords to be brute\nforce attacked. The average\
    \ SSH server deals with thousands of such attacks\nevery week, so use ssh keys.\
    \ Ubuntu provides some good documentation for it.</p>\n<h2>Don't store keys on\
    \ the image</h2>\n<p>The cloud provides a metadata service so you can download\
    \ keys on boot, so\nyou don't need to copy keys manually. This ensures that if\
    \ your key is\ncompromised, not all running instances of that image are compromised.</p>\n\
    <h2>Install SSH attack banning tools</h2>\n<p>Install a tools like fail2ban or\
    \ denyhosts, which checks log files for\nattempted breaches and then blocks malicious\
    \ IP addresses.</p>\n<h2>Disable unneeded services</h2>\n<p>Know what services\
    \ run on your image, and disable the unneeded ones before\nyou upload it. This\
    \ reduces the attack surface.</p>\n<h2>Use Encrypted Communications</h2>\n<p>Wherever\
    \ possible, use encrypted communications to avoid attacks which\nintercept data.</p>\n\
    <h2>Use best-practices for logging</h2>\n<p>Make sure that services are logging\
    \ to a secure location, that is as\ntamperproof as possible. If logging remotely,\
    \ ensure that it is done over\na secure channel so that eavesdroppers cannot monitor\
    \ what is happening on\nyour instance.</p>\n<h2>Only open ports for required services</h2>\n\
    <p>By default, virtual machines in NeCTAR has closed all ports, so in order to\
    \ make\nservices available to public, you need to open certain ports for it. Before\
    \ you\nopen a open, you need to think carefully about what service associated\
    \ with it\nand what is the intention. Never open ports for non-service binded\
    \ to it.</p>\n<h2>Only grant sufficient permission to user account</h2>\n<p>When\
    \ creating user account, make sure only permission sufficient for its use \nis\
    \ granted. Never grant extra permission if it is not needed.</p>\n<h2>Disable\
    \ root access from SSH and use sudo if possible</h2>\n<p>Disable root user SSH\
    \ login and setup user account with sudo permission to\nperform administrator\
    \ tasks.</p>\n<h2>Use other port for SSH</h2>\n<p>The SSH service on the virtual\
    \ machine uses port 22 by default. This port is \nwell-known and can attract many\
    \ attackers. Use a custom ssh port other than 22\nwill improve security. Be noted,\
    \ the port number below 1024 is well reserved and\nshouldn't be used for SSH.</p>\n\
    <h2>Read security guide for service installed</h2>\n<p>Before and after you install\
    \ a new service on your virtual machine, you need to\ncheck the service security\
    \ guide to perform any required steps to harden the\nservice security.</p>"
  parent: 43
  sha1: 9eecb6e94744460ef2b64df6275159329ba2d106
  title: Getting Started
61:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-05T19:39:49-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Defining an Instance (Virtual Machine) \n An instance (virtual\
          \ machine) is a computing environment completed with virtual\nhardware devices\
          \ which simulates the real computer system. The instance normally\nruns\
          \ as a process in a physical computer system called host and you can boot\
          \ an\noperating system inside the virtual machine. The instance will generally\
          \ behave\nas if it were a real, physical machine. \n Your instance's operating\
          \ system is stored on a virtual hard drive it is called\nan image. You can\
          \ launch a instance by using different images (operating system) \nand you\
          \ can access it through SSH. As the instance thinks it runs in a 'real'\
          \ computer\nsystem, you can do most things as with a normal computer system.\
          \ However, there\nare still some cases that can be restricted by underlying\
          \ virtual hardware support\nsuch as 3D graphics. \n Instances add some overhead\
          \ as there are virtualization layers to support required\nfunctions, so\
          \ they won't be as fast as if you run the operating system on real\nhardware.\
          \ \n Why is virtualization useful \n Virtualization is useful in the following\
          \ scenarios: \n \n \n Flexibility: If you need more instances or more computing\
          \ power, simply launch\n more instances or launch a instance with more CPUs\
          \ and RAMs. \n \n \n Easier software installations: Instances can be used\
          \ to ship the entire software\n configuration. The instances can be 'snapshot'\
          \ into an image after configuration, and\n then other users can use the\
          \ image to launch new virtual machines that are already set up. \n \n \n\
          \ Testing and disaster recovery: Once installed, a virtual machine can be\n\
          \ consider as a \"container\" (snapshot) that can be arbitrarily frozen,\
          \ woken up, copied,\n backed up, and transported between hosts.  \n \n \n\
          \ Infrastructure consolidation: Virtual machines can significantly\n reduce\
          \ hardware and electricity costs. \n \n \n Some terminology \n It is helpful\
          \ to understand some crucial terminology, especially the following\nterms:\
          \ \n \n \n host: This is the computer system where your virtual machine\
          \ is running on top\n of it. \n \n \n guest operating system: This is the\
          \ operating system that is running inside\n the virtual machine. \n \n \n\
          \ virtual machine image: a single file which contains a virtual disk that\
          \ has\n bootable operation system installed on it.  \n \n \n Target audience\
          \ \n This guide aims to provide more detailed information to advanced users\
          \ who might\nact as system administrator to manage instances running in\
          \ NeCTAR Cloud. "
        description: "<h2>Defining an Instance (Virtual Machine)</h2>\n<p>An instance\
          \ (virtual machine) is a computing environment completed with virtual\n\
          hardware devices which simulates the real computer system. The instance\
          \ normally\nruns as a process in a physical computer system called host\
          \ and you can boot an\noperating system inside the virtual machine. The\
          \ instance will generally behave\nas if it were a real, physical machine.</p>\n\
          <p>Your instance's operating system is stored on a virtual hard drive it\
          \ is called\nan image. You can launch a instance by using different images\
          \ (operating system) \nand you can access it through SSH. As the instance\
          \ thinks it runs in a 'real' computer\nsystem, you can do most things as\
          \ with a normal computer system. However, there\nare still some cases that\
          \ can be restricted by underlying virtual hardware support\nsuch as 3D graphics.</p>\n\
          <p>Instances add some overhead as there are virtualization layers to support\
          \ required\nfunctions, so they won't be as fast as if you run the operating\
          \ system on real\nhardware.</p>\n<h2>Why is virtualization useful</h2>\n\
          <p>Virtualization is useful in the following scenarios:</p>\n<ul>\n<li>\n\
          <p><strong>Flexibility:</strong> If you need more instances or more computing\
          \ power, simply launch\n more instances or launch a instance with more CPUs\
          \ and RAMs.</p>\n</li>\n<li>\n<p><strong>Easier software installations:</strong>\
          \ Instances can be used to ship the entire software\n configuration. The\
          \ instances can be 'snapshot' into an image after configuration, and\n then\
          \ other users can use the image to launch new virtual machines that are\
          \ already set up.</p>\n</li>\n<li>\n<p><strong>Testing and disaster recovery:</strong>\
          \ Once installed, a virtual machine can be\n consider as a \"container\"\
          \ (snapshot) that can be arbitrarily frozen, woken up, copied,\n backed\
          \ up, and transported between hosts. </p>\n</li>\n<li>\n<p><strong>Infrastructure\
          \ consolidation:</strong> Virtual machines can significantly\n reduce hardware\
          \ and electricity costs.</p>\n</li>\n</ul>\n<h2>Some terminology</h2>\n\
          <p>It is helpful to understand some crucial terminology, especially the\
          \ following\nterms:</p>\n<ul>\n<li>\n<p><strong>host:</strong> This is the\
          \ computer system where your virtual machine is running on top\n of it.</p>\n\
          </li>\n<li>\n<p><strong>guest operating system:</strong> This is the operating\
          \ system that is running inside\n the virtual machine.</p>\n</li>\n<li>\n\
          <p><strong>virtual machine image:</strong> a single file which contains\
          \ a virtual disk that has\n bootable operation system installed on it. </p>\n\
          </li>\n</ul>\n<h2>Target audience</h2>\n<p>This guide aims to provide more\
          \ detailed information to advanced users who might\nact as system administrator\
          \ to manage instances running in NeCTAR Cloud.</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:27:59-04:00'
          customer_folders: []
          description: Instance Management
          id: 6000190145
          is_default: false
          language_id: 6
          name: Instance Management
          parent_id: 6000190145
          position: 1
          updated_at: '2015-09-03T01:27:59-04:00'
          visibility: 1
        folder_id: 6000190145
        hits: 15
        id: 6000073471
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T20:34:01-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000073471
        position: 1
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Introduction to Instance Management
        updated_at: '2015-11-01T20:34:01-05:00'
        user_id: 6002464727
  html: "<h2>Defining an Instance (Virtual Machine)</h2>\n<p>An instance (virtual\
    \ machine) is a computing environment completed with virtual\nhardware devices\
    \ which simulates the real computer system. The instance normally\nruns as a process\
    \ in a physical computer system called host and you can boot an\noperating system\
    \ inside the virtual machine. The instance will generally behave\nas if it were\
    \ a real, physical machine.</p>\n<p>Your instance's operating system is stored\
    \ on a virtual hard drive it is called\nan image. You can launch a instance by\
    \ using different images (operating system) \nand you can access it through SSH.\
    \ As the instance thinks it runs in a 'real' computer\nsystem, you can do most\
    \ things as with a normal computer system. However, there\nare still some cases\
    \ that can be restricted by underlying virtual hardware support\nsuch as 3D graphics.</p>\n\
    <p>Instances add some overhead as there are virtualization layers to support required\n\
    functions, so they won't be as fast as if you run the operating system on real\n\
    hardware.</p>\n<h2>Why is virtualization useful</h2>\n<p>Virtualization is useful\
    \ in the following scenarios:</p>\n<ul>\n<li>\n<p><strong>Flexibility:</strong>\
    \ If you need more instances or more computing power, simply launch\n more instances\
    \ or launch a instance with more CPUs and RAMs.</p>\n</li>\n<li>\n<p><strong>Easier\
    \ software installations:</strong> Instances can be used to ship the entire software\n\
    \ configuration. The instances can be 'snapshot' into an image after configuration,\
    \ and\n then other users can use the image to launch new virtual machines that\
    \ are already set up.</p>\n</li>\n<li>\n<p><strong>Testing and disaster recovery:</strong>\
    \ Once installed, a virtual machine can be\n consider as a \"container\" (snapshot)\
    \ that can be arbitrarily frozen, woken up, copied,\n backed up, and transported\
    \ between hosts. </p>\n</li>\n<li>\n<p><strong>Infrastructure consolidation:</strong>\
    \ Virtual machines can significantly\n reduce hardware and electricity costs.</p>\n\
    </li>\n</ul>\n<h2>Some terminology</h2>\n<p>It is helpful to understand some crucial\
    \ terminology, especially the following\nterms:</p>\n<ul>\n<li>\n<p><strong>host:</strong>\
    \ This is the computer system where your virtual machine is running on top\n of\
    \ it.</p>\n</li>\n<li>\n<p><strong>guest operating system:</strong> This is the\
    \ operating system that is running inside\n the virtual machine.</p>\n</li>\n\
    <li>\n<p><strong>virtual machine image:</strong> a single file which contains\
    \ a virtual disk that has\n bootable operation system installed on it. </p>\n\
    </li>\n</ul>\n<h2>Target audience</h2>\n<p>This guide aims to provide more detailed\
    \ information to advanced users who might\nact as system administrator to manage\
    \ instances running in NeCTAR Cloud.</p>"
  parent: 39
  sha1: 9465e9ba0f9f6fce94490a8e7ecb8409acf460dd
  title: Introduction to Instance Management
62:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-06T19:44:43-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " The Heat command line client \n In true OpenStack fashion\
          \ there is a Heat command line client.\nTo our biased eye, the command line\
          \ tool seems more fully featured and\ngives more detailed feedback than\
          \ the dashboard, so we prefer to use it\nwhen developing templates. \n Instructions\
          \ on installing the command line tools can be found\nhere. \n We will step\
          \ through some the actions the command line tool can perform,\nusing one\
          \ of the NeCTAR Heat sample templates. \n To list all the stacks you have\
          \ created do (don't forget to source your\nRC file before you start!): \n\
          \ heat stack-list \n Repeat the above command liberally as you step through\
          \ the following commands! \n To validate the template (all one line): \n\
          \ heat template-validate --template-url https://raw.github.com/NeCTAR-RC/heat-templates/master/yaml/Fedora/WordPress_Single_Instance.yaml\
          \ \n Then to use the template to create a stack named \"teststack\" (again,\
          \ all one line): \n heat create teststack --template-url=https://raw.github.com/NeCTAR-RC/heat-templates/master/yaml/Fedora/WordPress_Single_Instance.yaml\
          \ --parameters=\"InstanceType=m1.small;DBUsername=dbuser;DBPassword=verybadpassword;DBRootPassword=anotherverybadpassword;KeyName=nectar_dev\"\
          \ \n PS: Don't forget to customise the command: e.g.: replace the passwords\
          \ with far\nbetter ones, and also to change the key name to match one of\
          \ your keys. \n Shell commands for exploring stacks: \n\n\n\nCommand\nAction\n\
          \n\n\n\nheat stack-list\nlist all the stacks you have created\n\n\nheat\
          \ stack-show\nshow all details for the stack\n\n\nheat event-list <stackname>\n\
          list events in the history of the stack\n\n\nheat event-show <stackname>\
          \ <resource> <eventID>\ninformation on a particular event (using the event\
          \ ID)\n\n\nheat action-suspend <stackname>\nsuspend the stack\n\n\nheat\
          \ action-resume <stackname>\nresume the stack\n\n\nheat resource-list <stackname>\n\
          list the resources being used by the stack\n\n\nheat resource-show <stackname>\
          \ <resource>\ninformation on a particular resource\n\n\nheat resource-metadata\
          \ <stackname> <resource>\nshow metadata on a resource\n\n\nheat template-show\
          \ <stackname>\nshow the template that was used to create the stack\n\n\n\
          heat stack-delete <stackname>\ndelete the stack\n\n\n"
        description: '<h1>The Heat command line client</h1>

          <p>In true OpenStack fashion there is a <a href="http://docs.openstack.org/user-guide/cli.html">Heat
          command line client</a>.

          To our biased eye, the command line tool seems more fully featured and

          gives more detailed feedback than the dashboard, so we prefer to use it

          when developing templates.</p>

          <p>Instructions on installing the command line tools can be found

          <a href="http://docs.openstack.org/user-guide/common/cli_install_openstack_command_line_clients.html">here</a>.</p>

          <p>We will step through some the actions the command line tool can perform,

          using one of the NeCTAR Heat sample templates.</p>

          <p>To list all the stacks you have created do (don''t forget to source your

          RC file before you start!):</p>

          <p><code>heat stack-list</code></p>

          <p>Repeat the above command liberally as you step through the following
          commands!</p>

          <p>To validate the template (all one line):</p>

          <p><code>heat template-validate --template-url https://raw.github.com/NeCTAR-RC/heat-templates/master/yaml/Fedora/WordPress_Single_Instance.yaml</code></p>

          <p>Then to use the template to create a stack named "teststack" (again,
          all one line):</p>

          <p><code>heat create teststack --template-url=https://raw.github.com/NeCTAR-RC/heat-templates/master/yaml/Fedora/WordPress_Single_Instance.yaml
          --parameters="InstanceType=m1.small;DBUsername=dbuser;DBPassword=verybadpassword;DBRootPassword=anotherverybadpassword;KeyName=nectar_dev"</code></p>

          <p><em>PS</em>: Don''t forget to customise the command: e.g.: replace the
          passwords with far

          better ones, and also to change the key name to match one of your keys.</p>

          <p>Shell commands for exploring stacks:</p>

          <table>

          <thead>

          <tr>

          <th>Command</th>

          <th>Action</th>

          </tr>

          </thead>

          <tbody>

          <tr>

          <td><code>heat stack-list</code></td>

          <td>list all the stacks you have created</td>

          </tr>

          <tr>

          <td><code>heat stack-show</code></td>

          <td>show all details for the stack</td>

          </tr>

          <tr>

          <td><code>heat event-list &lt;stackname&gt;</code></td>

          <td>list events in the history of the stack</td>

          </tr>

          <tr>

          <td><code>heat event-show &lt;stackname&gt; &lt;resource&gt; &lt;eventID&gt;</code></td>

          <td>information on a particular event (using the event ID)</td>

          </tr>

          <tr>

          <td><code>heat action-suspend &lt;stackname&gt;</code></td>

          <td>suspend the stack</td>

          </tr>

          <tr>

          <td><code>heat action-resume &lt;stackname&gt;</code></td>

          <td>resume the stack</td>

          </tr>

          <tr>

          <td><code>heat resource-list &lt;stackname&gt;</code></td>

          <td>list the resources being used by the stack</td>

          </tr>

          <tr>

          <td><code>heat resource-show &lt;stackname&gt; &lt;resource&gt;</code></td>

          <td>information on a particular resource</td>

          </tr>

          <tr>

          <td><code>heat resource-metadata &lt;stackname&gt; &lt;resource&gt;</code></td>

          <td>show metadata on a resource</td>

          </tr>

          <tr>

          <td><code>heat template-show &lt;stackname&gt;</code></td>

          <td>show the template that was used to create the stack</td>

          </tr>

          <tr>

          <td><code>heat stack-delete &lt;stackname&gt;</code></td>

          <td>delete the stack</td>

          </tr>

          </tbody>

          </table>'
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:02-04:00'
          customer_folders: []
          description: Heat
          id: 6000190148
          is_default: false
          language_id: 6
          name: Heat
          parent_id: 6000190148
          position: 4
          updated_at: '2015-09-03T01:28:02-04:00'
          visibility: 1
        folder_id: 6000190148
        hits: 21
        id: 6000074218
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T23:26:30-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000074218
        position: 6
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: API
        updated_at: '2015-11-01T23:26:30-05:00'
        user_id: 6002464727
  html: '<h1>The Heat command line client</h1>

    <p>In true OpenStack fashion there is a <a href="http://docs.openstack.org/user-guide/cli.html">Heat
    command line client</a>.

    To our biased eye, the command line tool seems more fully featured and

    gives more detailed feedback than the dashboard, so we prefer to use it

    when developing templates.</p>

    <p>Instructions on installing the command line tools can be found

    <a href="http://docs.openstack.org/user-guide/common/cli_install_openstack_command_line_clients.html">here</a>.</p>

    <p>We will step through some the actions the command line tool can perform,

    using one of the NeCTAR Heat sample templates.</p>

    <p>To list all the stacks you have created do (don''t forget to source your

    RC file before you start!):</p>

    <p><code>heat stack-list</code></p>

    <p>Repeat the above command liberally as you step through the following commands!</p>

    <p>To validate the template (all one line):</p>

    <p><code>heat template-validate --template-url https://raw.github.com/NeCTAR-RC/heat-templates/master/yaml/Fedora/WordPress_Single_Instance.yaml</code></p>

    <p>Then to use the template to create a stack named "teststack" (again, all one
    line):</p>

    <p><code>heat create teststack --template-url=https://raw.github.com/NeCTAR-RC/heat-templates/master/yaml/Fedora/WordPress_Single_Instance.yaml
    --parameters="InstanceType=m1.small;DBUsername=dbuser;DBPassword=verybadpassword;DBRootPassword=anotherverybadpassword;KeyName=nectar_dev"</code></p>

    <p><em>PS</em>: Don''t forget to customise the command: e.g.: replace the passwords
    with far

    better ones, and also to change the key name to match one of your keys.</p>

    <p>Shell commands for exploring stacks:</p>

    <table>

    <thead>

    <tr>

    <th>Command</th>

    <th>Action</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>heat stack-list</code></td>

    <td>list all the stacks you have created</td>

    </tr>

    <tr>

    <td><code>heat stack-show</code></td>

    <td>show all details for the stack</td>

    </tr>

    <tr>

    <td><code>heat event-list &lt;stackname&gt;</code></td>

    <td>list events in the history of the stack</td>

    </tr>

    <tr>

    <td><code>heat event-show &lt;stackname&gt; &lt;resource&gt; &lt;eventID&gt;</code></td>

    <td>information on a particular event (using the event ID)</td>

    </tr>

    <tr>

    <td><code>heat action-suspend &lt;stackname&gt;</code></td>

    <td>suspend the stack</td>

    </tr>

    <tr>

    <td><code>heat action-resume &lt;stackname&gt;</code></td>

    <td>resume the stack</td>

    </tr>

    <tr>

    <td><code>heat resource-list &lt;stackname&gt;</code></td>

    <td>list the resources being used by the stack</td>

    </tr>

    <tr>

    <td><code>heat resource-show &lt;stackname&gt; &lt;resource&gt;</code></td>

    <td>information on a particular resource</td>

    </tr>

    <tr>

    <td><code>heat resource-metadata &lt;stackname&gt; &lt;resource&gt;</code></td>

    <td>show metadata on a resource</td>

    </tr>

    <tr>

    <td><code>heat template-show &lt;stackname&gt;</code></td>

    <td>show the template that was used to create the stack</td>

    </tr>

    <tr>

    <td><code>heat stack-delete &lt;stackname&gt;</code></td>

    <td>delete the stack</td>

    </tr>

    </tbody>

    </table>'
  parent: 42
  sha1: e5724c0fd44f2de8e3a66b69344905e82ff5e26c
  title: API
63:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-08T00:39:43-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Manage instances \n As an NeCTAR Cloud administrative user,\
          \ You can manage instances for users via\nNeCTAR Dashboard. You can perform\
          \ many tasks such as view,\nterminate, reboot and create a snapshot from\
          \ an instance, etc.  \n Control the state of an instance \n To manage and\
          \ change the state of an instance, you can login to the NeCTAR\nDashboard\
          \ and follow the below steps: \n \n \n Login to Dashboard \n \n \n Authenticate\
          \ yourself via AAF \n \n \n Click 'Instances' on the left side of the page\
          \ and click 'Action' drop down\n list for an instance. You should see something\
          \ similar as the below screenshot \n \n \n \n The drop down list includes\
          \ all the available actions you can use to manage the\ninstance. The below\
          \ gives a brief explanation about them: \n \n \n Create Snapshot: create\
          \ a snapshot of instance. The snapshot will save all the\n state of instance\
          \ at the time you taking the snapshot and it can be used an\n image to launch\
          \ a new instance with all the saved state. Only primary disk is\n saved.\
          \ \n \n \n Edit Instance: change the name of the instance. \n \n \n Edit\
          \ Security Groups: you can add/delete security groups associated with the\n\
          \ instance. This allows your open/close ports after instance has been launched.\
          \ \n \n \n Console: this action allows you to access the instance via the\
          \ VNC console and\n allow your to access the instance via the web browser.\
          \ \n \n \n View Log: this action allows you view the boot messages that\
          \ normally displayed\n on the standard output (monitor). This is useful\
          \ for debugging. \n \n \n Pause Instance: this action temporarily pauses\
          \ the state of a running instance,\n it is useful for taking a snapshot.\
          \ \n \n \n Suspend Instance: this action stops a running instance. The difference\
          \ between\n pause and suspend is that pause is only for a shot period, all\
          \ resources binded\n to an instance are still available and suspend is for\
          \ long-term and resources may\n be removed. \n \n \n Soft Reboot Instance:\
          \ this action allows users to reboot the running instance. \n \n \n Hard\
          \ Reboot Instance: this action allows users to reboot the running instance.\n\
          \ The difference between soft reboot and hard reboot are that soft reboot\
          \ issues\n reboot signal to the running instance and will do a smooth reboot\
          \ and the hard\n reboot simulates the reboot like pressing the computer\
          \ power button. It is useful\n if the running instance is not responding\
          \ to any commands. \n \n \n Rebuild Instance: use different image to build\
          \ a new instance. The new instance\n maintains the same specification of\
          \ the old instance such as cpus, rams and etc.\n Remember, this action will\
          \ destroy all data in the instance and need to use with\n caution. \n \n\
          \ \n Terminate Instance: permanently delete the instance and data is removed\
          \ as well. \n \n \n You can refer to this document to see more information\
          \ about\nmanaging instances. \n Create instance snapshots \n To create an\
          \ snapshot, you can click 'Create Snapshot' from the above action list\n\
          and you will see a pop-up window like below: \n \n Provide a meaningful\
          \ name and the click 'Create Snapshot' button. \n Notes: You should always\
          \ pause the instance before snapshot it. However, live\nsnapshot is also\
          \ possible and you need to make sure the snapshot is consistent\nwith the\
          \ instance as the snapshot doesn't capture the state of the memory. So\n\
          before snapshot, you need to ensure that: \n \n \n running programs have\
          \ written their contenst to disk \n \n \n the file system does not have\
          \ any 'dirty' buffers \n \n \n For Linux user, you can execute sync to write\
          \ dirty buffer to disk.\nIt is not sufficient to only use sync to get file\
          \ system consistent. It is\nrecommend to use fsfreeze tool. In ubuntu, you\
          \ can run sudo apt-get install util-linux\nto install the fsfreeze tool.\
          \ \n To freeze a file system, you can run fsfreeze -f /mnt as a root user\n\
          in a command line console, where /mnt is the file system mount point. \n\
          \ After you created the snapshot, you can unfreeze the file system by executing\
          \ fsfreeze -u /mnt\nwhere /mnt is the file system mount point. \n You can\
          \ refer to Taking Snapshot for more information. \n Change security group\
          \ \n You can click \"Edit Security groups\" from the drop down list to add/remove\n\
          security group for a running instance. \n \n From the above screenshot,\
          \ You can see the currently applied security groups are\nlisted on the right\
          \ hand side and left hand side is a list of available security\ngroups.\
          \ You can click the plus button to add the available security groups\nto\
          \ the right hand side and click the minus button to remove a security group.\n\
          Once you have done, you can click 'Save' button to save your changes.  \n\
          \ Launch a VNC console \n Sometimes, you need to access your instance directly\
          \ via a web browser and you\ncan do it by using the VNC console. The console\
          \ provides a great way to access\nthe instance if you haven't open port\
          \ for SSH. \n Click the \"console\" item from the drop down list and you\
          \ should see a screen\nlike below: \n \n You can then click the 'Click here\
          \ to show only console' and you should see the\nfollowing screen: \n \n\
          \ After the login prompt appears, you can type in username and password\
          \ to login\nto the instance and perform any task as required. \n View log\
          \ \n The console log provides very useful information that may be required\
          \ in\ntroubleshooting issues. You can access the log by clicking \"view\
          \ log\" item from\nthe action drop down list. After clicking, you should\
          \ see the following screen: \n \n This gives you the latest system log messages,\
          \ if you want to see the full logs,\nyou can click the 'View Full Log Button'.\
          \ \n Create and Manage Volumes \n You can attach volumes as persistent storage\
          \ to instances. You can attach or\ndetach a volume from a instance at any\
          \ time and it is also easy to create snapshot\nfrom or delete a volume.\
          \ \n To create a volume, you can follow the below steps: \n \n \n Log in\
          \ to the dashboard \n \n \n select the project from the CURRENT PROJECT\
          \ on the Project tab \n \n \n On the Project tab, open the Compute tab and\
          \ click Volumes category \n \n \n Click 'Create Volume' button \n \n \n\
          \ In the pop-up window, you can enter or select the following values: \n\
          \ \n \n Volume Name: name for the volume \n Description: description for\
          \ the volume \n Type: Leave this field blank \n Size: The size of the volume\
          \ in gigabytes \n Volume Source: To create a standard empty disk for data\
          \ storage, select \"No source, empty volume\" \n Availability Zone: Select\
          \ the Availability Zone from the list \n \n \n Click 'Create Volume' button\
          \ \n \n \n The dashboard shows the volume on the 'Volumes' tab. \n \n \n\
          \ To attach a volume to an instance:  \n \n \n Log in to the dashboard[dashboard\
          \ ] \n \n \n select the project from the CURRENT PROJECT on the Project\
          \ tab \n \n \n On the Project tab, open the Compute tab and click Volumes\
          \ category \n \n \n Select the volume to add to an instance and in the action\
          \ drop down list, \n click Edit Attachments \n \n \n In the Manage Volume\
          \ Attachments dialog box, select an instance and click\n 'Attach Volume'\
          \ button \n \n \n To detach a volume from an instance: \n \n \n Log in to\
          \ the dashboard, choose a project, and click Volumes \n \n \n Select the\
          \ volume and click Edit Attachments \n \n \n Click 'Detach Volume' button\
          \ and confirm your changes \n \n \n To delete a volume: \n \n \n Log in\
          \ to the dashboard, choose a project, and click Volumes \n \n \n Select\
          \ the check boxes for the volumes that you want to delete. \n \n \n Click\
          \ 'Delete Volumes' button and confirm your choice. \n \n \n Note: the data\
          \ in its attached volumes is not destroyed after you delete a volume "
        description: "<h1>Manage instances</h1>\n<p>As an NeCTAR Cloud administrative\
          \ user, You can manage instances for users via\nNeCTAR <a href=\"https://dashboard.rc.nectar.org.au/\"\
          >Dashboard</a>. You can perform many tasks such as view,\nterminate, reboot\
          \ and create a snapshot from an instance, etc. </p>\n<h2>Control the state\
          \ of an instance</h2>\n<p>To manage and change the state of an instance,\
          \ you can login to the NeCTAR\n<a href=\"https://dashboard.rc.nectar.org.au/\"\
          >Dashboard</a> and follow the below steps:</p>\n<ul>\n<li>\n<p>Login to\
          \ <a href=\"https://dashboard.rc.nectar.org.au/\">Dashboard</a></p>\n</li>\n\
          <li>\n<p>Authenticate yourself via AAF</p>\n</li>\n<li>\n<p>Click 'Instances'\
          \ on the left side of the page and click 'Action' drop down\n list for an\
          \ instance. You should see something similar as the below screenshot</p>\n\
          </li>\n</ul>\n<p><img alt=\"instance management\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Instance%20Management--DOCID39/images/instance_management.png?raw=true\"\
          ></p>\n<p>The drop down list includes all the available actions you can\
          \ use to manage the\ninstance. The below gives a brief explanation about\
          \ them:</p>\n<ul>\n<li>\n<p><strong>Create Snapshot:</strong> create a snapshot\
          \ of instance. The snapshot will save all the\n state of instance at the\
          \ time you taking the snapshot and it can be used an\n image to launch a\
          \ new instance with all the saved state. Only primary disk is\n saved.</p>\n\
          </li>\n<li>\n<p><strong>Edit Instance:</strong> change the name of the instance.</p>\n\
          </li>\n<li>\n<p><strong>Edit Security Groups:</strong> you can add/delete\
          \ security groups associated with the\n instance. This allows your open/close\
          \ ports after instance has been launched.</p>\n</li>\n<li>\n<p><strong>Console:</strong>\
          \ this action allows you to access the instance via the VNC console and\n\
          \ allow your to access the instance via the web browser.</p>\n</li>\n<li>\n\
          <p><strong>View Log:</strong> this action allows you view the boot messages\
          \ that normally displayed\n on the standard output (monitor). This is useful\
          \ for debugging.</p>\n</li>\n<li>\n<p><strong>Pause Instance:</strong> this\
          \ action temporarily pauses the state of a running instance,\n it is useful\
          \ for taking a snapshot.</p>\n</li>\n<li>\n<p><strong>Suspend Instance:</strong>\
          \ this action stops a running instance. The difference between\n pause and\
          \ suspend is that pause is only for a shot period, all resources binded\n\
          \ to an instance are still available and suspend is for long-term and resources\
          \ may\n be removed.</p>\n</li>\n<li>\n<p><strong>Soft Reboot Instance:</strong>\
          \ this action allows users to reboot the running instance.</p>\n</li>\n\
          <li>\n<p><strong>Hard Reboot Instance:</strong> this action allows users\
          \ to reboot the running instance.\n The difference between soft reboot and\
          \ hard reboot are that soft reboot issues\n reboot signal to the running\
          \ instance and will do a smooth reboot and the hard\n reboot simulates the\
          \ reboot like pressing the computer power button. It is useful\n if the\
          \ running instance is not responding to any commands.</p>\n</li>\n<li>\n\
          <p><strong>Rebuild Instance:</strong> use different image to build a new\
          \ instance. The new instance\n maintains the same specification of the old\
          \ instance such as cpus, rams and etc.\n Remember, this action will destroy\
          \ all data in the instance and need to use with\n caution.</p>\n</li>\n\
          <li>\n<p><strong>Terminate Instance:</strong> permanently delete the instance\
          \ and data is removed as well.</p>\n</li>\n</ul>\n<p>You can refer to this\
          \ <a href=\"http://docs.openstack.org/user-guide/dashboard_launch_instances.html\"\
          >document</a> to see more information about\nmanaging instances.</p>\n<h2>Create\
          \ instance snapshots</h2>\n<p>To create an snapshot, you can click 'Create\
          \ Snapshot' from the above action list\nand you will see a pop-up window\
          \ like below:</p>\n<p><img alt=\"snapshot\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Instance%20Management--DOCID39/images/snapshot.png?raw=true\"\
          ></p>\n<p>Provide a meaningful name and the click 'Create Snapshot' button.</p>\n\
          <p>Notes: You should always pause the instance before snapshot it. However,\
          \ live\nsnapshot is also possible and you need to make sure the snapshot\
          \ is consistent\nwith the instance as the snapshot doesn't capture the state\
          \ of the memory. So\nbefore snapshot, you need to ensure that:</p>\n<ul>\n\
          <li>\n<p>running programs have written their contenst to disk</p>\n</li>\n\
          <li>\n<p>the file system does not have any 'dirty' buffers</p>\n</li>\n\
          </ul>\n<p>For Linux user, you can execute <code>sync</code> to write dirty\
          \ buffer to disk.\nIt is not sufficient to only use sync to get file system\
          \ consistent. It is\nrecommend to use fsfreeze tool. In ubuntu, you can\
          \ run <code>sudo apt-get install util-linux</code>\nto install the fsfreeze\
          \ tool.</p>\n<p>To freeze a file system, you can run <code>fsfreeze -f /mnt</code>\
          \ as a root user\nin a command line console, where /mnt is the file system\
          \ mount point.</p>\n<p>After you created the snapshot, you can unfreeze\
          \ the file system by executing <code>fsfreeze -u /mnt</code>\nwhere /mnt\
          \ is the file system mount point.</p>\n<p>You can refer to <a href=\"http://docs.openstack.org/openstack-ops/content/snapshots.html\"\
          >Taking Snapshot</a> for more information.</p>\n<h2>Change security group</h2>\n\
          <p>You can click \"Edit Security groups\" from the drop down list to add/remove\n\
          security group for a running instance.</p>\n<p><img alt=\"instance management\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Instance%20Management--DOCID39/images/security_group.png?raw=true\"\
          ></p>\n<p>From the above screenshot, You can see the currently applied security\
          \ groups are\nlisted on the right hand side and left hand side is a list\
          \ of available security\ngroups. You can click the plus button to add the\
          \ available security groups\nto the right hand side and click the minus\
          \ button to remove a security group.\nOnce you have done, you can click\
          \ 'Save' button to save your changes. </p>\n<h2>Launch a VNC console</h2>\n\
          <p>Sometimes, you need to access your instance directly via a web browser\
          \ and you\ncan do it by using the VNC console. The console provides a great\
          \ way to access\nthe instance if you haven't open port for SSH.</p>\n<p>Click\
          \ the \"console\" item from the drop down list and you should see a screen\n\
          like below:</p>\n<p><img alt=\"instance management\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Instance%20Management--DOCID39/images/console1.png?raw=true\"\
          ></p>\n<p>You can then click the 'Click here to show only console' and you\
          \ should see the\nfollowing screen:</p>\n<p><img alt=\"instance management\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Instance%20Management--DOCID39/images/console2.png?raw=true\"\
          ></p>\n<p>After the login prompt appears, you can type in username and password\
          \ to login\nto the instance and perform any task as required.</p>\n<h2>View\
          \ log</h2>\n<p>The console log provides very useful information that may\
          \ be required in\ntroubleshooting issues. You can access the log by clicking\
          \ \"view log\" item from\nthe action drop down list. After clicking, you\
          \ should see the following screen:</p>\n<p><img alt=\"instance management\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Instance%20Management--DOCID39/images/log.png?raw=true\"\
          ></p>\n<p>This gives you the latest system log messages, if you want to\
          \ see the full logs,\nyou can click the 'View Full Log Button'.</p>\n<h2>Create\
          \ and Manage Volumes</h2>\n<p>You can attach volumes as persistent storage\
          \ to instances. You can attach or\ndetach a volume from a instance at any\
          \ time and it is also easy to create snapshot\nfrom or delete a volume.</p>\n\
          <p>To <strong>create a volume</strong>, you can follow the below steps:</p>\n\
          <ul>\n<li>\n<p>Log in to the <a href=\"https://dashboard.rc.nectar.org.au/\"\
          >dashboard</a></p>\n</li>\n<li>\n<p>select the project from the CURRENT\
          \ PROJECT on the Project tab</p>\n</li>\n<li>\n<p>On the Project tab, open\
          \ the Compute tab and click Volumes category</p>\n</li>\n<li>\n<p>Click\
          \ 'Create Volume' button</p>\n</li>\n<li>\n<p>In the pop-up window, you\
          \ can enter or select the following values:</p>\n</li>\n</ul>\n<p><strong>Volume\
          \ Name:</strong> name for the volume</p>\n<p><strong>Description</strong>:\
          \ description for the volume</p>\n<p><strong>Type:</strong> Leave this field\
          \ blank</p>\n<p><strong>Size:</strong> The size of the volume in gigabytes</p>\n\
          <p><strong>Volume Source:</strong> To create a standard empty disk for data\
          \ storage, select \"No source, empty volume\"</p>\n<p><strong>Availability\
          \ Zone:</strong> Select the Availability Zone from the list</p>\n<ul>\n\
          <li>\n<p>Click 'Create Volume' button</p>\n</li>\n<li>\n<p>The dashboard\
          \ shows the volume on the 'Volumes' tab.</p>\n</li>\n</ul>\n<p>To <strong>attach\
          \ a volume</strong> to an instance: </p>\n<ul>\n<li>\n<p>Log in to the <a\
          \ href=\"https://dashboard.rc.nectar.org.au/\">dashboard</a>[dashboard ]</p>\n\
          </li>\n<li>\n<p>select the project from the CURRENT PROJECT on the Project\
          \ tab</p>\n</li>\n<li>\n<p>On the Project tab, open the Compute tab and\
          \ click Volumes category</p>\n</li>\n<li>\n<p>Select the volume to add to\
          \ an instance and in the action drop down list, \n click Edit Attachments</p>\n\
          </li>\n<li>\n<p>In the Manage Volume Attachments dialog box, select an instance\
          \ and click\n 'Attach Volume' button</p>\n</li>\n</ul>\n<p>To <strong>detach\
          \ a volume</strong> from an instance:</p>\n<ul>\n<li>\n<p>Log in to the\
          \ <a href=\"https://dashboard.rc.nectar.org.au/\">dashboard</a>, choose\
          \ a project, and click Volumes</p>\n</li>\n<li>\n<p>Select the volume and\
          \ click Edit Attachments</p>\n</li>\n<li>\n<p>Click 'Detach Volume' button\
          \ and confirm your changes</p>\n</li>\n</ul>\n<p>To <strong>delete a volume:</strong></p>\n\
          <ul>\n<li>\n<p>Log in to the <a href=\"https://dashboard.rc.nectar.org.au/\"\
          >dashboard</a>, choose a project, and click Volumes</p>\n</li>\n<li>\n<p>Select\
          \ the check boxes for the volumes that you want to delete.</p>\n</li>\n\
          <li>\n<p>Click 'Delete Volumes' button and confirm your choice.</p>\n</li>\n\
          </ul>\n<p>Note: the data in its attached volumes is not destroyed after\
          \ you delete a volume</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:27:59-04:00'
          customer_folders: []
          description: Instance Management
          id: 6000190145
          is_default: false
          language_id: 6
          name: Instance Management
          parent_id: 6000190145
          position: 1
          updated_at: '2015-09-03T01:27:59-04:00'
          visibility: 1
        folder_id: 6000190145
        hits: 16
        id: 6000075745
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T21:02:40-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000075745
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Getting Started
        updated_at: '2015-11-01T21:02:40-05:00'
        user_id: 6002464727
  html: "<h1>Manage instances</h1>\n<p>As an NeCTAR Cloud administrative user, You\
    \ can manage instances for users via\nNeCTAR <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >Dashboard</a>. You can perform many tasks such as view,\nterminate, reboot and\
    \ create a snapshot from an instance, etc. </p>\n<h2>Control the state of an instance</h2>\n\
    <p>To manage and change the state of an instance, you can login to the NeCTAR\n\
    <a href=\"https://dashboard.rc.nectar.org.au/\">Dashboard</a> and follow the below\
    \ steps:</p>\n<ul>\n<li>\n<p>Login to <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >Dashboard</a></p>\n</li>\n<li>\n<p>Authenticate yourself via AAF</p>\n</li>\n\
    <li>\n<p>Click 'Instances' on the left side of the page and click 'Action' drop\
    \ down\n list for an instance. You should see something similar as the below screenshot</p>\n\
    </li>\n</ul>\n<p><img alt=\"instance management\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Instance Management--DOCID39/images/instance_management.png?raw=true\"\
    ></p>\n<p>The drop down list includes all the available actions you can use to\
    \ manage the\ninstance. The below gives a brief explanation about them:</p>\n\
    <ul>\n<li>\n<p><strong>Create Snapshot:</strong> create a snapshot of instance.\
    \ The snapshot will save all the\n state of instance at the time you taking the\
    \ snapshot and it can be used an\n image to launch a new instance with all the\
    \ saved state. Only primary disk is\n saved.</p>\n</li>\n<li>\n<p><strong>Edit\
    \ Instance:</strong> change the name of the instance.</p>\n</li>\n<li>\n<p><strong>Edit\
    \ Security Groups:</strong> you can add/delete security groups associated with\
    \ the\n instance. This allows your open/close ports after instance has been launched.</p>\n\
    </li>\n<li>\n<p><strong>Console:</strong> this action allows you to access the\
    \ instance via the VNC console and\n allow your to access the instance via the\
    \ web browser.</p>\n</li>\n<li>\n<p><strong>View Log:</strong> this action allows\
    \ you view the boot messages that normally displayed\n on the standard output\
    \ (monitor). This is useful for debugging.</p>\n</li>\n<li>\n<p><strong>Pause\
    \ Instance:</strong> this action temporarily pauses the state of a running instance,\n\
    \ it is useful for taking a snapshot.</p>\n</li>\n<li>\n<p><strong>Suspend Instance:</strong>\
    \ this action stops a running instance. The difference between\n pause and suspend\
    \ is that pause is only for a shot period, all resources binded\n to an instance\
    \ are still available and suspend is for long-term and resources may\n be removed.</p>\n\
    </li>\n<li>\n<p><strong>Soft Reboot Instance:</strong> this action allows users\
    \ to reboot the running instance.</p>\n</li>\n<li>\n<p><strong>Hard Reboot Instance:</strong>\
    \ this action allows users to reboot the running instance.\n The difference between\
    \ soft reboot and hard reboot are that soft reboot issues\n reboot signal to the\
    \ running instance and will do a smooth reboot and the hard\n reboot simulates\
    \ the reboot like pressing the computer power button. It is useful\n if the running\
    \ instance is not responding to any commands.</p>\n</li>\n<li>\n<p><strong>Rebuild\
    \ Instance:</strong> use different image to build a new instance. The new instance\n\
    \ maintains the same specification of the old instance such as cpus, rams and\
    \ etc.\n Remember, this action will destroy all data in the instance and need\
    \ to use with\n caution.</p>\n</li>\n<li>\n<p><strong>Terminate Instance:</strong>\
    \ permanently delete the instance and data is removed as well.</p>\n</li>\n</ul>\n\
    <p>You can refer to this <a href=\"http://docs.openstack.org/user-guide/dashboard_launch_instances.html\"\
    >document</a> to see more information about\nmanaging instances.</p>\n<h2>Create\
    \ instance snapshots</h2>\n<p>To create an snapshot, you can click 'Create Snapshot'\
    \ from the above action list\nand you will see a pop-up window like below:</p>\n\
    <p><img alt=\"snapshot\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Instance Management--DOCID39/images/snapshot.png?raw=true\"\
    ></p>\n<p>Provide a meaningful name and the click 'Create Snapshot' button.</p>\n\
    <p>Notes: You should always pause the instance before snapshot it. However, live\n\
    snapshot is also possible and you need to make sure the snapshot is consistent\n\
    with the instance as the snapshot doesn't capture the state of the memory. So\n\
    before snapshot, you need to ensure that:</p>\n<ul>\n<li>\n<p>running programs\
    \ have written their contenst to disk</p>\n</li>\n<li>\n<p>the file system does\
    \ not have any 'dirty' buffers</p>\n</li>\n</ul>\n<p>For Linux user, you can execute\
    \ <code>sync</code> to write dirty buffer to disk.\nIt is not sufficient to only\
    \ use sync to get file system consistent. It is\nrecommend to use fsfreeze tool.\
    \ In ubuntu, you can run <code>sudo apt-get install util-linux</code>\nto install\
    \ the fsfreeze tool.</p>\n<p>To freeze a file system, you can run <code>fsfreeze\
    \ -f /mnt</code> as a root user\nin a command line console, where /mnt is the\
    \ file system mount point.</p>\n<p>After you created the snapshot, you can unfreeze\
    \ the file system by executing <code>fsfreeze -u /mnt</code>\nwhere /mnt is the\
    \ file system mount point.</p>\n<p>You can refer to <a href=\"http://docs.openstack.org/openstack-ops/content/snapshots.html\"\
    >Taking Snapshot</a> for more information.</p>\n<h2>Change security group</h2>\n\
    <p>You can click \"Edit Security groups\" from the drop down list to add/remove\n\
    security group for a running instance.</p>\n<p><img alt=\"instance management\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Instance Management--DOCID39/images/security_group.png?raw=true\"\
    ></p>\n<p>From the above screenshot, You can see the currently applied security\
    \ groups are\nlisted on the right hand side and left hand side is a list of available\
    \ security\ngroups. You can click the plus button to add the available security\
    \ groups\nto the right hand side and click the minus button to remove a security\
    \ group.\nOnce you have done, you can click 'Save' button to save your changes.\
    \ </p>\n<h2>Launch a VNC console</h2>\n<p>Sometimes, you need to access your instance\
    \ directly via a web browser and you\ncan do it by using the VNC console. The\
    \ console provides a great way to access\nthe instance if you haven't open port\
    \ for SSH.</p>\n<p>Click the \"console\" item from the drop down list and you\
    \ should see a screen\nlike below:</p>\n<p><img alt=\"instance management\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Instance Management--DOCID39/images/console1.png?raw=true\"\
    ></p>\n<p>You can then click the 'Click here to show only console' and you should\
    \ see the\nfollowing screen:</p>\n<p><img alt=\"instance management\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Instance Management--DOCID39/images/console2.png?raw=true\"\
    ></p>\n<p>After the login prompt appears, you can type in username and password\
    \ to login\nto the instance and perform any task as required.</p>\n<h2>View log</h2>\n\
    <p>The console log provides very useful information that may be required in\n\
    troubleshooting issues. You can access the log by clicking \"view log\" item from\n\
    the action drop down list. After clicking, you should see the following screen:</p>\n\
    <p><img alt=\"instance management\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Instance Management--DOCID39/images/log.png?raw=true\"></p>\n\
    <p>This gives you the latest system log messages, if you want to see the full\
    \ logs,\nyou can click the 'View Full Log Button'.</p>\n<h2>Create and Manage\
    \ Volumes</h2>\n<p>You can attach volumes as persistent storage to instances.\
    \ You can attach or\ndetach a volume from a instance at any time and it is also\
    \ easy to create snapshot\nfrom or delete a volume.</p>\n<p>To <strong>create\
    \ a volume</strong>, you can follow the below steps:</p>\n<ul>\n<li>\n<p>Log in\
    \ to the <a href=\"https://dashboard.rc.nectar.org.au/\">dashboard</a></p>\n</li>\n\
    <li>\n<p>select the project from the CURRENT PROJECT on the Project tab</p>\n\
    </li>\n<li>\n<p>On the Project tab, open the Compute tab and click Volumes category</p>\n\
    </li>\n<li>\n<p>Click 'Create Volume' button</p>\n</li>\n<li>\n<p>In the pop-up\
    \ window, you can enter or select the following values:</p>\n</li>\n</ul>\n<p><strong>Volume\
    \ Name:</strong> name for the volume</p>\n<p><strong>Description</strong>: description\
    \ for the volume</p>\n<p><strong>Type:</strong> Leave this field blank</p>\n<p><strong>Size:</strong>\
    \ The size of the volume in gigabytes</p>\n<p><strong>Volume Source:</strong>\
    \ To create a standard empty disk for data storage, select \"No source, empty\
    \ volume\"</p>\n<p><strong>Availability Zone:</strong> Select the Availability\
    \ Zone from the list</p>\n<ul>\n<li>\n<p>Click 'Create Volume' button</p>\n</li>\n\
    <li>\n<p>The dashboard shows the volume on the 'Volumes' tab.</p>\n</li>\n</ul>\n\
    <p>To <strong>attach a volume</strong> to an instance: </p>\n<ul>\n<li>\n<p>Log\
    \ in to the <a href=\"https://dashboard.rc.nectar.org.au/\">dashboard</a>[dashboard\
    \ ]</p>\n</li>\n<li>\n<p>select the project from the CURRENT PROJECT on the Project\
    \ tab</p>\n</li>\n<li>\n<p>On the Project tab, open the Compute tab and click\
    \ Volumes category</p>\n</li>\n<li>\n<p>Select the volume to add to an instance\
    \ and in the action drop down list, \n click Edit Attachments</p>\n</li>\n<li>\n\
    <p>In the Manage Volume Attachments dialog box, select an instance and click\n\
    \ 'Attach Volume' button</p>\n</li>\n</ul>\n<p>To <strong>detach a volume</strong>\
    \ from an instance:</p>\n<ul>\n<li>\n<p>Log in to the <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >dashboard</a>, choose a project, and click Volumes</p>\n</li>\n<li>\n<p>Select\
    \ the volume and click Edit Attachments</p>\n</li>\n<li>\n<p>Click 'Detach Volume'\
    \ button and confirm your changes</p>\n</li>\n</ul>\n<p>To <strong>delete a volume:</strong></p>\n\
    <ul>\n<li>\n<p>Log in to the <a href=\"https://dashboard.rc.nectar.org.au/\">dashboard</a>,\
    \ choose a project, and click Volumes</p>\n</li>\n<li>\n<p>Select the check boxes\
    \ for the volumes that you want to delete.</p>\n</li>\n<li>\n<p>Click 'Delete\
    \ Volumes' button and confirm your choice.</p>\n</li>\n</ul>\n<p>Note: the data\
    \ in its attached volumes is not destroyed after you delete a volume</p>"
  parent: 39
  sha1: f4b263876c9c9bfaea917cc20fa0ac3635a38e27
  title: Getting Started
64:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-08T00:45:12-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Manage instance via API \n The NeCTAR Dashboard is one way\
          \ to manage your instances in projects and NeCTAR\ncloud provides instance\
          \ management via API. There are two types of API you can use\nto manage\
          \ your instance, one is Nova command line API and another is Nova python\n\
          API. Which one to use depends on your needs. The Nova python API is great\
          \ if you\nwant integrate it with python programming to manage instance in\
          \ a programmatic way.\nIf you are a system administrator and you probably\
          \ will prefer to use Nova command\nline API through a console to manage\
          \ instances. Both of them provides more\nmanagement options than you can\
          \ do through the Dashboard.  \n Installation \n You can use pip to install\
          \ the python-nova API and the nova command line API. \n See below for the\
          \ instructions: \n OS X \n sudo easy_install pip \n sudo pip install --upgrade\
          \ setuptools \n sudo pip install python-novaclient \n Ubuntu \n ``` \n sudo\
          \ apt-get install python-pip \n sudo pip install python-novaclient \n ```\
          \ \n RHEL, CentOS, or Fedora \n sudo yum install python-setuptools\n\nsudo\
          \ easy_install pip\n\nsudo pip install --upgrade setuptools\n\nsudo pip\
          \ install python-novaclient\n \n Windows \n See pip windows for instructions\
          \ on installing pip for Windows. \n pip install python-novaclient \n Configuration\
          \ \n Before you can use the python nova client and command line API you\
          \ need to be\nauthenticated to the NeCTAR cloud. The below shows the instructions\
          \ of how to\nget username/password and get authenticated. \n \n \n Login\
          \ to NeCTAR Cloud Dashboard \n \n \n Click the drop down list beside the\
          \ top left nectar logo to select a project \n \n \n Click 'Access & Security'\
          \ \n \n \n On the 'Access & Security' page, click tab 'API Access' \n \n\
          \ \n Click button \"Download OpenStack RC File\" \n \n \n Save the file\
          \ into a directory \n \n \n Click the drop down list with your email on\
          \ the right top of page, then click\n Settings \n \n \n Click 'Reset Password'\
          \ and save the password appeared on the screen \n \n \n Nova API normally\
          \ requires 4 environment variables to be set for authentication: \n \n auth\
          \ URL \n username \n project id or name (most clients can handle either)\
          \ \n password \n \n When using the script file you downloaded from NeCTAR\
          \ Dashboard, these\nvariables are set by the script file and you can see\
          \ these variables\nif you open the file. Example: \n \n OS_AUTH_URL: https://keystone.rc.nectar.org.au:5000/v2.0/\
          \ \nOS_TENANT_NAME=my_science_project \nOS_TENANT_ID=sdfsdfsfwrwewer \n\
          OS_USERNAME=clouduser@example.edu.au \nOS_PASSWORD=XXXXXX \n \n Authentication\
          \ for Command Line API \n The below instruction assumes you use Linux operating\
          \ system. \n Once you have obtained the authentication script and password,\
          \ you can execute\nthe script using source file-name.sh. and type in the\
          \ password you\nobtained from Dashboard. \n Authentication for python swift\
          \ API \n You can use the below sample code to get authenticated.  \n from\
          \ novaclient import client \n nova = client.Client(VERSION, USERNAME, PASSWORD,\
          \ PROJECT_NAME, AUTH_URL) \n The VERSION parameter can be \"1.1\" or \"\
          2\". You can get USERNAME, PROJECT_NAME and\nAUTH_URL from the above .sh\
          \ file obtained from the NeCTAR Dashboard and you can\nalso get the PASSWORD\
          \ from above as copied from the NeCTAR Dashboard. \n Nova Command Line API\
          \ \n To get information about about managing instances in a selected project:\
          \ \n\n\n\nCommand\nAction\n\n\n\n\n\nnova --help or nova\n\nDiscover the\
          \ available options and sub-commands\n\n\nnova help <command-name>\nInformation\
          \ on a specific sub-command\n\n\nnova list\nTo list all active instances\
          \ in one project\n\n\nnova flavor-list\nTo list all available flavors\n\n\
          \nnova image-list\nTo list all available images\n\n\nnova secgroup-list\n\
          To list all available security groups\n\n\nnova keypair-list\nTo list all\
          \ available key pairs\n\n\nnova availability-zone-list\nTo list all available\
          \ availability zones\n\n\n\n Note: not all options are available as there\
          \ is a security policy applied and\nyour account might not have sufficient\
          \ permission.  \n Managing an Instance \n To boot a new instance, you need\
          \ to get image name, keypair name, security group\nname and flavor name.\
          \ You can use the above mentioned commands to acquire these\ninformation.\
          \ Then, you can use nova boot command to launch a new instance, the\nformat\
          \ is: \n nova boot [instance-name]  --flavor [name] --image [name] --key-name\
          \ [name] --security-groups [names separated by space] \n You can also specify\
          \ option --availability-zone to launch an instance in a\ndesigned zone and\
          \ option --user-data  for a initialization script\nused only for the first\
          \ time when instance boots. The user data script can be\nput in a file and\
          \ then passed to instance creation. You can see check this\nwebsite to see\
          \ what script you can use to initialize an instance.  \n\n\n\nCommands for\
          \ instance management\nAction\n\n\n\n\nnova help boot\nDiscover the available\
          \ options\n\n\nnova start <server name or ID>\nTo boot a stopped instance\n\
          \n\nnova stop <server name or ID>\nTo stop an instance\n\n\nnova suspend\
          \ <server name or ID>\nTo suspend an instance\n\n\nnova resume <server name\
          \ or ID>\nTo resume an instance\n\n\nnova show <server name or ID>\nTo show\
          \ details of an instance\n\n\nnova image-create <server name or ID> <snapshot\
          \ name>\nTo create a snapshot of a instance\n\n\n\n You can also find more\
          \ information about nova command line API via\nnovaclient. \n Nova Python\
          \ API \n You can also use Nova Python API to manage instances integrated\
          \ with Python\nprogramming language. \n Example of code to launch a new\
          \ instance: \n ``` \n from novaclient import client \n nova = client.Client(\"\
          2\", username, password, project_name, auth_url) \n nova.servers.list()\
          \ \n nova.flavors.list() \n nova.keypairs.list() \n nova.images.list() \n\
          \ nova.security_groups.list() \n server_name = 'new instance' \n image =\
          \ 'NeCTAR Ubuntu 14.04 (Trusty) amd64' \n flavor = 'm1.small' \n security_groups\
          \ = ['5c8c4dd0-db53-41e3-a53b-9730c764149c', '8cca1fba-b6b2-4ba3-b58e-b568f01e73ff']\
          \ \n key_name = 'ming' \n nova.servers.create(server_name, image, flavor,\
          \ security_groups=security_groups, key_name=) \n ```  \n You can find more\
          \ information about nova python API from this link "
        description: "<h2>Manage instance via API</h2>\n<p>The NeCTAR Dashboard is\
          \ one way to manage your instances in projects and NeCTAR\ncloud provides\
          \ instance management via API. There are two types of API you can use\n\
          to manage your instance, one is Nova command line API and another is Nova\
          \ python\nAPI. Which one to use depends on your needs. The Nova python API\
          \ is great if you\nwant integrate it with python programming to manage instance\
          \ in a programmatic way.\nIf you are a system administrator and you probably\
          \ will prefer to use Nova command\nline API through a console to manage\
          \ instances. Both of them provides more\nmanagement options than you can\
          \ do through the Dashboard. </p>\n<h2>Installation</h2>\n<p>You can use\
          \ pip to install the python-nova API and the nova command line API.</p>\n\
          <p>See below for the instructions:</p>\n<p>OS X</p>\n<p><code>sudo easy_install\
          \ pip</code></p>\n<p><code>sudo pip install --upgrade setuptools</code></p>\n\
          <p><code>sudo pip install python-novaclient</code></p>\n<p>Ubuntu</p>\n\
          <p>```</p>\n<p>sudo apt-get install python-pip</p>\n<p>sudo pip install\
          \ python-novaclient</p>\n<p>```</p>\n<p>RHEL, CentOS, or Fedora</p>\n<pre><code>sudo\
          \ yum install python-setuptools\n\nsudo easy_install pip\n\nsudo pip install\
          \ --upgrade setuptools\n\nsudo pip install python-novaclient\n</code></pre>\n\
          <p>Windows</p>\n<p>See <a href=\"http://docs.python-guide.org/en/latest/starting/install/win/\"\
          >pip windows</a> for instructions on installing pip for Windows.</p>\n<p><code>pip\
          \ install python-novaclient</code></p>\n<h2>Configuration</h2>\n<p>Before\
          \ you can use the python nova client and command line API you need to be\n\
          authenticated to the NeCTAR cloud. The below shows the instructions of how\
          \ to\nget username/password and get authenticated.</p>\n<ul>\n<li>\n<p>Login\
          \ to NeCTAR Cloud <a href=\"https://dashboard.rc.nectar.org.au\">Dashboard</a></p>\n\
          </li>\n<li>\n<p>Click the drop down list beside the top left nectar logo\
          \ to select a project</p>\n</li>\n<li>\n<p>Click 'Access &amp; Security'</p>\n\
          </li>\n<li>\n<p>On the 'Access &amp; Security' page, click tab 'API Access'</p>\n\
          </li>\n<li>\n<p>Click button \"Download OpenStack RC File\"</p>\n</li>\n\
          <li>\n<p>Save the file into a directory</p>\n</li>\n<li>\n<p>Click the drop\
          \ down list with your email on the right top of page, then click\n Settings</p>\n\
          </li>\n<li>\n<p>Click 'Reset Password' and save the password appeared on\
          \ the screen</p>\n</li>\n</ul>\n<p>Nova API normally requires 4 environment\
          \ variables to be set for authentication:</p>\n<ul>\n<li>auth URL</li>\n\
          <li>username</li>\n<li>project id or name (most clients can handle either)</li>\n\
          <li>password</li>\n</ul>\n<p>When using the script file you downloaded from\
          \ NeCTAR Dashboard, these\nvariables are set by the script file and you\
          \ can see these variables\nif you open the file. Example:</p>\n<blockquote>\n\
          <p>OS_AUTH_URL: https://keystone.rc.nectar.org.au:5000/v2.0/ \nOS_TENANT_NAME=my_science_project\
          \ \nOS_TENANT_ID=sdfsdfsfwrwewer \nOS_USERNAME=clouduser@example.edu.au\
          \ \nOS_PASSWORD=XXXXXX</p>\n</blockquote>\n<h3>Authentication for Command\
          \ Line API</h3>\n<p>The below instruction assumes you use Linux operating\
          \ system.</p>\n<p>Once you have obtained the authentication script and password,\
          \ you can execute\nthe script using <code>source file-name.sh</code>. and\
          \ type in the password you\nobtained from Dashboard.</p>\n<h3>Authentication\
          \ for python swift API</h3>\n<p>You can use the below sample code to get\
          \ authenticated. </p>\n<p><code>from novaclient import client</code></p>\n\
          <p><code>nova = client.Client(VERSION, USERNAME, PASSWORD, PROJECT_NAME,\
          \ AUTH_URL)</code></p>\n<p>The VERSION parameter can be \"1.1\" or \"2\"\
          . You can get USERNAME, PROJECT_NAME and\nAUTH_URL from the above .sh file\
          \ obtained from the NeCTAR Dashboard and you can\nalso get the PASSWORD\
          \ from above as copied from the NeCTAR Dashboard.</p>\n<h2>Nova Command\
          \ Line API</h2>\n<p>To get information about about managing instances in\
          \ a selected project:</p>\n<table>\n<thead>\n<tr>\n<th>Command</th>\n<th>Action</th>\n\
          </tr>\n</thead>\n<tbody>\n<tr>\n<td>\n<code>nova --help</code> or <code>nova</code>\n\
          </td>\n<td>Discover the available options and sub-commands</td>\n</tr>\n\
          <tr>\n<td><code>nova help &lt;command-name&gt;</code></td>\n<td>Information\
          \ on a specific sub-command</td>\n</tr>\n<tr>\n<td><code>nova list</code></td>\n\
          <td>To list all active instances in one project</td>\n</tr>\n<tr>\n<td><code>nova\
          \ flavor-list</code></td>\n<td>To list all available flavors</td>\n</tr>\n\
          <tr>\n<td><code>nova image-list</code></td>\n<td>To list all available images</td>\n\
          </tr>\n<tr>\n<td><code>nova secgroup-list</code></td>\n<td>To list all available\
          \ security groups</td>\n</tr>\n<tr>\n<td><code>nova keypair-list</code></td>\n\
          <td>To list all available key pairs</td>\n</tr>\n<tr>\n<td><code>nova availability-zone-list</code></td>\n\
          <td>To list all available availability zones</td>\n</tr>\n</tbody>\n</table>\n\
          <p>Note: not all options are available as there is a security policy applied\
          \ and\nyour account might not have sufficient permission. </p>\n<h3>Managing\
          \ an Instance</h3>\n<p>To boot a new instance, you need to get image name,\
          \ keypair name, security group\nname and flavor name. You can use the above\
          \ mentioned commands to acquire these\ninformation. Then, you can use nova\
          \ boot command to launch a new instance, the\nformat is:</p>\n<p><code>nova\
          \ boot [instance-name]  --flavor [name] --image [name] --key-name [name]\
          \ --security-groups [names separated by space]</code></p>\n<p>You can also\
          \ specify option --availability-zone to launch an instance in a\ndesigned\
          \ zone and option --user-data  for a initialization script\nused only for\
          \ the first time when instance boots. The user data script can be\nput in\
          \ a file and then passed to instance creation. You can see check this\n\
          <a href=\"https://cloudinit.readthedocs.org/en/latest/\">website</a> to\
          \ see what script you can use to initialize an instance. </p>\n<table>\n\
          <thead>\n<tr>\n<th>Commands for instance management</th>\n<th>Action</th>\n\
          </tr>\n</thead>\n<tbody>\n<tr>\n<td><code>nova help boot</code></td>\n<td>Discover\
          \ the available options</td>\n</tr>\n<tr>\n<td><code>nova start &lt;server\
          \ name or ID&gt;</code></td>\n<td>To boot a stopped instance</td>\n</tr>\n\
          <tr>\n<td><code>nova stop &lt;server name or ID&gt;</code></td>\n<td>To\
          \ stop an instance</td>\n</tr>\n<tr>\n<td><code>nova suspend &lt;server\
          \ name or ID&gt;</code></td>\n<td>To suspend an instance</td>\n</tr>\n<tr>\n\
          <td><code>nova resume &lt;server name or ID&gt;</code></td>\n<td>To resume\
          \ an instance</td>\n</tr>\n<tr>\n<td><code>nova show &lt;server name or\
          \ ID&gt;</code></td>\n<td>To show details of an instance</td>\n</tr>\n<tr>\n\
          <td><code>nova image-create &lt;server name or ID&gt; &lt;snapshot name&gt;</code></td>\n\
          <td>To create a snapshot of a instance</td>\n</tr>\n</tbody>\n</table>\n\
          <p>You can also find more information about nova command line API via\n\
          <a href=\"http://docs.openstack.org/cli-reference/content/novaclient_commands.html\"\
          >novaclient</a>.</p>\n<h2>Nova Python API</h2>\n<p>You can also use Nova\
          \ Python API to manage instances integrated with Python\nprogramming language.</p>\n\
          <p>Example of code to launch a new instance:</p>\n<p>```</p>\n<p>from novaclient\
          \ import client</p>\n<p>nova = client.Client(\"2\", username, password,\
          \ project_name, auth_url)</p>\n<p>nova.servers.list()</p>\n<p>nova.flavors.list()</p>\n\
          <p>nova.keypairs.list()</p>\n<p>nova.images.list()</p>\n<p>nova.security_groups.list()</p>\n\
          <p>server_name = 'new instance'</p>\n<p>image = 'NeCTAR Ubuntu 14.04 (Trusty)\
          \ amd64'</p>\n<p>flavor = 'm1.small'</p>\n<p>security_groups = ['5c8c4dd0-db53-41e3-a53b-9730c764149c',\
          \ '8cca1fba-b6b2-4ba3-b58e-b568f01e73ff']</p>\n<p>key_name = 'ming'</p>\n\
          <p>nova.servers.create(server_name, image, flavor, security_groups=security_groups,\
          \ key_name=)</p>\n<p>``` </p>\n<p>You can find more information about nova\
          \ python API from this <a href=\"http://docs.openstack.org/developer/python-novaclient/api.html\"\
          >link</a></p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:27:59-04:00'
          customer_folders: []
          description: Instance Management
          id: 6000190145
          is_default: false
          language_id: 6
          name: Instance Management
          parent_id: 6000190145
          position: 3
          updated_at: '2015-12-07T19:43:55-05:00'
          visibility: 1
        folder_id: 6000190145
        hits: 70
        id: 6000075747
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2016-01-26T18:22:21-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000075747
        position: 3
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 1
        thumbs_up: 1
        title: API
        updated_at: '2016-01-26T18:22:21-05:00'
        user_id: 6002464727
  html: "<h2>Manage instance via API</h2>\n<p>The NeCTAR Dashboard is one way to manage\
    \ your instances in projects and NeCTAR\ncloud provides instance management via\
    \ API. There are two types of API you can use\nto manage your instance, one is\
    \ Nova command line API and another is Nova python\nAPI. Which one to use depends\
    \ on your needs. The Nova python API is great if you\nwant integrate it with python\
    \ programming to manage instance in a programmatic way.\nIf you are a system administrator\
    \ and you probably will prefer to use Nova command\nline API through a console\
    \ to manage instances. Both of them provides more\nmanagement options than you\
    \ can do through the Dashboard. </p>\n<h2>Installation</h2>\n<p>You can use pip\
    \ to install the python-nova API and the nova command line API.</p>\n<p>See below\
    \ for the instructions:</p>\n<p>OS X</p>\n<p><code>sudo easy_install pip</code></p>\n\
    <p><code>sudo pip install --upgrade setuptools</code></p>\n<p><code>sudo pip install\
    \ python-novaclient</code></p>\n<p>Ubuntu</p>\n<p>```</p>\n<p>sudo apt-get install\
    \ python-pip</p>\n<p>sudo pip install python-novaclient</p>\n<p>```</p>\n<p>RHEL,\
    \ CentOS, or Fedora</p>\n<pre><code>sudo yum install python-setuptools\n\nsudo\
    \ easy_install pip\n\nsudo pip install --upgrade setuptools\n\nsudo pip install\
    \ python-novaclient\n</code></pre>\n<p>Windows</p>\n<p>See <a href=\"http://docs.python-guide.org/en/latest/starting/install/win/\"\
    >pip windows</a> for instructions on installing pip for Windows.</p>\n<p><code>pip\
    \ install python-novaclient</code></p>\n<h2>Configuration</h2>\n<p>Before you\
    \ can use the python nova client and command line API you need to be\nauthenticated\
    \ to the NeCTAR cloud. The below shows the instructions of how to\nget username/password\
    \ and get authenticated.</p>\n<ul>\n<li>\n<p>Login to NeCTAR Cloud <a href=\"\
    https://dashboard.rc.nectar.org.au\">Dashboard</a></p>\n</li>\n<li>\n<p>Click\
    \ the drop down list beside the top left nectar logo to select a project</p>\n\
    </li>\n<li>\n<p>Click 'Access &amp; Security'</p>\n</li>\n<li>\n<p>On the 'Access\
    \ &amp; Security' page, click tab 'API Access'</p>\n</li>\n<li>\n<p>Click button\
    \ \"Download OpenStack RC File\"</p>\n</li>\n<li>\n<p>Save the file into a directory</p>\n\
    </li>\n<li>\n<p>Click the drop down list with your email on the right top of page,\
    \ then click\n Settings</p>\n</li>\n<li>\n<p>Click 'Reset Password' and save the\
    \ password appeared on the screen</p>\n</li>\n</ul>\n<p>Nova API normally requires\
    \ 4 environment variables to be set for authentication:</p>\n<ul>\n<li>auth URL</li>\n\
    <li>username</li>\n<li>project id or name (most clients can handle either)</li>\n\
    <li>password</li>\n</ul>\n<p>When using the script file you downloaded from NeCTAR\
    \ Dashboard, these\nvariables are set by the script file and you can see these\
    \ variables\nif you open the file. Example:</p>\n<blockquote>\n<p>OS_AUTH_URL:\
    \ https://keystone.rc.nectar.org.au:5000/v2.0/ \nOS_TENANT_NAME=my_science_project\
    \ \nOS_TENANT_ID=sdfsdfsfwrwewer \nOS_USERNAME=clouduser@example.edu.au \nOS_PASSWORD=XXXXXX</p>\n\
    </blockquote>\n<h3>Authentication for Command Line API</h3>\n<p>The below instruction\
    \ assumes you use Linux operating system.</p>\n<p>Once you have obtained the authentication\
    \ script and password, you can execute\nthe script using <code>source file-name.sh</code>.\
    \ and type in the password you\nobtained from Dashboard.</p>\n<h3>Authentication\
    \ for python swift API</h3>\n<p>You can use the below sample code to get authenticated.\
    \ </p>\n<p><code>from novaclient import client</code></p>\n<p><code>nova = client.Client(VERSION,\
    \ USERNAME, PASSWORD, PROJECT_NAME, AUTH_URL)</code></p>\n<p>The VERSION parameter\
    \ can be \"1.1\" or \"2\". You can get USERNAME, PROJECT_NAME and\nAUTH_URL from\
    \ the above .sh file obtained from the NeCTAR Dashboard and you can\nalso get\
    \ the PASSWORD from above as copied from the NeCTAR Dashboard.</p>\n<h2>Nova Command\
    \ Line API</h2>\n<p>To get information about about managing instances in a selected\
    \ project:</p>\n<table>\n<thead>\n<tr>\n<th>Command</th>\n<th>Action</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td><code>nova --help</code> or <code>nova</code></td>\n\
    <td>Discover the available options and sub-commands</td>\n</tr>\n<tr>\n<td><code>nova\
    \ help &lt;command-name&gt;</code></td>\n<td>Information on a specific sub-command</td>\n\
    </tr>\n<tr>\n<td><code>nova list</code></td>\n<td>To list all active instances\
    \ in one project</td>\n</tr>\n<tr>\n<td><code>nova flavor-list</code></td>\n<td>To\
    \ list all available flavors</td>\n</tr>\n<tr>\n<td><code>nova image-list</code></td>\n\
    <td>To list all available images</td>\n</tr>\n<tr>\n<td><code>nova secgroup-list</code></td>\n\
    <td>To list all available security groups</td>\n</tr>\n<tr>\n<td><code>nova keypair-list</code></td>\n\
    <td>To list all available key pairs</td>\n</tr>\n<tr>\n<td><code>nova availability-zone-list</code></td>\n\
    <td>To list all available availability zones</td>\n</tr>\n</tbody>\n</table>\n\
    <p>Note: not all options are available as there is a security policy applied and\n\
    your account might not have sufficient permission. </p>\n<h3>Managing an Instance</h3>\n\
    <p>To boot a new instance, you need to get image name, keypair name, security\
    \ group\nname and flavor name. You can use the above mentioned commands to acquire\
    \ these\ninformation. Then, you can use nova boot command to launch a new instance,\
    \ the\nformat is:</p>\n<p><code>nova boot [instance-name]  --flavor [name] --image\
    \ [name] --key-name [name] --security-groups [names separated by space]</code></p>\n\
    <p>You can also specify option --availability-zone to launch an instance in a\n\
    designed zone and option --user-data <user-data-file> for a initialization script\n\
    used only for the first time when instance boots. The user data script can be\n\
    put in a file and then passed to instance creation. You can see check this\n<a\
    \ href=\"https://cloudinit.readthedocs.org/en/latest/\">website</a> to see what\
    \ script you can use to initialize an instance. </p>\n<table>\n<thead>\n<tr>\n\
    <th>Commands for instance management</th>\n<th>Action</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td><code>nova help boot</code></td>\n<td>Discover the available\
    \ options</td>\n</tr>\n<tr>\n<td><code>nova start &lt;server name or ID&gt;</code></td>\n\
    <td>To boot a stopped instance</td>\n</tr>\n<tr>\n<td><code>nova stop &lt;server\
    \ name or ID&gt;</code></td>\n<td>To stop an instance</td>\n</tr>\n<tr>\n<td><code>nova\
    \ suspend &lt;server name or ID&gt;</code></td>\n<td>To suspend an instance</td>\n\
    </tr>\n<tr>\n<td><code>nova resume &lt;server name or ID&gt;</code></td>\n<td>To\
    \ resume an instance</td>\n</tr>\n<tr>\n<td><code>nova show &lt;server name or\
    \ ID&gt;</code></td>\n<td>To show details of an instance</td>\n</tr>\n<tr>\n<td><code>nova\
    \ image-create &lt;server name or ID&gt; &lt;snapshot name&gt;</code></td>\n<td>To\
    \ create a snapshot of a instance</td>\n</tr>\n</tbody>\n</table>\n<p>You can\
    \ also find more information about nova command line API via\n<a href=\"http://docs.openstack.org/cli-reference/content/novaclient_commands.html\"\
    >novaclient</a>.</p>\n<h2>Nova Python API</h2>\n<p>You can also use Nova Python\
    \ API to manage instances integrated with Python\nprogramming language.</p>\n\
    <p>Example of code to launch a new instance:</p>\n<p>```</p>\n<p>from novaclient\
    \ import client</p>\n<p>nova = client.Client(\"2\", username, password, project_name,\
    \ auth_url)</p>\n<p>nova.servers.list()</p>\n<p>nova.flavors.list()</p>\n<p>nova.keypairs.list()</p>\n\
    <p>nova.images.list()</p>\n<p>nova.security_groups.list()</p>\n<p>server_name\
    \ = 'new instance'</p>\n<p>image = 'NeCTAR Ubuntu 14.04 (Trusty) amd64'</p>\n\
    <p>flavor = 'm1.small'</p>\n<p>security_groups = ['5c8c4dd0-db53-41e3-a53b-9730c764149c',\
    \ '8cca1fba-b6b2-4ba3-b58e-b568f01e73ff']</p>\n<p>key_name = 'ming'</p>\n<p>nova.servers.create(server_name,\
    \ image, flavor, security_groups=security_groups, key_name=)</p>\n<p>``` </p>\n\
    <p>You can find more information about nova python API from this <a href=\"http://docs.openstack.org/developer/python-novaclient/api.html\"\
    >link</a></p>"
  parent: 39
  sha1: 8b2543e77d41a55fccec2aa0fa471663ffcfce04
  title: API
65:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-08T02:01:22-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Debugging Nova Command line Client \n These instructions assume\
          \ you have installed Nova command client in a Linux\nenvironment. If you\
          \ have other operating systems, the debugging process might be\na slightly\
          \ different, however, the general rules should still apply. \n Nova command\
          \ line client is very much like other Linux commands, it outputs\nerrors\
          \ in the standard output, which is the monitor. \n If you get an error,\
          \ you can always read the error message and generally it give\nyou very\
          \ good hints about what might be wrong. \n For example, if you execute nova\
          \ service-list on the command line without\nauthentication, the error message\
          \ might look like this: \n ERROR: You must provide a username via either\
          \ --os-username or env[OS_USERNAME] \n The above message indicates you need\
          \ to be authenticated before you can use the\nAPI. The authentication requires\
          \ some environment variables to be set. To set\nthese environment variables\
          \ you can either source the script file obtained from\nNeCTAR Dashboard\
          \ or you can override it by using command line options. \n You can always\
          \ execute man nova or simply nova to get more help\ninformation and to learn\
          \ each supported options. \n If you find a useful command, you can also\
          \ execute nova help command,\nthis will give your more specific help for\
          \ the command. \n Debugging Nova Python API \n Debugging Nova Python API\
          \ takes more effects as it depends on how familiar\nwith Python programming\
          \ and what development environment you use. \n The below provides some basic\
          \ information about how you debug the Nova Python\nAPI. \n You can debug\
          \ your python code using Python debugger called pdb and you can find\nmore\
          \ information here. \n The below code uses pdb debuuger to debug a python\
          \ file contains clinet python\nAPI code. \n pdb file_name.py \n Once you\
          \ executed the above code, the command line will be stopped on the first\n\
          line of code and you can use some commands to control the execution flow.\
          \ \n Some useful ones to use are: \n\n\n\nCommand\nAction\n\n\n\n\nb\nset\
          \ a breakpoint\n\n\nc\ncontinue debugging until you hit a breakpoint\n\n\
          \ns\nstep through the code\n\n\nn\nto go to next line of code\n\n\nl\nlist\
          \ source code for the current file\n\n\nu\nnavigate up a stack frame\n\n\
          \nd\nnavigate down a stack frame\n\n\np\nto print the value of an expression\
          \ in the current context\n\n\n\n Debugging Via HTTP \n The both of command\
          \ line API and python API are restful web service client.\nThus the requests\
          \ are all made by using HTTP and you can always refer to\nOpenStack Service\
          \ End for further references about what should be\npresented in the HTTP\
          \ requests. The Nova API uses requests library\nto send and receive HTTP\
          \ requests/responses. \n For command line client, you can add --debug option\
          \ to print out HTTP request\nheader and HTTP response header, which give\
          \ you a lot of more insight\ninformation. To verify parameters in the request\
          \ header, you can refer to\nOpenStack service API to see what are expected.\
          \ \n To enable debugging information on the standard out for Python API,\
          \ you can add\nthe below code: \n ``` \n import logging \n logger = logging.getLogger(\"\
          novaclient\") \n logging.basicConfig(level=logging.DEBUG) \n ``` \n The\
          \ will print the same output as adding --debug option for command line API.\
          \ \n Debugging via Source Code \n If the above techniques are still not\
          \ helpful, you can always look at the source\ncode to find the problems.\
          \ \n The below source file structure is based on the installation in Ubuntu.\
          \ \n The command line nova command is located in '/usr/bin/nova'. By looking\
          \ at this\nfile, you should get a idea of how the various options are interpreted.\
          \ This file\nacts as an interface for Python API. \n The Python API files\
          \ are located under\n'/usr/lib/python2.7/dist-packages/novaclient' and the\
          \ most important file to look\nat is 'client.py'. This file does all the\
          \ request preparation, sending request and\nreceiving response. It is also\
          \ used by the command line Nova client.  "
        description: '<h2>Debugging Nova Command line Client</h2>

          <p>These instructions assume you have installed Nova command client in a
          Linux

          environment. If you have other operating systems, the debugging process
          might be

          a slightly different, however, the general rules should still apply.</p>

          <p>Nova command line client is very much like other Linux commands, it outputs

          errors in the standard output, which is the monitor.</p>

          <p>If you get an error, you can always read the error message and generally
          it give

          you very good hints about what might be wrong.</p>

          <p>For example, if you execute <code>nova service-list</code> on the command
          line without

          authentication, the error message might look like this:</p>

          <p><code>ERROR: You must provide a username via either --os-username or
          env[OS_USERNAME]</code></p>

          <p>The above message indicates you need to be authenticated before you can
          use the

          API. The authentication requires some environment variables to be set. To
          set

          these environment variables you can either source the script file obtained
          from

          NeCTAR <a href="https://dashboard.rc.nectar.org.au">Dashboard</a> or you
          can override it by using command line options.</p>

          <p>You can always execute <code>man nova</code> or simply <code>nova</code>
          to get more help

          information and to learn each supported options.</p>

          <p>If you find a useful command, you can also execute <code>nova help command</code>,

          this will give your more specific help for the command.</p>

          <h2>Debugging Nova Python API</h2>

          <p>Debugging Nova Python API takes more effects as it depends on how familiar

          with Python programming and what development environment you use.</p>

          <p>The below provides some basic information about how you debug the Nova
          Python

          API.</p>

          <p>You can debug your python code using Python debugger called pdb and you
          can find

          more information <a href="https://docs.python.org/2/library/pdb.html">here</a>.</p>

          <p>The below code uses pdb debuuger to debug a python file contains clinet
          python

          API code.</p>

          <p><code>pdb file_name.py</code></p>

          <p>Once you executed the above code, the command line will be stopped on
          the first

          line of code and you can use some commands to control the execution flow.</p>

          <p>Some useful ones to use are:</p>

          <table>

          <thead>

          <tr>

          <th align="right">Command</th>

          <th align="left">Action</th>

          </tr>

          </thead>

          <tbody>

          <tr>

          <td align="right">b</td>

          <td align="left">set a breakpoint</td>

          </tr>

          <tr>

          <td align="right">c</td>

          <td align="left">continue debugging until you hit a breakpoint</td>

          </tr>

          <tr>

          <td align="right">s</td>

          <td align="left">step through the code</td>

          </tr>

          <tr>

          <td align="right">n</td>

          <td align="left">to go to next line of code</td>

          </tr>

          <tr>

          <td align="right">l</td>

          <td align="left">list source code for the current file</td>

          </tr>

          <tr>

          <td align="right">u</td>

          <td align="left">navigate up a stack frame</td>

          </tr>

          <tr>

          <td align="right">d</td>

          <td align="left">navigate down a stack frame</td>

          </tr>

          <tr>

          <td align="right">p</td>

          <td align="left">to print the value of an expression in the current context</td>

          </tr>

          </tbody>

          </table>

          <h2>Debugging Via HTTP</h2>

          <p>The both of command line API and python API are restful web service client.

          Thus the requests are all made by using HTTP and you can always refer to

          <a href="http://developer.openstack.org/api-ref-objectstorage-v1.html">OpenStack
          Service End</a> for further references about what should be

          presented in the HTTP requests. The Nova API uses <a href="http://www.python-requests.org/en/latest/">requests</a>
          library

          to send and receive HTTP requests/responses.</p>

          <p>For command line client, you can add --debug option to print out HTTP
          request

          header and HTTP response header, which give you a lot of more insight

          information. To verify parameters in the request header, you can refer to

          OpenStack service <a href="http://developer.openstack.org/api-ref-objectstorage-v1.html">API</a>
          to see what are expected.</p>

          <p>To enable debugging information on the standard out for Python API, you
          can add

          the below code:</p>

          <p>```</p>

          <p>import logging</p>

          <p>logger = logging.getLogger("novaclient")</p>

          <p>logging.basicConfig(level=logging.DEBUG)</p>

          <p>```</p>

          <p>The will print the same output as adding --debug option for command line
          API.</p>

          <h2>Debugging via Source Code</h2>

          <p>If the above techniques are still not helpful, you can always look at
          the source

          code to find the problems.</p>

          <p>The below source file structure is based on the installation in Ubuntu.</p>

          <p>The command line nova command is located in ''/usr/bin/nova''. By looking
          at this

          file, you should get a idea of how the various options are interpreted.
          This file

          acts as an interface for Python API.</p>

          <p>The Python API files are located under

          ''/usr/lib/python2.7/dist-packages/novaclient'' and the most important file
          to look

          at is ''client.py''. This file does all the request preparation, sending
          request and

          receiving response. It is also used by the command line Nova client. </p>'
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:27:59-04:00'
          customer_folders: []
          description: Instance Management
          id: 6000190145
          is_default: false
          language_id: 6
          name: Instance Management
          parent_id: 6000190145
          position: 1
          updated_at: '2015-09-03T01:27:59-04:00'
          visibility: 1
        folder_id: 6000190145
        hits: 16
        id: 6000075752
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T21:03:07-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000075752
        position: 4
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Trouble Shooting
        updated_at: '2015-11-01T21:03:07-05:00'
        user_id: 6002464727
  html: '<h2>Debugging Nova Command line Client</h2>

    <p>These instructions assume you have installed Nova command client in a Linux

    environment. If you have other operating systems, the debugging process might
    be

    a slightly different, however, the general rules should still apply.</p>

    <p>Nova command line client is very much like other Linux commands, it outputs

    errors in the standard output, which is the monitor.</p>

    <p>If you get an error, you can always read the error message and generally it
    give

    you very good hints about what might be wrong.</p>

    <p>For example, if you execute <code>nova service-list</code> on the command line
    without

    authentication, the error message might look like this:</p>

    <p><code>ERROR: You must provide a username via either --os-username or env[OS_USERNAME]</code></p>

    <p>The above message indicates you need to be authenticated before you can use
    the

    API. The authentication requires some environment variables to be set. To set

    these environment variables you can either source the script file obtained from

    NeCTAR <a href="https://dashboard.rc.nectar.org.au">Dashboard</a> or you can override
    it by using command line options.</p>

    <p>You can always execute <code>man nova</code> or simply <code>nova</code> to
    get more help

    information and to learn each supported options.</p>

    <p>If you find a useful command, you can also execute <code>nova help command</code>,

    this will give your more specific help for the command.</p>

    <h2>Debugging Nova Python API</h2>

    <p>Debugging Nova Python API takes more effects as it depends on how familiar

    with Python programming and what development environment you use.</p>

    <p>The below provides some basic information about how you debug the Nova Python

    API.</p>

    <p>You can debug your python code using Python debugger called pdb and you can
    find

    more information <a href="https://docs.python.org/2/library/pdb.html">here</a>.</p>

    <p>The below code uses pdb debuuger to debug a python file contains clinet python

    API code.</p>

    <p><code>pdb file_name.py</code></p>

    <p>Once you executed the above code, the command line will be stopped on the first

    line of code and you can use some commands to control the execution flow.</p>

    <p>Some useful ones to use are:</p>

    <table>

    <thead>

    <tr>

    <th align="right">Command</th>

    <th align="left">Action</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td align="right">b</td>

    <td align="left">set a breakpoint</td>

    </tr>

    <tr>

    <td align="right">c</td>

    <td align="left">continue debugging until you hit a breakpoint</td>

    </tr>

    <tr>

    <td align="right">s</td>

    <td align="left">step through the code</td>

    </tr>

    <tr>

    <td align="right">n</td>

    <td align="left">to go to next line of code</td>

    </tr>

    <tr>

    <td align="right">l</td>

    <td align="left">list source code for the current file</td>

    </tr>

    <tr>

    <td align="right">u</td>

    <td align="left">navigate up a stack frame</td>

    </tr>

    <tr>

    <td align="right">d</td>

    <td align="left">navigate down a stack frame</td>

    </tr>

    <tr>

    <td align="right">p</td>

    <td align="left">to print the value of an expression in the current context</td>

    </tr>

    </tbody>

    </table>

    <h2>Debugging Via HTTP</h2>

    <p>The both of command line API and python API are restful web service client.

    Thus the requests are all made by using HTTP and you can always refer to

    <a href="http://developer.openstack.org/api-ref-objectstorage-v1.html">OpenStack
    Service End</a> for further references about what should be

    presented in the HTTP requests. The Nova API uses <a href="http://www.python-requests.org/en/latest/">requests</a>
    library

    to send and receive HTTP requests/responses.</p>

    <p>For command line client, you can add --debug option to print out HTTP request

    header and HTTP response header, which give you a lot of more insight

    information. To verify parameters in the request header, you can refer to

    OpenStack service <a href="http://developer.openstack.org/api-ref-objectstorage-v1.html">API</a>
    to see what are expected.</p>

    <p>To enable debugging information on the standard out for Python API, you can
    add

    the below code:</p>

    <p>```</p>

    <p>import logging</p>

    <p>logger = logging.getLogger("novaclient")</p>

    <p>logging.basicConfig(level=logging.DEBUG)</p>

    <p>```</p>

    <p>The will print the same output as adding --debug option for command line API.</p>

    <h2>Debugging via Source Code</h2>

    <p>If the above techniques are still not helpful, you can always look at the source

    code to find the problems.</p>

    <p>The below source file structure is based on the installation in Ubuntu.</p>

    <p>The command line nova command is located in ''/usr/bin/nova''. By looking at
    this

    file, you should get a idea of how the various options are interpreted. This file

    acts as an interface for Python API.</p>

    <p>The Python API files are located under

    ''/usr/lib/python2.7/dist-packages/novaclient'' and the most important file to
    look

    at is ''client.py''. This file does all the request preparation, sending request
    and

    receiving response. It is also used by the command line Nova client. </p>'
  parent: 39
  sha1: fb3ab57b531b8f5119c4b1f7d9fecf66000bc209
  title: Trouble Shooting
66:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-08T19:42:06-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Documentation \n The following documentations provides reference\
          \ and guidance information for the\nNova API: \n \n \n Nova Python API reference\
          \ \n \n \n Nova Command Line API Reference  \n \n \n Nova API Reference\
          \ \n \n \n The following documentations explain how to configure and run\
          \ Nova: \n \n \n Admin guide for Compute \n \n \n Operation guide for Compute\
          \ \n \n \n Security guide for Compute \n \n \n NeCTAR Support \n If you\
          \ have a problem and you cannot resolve it, you can always go to NecTAR\n\
          HelpDesk to log a support ticket and the NeCTAR support staff are\nmore\
          \ than happy to help you. "
        description: '<h2>Documentation</h2>

          <p>The following documentations provides reference and guidance information
          for the

          Nova API:</p>

          <ul>

          <li>

          <p><a href="http://docs.openstack.org/developer/nova/">Nova Python API reference</a></p>

          </li>

          <li>

          <p><a href="http://docs.openstack.org/cli-reference/content/novaclient_commands.html">Nova
          Command Line API Reference</a> </p>

          </li>

          <li>

          <p><a href="http://developer.openstack.org/api-ref-compute-v2.1.html">Nova
          API Reference</a></p>

          </li>

          </ul>

          <p>The following documentations explain how to configure and run Nova:</p>

          <ul>

          <li>

          <p><a href="http://docs.openstack.org/admin-guide-cloud/compute.html">Admin
          guide for Compute</a></p>

          </li>

          <li>

          <p><a href="http://docs.openstack.org/openstack-ops/content/instances.html">Operation
          guide for Compute</a></p>

          </li>

          <li>

          <p><a href="http://docs.openstack.org/security-guide/compute.html">Security
          guide for Compute</a></p>

          </li>

          </ul>

          <h2>NeCTAR Support</h2>

          <p>If you have a problem and you cannot resolve it, you can always go to
          NecTAR

          <a href="https://support.nectar.org.au/support/home">HelpDesk</a> to log
          a support ticket and the NeCTAR support staff are

          more than happy to help you.</p>'
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:27:59-04:00'
          customer_folders: []
          description: Instance Management
          id: 6000190145
          is_default: false
          language_id: 6
          name: Instance Management
          parent_id: 6000190145
          position: 2
          updated_at: '2015-09-03T01:27:59-04:00'
          visibility: 1
        folder_id: 6000190145
        hits: 0
        id: 6000076073
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-08T19:42:06-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000076073
        position: 5
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: More Info
        updated_at: '2015-10-08T19:42:06-04:00'
        user_id: 6002464727
  html: '<h2>Documentation</h2>

    <p>The following documentations provides reference and guidance information for
    the

    Nova API:</p>

    <ul>

    <li>

    <p><a href="http://docs.openstack.org/developer/nova/">Nova Python API reference</a></p>

    </li>

    <li>

    <p><a href="http://docs.openstack.org/cli-reference/content/novaclient_commands.html">Nova
    Command Line API Reference</a> </p>

    </li>

    <li>

    <p><a href="http://developer.openstack.org/api-ref-compute-v2.1.html">Nova API
    Reference</a></p>

    </li>

    </ul>

    <p>The following documentations explain how to configure and run Nova:</p>

    <ul>

    <li>

    <p><a href="http://docs.openstack.org/admin-guide-cloud/compute.html">Admin guide
    for Compute</a></p>

    </li>

    <li>

    <p><a href="http://docs.openstack.org/openstack-ops/content/instances.html">Operation
    guide for Compute</a></p>

    </li>

    <li>

    <p><a href="http://docs.openstack.org/security-guide/compute.html">Security guide
    for Compute</a></p>

    </li>

    </ul>

    <h2>NeCTAR Support</h2>

    <p>If you have a problem and you cannot resolve it, you can always go to NecTAR

    <a href="https://support.nectar.org.au/support/home">HelpDesk</a> to log a support
    ticket and the NeCTAR support staff are

    more than happy to help you.</p>'
  parent: 39
  sha1: 7560ab3a1020eea2385f16461c2acf7304615b14
  title: More Info
67:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-08T19:42:07-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Heat: the dashboard \n On the research cloud dashboard project\
          \ panel\nthere is a side menu heading named \"Orchestration\". It has a\
          \ sub menu entry\ntitled \"Stacks\": \n \n When you select it you will see\
          \ a list of the stacks that you have created, and\nto the top right, a button\
          \ pair, one labelled \"+ Launch Stack\", the other\n\"\u2716 Delete Stack\"\
          : \n \n Pressing the \"+ Launch Stack\" button creates a dialogue that invites\
          \ you to\nprovide a Heat template. \n \n The dialogue offers you three ways\
          \ of providing a template via the \"Template Source\"\ndrop down: \n \n\
          \ \nURL - The template can be reached via a web browser, and you are going\
          \ to\n  provide the URL it can be found at; \n \nFile - You are going to\
          \ upload the template from your local machine; \n \nDirect Input - You will\
          \ type the template in by hand. \n \n Dependent on which selection you make\
          \ in the \"Template Source\" drop down, the\ndialogue will reconfigure itself\
          \ to allow you to provide the required information. \n The dialogue also\
          \ offers you the chance to provide an \"Environment Source\".\nThis is also\
          \ in the form of a drop down, but here the choices are limited\nto: \n \n\
          \ \nFile - You are going to upload the environment from your local machine;\
          \ \n \nDirect Input - You will type the environment in by hand. \n \n Again,\
          \ dependant on which selection you make, the dialogue will reconfigure\n\
          itself to allow you to provide the required information. \n An environment\n\
          simply allows you to provide parameter values and to define custom resources.\
          \ \n In this example we are going to use one of the NeCTAR Heat sample templates.\
          \ \n So in the Template Source field select \"URL\", then in the \"Template\
          \ URL\" field\nenter: \n https://raw.githubusercontent.com/NeCTAR-RC/heat-templates/master/juno/Fedora/wordpress_single_instance.yaml\
          \ \n Then in the Environment Source field select \"Direct Input\", then\
          \ in the environment\ndata edit box type the following yaml (taking care\
          \ to enter the correct values): \n ``` \n parameters: \n # your nectar keypair\
          \ name instead of 'nectar_demo' \n key_name: nectar_demo \n # the latest\
          \ nectar fedora image id \n fedora_image_id: db354243-aba2-4831-81c7-a155b9089291\
          \ \n ``` \n Once you are done press the \"Next\" button. \n All going well,\
          \ you should now be presented with a page titled \"Launch Stack\".\nIt will\
          \ be a form that is made up of fields that are taken from your template's\n\
          parameters. \n Next to each field is a small question mark icon. As it gains\
          \ focus, so the user\nwill be shows the parameters comment field as a help\
          \ bubble to the right. \n \n The value entered into the \"Stack Name\" field\
          \ is used to give a name to the stack\nthat is going to be launched by Heat.\
          \ This name must start with a letter and may\nonly contain letters, numbers,\
          \ underscores, full stops and hyphens... \n The \"Creation Timeout (minutes)\"\
          \ field is the number of minutes that should be\nallowed for the stack creation\
          \ to take. If this time is exceeded then the stack\ncreation will be aborted.\
          \ \n The \"Rollback On Failure\" field, if checked, will ensure that the\
          \ complete\nstack gets deleted if there is a failure in creation. If it's\
          \ not checked then\nyou will have to manually delete the stack should there\
          \ be a failure in the creation. \n The rest of the fields are taken from\
          \ the template that has been uploaded.\nYou should find that the values\
          \ you entered in the environment file\nhave been used to fill the fields.\
          \ Otherwise, simply provide the requested\nvalues then select the \"Launch\"\
          \ button. \n All going well, the stack should be created. Once created you\
          \ can select it\nin the lists of stacks that are active, drilling down into\
          \ its\nparticular details. \n When you are finished with a stack, you can\
          \ simply hit the \"Delete\" button\nnext to it on the stack listings. If\
          \ you want to delete more than one\nstack, select the checkboxes next to\
          \ them and hit the \"\u2716 Delete Stack\"\nbutton. "
        description: "<h1>Heat: the dashboard</h1>\n<p>On the research cloud <a href=\"\
          https://dashboard.rc.nectar.org.au/project/\">dashboard project panel</a>\n\
          there is a side menu heading named \"Orchestration\". It has a sub menu\
          \ entry\ntitled <a href=\"https://dashboard.rc.nectar.org.au/project/stacks/\"\
          >\"Stacks\"</a>:</p>\n<p><img alt=\"Heat in the dashboard project menu\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_dash_side_menu.png?raw=true\"\
          ></p>\n<p>When you select it you will see a list of the stacks that you\
          \ have created, and\nto the top right, a button pair, one labelled \"+ Launch\
          \ Stack\", the other\n\"\u2716 Delete Stack\":</p>\n<p><img alt=\"Heat stack\
          \ listing\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_dash_stack_listing.png?raw=true\"\
          ></p>\n<p>Pressing the \"+ Launch Stack\" button creates a dialogue that\
          \ invites you to\nprovide a Heat template.</p>\n<p><img alt=\"Heat select\
          \ template dialog\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_dash_select_template.png?raw=true\"\
          ></p>\n<p>The dialogue offers you three ways of providing a template via\
          \ the \"Template Source\"\ndrop down:</p>\n<ul>\n<li>\n<code>URL</code>\
          \ - The template can be reached via a web browser, and you are going to\n\
          \  provide the URL it can be found at;</li>\n<li>\n<code>File</code> - You\
          \ are going to upload the template from your local machine;</li>\n<li>\n\
          <code>Direct Input</code> - You will type the template in by hand.</li>\n\
          </ul>\n<p>Dependent on which selection you make in the \"Template Source\"\
          \ drop down, the\ndialogue will reconfigure itself to allow you to provide\
          \ the required information.</p>\n<p>The dialogue also offers you the chance\
          \ to provide an \"Environment Source\".\nThis is also in the form of a drop\
          \ down, but here the choices are limited\nto:</p>\n<ul>\n<li>\n<code>File</code>\
          \ - You are going to upload the environment from your local machine;</li>\n\
          <li>\n<code>Direct Input</code> - You will type the environment in by hand.</li>\n\
          </ul>\n<p>Again, dependant on which selection you make, the dialogue will\
          \ reconfigure\nitself to allow you to provide the required information.</p>\n\
          <p>An <a href=\"http://docs.openstack.org/developer/heat/template_guide/environment.html\"\
          >environment</a>\nsimply allows you to provide parameter values and to define\
          \ custom resources.</p>\n<p>In this example we are going to use one of the\
          \ NeCTAR Heat sample templates.</p>\n<p>So in the Template Source field\
          \ select \"URL\", then in the \"Template URL\" field\nenter:</p>\n<p><a\
          \ href=\"https://raw.githubusercontent.com/NeCTAR-RC/heat-templates/master/juno/Fedora/wordpress_single_instance.yaml\"\
          >https://raw.githubusercontent.com/NeCTAR-RC/heat-templates/master/juno/Fedora/wordpress_single_instance.yaml</a></p>\n\
          <p>Then in the Environment Source field select \"Direct Input\", then in\
          \ the environment\ndata edit box type the following <code>yaml</code> (taking\
          \ care to enter the correct values):</p>\n<p>```</p>\n<p>parameters:</p>\n\
          <p># your nectar keypair name instead of 'nectar_demo'</p>\n<p>key_name:\
          \ nectar_demo</p>\n<p># the latest nectar fedora image id</p>\n<p>fedora_image_id:\
          \ db354243-aba2-4831-81c7-a155b9089291</p>\n<p>```</p>\n<p>Once you are\
          \ done press the \"Next\" button.</p>\n<p>All going well, you should now\
          \ be presented with a page titled \"Launch Stack\".\nIt will be a form that\
          \ is made up of fields that are taken from your template's\nparameters.</p>\n\
          <p>Next to each field is a small question mark icon. As it gains focus,\
          \ so the user\nwill be shows the parameters comment field as a help bubble\
          \ to the right.</p>\n<p><img alt=\"Heat launch template dialog\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Heat--DOCID42/images/heat_dash_launch.png?raw=true\"\
          ></p>\n<p>The value entered into the \"Stack Name\" field is used to give\
          \ a name to the stack\nthat is going to be launched by Heat. This name must\
          \ start with a letter and may\nonly contain letters, numbers, underscores,\
          \ full stops and hyphens...</p>\n<p>The \"Creation Timeout (minutes)\" field\
          \ is the number of minutes that should be\nallowed for the stack creation\
          \ to take. If this time is exceeded then the stack\ncreation will be aborted.</p>\n\
          <p>The \"Rollback On Failure\" field, if checked, will ensure that the complete\n\
          stack gets deleted if there is a failure in creation. If it's not checked\
          \ then\nyou will have to manually delete the stack should there be a failure\
          \ in the creation.</p>\n<p>The rest of the fields are taken from the template\
          \ that has been uploaded.\nYou should find that the values you entered in\
          \ the environment file\nhave been used to fill the fields. Otherwise, simply\
          \ provide the requested\nvalues then select the \"Launch\" button.</p>\n\
          <p>All going well, the stack should be created. Once created you can select\
          \ it\nin the lists of stacks that are active, drilling down into its\nparticular\
          \ details.</p>\n<p>When you are finished with a stack, you can simply hit\
          \ the \"Delete\" button\nnext to it on the stack listings. If you want to\
          \ delete more than one\nstack, select the checkboxes next to them and hit\
          \ the \"\u2716 Delete Stack\"\nbutton.</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:02-04:00'
          customer_folders: []
          description: Heat
          id: 6000190148
          is_default: false
          language_id: 6
          name: Heat
          parent_id: 6000190148
          position: 4
          updated_at: '2015-09-03T01:28:02-04:00'
          visibility: 1
        folder_id: 6000190148
        hits: 5
        id: 6000076074
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-21T20:04:18-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000076074
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Heat Dashboard Introduction
        updated_at: '2015-10-21T20:04:18-04:00'
        user_id: 6002464727
  html: "<h1>Heat: the dashboard</h1>\n<p>On the research cloud <a href=\"https://dashboard.rc.nectar.org.au/project/\"\
    >dashboard project panel</a>\nthere is a side menu heading named \"Orchestration\"\
    . It has a sub menu entry\ntitled <a href=\"https://dashboard.rc.nectar.org.au/project/stacks/\"\
    >\"Stacks\"</a>:</p>\n<p><img alt=\"Heat in the dashboard project menu\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_dash_side_menu.png?raw=true\"></p>\n\
    <p>When you select it you will see a list of the stacks that you have created,\
    \ and\nto the top right, a button pair, one labelled \"+ Launch Stack\", the other\n\
    \"\u2716 Delete Stack\":</p>\n<p><img alt=\"Heat stack listing\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_dash_stack_listing.png?raw=true\"\
    ></p>\n<p>Pressing the \"+ Launch Stack\" button creates a dialogue that invites\
    \ you to\nprovide a Heat template.</p>\n<p><img alt=\"Heat select template dialog\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_dash_select_template.png?raw=true\"\
    ></p>\n<p>The dialogue offers you three ways of providing a template via the \"\
    Template Source\"\ndrop down:</p>\n<ul>\n<li><code>URL</code> - The template can\
    \ be reached via a web browser, and you are going to\n  provide the URL it can\
    \ be found at;</li>\n<li><code>File</code> - You are going to upload the template\
    \ from your local machine;</li>\n<li><code>Direct Input</code> - You will type\
    \ the template in by hand.</li>\n</ul>\n<p>Dependent on which selection you make\
    \ in the \"Template Source\" drop down, the\ndialogue will reconfigure itself\
    \ to allow you to provide the required information.</p>\n<p>The dialogue also\
    \ offers you the chance to provide an \"Environment Source\".\nThis is also in\
    \ the form of a drop down, but here the choices are limited\nto:</p>\n<ul>\n<li><code>File</code>\
    \ - You are going to upload the environment from your local machine;</li>\n<li><code>Direct\
    \ Input</code> - You will type the environment in by hand.</li>\n</ul>\n<p>Again,\
    \ dependant on which selection you make, the dialogue will reconfigure\nitself\
    \ to allow you to provide the required information.</p>\n<p>An <a href=\"http://docs.openstack.org/developer/heat/template_guide/environment.html\"\
    >environment</a>\nsimply allows you to provide parameter values and to define\
    \ custom resources.</p>\n<p>In this example we are going to use one of the NeCTAR\
    \ Heat sample templates.</p>\n<p>So in the Template Source field select \"URL\"\
    , then in the \"Template URL\" field\nenter:</p>\n<p><a href=\"https://raw.githubusercontent.com/NeCTAR-RC/heat-templates/master/juno/Fedora/wordpress_single_instance.yaml\"\
    >https://raw.githubusercontent.com/NeCTAR-RC/heat-templates/master/juno/Fedora/wordpress_single_instance.yaml</a></p>\n\
    <p>Then in the Environment Source field select \"Direct Input\", then in the environment\n\
    data edit box type the following <code>yaml</code> (taking care to enter the correct\
    \ values):</p>\n<p>```</p>\n<p>parameters:</p>\n<p># your nectar keypair name\
    \ instead of 'nectar_demo'</p>\n<p>key_name: nectar_demo</p>\n<p># the latest\
    \ nectar fedora image id</p>\n<p>fedora_image_id: db354243-aba2-4831-81c7-a155b9089291</p>\n\
    <p>```</p>\n<p>Once you are done press the \"Next\" button.</p>\n<p>All going\
    \ well, you should now be presented with a page titled \"Launch Stack\".\nIt will\
    \ be a form that is made up of fields that are taken from your template's\nparameters.</p>\n\
    <p>Next to each field is a small question mark icon. As it gains focus, so the\
    \ user\nwill be shows the parameters comment field as a help bubble to the right.</p>\n\
    <p><img alt=\"Heat launch template dialog\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Heat--DOCID42/images/heat_dash_launch.png?raw=true\"></p>\n\
    <p>The value entered into the \"Stack Name\" field is used to give a name to the\
    \ stack\nthat is going to be launched by Heat. This name must start with a letter\
    \ and may\nonly contain letters, numbers, underscores, full stops and hyphens...</p>\n\
    <p>The \"Creation Timeout (minutes)\" field is the number of minutes that should\
    \ be\nallowed for the stack creation to take. If this time is exceeded then the\
    \ stack\ncreation will be aborted.</p>\n<p>The \"Rollback On Failure\" field,\
    \ if checked, will ensure that the complete\nstack gets deleted if there is a\
    \ failure in creation. If it's not checked then\nyou will have to manually delete\
    \ the stack should there be a failure in the creation.</p>\n<p>The rest of the\
    \ fields are taken from the template that has been uploaded.\nYou should find\
    \ that the values you entered in the environment file\nhave been used to fill\
    \ the fields. Otherwise, simply provide the requested\nvalues then select the\
    \ \"Launch\" button.</p>\n<p>All going well, the stack should be created. Once\
    \ created you can select it\nin the lists of stacks that are active, drilling\
    \ down into its\nparticular details.</p>\n<p>When you are finished with a stack,\
    \ you can simply hit the \"Delete\" button\nnext to it on the stack listings.\
    \ If you want to delete more than one\nstack, select the checkboxes next to them\
    \ and hit the \"\u2716 Delete Stack\"\nbutton.</p>"
  parent: 42
  sha1: 0eea9066a878cc69f0e9ed9da8dcdb06a6e7a350
  title: Heat Dashboard Introduction
68:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-08T20:25:50-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " When writing templates \n \n Always use the version indicator;\
          \ \n Use UTF-8 encoding; \n Don't use the TAB character anywhere in your\
          \ YAML; \n Remember to use a plain text editor; \n Use a mono spaced font\
          \ such as Courier New or Fixedsys to improve readability; \n YAML is more\
          \ expressive than JSON. And the YAML format is favoured in the\n  OpenStack\
          \ world. So, if possible, prefer the YAML format. A point to note\n  here\
          \ is that JSON is a subset of the latest YAML versions (> 1.2). Hence\n\
          \  a YAML templates can provide more information to readers than a JSON\
          \ equivalent. \n \n When designing templates \n \n Preference image id's\
          \ over image names. This will tie your template to\n  a specific image,\
          \ which means that changes or upgrades to the base image\n  will not affect\
          \ your template. However, it does mean that you take on the\n  responsibility\
          \ of ensuring that security updates are applied; \n Hence always get your\
          \ scripts to apply an update/upgrade when they launch; \n If your software\
          \ is to run in a variety of locations, try to use the user\n  data section\
          \ as little as possible: preference tools such as puppet/chef/ansible\n\
          \  if possible. This separation of concerns will make debugging problems\
          \ far\n  easier - and allow you to fire up your applications in other environments,\n\
          \  such as Vagrant/Virtualbox. \n "
        description: "<p>When writing templates</p>\n<ul>\n<li>Always use the version\
          \ indicator;</li>\n<li>Use UTF-8 encoding;</li>\n<li>Don't use the TAB character\
          \ anywhere in your YAML;</li>\n<li>Remember to use a plain text editor;</li>\n\
          <li>Use a mono spaced font such as Courier New or Fixedsys to improve readability;</li>\n\
          <li>YAML is more expressive than JSON. And the YAML format is favoured in\
          \ the\n  OpenStack world. So, if possible, prefer the YAML format. A point\
          \ to note\n  here is that JSON is a subset of the latest YAML versions (&gt;\
          \ 1.2). Hence\n  a YAML templates can provide more information to readers\
          \ than a JSON equivalent.</li>\n</ul>\n<p>When designing templates</p>\n\
          <ul>\n<li>Preference image id's over image names. This will tie your template\
          \ to\n  a specific image, which means that changes or upgrades to the base\
          \ image\n  will not affect your template. However, it does mean that you\
          \ take on the\n  responsibility of ensuring that security updates are applied;</li>\n\
          <li>Hence always get your scripts to apply an update/upgrade when they launch;</li>\n\
          <li>If your software is to run in a variety of locations, try to use the\
          \ user\n  data section as little as possible: preference tools such as puppet/chef/ansible\n\
          \  if possible. This separation of concerns will make debugging problems\
          \ far\n  easier - and allow you to fire up your applications in other environments,\n\
          \  such as Vagrant/Virtualbox.</li>\n</ul>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:02-04:00'
          customer_folders: []
          description: Heat
          id: 6000190148
          is_default: false
          language_id: 6
          name: Heat
          parent_id: 6000190148
          position: 5
          updated_at: '2015-09-03T01:28:02-04:00'
          visibility: 1
        folder_id: 6000190148
        hits: 1
        id: 6000076079
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-14T20:05:37-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000076079
        position: 7
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Best Practice
        updated_at: '2015-10-14T20:05:37-04:00'
        user_id: 6002464727
  html: "<p>When writing templates</p>\n<ul>\n<li>Always use the version indicator;</li>\n\
    <li>Use UTF-8 encoding;</li>\n<li>Don't use the TAB character anywhere in your\
    \ YAML;</li>\n<li>Remember to use a plain text editor;</li>\n<li>Use a mono spaced\
    \ font such as Courier New or Fixedsys to improve readability;</li>\n<li>YAML\
    \ is more expressive than JSON. And the YAML format is favoured in the\n  OpenStack\
    \ world. So, if possible, prefer the YAML format. A point to note\n  here is that\
    \ JSON is a subset of the latest YAML versions (&gt; 1.2). Hence\n  a YAML templates\
    \ can provide more information to readers than a JSON equivalent.</li>\n</ul>\n\
    <p>When designing templates</p>\n<ul>\n<li>Preference image id's over image names.\
    \ This will tie your template to\n  a specific image, which means that changes\
    \ or upgrades to the base image\n  will not affect your template. However, it\
    \ does mean that you take on the\n  responsibility of ensuring that security updates\
    \ are applied;</li>\n<li>Hence always get your scripts to apply an update/upgrade\
    \ when they launch;</li>\n<li>If your software is to run in a variety of locations,\
    \ try to use the user\n  data section as little as possible: preference tools\
    \ such as puppet/chef/ansible\n  if possible. This separation of concerns will\
    \ make debugging problems far\n  easier - and allow you to fire up your applications\
    \ in other environments,\n  such as Vagrant/Virtualbox.</li>\n</ul>"
  parent: 42
  sha1: cea02667f65d5b3332e0fe3e72705a2bb88ad285
  title: Best Practice
69:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-08T20:43:18-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Actions that can be performed \n The following is the list\
          \ of actions that you can perform on or with your stacks.\nThey are all\
          \ available from the command line. Only some are available via the dashboard.\
          \ \n With templates \n \n \nShow - display the particular template that\
          \ was used to create the stack. \n \nValidate - check a template for errors.\
          \ \n \n On stacks \n \n \nCreate - build a running stack up from a template.\
          \ \n \nDelete - remove a stack and resources from existence. \n \nSuspend\
          \ - moves a stacks resources to a suspended state (powered off,\n  but still\
          \ present). If you suspend as stack with an already suspended VM this\n\
          \  command will fail. The only way to recover is to delete the stack. \n\
          \ \nResume - takes a stack that's in a suspended state back to powered on.\
          \ \n \nList - list the stacks that you have created. \n \nShow - show a\
          \ lot of detail about a particular stack. \n \nUpdate - modify an existing\
          \ running stack. You will have to understand the\n  update action on each\
          \ resource to know how this will affect the stack. \n \n On resources \n\
          \ \n \nList - list the resources that a stack is using \n \nShow - show\
          \ the details of a particular resource \n \nMetadata - show the metadata\
          \ associated with a particular resource \n \n On events \n \n \nList - list\
          \ all the events a stack has experienced. \n \nShow - show the details of\
          \ a particular resource. \n "
        description: "<h1>Actions that can be performed</h1>\n<p>The following is\
          \ the list of actions that you can perform on or with your stacks.\nThey\
          \ are all available from the command line. Only some are available via the\
          \ dashboard.</p>\n<h2>With templates</h2>\n<ul>\n<li>\n<strong>Show</strong>\
          \ - display the particular template that was used to create the stack.</li>\n\
          <li>\n<strong>Validate</strong> - check a template for errors.</li>\n</ul>\n\
          <h2>On stacks</h2>\n<ul>\n<li>\n<strong>Create</strong> - build a running\
          \ stack up from a template.</li>\n<li>\n<strong>Delete</strong> - remove\
          \ a stack and resources from existence.</li>\n<li>\n<strong>Suspend</strong>\
          \ - moves a stacks resources to a suspended state (powered off,\n  but still\
          \ present). If you suspend as stack with an already suspended VM this\n\
          \  command will fail. The only way to recover is to delete the stack.</li>\n\
          <li>\n<strong>Resume</strong> - takes a stack that's in a suspended state\
          \ back to powered on.</li>\n<li>\n<strong>List</strong> - list the stacks\
          \ that you have created.</li>\n<li>\n<strong>Show</strong> - show a lot\
          \ of detail about a particular stack.</li>\n<li>\n<strong>Update</strong>\
          \ - modify an existing running stack. You will have to understand the\n\
          \  update action on each resource to know how this will affect the stack.</li>\n\
          </ul>\n<h2>On resources</h2>\n<ul>\n<li>\n<strong>List</strong> - list the\
          \ resources that a stack is using</li>\n<li>\n<strong>Show</strong> - show\
          \ the details of a particular resource</li>\n<li>\n<strong>Metadata</strong>\
          \ - show the metadata associated with a particular resource</li>\n</ul>\n\
          <h2>On events</h2>\n<ul>\n<li>\n<strong>List</strong> - list all the events\
          \ a stack has experienced.</li>\n<li>\n<strong>Show</strong> - show the\
          \ details of a particular resource.</li>\n</ul>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:02-04:00'
          customer_folders: []
          description: Heat
          id: 6000190148
          is_default: false
          language_id: 6
          name: Heat
          parent_id: 6000190148
          position: 5
          updated_at: '2015-09-03T01:28:02-04:00'
          visibility: 1
        folder_id: 6000190148
        hits: 0
        id: 6000076082
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-08T20:43:18-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000076082
        position: 8
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Heat Actions
        updated_at: '2015-10-08T20:43:18-04:00'
        user_id: 6002464727
  html: "<h1>Actions that can be performed</h1>\n<p>The following is the list of actions\
    \ that you can perform on or with your stacks.\nThey are all available from the\
    \ command line. Only some are available via the dashboard.</p>\n<h2>With templates</h2>\n\
    <ul>\n<li><strong>Show</strong> - display the particular template that was used\
    \ to create the stack.</li>\n<li><strong>Validate</strong> - check a template\
    \ for errors.</li>\n</ul>\n<h2>On stacks</h2>\n<ul>\n<li><strong>Create</strong>\
    \ - build a running stack up from a template.</li>\n<li><strong>Delete</strong>\
    \ - remove a stack and resources from existence.</li>\n<li><strong>Suspend</strong>\
    \ - moves a stacks resources to a suspended state (powered off,\n  but still present).\
    \ If you suspend as stack with an already suspended VM this\n  command will fail.\
    \ The only way to recover is to delete the stack.</li>\n<li><strong>Resume</strong>\
    \ - takes a stack that's in a suspended state back to powered on.</li>\n<li><strong>List</strong>\
    \ - list the stacks that you have created.</li>\n<li><strong>Show</strong> - show\
    \ a lot of detail about a particular stack.</li>\n<li><strong>Update</strong>\
    \ - modify an existing running stack. You will have to understand the\n  update\
    \ action on each resource to know how this will affect the stack.</li>\n</ul>\n\
    <h2>On resources</h2>\n<ul>\n<li><strong>List</strong> - list the resources that\
    \ a stack is using</li>\n<li><strong>Show</strong> - show the details of a particular\
    \ resource</li>\n<li><strong>Metadata</strong> - show the metadata associated\
    \ with a particular resource</li>\n</ul>\n<h2>On events</h2>\n<ul>\n<li><strong>List</strong>\
    \ - list all the events a stack has experienced.</li>\n<li><strong>Show</strong>\
    \ - show the details of a particular resource.</li>\n</ul>"
  parent: 42
  sha1: 5fe40b8d23dab31c94978688fa9f5608cf655b64
  title: Heat Actions
70:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-08T20:47:14-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Debugging Swift Command line Client \n The below assumes you\
          \ have installed swift command client in a Linux\nenvironment. If you have\
          \ other operating systems, the debugging process might be\nslightly different,\
          \ however the general rules should still apply. \n Swift command line client\
          \ is very much like other Linux commands; error messages\nare sent to standard\
          \ output, which is the monitor. \n If you get an error, you can always read\
          \ the error message and generally it will\ngive you very good hints about\
          \ what might be wrong. \n For example, if you execute swift list on the\
          \ command line without\nauthentication, the error message might look like\
          \ this: \n \n Auth version 1.0 requires ST_AUTH, ST_USER, and ST_KEY environment\
          \ variables\nto be set or overridden with -A, -U, or -K. \n Auth version\
          \ 2.0 requires OS_AUTH_URL, OS_USERNAME, OS_PASSWORD, and\nOS_TENANT_NAME\
          \ OS_TENANT_ID to be set or overridden with --os-auth-url,\n--os-username,\
          \ --os-password, --os-tenant-name or os-tenant-id. Note:\nadding \"-V 2\"\
          \ is necessary for this. \n \n The above message indicates you that there\
          \ are 2 authentication versions that\nswift currently supports and each\
          \ version requires some environment variables\nto be set. To set these environment\
          \ variables you can either source the script\nfile downloaded from NeCTAR\
          \ Dashboard or you can override it by\nusing command line options. \n You\
          \ can always execute man swift or simply swift to get more help\ninformation\
          \ and to learn about supported options. \n If you find a useful command,\
          \ you can also execute swift command --help,\nthis will give you more specific\
          \ help for the command. \n Debugging Client Python API \n Debugging client\
          \ Python API takes more effort as it depends on how familiar\nwith Python\
          \ programming and what development environment you use. \n The below provides\
          \ some basic information about how you debug the client Python\nAPI. \n\
          \ You can debug your python code using Python debugger called pdb and you\
          \ can find\nmore information here. \n The following code uses pdb debugger\
          \ to debug a python file contains client python\nAPI code. \n pdb file_name.py\
          \ \n Once you executed the above code, the command line will be stopped\
          \ on the first\nline of code and you can use some commands to control the\
          \ execution flow. \n Some useful ones to use are: \n\n\n\nCommand\nAction\n\
          \n\n\n\nb\nset a breakpoint\n\n\nc\ncontinue debugging until you hit a breakpoint\n\
          \n\ns\nstep through the code\n\n\nn\nto go to next line of code\n\n\nl\n\
          list source code for the current file\n\n\nu\nnavigate up a stack frame\n\
          \n\nd\nnavigate down a stack frame\n\n\np\nto print the value of an expression\
          \ in the current context\n\n\n\n Debugging Via HTTP \n Both command line\
          \ API and python API are accessed via a web service client.\nThus the requests\
          \ are all made by using HTTP and you can always refer to\nOpenStack Service\
          \ End for further references about what should be\npresented in the HTTP\
          \ requests. The swift API uses requests library\nto send and receive HTTP\
          \ requests/responses. \n For command line client, you can add --debug option\
          \ to print out HTTP request\nheader and HTTP response header, which give\
          \ you a lot of more insight\ninformation. To verify parameters in the request\
          \ header, you can refer to\nOpenStack service API to see what are expected.\
          \ \n To enable debugging information on the standard out for Python API,\
          \ you can add\nthe below code: \n ``` \n import logging \n logger = logging.getLogger(\"\
          swiftclient\") \n logging.basicConfig(level=logging.DEBUG) \n ``` \n The\
          \ will print the same output as adding --debug option for command line API.\
          \ \n Debugging via Source Code \n If the above techniques are still not\
          \ helpful, you can always look at the source\ncode to find the problems.\
          \ \n The following source file structure is based on the installation in\
          \ Ubuntu. \n The command line swift command is located in '/usr/bin/swift'.\
          \ By looking at this\nfile, you should get a idea of how the various options\
          \ are interpreted. This file\nacts as an interface for Python API. \n The\
          \ Python API files are located under\n'/usr/lib/python2.7/dist-packages/swiftclient'\
          \ and the most important file to look\nat is 'client.py'. This is file does\
          \ all the request preparation, sending request\nand receiving response.\
          \ It is also used by the command line swift client.  "
        description: '<h2>Debugging Swift Command line Client</h2>

          <p>The below assumes you have installed swift command client in a Linux

          environment. If you have other operating systems, the debugging process
          might be

          slightly different, however the general rules should still apply.</p>

          <p>Swift command line client is very much like other Linux commands; error
          messages

          are sent to standard output, which is the monitor.</p>

          <p>If you get an error, you can always read the error message and generally
          it will

          give you very good hints about what might be wrong.</p>

          <p>For example, if you execute <code>swift list</code> on the command line
          without

          authentication, the error message might look like this:</p>

          <blockquote>

          <p>Auth version 1.0 requires ST_AUTH, ST_USER, and ST_KEY environment variables

          to be set or overridden with -A, -U, or -K.</p>

          <p>Auth version 2.0 requires OS_AUTH_URL, OS_USERNAME, OS_PASSWORD, and

          OS_TENANT_NAME OS_TENANT_ID to be set or overridden with --os-auth-url,

          --os-username, --os-password, --os-tenant-name or os-tenant-id. Note:

          adding "-V 2" is necessary for this.</p>

          </blockquote>

          <p>The above message indicates you that there are 2 authentication versions
          that

          swift currently supports and each version requires some environment variables

          to be set. To set these environment variables you can either source the
          script

          file downloaded from NeCTAR <a href="https://dashboard.rc.nectar.org.au">Dashboard</a>
          or you can override it by

          using command line options.</p>

          <p>You can always execute <code>man swift</code> or simply <code>swift</code>
          to get more help

          information and to learn about supported options.</p>

          <p>If you find a useful command, you can also execute <code>swift command
          --help</code>,

          this will give you more specific help for the command.</p>

          <h2>Debugging Client Python API</h2>

          <p>Debugging client Python API takes more effort as it depends on how familiar

          with Python programming and what development environment you use.</p>

          <p>The below provides some basic information about how you debug the client
          Python

          API.</p>

          <p>You can debug your python code using Python debugger called pdb and you
          can find

          more information <a href="https://docs.python.org/2/library/pdb.html">here</a>.</p>

          <p>The following code uses pdb debugger to debug a python file contains
          client python

          API code.</p>

          <p><code>pdb file_name.py</code></p>

          <p>Once you executed the above code, the command line will be stopped on
          the first

          line of code and you can use some commands to control the execution flow.</p>

          <p>Some useful ones to use are:</p>

          <table>

          <thead>

          <tr>

          <th align="right">Command</th>

          <th align="left">Action</th>

          </tr>

          </thead>

          <tbody>

          <tr>

          <td align="right">b</td>

          <td align="left">set a breakpoint</td>

          </tr>

          <tr>

          <td align="right">c</td>

          <td align="left">continue debugging until you hit a breakpoint</td>

          </tr>

          <tr>

          <td align="right">s</td>

          <td align="left">step through the code</td>

          </tr>

          <tr>

          <td align="right">n</td>

          <td align="left">to go to next line of code</td>

          </tr>

          <tr>

          <td align="right">l</td>

          <td align="left">list source code for the current file</td>

          </tr>

          <tr>

          <td align="right">u</td>

          <td align="left">navigate up a stack frame</td>

          </tr>

          <tr>

          <td align="right">d</td>

          <td align="left">navigate down a stack frame</td>

          </tr>

          <tr>

          <td align="right">p</td>

          <td align="left">to print the value of an expression in the current context</td>

          </tr>

          </tbody>

          </table>

          <h2>Debugging Via HTTP</h2>

          <p>Both command line API and python API are accessed via a web service client.

          Thus the requests are all made by using HTTP and you can always refer to

          <a href="http://developer.openstack.org/api-ref-objectstorage-v1.html">OpenStack
          Service End</a> for further references about what should be

          presented in the HTTP requests. The swift API uses <a href="http://www.python-requests.org/en/latest/">requests</a>
          library

          to send and receive HTTP requests/responses.</p>

          <p>For command line client, you can add <code>--debug</code> option to print
          out HTTP request

          header and HTTP response header, which give you a lot of more insight

          information. To verify parameters in the request header, you can refer to

          <a href="http://developer.openstack.org/api-ref-objectstorage-v1.html">OpenStack
          service API</a> to see what are expected.</p>

          <p>To enable debugging information on the standard out for Python API, you
          can add

          the below code:</p>

          <p>```</p>

          <p>import logging</p>

          <p>logger = logging.getLogger("swiftclient")</p>

          <p>logging.basicConfig(level=logging.DEBUG)</p>

          <p>```</p>

          <p>The will print the same output as adding --debug option for command line
          API.</p>

          <h2>Debugging via Source Code</h2>

          <p>If the above techniques are still not helpful, you can always look at
          the source

          code to find the problems.</p>

          <p>The following source file structure is based on the installation in Ubuntu.</p>

          <p>The command line swift command is located in ''/usr/bin/swift''. By looking
          at this

          file, you should get a idea of how the various options are interpreted.
          This file

          acts as an interface for Python API.</p>

          <p>The Python API files are located under

          ''/usr/lib/python2.7/dist-packages/swiftclient'' and the most important
          file to look

          at is ''client.py''. This is file does all the request preparation, sending
          request

          and receiving response. It is also used by the command line swift client.
          </p>'
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:00-04:00'
          customer_folders: []
          description: Object Storage
          id: 6000190146
          is_default: false
          language_id: 6
          name: Object Storage
          parent_id: 6000190146
          position: 2
          updated_at: '2015-09-03T01:28:00-04:00'
          visibility: 1
        folder_id: 6000190146
        hits: 9
        id: 6000076083
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T22:50:53-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000076083
        position: 4
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Trouble Shooting
        updated_at: '2015-11-01T22:50:53-05:00'
        user_id: 6002464727
  html: '<h2>Debugging Swift Command line Client</h2>

    <p>The below assumes you have installed swift command client in a Linux

    environment. If you have other operating systems, the debugging process might
    be

    slightly different, however the general rules should still apply.</p>

    <p>Swift command line client is very much like other Linux commands; error messages

    are sent to standard output, which is the monitor.</p>

    <p>If you get an error, you can always read the error message and generally it
    will

    give you very good hints about what might be wrong.</p>

    <p>For example, if you execute <code>swift list</code> on the command line without

    authentication, the error message might look like this:</p>

    <blockquote>

    <p>Auth version 1.0 requires ST_AUTH, ST_USER, and ST_KEY environment variables

    to be set or overridden with -A, -U, or -K.</p>

    <p>Auth version 2.0 requires OS_AUTH_URL, OS_USERNAME, OS_PASSWORD, and

    OS_TENANT_NAME OS_TENANT_ID to be set or overridden with --os-auth-url,

    --os-username, --os-password, --os-tenant-name or os-tenant-id. Note:

    adding "-V 2" is necessary for this.</p>

    </blockquote>

    <p>The above message indicates you that there are 2 authentication versions that

    swift currently supports and each version requires some environment variables

    to be set. To set these environment variables you can either source the script

    file downloaded from NeCTAR <a href="https://dashboard.rc.nectar.org.au">Dashboard</a>
    or you can override it by

    using command line options.</p>

    <p>You can always execute <code>man swift</code> or simply <code>swift</code>
    to get more help

    information and to learn about supported options.</p>

    <p>If you find a useful command, you can also execute <code>swift command --help</code>,

    this will give you more specific help for the command.</p>

    <h2>Debugging Client Python API</h2>

    <p>Debugging client Python API takes more effort as it depends on how familiar

    with Python programming and what development environment you use.</p>

    <p>The below provides some basic information about how you debug the client Python

    API.</p>

    <p>You can debug your python code using Python debugger called pdb and you can
    find

    more information <a href="https://docs.python.org/2/library/pdb.html">here</a>.</p>

    <p>The following code uses pdb debugger to debug a python file contains client
    python

    API code.</p>

    <p><code>pdb file_name.py</code></p>

    <p>Once you executed the above code, the command line will be stopped on the first

    line of code and you can use some commands to control the execution flow.</p>

    <p>Some useful ones to use are:</p>

    <table>

    <thead>

    <tr>

    <th align="right">Command</th>

    <th align="left">Action</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td align="right">b</td>

    <td align="left">set a breakpoint</td>

    </tr>

    <tr>

    <td align="right">c</td>

    <td align="left">continue debugging until you hit a breakpoint</td>

    </tr>

    <tr>

    <td align="right">s</td>

    <td align="left">step through the code</td>

    </tr>

    <tr>

    <td align="right">n</td>

    <td align="left">to go to next line of code</td>

    </tr>

    <tr>

    <td align="right">l</td>

    <td align="left">list source code for the current file</td>

    </tr>

    <tr>

    <td align="right">u</td>

    <td align="left">navigate up a stack frame</td>

    </tr>

    <tr>

    <td align="right">d</td>

    <td align="left">navigate down a stack frame</td>

    </tr>

    <tr>

    <td align="right">p</td>

    <td align="left">to print the value of an expression in the current context</td>

    </tr>

    </tbody>

    </table>

    <h2>Debugging Via HTTP</h2>

    <p>Both command line API and python API are accessed via a web service client.

    Thus the requests are all made by using HTTP and you can always refer to

    <a href="http://developer.openstack.org/api-ref-objectstorage-v1.html">OpenStack
    Service End</a> for further references about what should be

    presented in the HTTP requests. The swift API uses <a href="http://www.python-requests.org/en/latest/">requests</a>
    library

    to send and receive HTTP requests/responses.</p>

    <p>For command line client, you can add <code>--debug</code> option to print out
    HTTP request

    header and HTTP response header, which give you a lot of more insight

    information. To verify parameters in the request header, you can refer to

    <a href="http://developer.openstack.org/api-ref-objectstorage-v1.html">OpenStack
    service API</a> to see what are expected.</p>

    <p>To enable debugging information on the standard out for Python API, you can
    add

    the below code:</p>

    <p>```</p>

    <p>import logging</p>

    <p>logger = logging.getLogger("swiftclient")</p>

    <p>logging.basicConfig(level=logging.DEBUG)</p>

    <p>```</p>

    <p>The will print the same output as adding --debug option for command line API.</p>

    <h2>Debugging via Source Code</h2>

    <p>If the above techniques are still not helpful, you can always look at the source

    code to find the problems.</p>

    <p>The following source file structure is based on the installation in Ubuntu.</p>

    <p>The command line swift command is located in ''/usr/bin/swift''. By looking
    at this

    file, you should get a idea of how the various options are interpreted. This file

    acts as an interface for Python API.</p>

    <p>The Python API files are located under

    ''/usr/lib/python2.7/dist-packages/swiftclient'' and the most important file to
    look

    at is ''client.py''. This is file does all the request preparation, sending request

    and receiving response. It is also used by the command line swift client. </p>'
  parent: 40
  sha1: 924f2142908742e324041f06f5c3f9692fd30c3d
  title: Trouble Shooting
71:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-09T00:30:20-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " The Nectar dashboard \n The Nectar dashboard is the first\
          \ and easiest way to manage your VMs in the\nNectar cloud. You will find\
          \ a guide to the dashboard below. You can find the\nNectar at https://dashboard.rc.nectar.org.au/,\
          \ where you'll\nbe asked to log in with your AAF credentials. \n Overview\
          \ \n The first screen you'll see when you log on to the dashboard is the\
          \ Overview\nscreen. It has a familiar navigation panel on the left hand\
          \ side and a\ncentral space that shows your dashboard information. On the\
          \ overview screen\nthis information consists of pie charts indicating the\
          \ resource usage (e.g.\nnumber VCPUs in use) in your allocation. An important\
          \ part of your dashboard\nis the Project Selector on the top left hand side:\
          \ if you manage more than\none project on the Nectar cloud this selector\
          \ will determine which project\nyour dashboard information relates to. \n\
          \ \n Instances \n You reach the instances screen in the dashboard by clicking\
          \ the Instances\ntab in the navigation panel. Thecentral space now shows\
          \ information about the\ninstances in your project, including their Name,\
          \ IP Address and other info. \n Beside a filter function at the top of the\
          \ table (which can be handy if your\nproject contains many instances), there\
          \ are some command buttons (e.g.\nLaunch Instance). You can find detailed\
          \ information for each instance by\nclicking the Instance Name and you can\
          \ perform a number of administrative\nActions on each VM by making a selection\
          \ from the instance's corresponding\nAction selector. \n You can find similar\
          \ information screens for information about your\nVolumes, Images and Access\
          \ & Security using the navigation panel. \n \n Allocations \n You use the\
          \ Allocations screens for managing aallocation request. You can\nstart a\
          \ new allocation request using the New Request tab, and you can find\ninformation\
          \ about any existing request that you may have on the My Request\nscreen.\
          \ You can also use the My Request screen to request amendments to any\n\
          of your allocations, should you need additional resources. \n \n Other features\
          \ \n All basic features for managing your Nectar OpenStack VMs, including\n\
          Orchestrating a stack of them, and various Storage options are in \nthe\
          \ Nectar Dashboard. Additional features can be accessed using Command \n\
          Line Interface or one of the OpenStack APIs. "
        description: "<h1>The Nectar dashboard</h1>\n<p>The Nectar dashboard is the\
          \ first and easiest way to manage your VMs in the\nNectar cloud. You will\
          \ find a guide to the dashboard below. You can find the\nNectar at <a href=\"\
          https://dashboard.rc.nectar.org.au/\">https://dashboard.rc.nectar.org.au/</a>,\
          \ where you'll\nbe asked to log in with your AAF credentials.</p>\n<h2>Overview</h2>\n\
          <p>The first screen you'll see when you log on to the dashboard is the <strong>Overview\n\
          screen</strong>. It has a familiar <strong>navigation panel</strong> on\
          \ the left hand side and a\ncentral space that shows your dashboard information.\
          \ On the overview screen\nthis information consists of pie charts indicating\
          \ the resource usage (e.g.\nnumber VCPUs in use) in your allocation. An\
          \ important part of your dashboard\nis the <strong>Project Selector</strong>\
          \ on the top left hand side: if you manage more than\none project on the\
          \ Nectar cloud this selector will determine which project\nyour dashboard\
          \ information relates to.</p>\n<p><img alt=\"Dashboard Overview\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/dashboard_overview.png?raw=true\"\
          ></p>\n<h2>Instances</h2>\n<p>You reach the <strong>instances screen</strong>\
          \ in the dashboard by clicking the Instances\ntab in the navigation panel.\
          \ Thecentral space now shows information about the\ninstances in your project,\
          \ including their Name, IP Address and other info.</p>\n<p>Beside a filter\
          \ function at the top of the table (which can be handy if your\nproject\
          \ contains many instances), there are some <strong>command buttons</strong>\
          \ (e.g.\nLaunch Instance). You can find <strong>detailed information</strong>\
          \ for each instance by\nclicking the Instance Name and you can perform a\
          \ number of administrative\nActions on each VM by making a selection from\
          \ the instance's corresponding\n<strong>Action selector</strong>.</p>\n\
          <p>You can find similar information screens for information about your\n\
          <strong>Volumes</strong>, <strong>Images</strong> and <strong>Access &amp;\
          \ Security</strong> using the navigation panel.</p>\n<p><img alt=\"Dashboard\
          \ Instances\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/dashboard_instances.png?raw=true\"\
          ></p>\n<h2>Allocations</h2>\n<p>You use the Allocations screens for managing\
          \ aallocation request. You can\nstart a new allocation request using the\
          \ New Request tab, and you can find\ninformation about any existing request\
          \ that you may have on the My Request\nscreen. You can also use the My Request\
          \ screen to request amendments to any\nof your allocations, should you need\
          \ additional resources.</p>\n<p><img alt=\"Dashboard Allocations\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/dashboard_allocations.png?raw=true\"\
          ></p>\n<h2>Other features</h2>\n<p>All basic features for managing your\
          \ Nectar OpenStack VMs, including\n<strong>Orchestrating</strong> a stack\
          \ of them, and various <strong>Storage options</strong> are in \nthe Nectar\
          \ Dashboard. Additional features can be accessed using Command \nLine Interface\
          \ or one of the OpenStack APIs.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 7
        id: 6000076111
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-22T00:57:12-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000076111
        position: 9
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Nectar Dashboard
        updated_at: '2015-10-22T00:57:12-04:00'
        user_id: 6002464727
  html: "<h1>The Nectar dashboard</h1>\n<p>The Nectar dashboard is the first and easiest\
    \ way to manage your VMs in the\nNectar cloud. You will find a guide to the dashboard\
    \ below. You can find the\nNectar at <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >https://dashboard.rc.nectar.org.au/</a>, where you'll\nbe asked to log in with\
    \ your AAF credentials.</p>\n<h2>Overview</h2>\n<p>The first screen you'll see\
    \ when you log on to the dashboard is the <strong>Overview\nscreen</strong>. It\
    \ has a familiar <strong>navigation panel</strong> on the left hand side and a\n\
    central space that shows your dashboard information. On the overview screen\n\
    this information consists of pie charts indicating the resource usage (e.g.\n\
    number VCPUs in use) in your allocation. An important part of your dashboard\n\
    is the <strong>Project Selector</strong> on the top left hand side: if you manage\
    \ more than\none project on the Nectar cloud this selector will determine which\
    \ project\nyour dashboard information relates to.</p>\n<p><img alt=\"Dashboard\
    \ Overview\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/dashboard_overview.png?raw=true\"\
    ></p>\n<h2>Instances</h2>\n<p>You reach the <strong>instances screen</strong>\
    \ in the dashboard by clicking the Instances\ntab in the navigation panel. Thecentral\
    \ space now shows information about the\ninstances in your project, including\
    \ their Name, IP Address and other info.</p>\n<p>Beside a filter function at the\
    \ top of the table (which can be handy if your\nproject contains many instances),\
    \ there are some <strong>command buttons</strong> (e.g.\nLaunch Instance). You\
    \ can find <strong>detailed information</strong> for each instance by\nclicking\
    \ the Instance Name and you can perform a number of administrative\nActions on\
    \ each VM by making a selection from the instance's corresponding\n<strong>Action\
    \ selector</strong>.</p>\n<p>You can find similar information screens for information\
    \ about your\n<strong>Volumes</strong>, <strong>Images</strong> and <strong>Access\
    \ &amp; Security</strong> using the navigation panel.</p>\n<p><img alt=\"Dashboard\
    \ Instances\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/dashboard_instances.png?raw=true\"\
    ></p>\n<h2>Allocations</h2>\n<p>You use the Allocations screens for managing aallocation\
    \ request. You can\nstart a new allocation request using the New Request tab,\
    \ and you can find\ninformation about any existing request that you may have on\
    \ the My Request\nscreen. You can also use the My Request screen to request amendments\
    \ to any\nof your allocations, should you need additional resources.</p>\n<p><img\
    \ alt=\"Dashboard Allocations\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/dashboard_allocations.png?raw=true\"\
    ></p>\n<h2>Other features</h2>\n<p>All basic features for managing your Nectar\
    \ OpenStack VMs, including\n<strong>Orchestrating</strong> a stack of them, and\
    \ various <strong>Storage options</strong> are in \nthe Nectar Dashboard. Additional\
    \ features can be accessed using Command \nLine Interface or one of the OpenStack\
    \ APIs.</p>"
  parent: 21
  sha1: 0cf114be6248c63a0793dd7bf20ab5bd3398ec4f
  title: Nectar Dashboard
72:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-09T00:35:24-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Videos \n The object storage for OpenStack was built by SwiftStack,\
          \ and they have published \nseveral useful videos on the SwiftStack website\
          \ \n They have also published a good introductory video about object storage\
          \ on YouTube \n This series of swiftstack videos provides a more thorough\
          \ introduction. \n You can also search YouTube by keywords 'object storage'\
          \ or 'swift'.\nYou will find that there are large amount of videos about\
          \ this topic which can certainly help you.  \n Documentation \n The following\
          \ documentations provides reference and guidance information for the\nSwift\
          \ API: \n \n \n Swift Python API reference \n \n \n Swift Command Line API\
          \ Reference  \n \n \n Swift API Reference \n \n \n The following documentations\
          \ explain how to configure and run Swift Object\nStorage: \n \n \n Admin\
          \ guide for Object Storage \n \n \n Operation guide for Object Storage \n\
          \ \n \n Security guide for Object Storage \n \n \n Books \n The following\
          \ book explain how to use and develop Swift Object Storage: \n \n \nOpenStack\
          \ Swift Using, Administering, and Developing for Swift Object Storage  \n\
          \ \n NeCTAR Support \n If you have a problem and you cannot resolve it,\
          \ you can always go to NecTAR\nHelpDesk to log a support ticket and the\
          \ NeCTAR support staff are\nmore than happy to help you. \n Useful Links\
          \ \n SwftStack Resources "
        description: "<h2>Videos</h2>\n<p>The object storage for OpenStack was built\
          \ by SwiftStack, and they have published \nseveral useful videos on the\
          \ <a href=\"https://swiftstack.com/resources/videos/#\">SwiftStack website</a></p>\n\
          <p>They have also published a good <a href=\"https://www.youtube.com/watch?v=LPXM0sC2TL8\"\
          >introductory video</a> about object storage on YouTube</p>\n<p>This series\
          \ of <a href=\"https://www.youtube.com/watch?v=JUXRJaZMOb0&amp;list=PLIr7I80Leee5NpoYTd9ffNvWq0pG18CN3\"\
          >swiftstack videos</a> provides a more thorough introduction.</p>\n<p>You\
          \ can also search <a href=\"https://www.youtube.com/\">YouTube</a> by keywords\
          \ 'object storage' or 'swift'.\nYou will find that there are large amount\
          \ of videos about this topic which can certainly help you. </p>\n<h2>Documentation</h2>\n\
          <p>The following documentations provides reference and guidance information\
          \ for the\nSwift API:</p>\n<ul>\n<li>\n<p><a href=\"http://docs.openstack.org/developer/swift/\"\
          >Swift Python API reference</a></p>\n</li>\n<li>\n<p><a href=\"http://docs.openstack.org/cli-reference/content/swiftclient_commands.html\"\
          >Swift Command Line API Reference</a> </p>\n</li>\n<li>\n<p><a href=\"http://developer.openstack.org/api-ref-objectstorage-v1.html\"\
          >Swift API Reference</a></p>\n</li>\n</ul>\n<p>The following documentations\
          \ explain how to configure and run Swift Object\nStorage:</p>\n<ul>\n<li>\n\
          <p><a href=\"http://docs.openstack.org/admin-guide-cloud/objectstorage.html\"\
          >Admin guide for Object Storage</a></p>\n</li>\n<li>\n<p><a href=\"http://docs.openstack.org/openstack-ops/content/storage_decision.html\"\
          >Operation guide for Object Storage</a></p>\n</li>\n<li>\n<p><a href=\"\
          http://docs.openstack.org/security-guide/object-storage.html\">Security\
          \ guide for Object Storage</a></p>\n</li>\n</ul>\n<h2>Books</h2>\n<p>The\
          \ following book explain how to use and develop Swift Object Storage:</p>\n\
          <ul>\n<li>\n<a href=\"http://shop.oreilly.com/product/0636920033288.do\"\
          >OpenStack Swift Using, Administering, and Developing for Swift Object Storage</a>\
          \ </li>\n</ul>\n<h2>NeCTAR Support</h2>\n<p>If you have a problem and you\
          \ cannot resolve it, you can always go to NecTAR\n<a href=\"https://support.nectar.org.au/support/home\"\
          >HelpDesk</a> to log a support ticket and the NeCTAR support staff are\n\
          more than happy to help you.</p>\n<h2>Useful Links</h2>\n<p><a href=\"https://swiftstack.com/resources/data-sheets/#\"\
          >SwftStack Resources</a></p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:00-04:00'
          customer_folders: []
          description: Object Storage
          id: 6000190146
          is_default: false
          language_id: 6
          name: Object Storage
          parent_id: 6000190146
          position: 2
          updated_at: '2015-09-03T01:28:00-04:00'
          visibility: 1
        folder_id: 6000190146
        hits: 8
        id: 6000076112
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T19:53:24-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000076112
        position: 5
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: More Info
        updated_at: '2015-11-01T19:53:24-05:00'
        user_id: 6002464727
  html: "<h2>Videos</h2>\n<p>The object storage for OpenStack was built by SwiftStack,\
    \ and they have published \nseveral useful videos on the <a href=\"https://swiftstack.com/resources/videos/#\"\
    >SwiftStack website</a></p>\n<p>They have also published a good <a href=\"https://www.youtube.com/watch?v=LPXM0sC2TL8\"\
    >introductory video</a> about object storage on YouTube</p>\n<p>This series of\
    \ <a href=\"https://www.youtube.com/watch?v=JUXRJaZMOb0&amp;list=PLIr7I80Leee5NpoYTd9ffNvWq0pG18CN3\"\
    >swiftstack videos</a> provides a more thorough introduction.</p>\n<p>You can\
    \ also search <a href=\"https://www.youtube.com/\">YouTube</a> by keywords 'object\
    \ storage' or 'swift'.\nYou will find that there are large amount of videos about\
    \ this topic which can certainly help you. </p>\n<h2>Documentation</h2>\n<p>The\
    \ following documentations provides reference and guidance information for the\n\
    Swift API:</p>\n<ul>\n<li>\n<p><a href=\"http://docs.openstack.org/developer/swift/\"\
    >Swift Python API reference</a></p>\n</li>\n<li>\n<p><a href=\"http://docs.openstack.org/cli-reference/content/swiftclient_commands.html\"\
    >Swift Command Line API Reference</a> </p>\n</li>\n<li>\n<p><a href=\"http://developer.openstack.org/api-ref-objectstorage-v1.html\"\
    >Swift API Reference</a></p>\n</li>\n</ul>\n<p>The following documentations explain\
    \ how to configure and run Swift Object\nStorage:</p>\n<ul>\n<li>\n<p><a href=\"\
    http://docs.openstack.org/admin-guide-cloud/objectstorage.html\">Admin guide for\
    \ Object Storage</a></p>\n</li>\n<li>\n<p><a href=\"http://docs.openstack.org/openstack-ops/content/storage_decision.html\"\
    >Operation guide for Object Storage</a></p>\n</li>\n<li>\n<p><a href=\"http://docs.openstack.org/security-guide/object-storage.html\"\
    >Security guide for Object Storage</a></p>\n</li>\n</ul>\n<h2>Books</h2>\n<p>The\
    \ following book explain how to use and develop Swift Object Storage:</p>\n<ul>\n\
    <li><a href=\"http://shop.oreilly.com/product/0636920033288.do\">OpenStack Swift\
    \ Using, Administering, and Developing for Swift Object Storage</a> </li>\n</ul>\n\
    <h2>NeCTAR Support</h2>\n<p>If you have a problem and you cannot resolve it, you\
    \ can always go to NecTAR\n<a href=\"https://support.nectar.org.au/support/home\"\
    >HelpDesk</a> to log a support ticket and the NeCTAR support staff are\nmore than\
    \ happy to help you.</p>\n<h2>Useful Links</h2>\n<p><a href=\"https://swiftstack.com/resources/data-sheets/#\"\
    >SwftStack Resources</a></p>"
  parent: 40
  sha1: 1429751e6be5381585de71a85215189648511d05
  title: More Info
73:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-09T00:35:39-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Best Practice - general rules to follow \n Command line API:\
          \ \n \n \n Look at the help page for the command before use \n \n \n Always\
          \ look at the output to learn what happened \n \n \n Always check your command\
          \ before you execute a command that changes the state\n of the storage such\
          \ as delete and update \n \n \n Keep your authentication credential secure\
          \ \n \n \n Python API: \n \n \n Use Python PEP-8 for code style guide \n\
          \ \n \n Use logging to record what has been done for later reference \n\
          \ \n \n Be cautious with code that updates the state of the object storage\
          \ \n \n \n Backup sensitive data \n \n \n Keep your authentication credential\
          \ secure \n \n \n Object Storage: \n \n \n Use Object Storage for static\
          \ files, as opposed to files that are frequently\n updated \n \n \n Have\
          \ a basic organization structure and separate your content into\n different\
          \ containers based on object type (for example): images, videos, etc.\n\
          \ This structure enables quick location of objects when you need them. \n\
          \ \n \n Use multiple containers if you have a large number of objects. \n\
          \ \n \n Always give your container a meaningful name for easy use. \n \n\
          \ \n If you have large number of files, it is recommend to keep a local\
          \ copy of the\n container structure and listing so that you are not waiting\
          \ on the container to\n list all the objects. This can be done by using\
          \ a database. \n \n \n Keep track of object count and usage and this should\
          \ improve performance\n when you need to frequently update the object storage.\
          \ \n \n \n Provide a virtual path for objects and this allows for better\
          \ subdivision of\n slow growth closely-grouped data. This also overcomes\
          \ the problem as Objects do\n not nest, and all objects in a single container\
          \ are subject to the same\n limitations. \n \n "
        description: "<h2>Best Practice - general rules to follow</h2>\n<p>Command\
          \ line API:</p>\n<ul>\n<li>\n<p>Look at the help page for the command before\
          \ use</p>\n</li>\n<li>\n<p>Always look at the output to learn what happened</p>\n\
          </li>\n<li>\n<p>Always check your command before you execute a command that\
          \ changes the state\n of the storage such as <code>delete</code> and <code>update</code></p>\n\
          </li>\n<li>\n<p>Keep your authentication credential secure</p>\n</li>\n\
          </ul>\n<p>Python API:</p>\n<ul>\n<li>\n<p>Use Python PEP-8 for code style\
          \ guide</p>\n</li>\n<li>\n<p>Use logging to record what has been done for\
          \ later reference</p>\n</li>\n<li>\n<p>Be cautious with code that updates\
          \ the state of the object storage</p>\n</li>\n<li>\n<p>Backup sensitive\
          \ data</p>\n</li>\n<li>\n<p>Keep your authentication credential secure</p>\n\
          </li>\n</ul>\n<p>Object Storage:</p>\n<ul>\n<li>\n<p>Use Object Storage\
          \ for static files, as opposed to files that are frequently\n updated</p>\n\
          </li>\n<li>\n<p>Have a basic organization structure and separate your content\
          \ into\n different containers based on object type (for example): images,\
          \ videos, etc.\n This structure enables quick location of objects when you\
          \ need them.</p>\n</li>\n<li>\n<p>Use multiple containers if you have a\
          \ large number of objects.</p>\n</li>\n<li>\n<p>Always give your container\
          \ a meaningful name for easy use.</p>\n</li>\n<li>\n<p>If you have large\
          \ number of files, it is recommend to keep a local copy of the\n container\
          \ structure and listing so that you are not waiting on the container to\n\
          \ list all the objects. This can be done by using a database.</p>\n</li>\n\
          <li>\n<p>Keep track of object count and usage and this should improve performance\n\
          \ when you need to frequently update the object storage.</p>\n</li>\n<li>\n\
          <p>Provide a virtual path for objects and this allows for better subdivision\
          \ of\n slow growth closely-grouped data. This also overcomes the problem\
          \ as Objects do\n not nest, and all objects in a single container are subject\
          \ to the same\n limitations.</p>\n</li>\n</ul>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:00-04:00'
          customer_folders: []
          description: Object Storage
          id: 6000190146
          is_default: false
          language_id: 6
          name: Object Storage
          parent_id: 6000190146
          position: 2
          updated_at: '2015-09-03T01:28:00-04:00'
          visibility: 1
        folder_id: 6000190146
        hits: 6
        id: 6000076113
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T19:53:47-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000076113
        position: 6
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Best Practice
        updated_at: '2015-11-01T19:53:47-05:00'
        user_id: 6002464727
  html: "<h2>Best Practice - general rules to follow</h2>\n<p>Command line API:</p>\n\
    <ul>\n<li>\n<p>Look at the help page for the command before use</p>\n</li>\n<li>\n\
    <p>Always look at the output to learn what happened</p>\n</li>\n<li>\n<p>Always\
    \ check your command before you execute a command that changes the state\n of\
    \ the storage such as <code>delete</code> and <code>update</code></p>\n</li>\n\
    <li>\n<p>Keep your authentication credential secure</p>\n</li>\n</ul>\n<p>Python\
    \ API:</p>\n<ul>\n<li>\n<p>Use Python PEP-8 for code style guide</p>\n</li>\n\
    <li>\n<p>Use logging to record what has been done for later reference</p>\n</li>\n\
    <li>\n<p>Be cautious with code that updates the state of the object storage</p>\n\
    </li>\n<li>\n<p>Backup sensitive data</p>\n</li>\n<li>\n<p>Keep your authentication\
    \ credential secure</p>\n</li>\n</ul>\n<p>Object Storage:</p>\n<ul>\n<li>\n<p>Use\
    \ Object Storage for static files, as opposed to files that are frequently\n updated</p>\n\
    </li>\n<li>\n<p>Have a basic organization structure and separate your content\
    \ into\n different containers based on object type (for example): images, videos,\
    \ etc.\n This structure enables quick location of objects when you need them.</p>\n\
    </li>\n<li>\n<p>Use multiple containers if you have a large number of objects.</p>\n\
    </li>\n<li>\n<p>Always give your container a meaningful name for easy use.</p>\n\
    </li>\n<li>\n<p>If you have large number of files, it is recommend to keep a local\
    \ copy of the\n container structure and listing so that you are not waiting on\
    \ the container to\n list all the objects. This can be done by using a database.</p>\n\
    </li>\n<li>\n<p>Keep track of object count and usage and this should improve performance\n\
    \ when you need to frequently update the object storage.</p>\n</li>\n<li>\n<p>Provide\
    \ a virtual path for objects and this allows for better subdivision of\n slow\
    \ growth closely-grouped data. This also overcomes the problem as Objects do\n\
    \ not nest, and all objects in a single container are subject to the same\n limitations.</p>\n\
    </li>\n</ul>"
  parent: 40
  sha1: 1015e0aca8a081cf30c5762985683eb2eb68b987
  title: Best Practice
74:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-14T07:10:16-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Getting Started \n This section is going to show you how to\
          \ use your AAF (Australian Access Federation) \ncredentials to authenticate\
          \ to NeCTAR Dashboard and use SSH to login to Virtual Machine. \n Dashboard\
          \ Authentication \n NeCTAR Dashboard uses AAF to authenticate users. Please\
          \ follow the below\ninstructions to login to NeCTAR Dashboard. \n \n Click\
          \ here to go to the NeCTAR Dashboard and you will see the\n following screen:\
          \ \n \n \n \n Click 'Log In' button, then select your AAF organisation from\
          \ the menu: \n \n \n \n You will be redirected to a login page provided\
          \ by your selected institution/organization: \n \n \n \n Type in username/password\
          \ supplied by your institution/organization and click\n 'Continue' button,\
          \ if successful, you should see the NeCTAR Dashboard \n \n Note, if your\
          \ institution or organization is not the list, you can contact the\nhelp\
          \ desk in your institution or organization to see whether there is AAF support.\n\
          Or you can contact NecTAR HelpDesk to arrange an alternative way to\nlogin.\
          \ \n Virtual Machine Authentication \n To create a key pair in NecTAR Cloud:\
          \ \n \n \n Login to NeCTAR Dashboard \n \n \n Select a project from the\
          \ project drop down list and click 'Access & Security',\n your screen should\
          \ look similar to the following screenshots, which have a list \n of existing\
          \ keys: \n \n \n \n \n \n You can click the 'Create Key Pair' button to\
          \ create a new key pair: \n \n \n \n \n After entering the key pair name\
          \ and clicking 'Create Key Pair', the system\n will ask you to save the\
          \ private key. You should download the private key and\n save it in a secure\
          \ place. \n \n \n You can also click the 'Import Key Pair' button to import\
          \ an existing public\n key, see the below screenshot: \n \n \n    \n \n\
          \ You can copy and paste the public key into the 'Public Key' text area\
          \ and give\n a key pair name. Then you click 'Import Key Pair' button to\
          \ upload the public key. \n \n This key pair can be used later when you\
          \ launch a new Virtual Machine for\nauthentication. Please see relevant\
          \ articles about how to use the key in launching\na new Virtual Machine.\
          \   \n Linux and MacOSX Authentication \n In Linux, you can use the following\
          \ command to login to the Virtual Machine: \n ssh -i private_key_file_name\
          \ ip_address  \n The 'private_key_file_name' is the private key you download\
          \ from the NeCTAR\nDashboard (you may also need to specify the path to the\
          \ key, if it is not in \nthe '~/.ssh/' directory). The ip_address for the\
          \ instance is found on the \n'Instances' tab of the NeCTAR dashboard. \n\
          \ Windows Authentication \n For Windows users, you need to use putty for\
          \ key based authentication\nto access Virtual Machines. Windows uses different\
          \ file format for the private\nkey You download from the NeCTAR Dashboard.\
          \ You can use puttygen for\nthe key conversion. \n After you download the\
          \ files from the above links, you can double click the\nputtygen.exe file\
          \ to launch puttygen and you should see the below screenshot: \n   \n Then\
          \ you can click 'Import Key' item from the 'Conversions' menu: \n   \n You\
          \ select the private key you saved before and click 'Ok'. \n You can then\
          \ click 'Export OpenSSH Key' from the 'Conversions'. Click 'yes' for not\n\
          saving key with a password and provide a file name for the key: \n \n Instructions\
          \ for how to login using the SSH key via putty: \n \n Double click 'putty.exe'\
          \ to launch putty: \n \n \n \n You can click 'Auth' under 'Connection' and\
          \ then click 'Browse' button to load\n the private key you generated from\
          \ above:  \n \n \n \n \n Click 'Section' and you can enter Virtual Machine\
          \ IP Adddress in the 'Host Name'\n text field \n \n \n Click 'Open' button\
          \ to login \n \n \n "
        description: "<h2>Getting Started</h2>\n<p>This section is going to show you\
          \ how to use your AAF (Australian Access Federation) \ncredentials to authenticate\
          \ to NeCTAR Dashboard and use SSH to login to Virtual Machine.</p>\n<h2>Dashboard\
          \ Authentication</h2>\n<p>NeCTAR Dashboard uses AAF to authenticate users.\
          \ Please follow the below\ninstructions to login to NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/\"\
          >Dashboard</a>.</p>\n<ul>\n<li>Click <a href=\"https://dashboard.rc.nectar.org.au/\"\
          >here</a> to go to the NeCTAR Dashboard and you will see the\n following\
          \ screen:</li>\n</ul>\n<p><img alt=\"aaf1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/aaf1.png?raw=true\"\
          ></p>\n<ul>\n<li>Click 'Log In' button, then select your AAF organisation\
          \ from the menu:</li>\n</ul>\n<p><img alt=\"aaf2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/aaf2.png?raw=true\"\
          ></p>\n<ul>\n<li>You will be redirected to a login page provided by your\
          \ selected institution/organization:</li>\n</ul>\n<p><img alt=\"aaf3\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/aaf3.png?raw=true\"\
          ></p>\n<ul>\n<li>Type in username/password supplied by your institution/organization\
          \ and click\n 'Continue' button, if successful, you should see the NeCTAR\
          \ Dashboard</li>\n</ul>\n<p>Note, if your institution or organization is\
          \ not the list, you can contact the\nhelp desk in your institution or organization\
          \ to see whether there is AAF support.\nOr you can contact NecTAR <a href=\"\
          https://support.nectar.org.au/support/home\">HelpDesk</a> to arrange an\
          \ alternative way to\nlogin.</p>\n<h2>Virtual Machine Authentication</h2>\n\
          <p>To create a key pair in NecTAR Cloud:</p>\n<ul>\n<li>\n<p>Login to NeCTAR\
          \ <a href=\"https://dashboard.rc.nectar.org.au/\">Dashboard</a></p>\n</li>\n\
          <li>\n<p>Select a project from the project drop down list and click 'Access\
          \ &amp; Security',\n your screen should look similar to the following screenshots,\
          \ which have a list \n of existing keys:</p>\n</li>\n</ul>\n<p><img alt=\"\
          key1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/key1.png?raw=true\"\
          >\n<img alt=\"key2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/key2.png?raw=true\"\
          ></p>\n<ul>\n<li>You can click the 'Create Key Pair' button to create a\
          \ new key pair:</li>\n</ul>\n<p><img alt=\"key3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/key3.png?raw=true\"\
          ></p>\n<ul>\n<li>\n<p>After entering the key pair name and clicking 'Create\
          \ Key Pair', the system\n will ask you to save the private key. You should\
          \ download the private key and\n save it in a secure place.</p>\n</li>\n\
          <li>\n<p>You can also click the 'Import Key Pair' button to import an existing\
          \ public\n key, see the below screenshot:</p>\n</li>\n</ul>\n<p><img alt=\"\
          key4\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/key4.png?raw=true\"\
          >  </p>\n<ul>\n<li>You can copy and paste the public key into the 'Public\
          \ Key' text area and give\n a key pair name. Then you click 'Import Key\
          \ Pair' button to upload the public key.</li>\n</ul>\n<p>This key pair can\
          \ be used later when you launch a new Virtual Machine for\nauthentication.\
          \ Please see relevant articles about how to use the key in launching\na\
          \ new Virtual Machine.  </p>\n<h3>Linux and MacOSX Authentication</h3>\n\
          <p>In Linux, you can use the following command to login to the Virtual Machine:</p>\n\
          <p><code>ssh -i private_key_file_name ip_address</code> </p>\n<p>The 'private_key_file_name'\
          \ is the private key you download from the NeCTAR\nDashboard (you may also\
          \ need to specify the path to the key, if it is not in \nthe '~/.ssh/' directory).\
          \ The ip_address for the instance is found on the \n'Instances' tab of the\
          \ <a href=\"https://dashboard.rc.nectar.org.au/\">NeCTAR dashboard</a>.</p>\n\
          <h3>Windows Authentication</h3>\n<p>For Windows users, you need to use <a\
          \ href=\"http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\"\
          >putty</a> for key based authentication\nto access Virtual Machines. Windows\
          \ uses different file format for the private\nkey You download from the\
          \ NeCTAR Dashboard. You can use <a href=\"http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\"\
          >puttygen</a> for\nthe key conversion.</p>\n<p>After you download the files\
          \ from the above links, you can double click the\nputtygen.exe file to launch\
          \ puttygen and you should see the below screenshot:</p>\n<p><img alt=\"\
          puttygen1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/puttygen1.png?raw=true\"\
          > </p>\n<p>Then you can click 'Import Key' item from the 'Conversions' menu:</p>\n\
          <p><img alt=\"puttygen2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/puttygen2.png?raw=true\"\
          > </p>\n<p>You select the private key you saved before and click 'Ok'.</p>\n\
          <p>You can then click 'Export OpenSSH Key' from the 'Conversions'. Click\
          \ 'yes' for not\nsaving key with a password and provide a file name for\
          \ the key:</p>\n<p><img alt=\"puttygen3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/puttygen3.png?raw=true\"\
          ></p>\n<p>Instructions for how to login using the SSH key via putty:</p>\n\
          <ul>\n<li>Double click 'putty.exe' to launch putty:</li>\n</ul>\n<p><img\
          \ alt=\"putty1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/putty1.png?raw=true\"\
          ></p>\n<ul>\n<li>You can click 'Auth' under 'Connection' and then click\
          \ 'Browse' button to load\n the private key you generated from above: </li>\n\
          </ul>\n<p><img alt=\"putty2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/putty2.png?raw=true\"\
          ></p>\n<ul>\n<li>\n<p>Click 'Section' and you can enter Virtual Machine\
          \ IP Adddress in the 'Host Name'\n text field</p>\n</li>\n<li>\n<p>Click\
          \ 'Open' button to login</p>\n</li>\n</ul>\n<p><img alt=\"putty3\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/putty3.png?raw=true\"\
          ></p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:01-04:00'
          customer_folders: []
          description: Authentication
          id: 6000190147
          is_default: false
          language_id: 6
          name: Authentication
          parent_id: 6000190147
          position: 3
          updated_at: '2015-09-03T01:28:01-04:00'
          visibility: 1
        folder_id: 6000190147
        hits: 4
        id: 6000077794
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-19T04:31:42-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000077794
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Getting Started
        updated_at: '2015-10-19T04:31:42-04:00'
        user_id: 6002464727
  html: "<h2>Getting Started</h2>\n<p>This section is going to show you how to use\
    \ your AAF (Australian Access Federation) \ncredentials to authenticate to NeCTAR\
    \ Dashboard and use SSH to login to Virtual Machine.</p>\n<h2>Dashboard Authentication</h2>\n\
    <p>NeCTAR Dashboard uses AAF to authenticate users. Please follow the below\n\
    instructions to login to NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >Dashboard</a>.</p>\n<ul>\n<li>Click <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >here</a> to go to the NeCTAR Dashboard and you will see the\n following screen:</li>\n\
    </ul>\n<p><img alt=\"aaf1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/aaf1.png?raw=true\"></p>\n<ul>\n\
    <li>Click 'Log In' button, then select your AAF organisation from the menu:</li>\n\
    </ul>\n<p><img alt=\"aaf2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/aaf2.png?raw=true\"></p>\n<ul>\n\
    <li>You will be redirected to a login page provided by your selected institution/organization:</li>\n\
    </ul>\n<p><img alt=\"aaf3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/aaf3.png?raw=true\"></p>\n<ul>\n\
    <li>Type in username/password supplied by your institution/organization and click\n\
    \ 'Continue' button, if successful, you should see the NeCTAR Dashboard</li>\n\
    </ul>\n<p>Note, if your institution or organization is not the list, you can contact\
    \ the\nhelp desk in your institution or organization to see whether there is AAF\
    \ support.\nOr you can contact NecTAR <a href=\"https://support.nectar.org.au/support/home\"\
    >HelpDesk</a> to arrange an alternative way to\nlogin.</p>\n<h2>Virtual Machine\
    \ Authentication</h2>\n<p>To create a key pair in NecTAR Cloud:</p>\n<ul>\n<li>\n\
    <p>Login to NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/\">Dashboard</a></p>\n\
    </li>\n<li>\n<p>Select a project from the project drop down list and click 'Access\
    \ &amp; Security',\n your screen should look similar to the following screenshots,\
    \ which have a list \n of existing keys:</p>\n</li>\n</ul>\n<p><img alt=\"key1\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/key1.png?raw=true\">\n<img alt=\"\
    key2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/key2.png?raw=true\"></p>\n<ul>\n\
    <li>You can click the 'Create Key Pair' button to create a new key pair:</li>\n\
    </ul>\n<p><img alt=\"key3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/key3.png?raw=true\"></p>\n<ul>\n\
    <li>\n<p>After entering the key pair name and clicking 'Create Key Pair', the\
    \ system\n will ask you to save the private key. You should download the private\
    \ key and\n save it in a secure place.</p>\n</li>\n<li>\n<p>You can also click\
    \ the 'Import Key Pair' button to import an existing public\n key, see the below\
    \ screenshot:</p>\n</li>\n</ul>\n<p><img alt=\"key4\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/key4.png?raw=true\">  </p>\n\
    <ul>\n<li>You can copy and paste the public key into the 'Public Key' text area\
    \ and give\n a key pair name. Then you click 'Import Key Pair' button to upload\
    \ the public key.</li>\n</ul>\n<p>This key pair can be used later when you launch\
    \ a new Virtual Machine for\nauthentication. Please see relevant articles about\
    \ how to use the key in launching\na new Virtual Machine.  </p>\n<h3>Linux and\
    \ MacOSX Authentication</h3>\n<p>In Linux, you can use the following command to\
    \ login to the Virtual Machine:</p>\n<p><code>ssh -i private_key_file_name ip_address</code>\
    \ </p>\n<p>The 'private_key_file_name' is the private key you download from the\
    \ NeCTAR\nDashboard (you may also need to specify the path to the key, if it is\
    \ not in \nthe '~/.ssh/' directory). The ip_address for the instance is found\
    \ on the \n'Instances' tab of the <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >NeCTAR dashboard</a>.</p>\n<h3>Windows Authentication</h3>\n<p>For Windows users,\
    \ you need to use <a href=\"http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\"\
    >putty</a> for key based authentication\nto access Virtual Machines. Windows uses\
    \ different file format for the private\nkey You download from the NeCTAR Dashboard.\
    \ You can use <a href=\"http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\"\
    >puttygen</a> for\nthe key conversion.</p>\n<p>After you download the files from\
    \ the above links, you can double click the\nputtygen.exe file to launch puttygen\
    \ and you should see the below screenshot:</p>\n<p><img alt=\"puttygen1\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/puttygen1.png?raw=true\"> </p>\n\
    <p>Then you can click 'Import Key' item from the 'Conversions' menu:</p>\n<p><img\
    \ alt=\"puttygen2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/puttygen2.png?raw=true\"> </p>\n\
    <p>You select the private key you saved before and click 'Ok'.</p>\n<p>You can\
    \ then click 'Export OpenSSH Key' from the 'Conversions'. Click 'yes' for not\n\
    saving key with a password and provide a file name for the key:</p>\n<p><img alt=\"\
    puttygen3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/puttygen3.png?raw=true\"></p>\n\
    <p>Instructions for how to login using the SSH key via putty:</p>\n<ul>\n<li>Double\
    \ click 'putty.exe' to launch putty:</li>\n</ul>\n<p><img alt=\"putty1\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/putty1.png?raw=true\"></p>\n\
    <ul>\n<li>You can click 'Auth' under 'Connection' and then click 'Browse' button\
    \ to load\n the private key you generated from above: </li>\n</ul>\n<p><img alt=\"\
    putty2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/putty2.png?raw=true\"></p>\n\
    <ul>\n<li>\n<p>Click 'Section' and you can enter Virtual Machine IP Adddress in\
    \ the 'Host Name'\n text field</p>\n</li>\n<li>\n<p>Click 'Open' button to login</p>\n\
    </li>\n</ul>\n<p><img alt=\"putty3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/putty3.png?raw=true\"></p>"
  parent: 41
  sha1: 8bf0cd6f62150c2ac27a0abe5d967b52cb893020
  title: Getting Started
75:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-14T07:10:34-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Introduction to Authentication \n Authentication is the process\
          \ of verifying the identify of a user that is requesting\nto access a computer\
          \ system. In the context of NeCTAR Cloud, the identities of\nusers or host\
          \ computers must be established before accessing the Cloud resources\nsuch\
          \ as Dashboard, APIs, Virtual Machines, etc. \n Methods of Authentication\
          \ \n The NecTAR Cloud uses three basic types of authentication for users\
          \ to access\nthe Cloud: single sign on authentication (AAF), SSH based authentication\n\
          for virtual machines and token based authentication for APIs. \n Single\
          \ Sign on Authentication \n Single sign on authentication is the process\
          \ that gives users the ability to access\ndistributed multiple protected\
          \ computer system with a single authentication.\nNeCTAR Cloud uses Australian\
          \ Access Federation (AAF) as the single sign on\nauthentication solution\
          \ for access of the Dashboard. The AAF provides the ability\nfor users to\
          \ log into a number of eResearch services including NeCTAR Cloud using\n\
          the same username and password you would usually use when logging into your\n\
          institution's or organization's computer system. The authentications involves\n\
          2 steps, select your institution or organization and provide your username/password.\n\
          To get more information about AAF, you can visit their website at\nhttp://aaf.edu.au.\
          \ \n SSH Based Authentication \n SSH (Secure SHell) based authentication\
          \ is an alternative way to identify\nyourself to a computer service, rather\
          \ than typing a username and password. It\nis more secure and flexible,\
          \ but more difficult to set up. \n You generate a key pair, consisting of\
          \ public key and a private key. The private\nkey can generate an unique\
          \ signature and only the relevant public key can\nverify if the signature\
          \ is genuine. \n After generating a key pair, you copy the public the key\
          \ to the Virtual Machine.\nThen, when the Virtual Machines asks you to prove\
          \ who you are, you use\nthe private key to sign a message and the Virtual\
          \ Machine can verify the\nsignature and allow you to log in. Even if the\
          \ Virtual Machine is hacked and\nyour public key is stolen, the public key\
          \ cannot be used to do authentication\nand you are still safe. \n By default,\
          \ virtual machines in NeCTAR Cloud uses this authentication method and\n\
          it requires you to generate a public/private key pairs before you can login.\
          \ \n Token based authentication \n NeCTAR Cloud APIs use Token based authentication.\
          \ The token is temporary and\nshort lived, which means it is safer to cache\
          \ them than username/password pairs. \n A token is a piece of data given\
          \ to a user by the Cloud after a valid username/password\npair has been\
          \ provided. The token also has an associated expiration date to indicate\n\
          its validation. Then, the user can use this token in the API request and\
          \ the token\nis validated on the API end point. "
        description: '<h2>Introduction to Authentication</h2>

          <p>Authentication is the process of verifying the identify of a user that
          is requesting

          to access a computer system. In the context of NeCTAR Cloud, the identities
          of

          users or host computers must be established before accessing the Cloud resources

          such as Dashboard, APIs, Virtual Machines, etc.</p>

          <h2>Methods of Authentication</h2>

          <p>The NecTAR Cloud uses three basic types of authentication for users to
          access

          the Cloud: single sign on authentication (AAF), SSH based authentication

          for virtual machines and token based authentication for APIs.</p>

          <h3>Single Sign on Authentication</h3>

          <p>Single sign on authentication is the process that gives users the ability
          to access

          distributed multiple protected computer system with a single authentication.

          NeCTAR Cloud uses Australian Access Federation (AAF) as the single sign
          on

          authentication solution for access of the Dashboard. The AAF provides the
          ability

          for users to log into a number of eResearch services including NeCTAR Cloud
          using

          the same username and password you would usually use when logging into your

          institution''s or organization''s computer system. The authentications involves

          2 steps, select your institution or organization and provide your username/password.

          To get more information about AAF, you can visit their website at

          <a href="http://aaf.edu.au/">http://aaf.edu.au</a>.</p>

          <h3>SSH Based Authentication</h3>

          <p>SSH (Secure SHell) based authentication is an alternative way to identify

          yourself to a computer service, rather than typing a username and password.
          It

          is more secure and flexible, but more difficult to set up.</p>

          <p>You generate a key pair, consisting of public key and a private key.
          The private

          key can generate an unique signature and only the relevant public key can

          verify if the signature is genuine.</p>

          <p>After generating a key pair, you copy the public the key to the Virtual
          Machine.

          Then, when the Virtual Machines asks you to prove who you are, you use

          the private key to sign a message and the Virtual Machine can verify the

          signature and allow you to log in. Even if the Virtual Machine is hacked
          and

          your public key is stolen, the public key cannot be used to do authentication

          and you are still safe.</p>

          <p>By default, virtual machines in NeCTAR Cloud uses this authentication
          method and

          it requires you to generate a public/private key pairs before you can login.</p>

          <h3>Token based authentication</h3>

          <p>NeCTAR Cloud APIs use Token based authentication. The token is temporary
          and

          short lived, which means it is safer to cache them than username/password
          pairs.</p>

          <p>A token is a piece of data given to a user by the Cloud after a valid
          username/password

          pair has been provided. The token also has an associated expiration date
          to indicate

          its validation. Then, the user can use this token in the API request and
          the token

          is validated on the API end point.</p>'
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:01-04:00'
          customer_folders: []
          description: Authentication
          id: 6000190147
          is_default: false
          language_id: 6
          name: Authentication
          parent_id: 6000190147
          position: 3
          updated_at: '2015-09-03T01:28:01-04:00'
          visibility: 1
        folder_id: 6000190147
        hits: 3
        id: 6000077795
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-21T20:00:22-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000077795
        position: 1
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Introduction to Authentication
        updated_at: '2015-10-21T20:00:22-04:00'
        user_id: 6002464727
  html: '<h2>Introduction to Authentication</h2>

    <p>Authentication is the process of verifying the identify of a user that is requesting

    to access a computer system. In the context of NeCTAR Cloud, the identities of

    users or host computers must be established before accessing the Cloud resources

    such as Dashboard, APIs, Virtual Machines, etc.</p>

    <h2>Methods of Authentication</h2>

    <p>The NecTAR Cloud uses three basic types of authentication for users to access

    the Cloud: single sign on authentication (AAF), SSH based authentication

    for virtual machines and token based authentication for APIs.</p>

    <h3>Single Sign on Authentication</h3>

    <p>Single sign on authentication is the process that gives users the ability to
    access

    distributed multiple protected computer system with a single authentication.

    NeCTAR Cloud uses Australian Access Federation (AAF) as the single sign on

    authentication solution for access of the Dashboard. The AAF provides the ability

    for users to log into a number of eResearch services including NeCTAR Cloud using

    the same username and password you would usually use when logging into your

    institution''s or organization''s computer system. The authentications involves

    2 steps, select your institution or organization and provide your username/password.

    To get more information about AAF, you can visit their website at

    <a href="http://aaf.edu.au/">http://aaf.edu.au</a>.</p>

    <h3>SSH Based Authentication</h3>

    <p>SSH (Secure SHell) based authentication is an alternative way to identify

    yourself to a computer service, rather than typing a username and password. It

    is more secure and flexible, but more difficult to set up.</p>

    <p>You generate a key pair, consisting of public key and a private key. The private

    key can generate an unique signature and only the relevant public key can

    verify if the signature is genuine.</p>

    <p>After generating a key pair, you copy the public the key to the Virtual Machine.

    Then, when the Virtual Machines asks you to prove who you are, you use

    the private key to sign a message and the Virtual Machine can verify the

    signature and allow you to log in. Even if the Virtual Machine is hacked and

    your public key is stolen, the public key cannot be used to do authentication

    and you are still safe.</p>

    <p>By default, virtual machines in NeCTAR Cloud uses this authentication method
    and

    it requires you to generate a public/private key pairs before you can login.</p>

    <h3>Token based authentication</h3>

    <p>NeCTAR Cloud APIs use Token based authentication. The token is temporary and

    short lived, which means it is safer to cache them than username/password pairs.</p>

    <p>A token is a piece of data given to a user by the Cloud after a valid username/password

    pair has been provided. The token also has an associated expiration date to indicate

    its validation. Then, the user can use this token in the API request and the token

    is validated on the API end point.</p>'
  parent: 41
  sha1: 0625128a66318e3b7dc0886b244435ce2a03c6c8
  title: Introduction to Authentication
76:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-14T07:17:45-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Videos \n The following videos provides useful information\
          \ about NeCTAR Cloud security: \n \n \n Security on Openstack \n \n \n Building\
          \ an OpenStack Security Group \n \n \n State of OpenStack Security \n \n\
          \ \n Documentation \n The following documentations provides reference and\
          \ guidance information for\nLinux security: \n \n \n A guide to securing\
          \ red hat enterprise linux 7 \n \n \n Securing debian manual \n \n \n OpenStack\
          \ security guide \n \n \n NeCTAR Support \n If you have a problem and you\
          \ cannot resolve it, you can always go to NecTAR\nHelpDesk to log a support\
          \ ticket and the NeCTAR support staff are\nmore than happy to help you. "
        description: '<h2>Videos</h2>

          <p>The following videos provides useful information about NeCTAR Cloud security:</p>

          <ul>

          <li>

          <p><a href="https://www.youtube.com/watch?v=rI0XLWjEqPc">Security on Openstack</a></p>

          </li>

          <li>

          <p><a href="https://www.youtube.com/watch?v=5zT4RfOfrJg">Building an OpenStack
          Security Group</a></p>

          </li>

          <li>

          <p><a href="https://www.youtube.com/watch?v=tYfa7GnSwz8">State of OpenStack
          Security</a></p>

          </li>

          </ul>

          <h2>Documentation</h2>

          <p>The following documentations provides reference and guidance information
          for

          Linux security:</p>

          <ul>

          <li>

          <p><a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7-Beta/html/Security_Guide/index.html">A
          guide to securing red hat enterprise linux 7</a></p>

          </li>

          <li>

          <p><a href="https://www.debian.org/doc/manuals/securing-debian-howto/">Securing
          debian manual</a></p>

          </li>

          <li>

          <p><a href="http://docs.openstack.org/security-guide/">OpenStack security
          guide</a></p>

          </li>

          </ul>

          <h2>NeCTAR Support</h2>

          <p>If you have a problem and you cannot resolve it, you can always go to
          NecTAR

          <a href="https://support.nectar.org.au/support/home">HelpDesk</a> to log
          a support ticket and the NeCTAR support staff are

          more than happy to help you.</p>'
        folder:
          category_id: 6000122279
          created_at: '2015-10-01T22:28:23-04:00'
          customer_folders: []
          description: Security Guidelines
          id: 6000203455
          is_default: false
          language_id: 6
          name: Security Guidelines
          parent_id: 6000203455
          position: 6
          updated_at: '2015-10-01T22:28:23-04:00'
          visibility: 1
        folder_id: 6000203455
        hits: 0
        id: 6000077797
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-14T07:17:45-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000077797
        position: 3
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: More Info
        updated_at: '2015-10-14T07:17:45-04:00'
        user_id: 6002464727
  html: '<h2>Videos</h2>

    <p>The following videos provides useful information about NeCTAR Cloud security:</p>

    <ul>

    <li>

    <p><a href="https://www.youtube.com/watch?v=rI0XLWjEqPc">Security on Openstack</a></p>

    </li>

    <li>

    <p><a href="https://www.youtube.com/watch?v=5zT4RfOfrJg">Building an OpenStack
    Security Group</a></p>

    </li>

    <li>

    <p><a href="https://www.youtube.com/watch?v=tYfa7GnSwz8">State of OpenStack Security</a></p>

    </li>

    </ul>

    <h2>Documentation</h2>

    <p>The following documentations provides reference and guidance information for

    Linux security:</p>

    <ul>

    <li>

    <p><a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7-Beta/html/Security_Guide/index.html">A
    guide to securing red hat enterprise linux 7</a></p>

    </li>

    <li>

    <p><a href="https://www.debian.org/doc/manuals/securing-debian-howto/">Securing
    debian manual</a></p>

    </li>

    <li>

    <p><a href="http://docs.openstack.org/security-guide/">OpenStack security guide</a></p>

    </li>

    </ul>

    <h2>NeCTAR Support</h2>

    <p>If you have a problem and you cannot resolve it, you can always go to NecTAR

    <a href="https://support.nectar.org.au/support/home">HelpDesk</a> to log a support
    ticket and the NeCTAR support staff are

    more than happy to help you.</p>'
  parent: 43
  sha1: ac55360179d9e08115e5cd9e597d4d52bd9add95
  title: More Info
77:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-14T07:19:28-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Security Assessment \n After you have applied all your security\
          \ steps, you can use some tools to test\nwhether there are still potential\
          \ security risks within the system. Listed below\nis some basic information\
          \ about how to use some of the common tools. You will \nfind there are more\
          \ tools available to perform security assessments. \n System log files \n\
          \ Linux systems come with log files to record all system activities under\
          \ '/var/log'.\nYou can examine the 'auth.log' file to check SSH logins,\
          \ and examine the 'syslog' file \nfor any system wide activities.  \n OpenVAS\
          \ \n Open Vulnerability Assessment System (OpenVAS) is a set of tools and\
          \ services\nthat can be used to scan for vulnerabilities and vulnerability\
          \ management.\nOpenVAS uses a security scanner that makes use of over 33\
          \ thousand daily-updated\ntests to conduct the security test. You can download\
          \ and install the software from\nits website and also if you want to learn\
          \ more about it, you can look\nat its documentation link. \n Nmap \n Nmap\
          \ is a tool that you can use to determine the layout of a network and it\
          \ is\nvery useful to collect information about the system for security use.\
          \ You can run man nmap\nto get more detailed descriptions of its options\
          \ and usage.\nYou can also find out open ports on the system and to check\
          \ whether any ports\nhave potential security risks. It is a good starting\
          \ point for making a security\npolicy and restricting unused services. \n\
          \ To install Nmap, run the yum install nmap or apt-get install nmap\ncommand\
          \ as the root user. \n To scan a host, you can use nmap <hostname> \n The\
          \ results return a list ports of listening or waiting services, and this\
          \ can\nhelp to close unnecessary or unused services.  \n To find out more\
          \ information, you can see the official homepage at the following\nURL:\
          \ http://www.insecure.org/ "
        description: "<h2>Security Assessment</h2>\n<p>After you have applied all\
          \ your security steps, you can use some tools to test\nwhether there are\
          \ still potential security risks within the system. Listed below\nis some\
          \ basic information about how to use some of the common tools. You will\
          \ \nfind there are more tools available to perform security assessments.</p>\n\
          <h2>System log files</h2>\n<p>Linux systems come with log files to record\
          \ all system activities under '/var/log'.\nYou can examine the 'auth.log'\
          \ file to check SSH logins, and examine the 'syslog' file \nfor any system\
          \ wide activities. </p>\n<h2>OpenVAS</h2>\n<p>Open Vulnerability Assessment\
          \ System (OpenVAS) is a set of tools and services\nthat can be used to scan\
          \ for vulnerabilities and vulnerability management.\nOpenVAS uses a security\
          \ scanner that makes use of over 33 thousand daily-updated\ntests to conduct\
          \ the security test. You can download and install the software from\nits\
          \ <a href=\"http://www.openvas.org/\">website</a> and also if you want to\
          \ learn more about it, you can look\nat its documentation <a href=\"http://docs.greenbone.net/index.html#user_documentation\"\
          >link</a>.</p>\n<h2>Nmap</h2>\n<p>Nmap is a tool that you can use to determine\
          \ the layout of a network and it is\nvery useful to collect information\
          \ about the system for security use. You can run <code>man nmap</code>\n\
          to get more detailed descriptions of its options and usage.\nYou can also\
          \ find out open ports on the system and to check whether any ports\nhave\
          \ potential security risks. It is a good starting point for making a security\n\
          policy and restricting unused services.</p>\n<p>To install Nmap, run the\
          \ <code>yum install nmap</code> or <code>apt-get install nmap</code>\ncommand\
          \ as the root user.</p>\n<p>To scan a host, you can use <code>nmap &lt;hostname&gt;</code></p>\n\
          <p>The results return a list ports of listening or waiting services, and\
          \ this can\nhelp to close unnecessary or unused services. </p>\n<p>To find\
          \ out more information, you can see the official homepage at the following\n\
          URL: <a href=\"http://www.insecure.org/\">http://www.insecure.org/</a></p>"
        folder:
          category_id: 6000122279
          created_at: '2015-10-01T22:28:23-04:00'
          customer_folders: []
          description: Security Guidelines
          id: 6000203455
          is_default: false
          language_id: 6
          name: Security Guidelines
          parent_id: 6000203455
          position: 5
          updated_at: '2015-10-01T22:28:23-04:00'
          visibility: 1
        folder_id: 6000203455
        hits: 1
        id: 6000077798
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-20T21:03:16-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000077798
        position: 4
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Security Assessment
        updated_at: '2015-10-20T21:03:16-04:00'
        user_id: 6002464727
  html: "<h2>Security Assessment</h2>\n<p>After you have applied all your security\
    \ steps, you can use some tools to test\nwhether there are still potential security\
    \ risks within the system. Listed below\nis some basic information about how to\
    \ use some of the common tools. You will \nfind there are more tools available\
    \ to perform security assessments.</p>\n<h2>System log files</h2>\n<p>Linux systems\
    \ come with log files to record all system activities under '/var/log'.\nYou can\
    \ examine the 'auth.log' file to check SSH logins, and examine the 'syslog' file\
    \ \nfor any system wide activities. </p>\n<h2>OpenVAS</h2>\n<p>Open Vulnerability\
    \ Assessment System (OpenVAS) is a set of tools and services\nthat can be used\
    \ to scan for vulnerabilities and vulnerability management.\nOpenVAS uses a security\
    \ scanner that makes use of over 33 thousand daily-updated\ntests to conduct the\
    \ security test. You can download and install the software from\nits <a href=\"\
    http://www.openvas.org/\">website</a> and also if you want to learn more about\
    \ it, you can look\nat its documentation <a href=\"http://docs.greenbone.net/index.html#user_documentation\"\
    >link</a>.</p>\n<h2>Nmap</h2>\n<p>Nmap is a tool that you can use to determine\
    \ the layout of a network and it is\nvery useful to collect information about\
    \ the system for security use. You can run <code>man nmap</code>\nto get more\
    \ detailed descriptions of its options and usage.\nYou can also find out open\
    \ ports on the system and to check whether any ports\nhave potential security\
    \ risks. It is a good starting point for making a security\npolicy and restricting\
    \ unused services.</p>\n<p>To install Nmap, run the <code>yum install nmap</code>\
    \ or <code>apt-get install nmap</code>\ncommand as the root user.</p>\n<p>To scan\
    \ a host, you can use <code>nmap &lt;hostname&gt;</code></p>\n<p>The results return\
    \ a list ports of listening or waiting services, and this can\nhelp to close unnecessary\
    \ or unused services. </p>\n<p>To find out more information, you can see the official\
    \ homepage at the following\nURL: <a href=\"http://www.insecure.org/\">http://www.insecure.org/</a></p>"
  parent: 43
  sha1: 63c25723ed3e8e74971a1f4a7b9b7c4a15faca4e
  title: Security Assessment
78:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-14T07:19:43-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Security API \n The NeCTAR Cloud doesn't provide a specific\
          \ API for security purposes. The only\nsecurity relevant operation is to\
          \ manage security groups through the Nova API.\nIf you want to know the\
          \ Nova API, You can find the related information from the\narticles in the\
          \ 'Instance Management' section. \n This article describes some techniques\
          \ to help you to secure a Linux based\nvirtual machine in the NeCTAR cloud.\
          \ \n As security is a very broad topic, the techniques showed here only\
          \ provides a\nbasic introduction. You can always go to Internet and find\
          \ more useful information\nabout security. \n The instructions below assume\
          \ your operating system is debian/ubuntu. \n Securing SSH \n You need to\
          \ encourage all the users on your system to use SSH certificate\nauthentication\
          \ and disable password login. In addition, you need to avoid logging\ninto\
          \ the system using SSH as root and use alternative methods to become root,\n\
          such as su or sudo. \n To change the SSH configuration, you can edit the\
          \ configuration file on the virtual\nmachine, in '/etc/ssh/sshd_config'.\
          \ \n A basic description of some important configuration items: \n \n \n\
          \ PermitRootLogin no \n You need to set this to 'no' to avoid root access\
          \ via SSH \n \n \n Port 22 \n For better security, you can change the SSH\
          \ port to other port number \n \n \n PermitEmptyPasswords no \n  This should\
          \ be always 'no', for non-empty password access \n \n \n AllowUsers \n \
          \ This directive allows only certain users to have access via SSH to this\
          \ machine. \n \n \n PasswordAuthentication no \n  You should set this to\
          \ 'no' to disable user loggin using password \n \n \n After you have changed\
          \ the '/etc/ssh/sshd_config file', you can execute sudo service ssh restart\n\
          to apply the new changes. \n If you are using an SSH client to access your\
          \ Virtual Machine, you need to make\nsure both SSH server and client are\
          \ using the same version of protocols. \n You can also restrict access to\
          \ file transfer only if you want to allow accounts\non your Virtual Machine\
          \ to transfer files. You can do it by giving users a\nrestricted shell such\
          \ as scpoly or rssh. These shells restrict the commands\navailable to the\
          \ users to execute. You can change an account's shell by editing\n'/etc/passwd'\
          \ file. \n Securing Apache \n If you don't want your Apache web service\
          \ available to public, you can use the\nListen or BindAddress directives\
          \ in '/etc/apache2/apache2.conf'. \n Using Listen:\n    Listen 127.0.0.1:80\n\
          Using BindAddress:\n    BindAddress 127.0.0.1 \n Then you can restart your\
          \ apache service with sudo service apache2 restart \n The default Apache\
          \ installation in Debian permits users to publish content\nunder the '$HOME/public_html'.\
          \ This content can be retrieved remotely using an\nURL such as: http://your_apache_server/~user.\
          \ \n You can restrict the default configuration by editing '/etc/apache2/mods-enabled/userdir.conf'\
          \ \n You can also make sure the permission of log files can only be read/write\
          \ by the\nrequired user and groups. The default permission for the log files\
          \ may be readable\nby anyone. \n By default, Apache web files are located\
          \ under /'var/www'. The default file provides\nsome hints on the system\
          \ like what is the operating system. You should substitute\nthe default\
          \ web pages with your own. \n To further strengthen the Apache security,\
          \ you can run Apache by chroot. See this\ninstruction to set up Apache.\
          \ \n Keep System Update to Date \n In debian/ubuntu, you run sudo apt-get\
          \ update regularly to keep system\nsecurity patch update to date. \n Setup\
          \ Local Firewall \n A local firewall can also be installed with filtering\
          \ rules to protect access to\nthe system. You can use IPtable tools to create\
          \ rules to filter network traffic.\nIt is advised to use Security Group\
          \ to manage which ports to open as it is simple\nto do. The below only provides\
          \ basic introduction to IPtables, for more\ninformation, please refer to\
          \ IPtables MAN page. \n To list all current rules, execute:  sudo iptables\
          \ --list \n By default, the IPtables defines 3 chains. The INPUT Chain is\
          \ for incoming traffic\n, the Forward Chain is for forwarded traffic and\
          \ the OUTPUT Chain is for outgoing\ntraffic. Which chains you need to add\
          \ rules depends on what traffic you want to\nfilter. \n IPtables also defines\
          \ policies that defines actions for rules: \n \n \n Accept, accept traffic\
          \ \n \n \n Reject, reject traffic by sending back an error packet \n \n\
          \ \n Drop, reject traffic by dropping traffic \n \n \n The below shows an\
          \ example how to enable SSH and HTTP/HTTPS traffic in IPtables. \n Firstly,\
          \ you need to allow connections that are already connected to your server:\
          \ \n sudo iptables - I INPUT 1 -p tcp --dport 22 -j ACCEPT \n Secondly,\
          \ you need to allow SSH connections: \n sudo iptables -I INPUT 1 -p tcp\
          \ --dport 22 -j ACCEPT \n Thirdly, you can allow HTTP/HTTPS traffic: \n\
          \ sudo iptables -I INPUT 1 -p tcp -dport 80 -j ACCEPT\nsudo iptables -I\
          \ INPUT 1 -p tcp --dport 443 -j ACCEPT \n Finally, you need to drop all\
          \ other traffic. You need to make sure you have set\nto allow SSH connection,\
          \ otherwise you will lose access to the Virtual Machine: \n sudo iptables\
          \ -P INPUT DROP \n You can save your IPtables changes by (Ubuntu):  \n iptables-save\
          \ > /etc/iptables.rules \n Install fail2ban \n The SSH daemon itself is\
          \ a Linux service that exposed to the Internet and creates\na security risk\
          \ for the system. fail2ban can mitigate this problem by creating\nrules\
          \ that can automatically alter your your IPtables firewall and ban\nunsuccessful\
          \ login attempts based on a predefined number.  \n You can use the below\
          \ commands to install fail2ban in Ubuntu: \n sudo apt-get update\nsudo apt-get\
          \ install fail2ban \n To setup the fail2ban, please follow this instruction.\
          \ \n Disable Unneeded Services \n Unneeded services are a potential security\
          \ risk, so you can execute sudo service --status-all\nto list all available\
          \ services.  You can examine the output carefully and disable\nany services\
          \ not desired. "
        description: "<h2>Security API</h2>\n<p>The NeCTAR Cloud doesn't provide a\
          \ specific API for security purposes. The only\nsecurity relevant operation\
          \ is to manage security groups through the Nova API.\nIf you want to know\
          \ the Nova API, You can find the related information from the\narticles\
          \ in the 'Instance Management' section.</p>\n<p>This article describes some\
          \ techniques to help you to secure a Linux based\nvirtual machine in the\
          \ NeCTAR cloud.</p>\n<p>As security is a very broad topic, the techniques\
          \ showed here only provides a\nbasic introduction. You can always go to\
          \ Internet and find more useful information\nabout security.</p>\n<p>The\
          \ instructions below assume your operating system is debian/ubuntu.</p>\n\
          <h2>Securing SSH</h2>\n<p>You need to encourage all the users on your system\
          \ to use SSH certificate\nauthentication and disable password login. In\
          \ addition, you need to avoid logging\ninto the system using SSH as root\
          \ and use alternative methods to become root,\nsuch as su or sudo.</p>\n\
          <p>To change the SSH configuration, you can edit the configuration file\
          \ on the virtual\nmachine, in '/etc/ssh/sshd_config'.</p>\n<p>A basic description\
          \ of some important configuration items:</p>\n<ul>\n<li>\n<p><strong>PermitRootLogin</strong>\
          \ <strong><em>no</em></strong><br>\n You need to set this to 'no' to avoid\
          \ root access via SSH</p>\n</li>\n<li>\n<p><strong>Port 22</strong><br>\n\
          \ For better security, you can change the SSH port to other port number</p>\n\
          </li>\n<li>\n<p><strong>PermitEmptyPasswords</strong> <strong><em>no</em></strong><br>\n\
          \  This should be always 'no', for non-empty password access</p>\n</li>\n\
          <li>\n<p><strong>AllowUsers</strong><br>\n  This directive allows only certain\
          \ users to have access via SSH to this machine.</p>\n</li>\n<li>\n<p><strong>PasswordAuthentication</strong>\
          \ <strong><em>no</em></strong><br>\n  You should set this to 'no' to disable\
          \ user loggin using password</p>\n</li>\n</ul>\n<p>After you have changed\
          \ the '/etc/ssh/sshd_config file', you can execute <code>sudo service ssh\
          \ restart</code>\nto apply the new changes.</p>\n<p>If you are using an\
          \ SSH client to access your Virtual Machine, you need to make\nsure both\
          \ SSH server and client are using the same version of protocols.</p>\n<p>You\
          \ can also restrict access to file transfer only if you want to allow accounts\n\
          on your Virtual Machine to transfer files. You can do it by giving users\
          \ a\nrestricted shell such as scpoly or rssh. These shells restrict the\
          \ commands\navailable to the users to execute. You can change an account's\
          \ shell by editing\n'/etc/passwd' file.</p>\n<h2>Securing Apache</h2>\n\
          <p>If you don't want your Apache web service available to public, you can\
          \ use the\nListen or BindAddress directives in '/etc/apache2/apache2.conf'.</p>\n\
          <p>Using Listen:\n    Listen 127.0.0.1:80\nUsing BindAddress:\n    BindAddress\
          \ 127.0.0.1</p>\n<p>Then you can restart your apache service with <code>sudo\
          \ service apache2 restart</code></p>\n<p>The default Apache installation\
          \ in Debian permits users to publish content\nunder the '$HOME/public_html'.\
          \ This content can be retrieved remotely using an\nURL such as: http://your_apache_server/~user.</p>\n\
          <p>You can restrict the default configuration by editing '/etc/apache2/mods-enabled/userdir.conf'</p>\n\
          <p>You can also make sure the permission of log files can only be read/write\
          \ by the\nrequired user and groups. The default permission for the log files\
          \ may be readable\nby anyone.</p>\n<p>By default, Apache web files are located\
          \ under /'var/www'. The default file provides\nsome hints on the system\
          \ like what is the operating system. You should substitute\nthe default\
          \ web pages with your own.</p>\n<p>To further strengthen the Apache security,\
          \ you can run Apache by chroot. See this\n<a href=\"https://www.debian.org/doc/manuals/securing-debian-howto/ap-chroot-apache-env.en.html\"\
          >instruction</a> to set up Apache.</p>\n<h2>Keep System Update to Date</h2>\n\
          <p>In debian/ubuntu, you run <code>sudo apt-get update</code> regularly\
          \ to keep system\nsecurity patch update to date.</p>\n<h2>Setup Local Firewall</h2>\n\
          <p>A local firewall can also be installed with filtering rules to protect\
          \ access to\nthe system. You can use IPtable tools to create rules to filter\
          \ network traffic.\nIt is advised to use Security Group to manage which\
          \ ports to open as it is simple\nto do. The below only provides basic introduction\
          \ to IPtables, for more\ninformation, please refer to IPtables <a href=\"\
          http://linux.die.net/man/8/iptables\">MAN page</a>.</p>\n<p>To list all\
          \ current rules, execute:  <code>sudo iptables --list</code></p>\n<p>By\
          \ default, the IPtables defines 3 chains. The INPUT Chain is for incoming\
          \ traffic\n, the Forward Chain is for forwarded traffic and the OUTPUT Chain\
          \ is for outgoing\ntraffic. Which chains you need to add rules depends on\
          \ what traffic you want to\nfilter.</p>\n<p>IPtables also defines policies\
          \ that defines actions for rules:</p>\n<ul>\n<li>\n<p><strong>Accept</strong>,\
          \ accept traffic</p>\n</li>\n<li>\n<p><strong>Reject</strong>, reject traffic\
          \ by sending back an error packet</p>\n</li>\n<li>\n<p><strong>Drop</strong>,\
          \ reject traffic by dropping traffic</p>\n</li>\n</ul>\n<p>The below shows\
          \ an example how to enable SSH and HTTP/HTTPS traffic in IPtables.</p>\n\
          <p>Firstly, you need to allow connections that are already connected to\
          \ your server:</p>\n<p><code>sudo iptables - I INPUT 1 -p tcp --dport 22\
          \ -j ACCEPT</code></p>\n<p>Secondly, you need to allow SSH connections:</p>\n\
          <p><code>sudo iptables -I INPUT 1 -p tcp --dport 22 -j ACCEPT</code></p>\n\
          <p>Thirdly, you can allow HTTP/HTTPS traffic:</p>\n<p><code>sudo iptables\
          \ -I INPUT 1 -p tcp -dport 80 -j ACCEPT</code>\n<code>sudo iptables -I INPUT\
          \ 1 -p tcp --dport 443 -j ACCEPT</code></p>\n<p>Finally, you need to drop\
          \ all other traffic. You need to make sure you have set\nto allow SSH connection,\
          \ otherwise you will lose access to the Virtual Machine:</p>\n<p><code>sudo\
          \ iptables -P INPUT DROP</code></p>\n<p>You can save your IPtables changes\
          \ by (Ubuntu): </p>\n<p><code>iptables-save &gt; /etc/iptables.rules</code></p>\n\
          <h2>Install fail2ban</h2>\n<p>The SSH daemon itself is a Linux service that\
          \ exposed to the Internet and creates\na security risk for the system. fail2ban\
          \ can mitigate this problem by creating\nrules that can automatically alter\
          \ your your IPtables firewall and ban\nunsuccessful login attempts based\
          \ on a predefined number. </p>\n<p>You can use the below commands to install\
          \ fail2ban in Ubuntu:</p>\n<p><code>sudo apt-get update</code>\n<code>sudo\
          \ apt-get install fail2ban</code></p>\n<p>To setup the fail2ban, please\
          \ follow this <a href=\"https://www.digitalocean.com/community/tutorials/how-to-protect-ssh-with-fail2ban-on-ubuntu-14-04\"\
          >instruction</a>.</p>\n<h2>Disable Unneeded Services</h2>\n<p>Unneeded services\
          \ are a potential security risk, so you can execute <code>sudo service --status-all</code>\n\
          to list all available services.  You can examine the output carefully and\
          \ disable\nany services not desired.</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-10-01T22:28:23-04:00'
          customer_folders: []
          description: Security Guidelines
          id: 6000203455
          is_default: false
          language_id: 6
          name: Security Guidelines
          parent_id: 6000203455
          position: 5
          updated_at: '2015-10-01T22:28:23-04:00'
          visibility: 1
        folder_id: 6000203455
        hits: 8
        id: 6000077799
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-02T17:26:53-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000077799
        position: 5
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: API
        updated_at: '2015-11-02T17:26:53-05:00'
        user_id: 6002464727
  html: "<h2>Security API</h2>\n<p>The NeCTAR Cloud doesn't provide a specific API\
    \ for security purposes. The only\nsecurity relevant operation is to manage security\
    \ groups through the Nova API.\nIf you want to know the Nova API, You can find\
    \ the related information from the\narticles in the 'Instance Management' section.</p>\n\
    <p>This article describes some techniques to help you to secure a Linux based\n\
    virtual machine in the NeCTAR cloud.</p>\n<p>As security is a very broad topic,\
    \ the techniques showed here only provides a\nbasic introduction. You can always\
    \ go to Internet and find more useful information\nabout security.</p>\n<p>The\
    \ instructions below assume your operating system is debian/ubuntu.</p>\n<h2>Securing\
    \ SSH</h2>\n<p>You need to encourage all the users on your system to use SSH certificate\n\
    authentication and disable password login. In addition, you need to avoid logging\n\
    into the system using SSH as root and use alternative methods to become root,\n\
    such as su or sudo.</p>\n<p>To change the SSH configuration, you can edit the\
    \ configuration file on the virtual\nmachine, in '/etc/ssh/sshd_config'.</p>\n\
    <p>A basic description of some important configuration items:</p>\n<ul>\n<li>\n\
    <p><strong>PermitRootLogin</strong> <strong><em>no</em></strong><br>\n You need\
    \ to set this to 'no' to avoid root access via SSH</p>\n</li>\n<li>\n<p><strong>Port\
    \ 22</strong><br>\n For better security, you can change the SSH port to other\
    \ port number</p>\n</li>\n<li>\n<p><strong>PermitEmptyPasswords</strong> <strong><em>no</em></strong><br>\n\
    \  This should be always 'no', for non-empty password access</p>\n</li>\n<li>\n\
    <p><strong>AllowUsers</strong><br>\n  This directive allows only certain users\
    \ to have access via SSH to this machine.</p>\n</li>\n<li>\n<p><strong>PasswordAuthentication</strong>\
    \ <strong><em>no</em></strong><br>\n  You should set this to 'no' to disable user\
    \ loggin using password</p>\n</li>\n</ul>\n<p>After you have changed the '/etc/ssh/sshd_config\
    \ file', you can execute <code>sudo service ssh restart</code>\nto apply the new\
    \ changes.</p>\n<p>If you are using an SSH client to access your Virtual Machine,\
    \ you need to make\nsure both SSH server and client are using the same version\
    \ of protocols.</p>\n<p>You can also restrict access to file transfer only if\
    \ you want to allow accounts\non your Virtual Machine to transfer files. You can\
    \ do it by giving users a\nrestricted shell such as scpoly or rssh. These shells\
    \ restrict the commands\navailable to the users to execute. You can change an\
    \ account's shell by editing\n'/etc/passwd' file.</p>\n<h2>Securing Apache</h2>\n\
    <p>If you don't want your Apache web service available to public, you can use\
    \ the\nListen or BindAddress directives in '/etc/apache2/apache2.conf'.</p>\n\
    <p>Using Listen:\n    Listen 127.0.0.1:80\nUsing BindAddress:\n    BindAddress\
    \ 127.0.0.1</p>\n<p>Then you can restart your apache service with <code>sudo service\
    \ apache2 restart</code></p>\n<p>The default Apache installation in Debian permits\
    \ users to publish content\nunder the '$HOME/public_html'. This content can be\
    \ retrieved remotely using an\nURL such as: http://your_apache_server/~user.</p>\n\
    <p>You can restrict the default configuration by editing '/etc/apache2/mods-enabled/userdir.conf'</p>\n\
    <p>You can also make sure the permission of log files can only be read/write by\
    \ the\nrequired user and groups. The default permission for the log files may\
    \ be readable\nby anyone.</p>\n<p>By default, Apache web files are located under\
    \ /'var/www'. The default file provides\nsome hints on the system like what is\
    \ the operating system. You should substitute\nthe default web pages with your\
    \ own.</p>\n<p>To further strengthen the Apache security, you can run Apache by\
    \ chroot. See this\n<a href=\"https://www.debian.org/doc/manuals/securing-debian-howto/ap-chroot-apache-env.en.html\"\
    >instruction</a> to set up Apache.</p>\n<h2>Keep System Update to Date</h2>\n\
    <p>In debian/ubuntu, you run <code>sudo apt-get update</code> regularly to keep\
    \ system\nsecurity patch update to date.</p>\n<h2>Setup Local Firewall</h2>\n\
    <p>A local firewall can also be installed with filtering rules to protect access\
    \ to\nthe system. You can use IPtable tools to create rules to filter network\
    \ traffic.\nIt is advised to use Security Group to manage which ports to open\
    \ as it is simple\nto do. The below only provides basic introduction to IPtables,\
    \ for more\ninformation, please refer to IPtables <a href=\"http://linux.die.net/man/8/iptables\"\
    >MAN page</a>.</p>\n<p>To list all current rules, execute:  <code>sudo iptables\
    \ --list</code></p>\n<p>By default, the IPtables defines 3 chains. The INPUT Chain\
    \ is for incoming traffic\n, the Forward Chain is for forwarded traffic and the\
    \ OUTPUT Chain is for outgoing\ntraffic. Which chains you need to add rules depends\
    \ on what traffic you want to\nfilter.</p>\n<p>IPtables also defines policies\
    \ that defines actions for rules:</p>\n<ul>\n<li>\n<p><strong>Accept</strong>,\
    \ accept traffic</p>\n</li>\n<li>\n<p><strong>Reject</strong>, reject traffic\
    \ by sending back an error packet</p>\n</li>\n<li>\n<p><strong>Drop</strong>,\
    \ reject traffic by dropping traffic</p>\n</li>\n</ul>\n<p>The below shows an\
    \ example how to enable SSH and HTTP/HTTPS traffic in IPtables.</p>\n<p>Firstly,\
    \ you need to allow connections that are already connected to your server:</p>\n\
    <p><code>sudo iptables - I INPUT 1 -p tcp --dport 22 -j ACCEPT</code></p>\n<p>Secondly,\
    \ you need to allow SSH connections:</p>\n<p><code>sudo iptables -I INPUT 1 -p\
    \ tcp --dport 22 -j ACCEPT</code></p>\n<p>Thirdly, you can allow HTTP/HTTPS traffic:</p>\n\
    <p><code>sudo iptables -I INPUT 1 -p tcp -dport 80 -j ACCEPT</code>\n<code>sudo\
    \ iptables -I INPUT 1 -p tcp --dport 443 -j ACCEPT</code></p>\n<p>Finally, you\
    \ need to drop all other traffic. You need to make sure you have set\nto allow\
    \ SSH connection, otherwise you will lose access to the Virtual Machine:</p>\n\
    <p><code>sudo iptables -P INPUT DROP</code></p>\n<p>You can save your IPtables\
    \ changes by (Ubuntu): </p>\n<p><code>iptables-save &gt; /etc/iptables.rules</code></p>\n\
    <h2>Install fail2ban</h2>\n<p>The SSH daemon itself is a Linux service that exposed\
    \ to the Internet and creates\na security risk for the system. fail2ban can mitigate\
    \ this problem by creating\nrules that can automatically alter your your IPtables\
    \ firewall and ban\nunsuccessful login attempts based on a predefined number.\
    \ </p>\n<p>You can use the below commands to install fail2ban in Ubuntu:</p>\n\
    <p><code>sudo apt-get update</code>\n<code>sudo apt-get install fail2ban</code></p>\n\
    <p>To setup the fail2ban, please follow this <a href=\"https://www.digitalocean.com/community/tutorials/how-to-protect-ssh-with-fail2ban-on-ubuntu-14-04\"\
    >instruction</a>.</p>\n<h2>Disable Unneeded Services</h2>\n<p>Unneeded services\
    \ are a potential security risk, so you can execute <code>sudo service --status-all</code>\n\
    to list all available services.  You can examine the output carefully and disable\n\
    any services not desired.</p>"
  parent: 43
  sha1: 920adae78777a39c1d474e2f709cacb3343e520f
  title: API
79:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-14T19:51:55-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " On The NeCTAR cloud: \n \n The list of supported resources\
          \ \n \nNeCTAR sample templates -\n  a set of templates demonstrating Heat\
          \ that have been run against the NeCTAR cloud. \n \n Videos \n \n An introduction\
          \ to Heat on the NeCTAR cloud \n The Research Bazaar overview of Heat on\
          \ the NeCTAR cloud \n \n Documentation \n \n The OpenStack End User Guide:\
          \ Heat\n \n The Heat wiki\n \n The Heat template guide\n \n The command\
          \ line client\n \n \n Books \n \n The online book \"Writing your first OpenStack\
          \ application\"\n has a chapter on Heat. \n \n NeCTAR support \n If you\
          \ have a problem and you cannot resolve it, you can always go to NecTAR\n\
          HelpDesk to log a support ticket and the NeCTAR\nsupport staff are more\
          \ than happy to help you. "
        description: "<p>On The NeCTAR cloud:</p>\n<ul>\n<li><a href=\"https://github.com/NeCTAR-RC/heat-templates\"\
          >The list of supported resources</a></li>\n<li>\n<a href=\"https://github.com/NeCTAR-RC/heat-templates\"\
          >NeCTAR sample templates</a> -\n  a set of templates demonstrating Heat\
          \ that have been run against the NeCTAR cloud.</li>\n</ul>\n<h2>Videos</h2>\n\
          <ul>\n<li><a href=\"https://youtu.be/swhUwc_LZB8\">An introduction to Heat\
          \ on the NeCTAR cloud</a></li>\n<li><a href=\"https://youtu.be/cKDda2RRE4E\"\
          >The Research Bazaar overview of Heat on the NeCTAR cloud</a></li>\n</ul>\n\
          <h2>Documentation</h2>\n<ul>\n<li>The OpenStack End User Guide: <a href=\"\
          http://docs.openstack.org/user-guide/dashboard_stacks.html\">Heat</a>\n\
          </li>\n<li>The Heat <a href=\"https://wiki.openstack.org/wiki/Heat\">wiki</a>\n\
          </li>\n<li>The Heat <a href=\"http://docs.openstack.org/developer/heat/template_guide/\"\
          >template guide</a>\n</li>\n<li>The <a href=\"http://docs.openstack.org/user-guide/cli_create_and_manage_stacks.html\"\
          >command line client</a>\n</li>\n</ul>\n<h2>Books</h2>\n<ul>\n<li>The online\
          \ book <a href=\"http://developer.openstack.org/firstapp-libcloud/\">\"\
          Writing your first OpenStack application\"</a>\n has a chapter on Heat.</li>\n\
          </ul>\n<h2>NeCTAR support</h2>\n<p>If you have a problem and you cannot\
          \ resolve it, you can always go to NecTAR\n<a href=\"https://support.nectar.org.au/support/home\"\
          >HelpDesk</a> to log a support ticket and the NeCTAR\nsupport staff are\
          \ more than happy to help you.</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:02-04:00'
          customer_folders: []
          description: Heat
          id: 6000190148
          is_default: false
          language_id: 6
          name: Heat
          parent_id: 6000190148
          position: 5
          updated_at: '2015-09-03T01:28:02-04:00'
          visibility: 1
        folder_id: 6000190148
        hits: 0
        id: 6000078062
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-14T19:51:55-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000078062
        position: 9
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: More Info
        updated_at: '2015-10-14T19:51:55-04:00'
        user_id: 6002464727
  html: "<p>On The NeCTAR cloud:</p>\n<ul>\n<li><a href=\"https://github.com/NeCTAR-RC/heat-templates\"\
    >The list of supported resources</a></li>\n<li><a href=\"https://github.com/NeCTAR-RC/heat-templates\"\
    >NeCTAR sample templates</a> -\n  a set of templates demonstrating Heat that have\
    \ been run against the NeCTAR cloud.</li>\n</ul>\n<h2>Videos</h2>\n<ul>\n<li><a\
    \ href=\"https://youtu.be/swhUwc_LZB8\">An introduction to Heat on the NeCTAR\
    \ cloud</a></li>\n<li><a href=\"https://youtu.be/cKDda2RRE4E\">The Research Bazaar\
    \ overview of Heat on the NeCTAR cloud</a></li>\n</ul>\n<h2>Documentation</h2>\n\
    <ul>\n<li>The OpenStack End User Guide: <a href=\"http://docs.openstack.org/user-guide/dashboard_stacks.html\"\
    >Heat</a></li>\n<li>The Heat <a href=\"https://wiki.openstack.org/wiki/Heat\"\
    >wiki</a></li>\n<li>The Heat <a href=\"http://docs.openstack.org/developer/heat/template_guide/\"\
    >template guide</a></li>\n<li>The <a href=\"http://docs.openstack.org/user-guide/cli_create_and_manage_stacks.html\"\
    >command line client</a></li>\n</ul>\n<h2>Books</h2>\n<ul>\n<li>The online book\
    \ <a href=\"http://developer.openstack.org/firstapp-libcloud/\">\"Writing your\
    \ first OpenStack application\"</a>\n has a chapter on Heat.</li>\n</ul>\n<h2>NeCTAR\
    \ support</h2>\n<p>If you have a problem and you cannot resolve it, you can always\
    \ go to NecTAR\n<a href=\"https://support.nectar.org.au/support/home\">HelpDesk</a>\
    \ to log a support ticket and the NeCTAR\nsupport staff are more than happy to\
    \ help you.</p>"
  parent: 42
  sha1: 089d0705ebfb8b4f5b3e44575ba5c620f3f6245b
  title: More Info
80:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-14T20:05:20-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " API Authentication \n All NecTAR Cloud APIs such as Nova,\
          \ Cinder, etc., require authentication before\nyou can use them. NeCTAR\
          \ Cloud API supports 2 styles of authentication,\nOpenStack authentication\
          \ and EC2 authentication. \n OpenStack API Authentication \n OpenStack API\
          \ Authentication requires 4 environment variables to be set for\nauthentication:\
          \ \n \n auth URL \n username \n project id or name (most clients can handle\
          \ either) \n password \n \n You can download the authentication script from\
          \ the NeCTAR Dashboard. These\nvariables are set by the script file and\
          \ you can see these variables\nif you open the file. Example: \n \n OS_AUTH_URL:\
          \ https://keystone.rc.nectar.org.au:5000/v2.0/ \n OS_TENANT_NAME=my_science_project\
          \ \n OS_TENANT_ID=sdfsdfsfwrwewer \n OS_USERNAME=clouduser@example.edu.au\
          \ \n OS_PASSWORD=XXXXXX \n \n Instructions for downloading the OpenStack\
          \ authentication script file: \n \n \n Login to the NeCTAR Cloud Dashboard\
          \ \n \n \n Select a project name from the project drop down list \n \n \n\
          \ Click 'Access & Security' \n \n \n On the 'Access & Security' page, click\
          \ tab 'API Access' and you should see the\n following screen:  \n \n \n\
          \ \n \n \n Click the button: \"Download OpenStack RC File\" \n \n \n Save\
          \ the file into a directory \n \n \n Click the drop down list with your\
          \ email on the right top of page, then click\n Settings. You should see\
          \ the following screen: \n \n \n \n \n Click the 'Reset Password' button\
          \ and save the password that appears on the screen.\n This is the API password.\
          \ \n \n You use this script file to get authenticated before using the API.\n\
          One way is to run source script_file ; or you can grab the required\nvariables\
          \ from the authentication script file and pass them to the API calls. \n\
          \ EC2 authentication \n EC2 authentication requires 2 variables to be set:\
          \ \n \n EC2_ACCESS_KEY \n EC2_SECRET_KEY \n \n The EC2_ACCESS_KEY is the\
          \ account number and EC2_SECRET_KEY is the password. You\ncan get these\
          \ 2 variables from the NeCTAR Dashboard using the following\ninstructions:\
          \ \n \n \n Login to the NeCTAR Cloud Dashboard \n \n \n Select a project\
          \ name from the project drop down list \n \n \n Click 'Access & Security'\
          \ \n \n \n On the 'Access & Security' page, click tab 'API Access' and the\
          \ screen should look like this:  \n \n \n \n \n \n Click the button: \"\
          Download EC2 Credentials\" \n \n \n Save the file into a directory  \n \n\
          \ \n You can find the 2 variables from the file you just downloaded. You\
          \ can then\npass these 2 variables to API calls. "
        description: "<h2>API Authentication</h2>\n<p>All NecTAR Cloud APIs such as\
          \ Nova, Cinder, etc., require authentication before\nyou can use them. NeCTAR\
          \ Cloud API supports 2 styles of authentication,\nOpenStack authentication\
          \ and EC2 authentication.</p>\n<h3>OpenStack API Authentication</h3>\n<p>OpenStack\
          \ API Authentication requires 4 environment variables to be set for\nauthentication:</p>\n\
          <ul>\n<li>auth URL</li>\n<li>username</li>\n<li>project id or name (most\
          \ clients can handle either)</li>\n<li>password</li>\n</ul>\n<p>You can\
          \ download the authentication script from the NeCTAR Dashboard. These\n\
          variables are set by the script file and you can see these variables\nif\
          \ you open the file. Example:</p>\n<blockquote>\n<p>OS_AUTH_URL: https://keystone.rc.nectar.org.au:5000/v2.0/</p>\n\
          <p>OS_TENANT_NAME=my_science_project</p>\n<p>OS_TENANT_ID=sdfsdfsfwrwewer</p>\n\
          <p>OS_USERNAME=clouduser@example.edu.au</p>\n<p>OS_PASSWORD=XXXXXX</p>\n\
          </blockquote>\n<p>Instructions for downloading the OpenStack authentication\
          \ script file:</p>\n<ul>\n<li>\n<p>Login to the NeCTAR Cloud <a href=\"\
          https://dashboard.rc.nectar.org.au\">Dashboard</a></p>\n</li>\n<li>\n<p>Select\
          \ a project name from the project drop down list</p>\n</li>\n<li>\n<p>Click\
          \ 'Access &amp; Security'</p>\n</li>\n<li>\n<p>On the 'Access &amp; Security'\
          \ page, click tab 'API Access' and you should see the\n following screen:\
          \ </p>\n</li>\n</ul>\n<p><img alt=\"api1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/api1.png?raw=true\"\
          ></p>\n<ul>\n<li>\n<p>Click the button: \"Download OpenStack RC File\"</p>\n\
          </li>\n<li>\n<p>Save the file into a directory</p>\n</li>\n<li>\n<p>Click\
          \ the drop down list with your email on the right top of page, then click\n\
          \ Settings. You should see the following screen:</p>\n</li>\n</ul>\n<p><img\
          \ alt=\"api2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/api2.png?raw=true\"\
          ></p>\n<ul>\n<li>Click the 'Reset Password' button and save the password\
          \ that appears on the screen.\n This is the API password.</li>\n</ul>\n\
          <p>You use this script file to get authenticated before using the API.\n\
          One way is to run <code>source script_file</code> ; or you can grab the\
          \ required\nvariables from the authentication script file and pass them\
          \ to the API calls.</p>\n<h3>EC2 authentication</h3>\n<p>EC2 authentication\
          \ requires 2 variables to be set:</p>\n<blockquote>\n<p>EC2_ACCESS_KEY</p>\n\
          <p>EC2_SECRET_KEY</p>\n</blockquote>\n<p>The EC2_ACCESS_KEY is the account\
          \ number and EC2_SECRET_KEY is the password. You\ncan get these 2 variables\
          \ from the NeCTAR Dashboard using the following\ninstructions:</p>\n<ul>\n\
          <li>\n<p>Login to the NeCTAR Cloud <a href=\"https://dashboard.rc.nectar.org.au\"\
          >Dashboard</a></p>\n</li>\n<li>\n<p>Select a project name from the project\
          \ drop down list</p>\n</li>\n<li>\n<p>Click 'Access &amp; Security'</p>\n\
          </li>\n<li>\n<p>On the 'Access &amp; Security' page, click tab 'API Access'\
          \ and the screen should look like this: </p>\n</li>\n</ul>\n<p><img alt=\"\
          api1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Authentication--DOCID41/images/api1.png?raw=true\"\
          ></p>\n<ul>\n<li>\n<p>Click the button: \"Download EC2 Credentials\"</p>\n\
          </li>\n<li>\n<p>Save the file into a directory </p>\n</li>\n</ul>\n<p>You\
          \ can find the 2 variables from the file you just downloaded. You can then\n\
          pass these 2 variables to API calls.</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:01-04:00'
          customer_folders: []
          description: Authentication
          id: 6000190147
          is_default: false
          language_id: 6
          name: Authentication
          parent_id: 6000190147
          position: 3
          updated_at: '2015-09-03T01:28:01-04:00'
          visibility: 1
        folder_id: 6000190147
        hits: 6
        id: 6000078065
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-01T20:22:38-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000078065
        position: 3
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: API
        updated_at: '2015-11-01T20:22:38-05:00'
        user_id: 6002464727
  html: "<h2>API Authentication</h2>\n<p>All NecTAR Cloud APIs such as Nova, Cinder,\
    \ etc., require authentication before\nyou can use them. NeCTAR Cloud API supports\
    \ 2 styles of authentication,\nOpenStack authentication and EC2 authentication.</p>\n\
    <h3>OpenStack API Authentication</h3>\n<p>OpenStack API Authentication requires\
    \ 4 environment variables to be set for\nauthentication:</p>\n<ul>\n<li>auth URL</li>\n\
    <li>username</li>\n<li>project id or name (most clients can handle either)</li>\n\
    <li>password</li>\n</ul>\n<p>You can download the authentication script from the\
    \ NeCTAR Dashboard. These\nvariables are set by the script file and you can see\
    \ these variables\nif you open the file. Example:</p>\n<blockquote>\n<p>OS_AUTH_URL:\
    \ https://keystone.rc.nectar.org.au:5000/v2.0/</p>\n<p>OS_TENANT_NAME=my_science_project</p>\n\
    <p>OS_TENANT_ID=sdfsdfsfwrwewer</p>\n<p>OS_USERNAME=clouduser@example.edu.au</p>\n\
    <p>OS_PASSWORD=XXXXXX</p>\n</blockquote>\n<p>Instructions for downloading the\
    \ OpenStack authentication script file:</p>\n<ul>\n<li>\n<p>Login to the NeCTAR\
    \ Cloud <a href=\"https://dashboard.rc.nectar.org.au\">Dashboard</a></p>\n</li>\n\
    <li>\n<p>Select a project name from the project drop down list</p>\n</li>\n<li>\n\
    <p>Click 'Access &amp; Security'</p>\n</li>\n<li>\n<p>On the 'Access &amp; Security'\
    \ page, click tab 'API Access' and you should see the\n following screen: </p>\n\
    </li>\n</ul>\n<p><img alt=\"api1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/api1.png?raw=true\"></p>\n<ul>\n\
    <li>\n<p>Click the button: \"Download OpenStack RC File\"</p>\n</li>\n<li>\n<p>Save\
    \ the file into a directory</p>\n</li>\n<li>\n<p>Click the drop down list with\
    \ your email on the right top of page, then click\n Settings. You should see the\
    \ following screen:</p>\n</li>\n</ul>\n<p><img alt=\"api2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/api2.png?raw=true\"></p>\n<ul>\n\
    <li>Click the 'Reset Password' button and save the password that appears on the\
    \ screen.\n This is the API password.</li>\n</ul>\n<p>You use this script file\
    \ to get authenticated before using the API.\nOne way is to run <code>source script_file</code>\
    \ ; or you can grab the required\nvariables from the authentication script file\
    \ and pass them to the API calls.</p>\n<h3>EC2 authentication</h3>\n<p>EC2 authentication\
    \ requires 2 variables to be set:</p>\n<blockquote>\n<p>EC2_ACCESS_KEY</p>\n<p>EC2_SECRET_KEY</p>\n\
    </blockquote>\n<p>The EC2_ACCESS_KEY is the account number and EC2_SECRET_KEY\
    \ is the password. You\ncan get these 2 variables from the NeCTAR Dashboard using\
    \ the following\ninstructions:</p>\n<ul>\n<li>\n<p>Login to the NeCTAR Cloud <a\
    \ href=\"https://dashboard.rc.nectar.org.au\">Dashboard</a></p>\n</li>\n<li>\n\
    <p>Select a project name from the project drop down list</p>\n</li>\n<li>\n<p>Click\
    \ 'Access &amp; Security'</p>\n</li>\n<li>\n<p>On the 'Access &amp; Security'\
    \ page, click tab 'API Access' and the screen should look like this: </p>\n</li>\n\
    </ul>\n<p><img alt=\"api1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud\
    \ Expert--DOCID19/Authentication--DOCID41/images/api1.png?raw=true\"></p>\n<ul>\n\
    <li>\n<p>Click the button: \"Download EC2 Credentials\"</p>\n</li>\n<li>\n<p>Save\
    \ the file into a directory </p>\n</li>\n</ul>\n<p>You can find the 2 variables\
    \ from the file you just downloaded. You can then\npass these 2 variables to API\
    \ calls.</p>"
  parent: 41
  sha1: a0a89025845b291ff839964ddc5e31321d6be8bf
  title: API
81:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-14T20:50:46-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Videos \n The following videos provides useful information\
          \ about Authentication: \n \n \n OpenStack Authentication Overview \n \n\
          \ \n Keystone advanced authentication methods \n \n \n OpenStack Fundamentals\
          \ OpenStack Identity Services \n \n \n OpenStack: Keystone Deep Dive Presentation\
          \ \n \n \n OpenStack Bootstrapping Hour - Authentication in Keystone \n\
          \ \n \n Documentation \n The following documentations provides reference\
          \ and guidance information for\nLinux security: \n \n \n OpenStack APIs\
          \ \n \n \n OpenStack Identity API \n \n \n OpenStack Python bindings to\
          \ the Identity API \n \n \n NeCTAR Support \n If you have a problem and\
          \ you cannot resolve it, you can always go to NecTAR\nHelpDesk to log a\
          \ support ticket and the NeCTAR support staff are\nmore than happy to help\
          \ you. "
        description: '<h2>Videos</h2>

          <p>The following videos provides useful information about Authentication:</p>

          <ul>

          <li>

          <p><a href="https://www.youtube.com/watch?v=TbkpGXzxl4E">OpenStack Authentication
          Overview</a></p>

          </li>

          <li>

          <p><a href="https://www.youtube.com/watch?v=ZLHGGpRAHgE">Keystone advanced
          authentication methods</a></p>

          </li>

          <li>

          <p><a href="https://www.youtube.com/watch?v=H_m369ZqEf4">OpenStack Fundamentals
          OpenStack Identity Services</a></p>

          </li>

          <li>

          <p><a href="https://www.youtube.com/watch?v=nHCxcN3pgQw">OpenStack: Keystone
          Deep Dive Presentation</a></p>

          </li>

          <li>

          <p><a href="https://www.youtube.com/watch?v=Th61TgUVnzU">OpenStack Bootstrapping
          Hour - Authentication in Keystone</a></p>

          </li>

          </ul>

          <h2>Documentation</h2>

          <p>The following documentations provides reference and guidance information
          for

          Linux security:</p>

          <ul>

          <li>

          <p><a href="http://developer.openstack.org/api-guide/quick-start/api-quick-start.html#authentication-and-api-request-workflow">OpenStack
          APIs</a></p>

          </li>

          <li>

          <p><a href="http://developer.openstack.org/api-ref-identity-v3.html">OpenStack
          Identity API</a></p>

          </li>

          <li>

          <p><a href="http://docs.openstack.org/developer/python-keystoneclient/">OpenStack
          Python bindings to the Identity API</a></p>

          </li>

          </ul>

          <h2>NeCTAR Support</h2>

          <p>If you have a problem and you cannot resolve it, you can always go to
          NecTAR

          <a href="https://support.nectar.org.au/support/home">HelpDesk</a> to log
          a support ticket and the NeCTAR support staff are

          more than happy to help you.</p>'
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:01-04:00'
          customer_folders: []
          description: Authentication
          id: 6000190147
          is_default: false
          language_id: 6
          name: Authentication
          parent_id: 6000190147
          position: 3
          updated_at: '2015-09-03T01:28:01-04:00'
          visibility: 1
        folder_id: 6000190147
        hits: 0
        id: 6000078071
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-14T20:50:46-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000078071
        position: 4
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: More Info
        updated_at: '2015-10-14T20:50:46-04:00'
        user_id: 6002464727
  html: '<h2>Videos</h2>

    <p>The following videos provides useful information about Authentication:</p>

    <ul>

    <li>

    <p><a href="https://www.youtube.com/watch?v=TbkpGXzxl4E">OpenStack Authentication
    Overview</a></p>

    </li>

    <li>

    <p><a href="https://www.youtube.com/watch?v=ZLHGGpRAHgE">Keystone advanced authentication
    methods</a></p>

    </li>

    <li>

    <p><a href="https://www.youtube.com/watch?v=H_m369ZqEf4">OpenStack Fundamentals
    OpenStack Identity Services</a></p>

    </li>

    <li>

    <p><a href="https://www.youtube.com/watch?v=nHCxcN3pgQw">OpenStack: Keystone Deep
    Dive Presentation</a></p>

    </li>

    <li>

    <p><a href="https://www.youtube.com/watch?v=Th61TgUVnzU">OpenStack Bootstrapping
    Hour - Authentication in Keystone</a></p>

    </li>

    </ul>

    <h2>Documentation</h2>

    <p>The following documentations provides reference and guidance information for

    Linux security:</p>

    <ul>

    <li>

    <p><a href="http://developer.openstack.org/api-guide/quick-start/api-quick-start.html#authentication-and-api-request-workflow">OpenStack
    APIs</a></p>

    </li>

    <li>

    <p><a href="http://developer.openstack.org/api-ref-identity-v3.html">OpenStack
    Identity API</a></p>

    </li>

    <li>

    <p><a href="http://docs.openstack.org/developer/python-keystoneclient/">OpenStack
    Python bindings to the Identity API</a></p>

    </li>

    </ul>

    <h2>NeCTAR Support</h2>

    <p>If you have a problem and you cannot resolve it, you can always go to NecTAR

    <a href="https://support.nectar.org.au/support/home">HelpDesk</a> to log a support
    ticket and the NeCTAR support staff are

    more than happy to help you.</p>'
  parent: 41
  sha1: 72a60e59f1612bf38c706d80dd49230706a52992
  title: More Info
82:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-10-15T00:41:22-04:00'
        datetime_01: null
        delta: true
        desc_un_html: " Debugging Dashboard Authentication \n The NeCTAR Dashboard\
          \ uses Australian Access Federation for its authentication.\nIf you have\
          \ any problems with the login, you can contact the IT helpdesk in your\n\
          local organization or institution. You can log a ticket in the NeCTAR\n\
          helpdesk. You can also submit a help request to aaf\nhelpdesk for help.\
          \ \n Debugging API Authentication \n You must first send an authentication\
          \ request to OpenStack Identity service to\nget an authentication token\
          \ before you can access API services. To request an\nauthentication token,\
          \ you must supply the credentials in the authentication request. \n The\
          \ credentials are a combination of username, password and project name.\
          \ You also\nneed to get the authentication URL for credentials validation.\
          \ \n You need to make sure you have the correct Credentials download from\
          \ the NeCTAR\nDashboard. Before you use them, please check the username,\
          \ projet name and the\nAPI endpoints. You can reference these information\
          \ from the script file you\nobtained from the NeCTAR Dashboard. \n After\
          \ you send the username/password and project name to the authentication\
          \ URL,\nYou will get a authentication token. Then, you need to include the\
          \ token in the\nX-Auth-Token HTTP header. If you access multiple API services,\
          \ you must get a\ntoken for each API service. The token has a limited time\
          \ and can become invalid\nfor other reasons. \n Authentication and API request\
          \ workflow \n \n \n Send a request with credentials to get a token from\
          \ the Identity endpoint. If\n the request succeeds, the server returns an\
          \ authentication token. \n \n \n Send API requests and include the token\
          \ in the X-Auth-Token HTTP header. The\n following HTTP requests use the\
          \ same token until the requests complete. \n \n \n If a 401 Unauthorized\
          \ error returned, the request requires a new token. \n \n \n Debug Authentication\
          \ \n The below use cURL commands to show your how to debug authentication\
          \ request.\nFor information about cURL, see http://curl.haxx.se/. For information\n\
          about the OpenStack APIs, see OpenStack API Reference. \n To get a valid\
          \ token, you need 3 parameters: \n \n \n username \n \n \n password \n \n\
          \ \n project name/project id \n \n \n The below shows a code to get token:\
          \ \n ``` \n curl -s -X POST https://keystone.rc.nectar.org.au:5000/v2.0/tokens\
          \ \\ \n         -H \"Content-Type: application/json\" \\\n\n        -d '{\"\
          auth\": {\"tenantName\": \"'\"$OS_TENANT_NAME\"'\", \"passwordCredentials\"\
          :\n\n        {\"username\": \"'\"$OS_USERNAME\"'\", \"password\": \"'\"\
          $OS_PASSWORD\"'\"}}}' \\\n\n        | python -m json.tool\n \n ``` \n You\
          \ need to replace the username, password and tenantname with the values\
          \ in\nthe authentication script file you obtained from the NeCTAR Dashboard.\
          \ \n The response would look like below: \n ``` \n {\n    \"access\": {\n\
          \        \"metadata\": {\n            \"is_admin\": 0,\n            \"roles\"\
          : [\n                \"22\",\n                \"143\"\n            ]\n \
          \       },\n        \"serviceCatalog\": [\n            {\n             \
          \   \"endpoints\": [\n                    {\n                        \"\
          adminURL\": \"https://nova.rc.abc:8774/v1.1/\",\n                      \
          \  \"internalURL\": \"https://nova.rc.abc:8774/v1.1/\",\n              \
          \          \"publicURL\": \"https://nova.rc.abc:8774/v1.1/\",\n        \
          \                \"region\": \"Melbourne\"\n                    }\n    \
          \            ],\n                \"endpoints_links\": [],\n            \
          \    \"name\": \"Compute Service\",\n                \"type\": \"compute\"\
          \n            }\n        ],\n        \"token\": {\n            \"audit_ids\"\
          : [\n                \"SUtsLIdWQJ634dfdsfdsffdszVe6D2ijg\"\n           \
          \ ],\n            \"expires\": \"2015-10-15T10:08:53Z\",\n            \"\
          id\": \"MIIUsdfsfsd2AYJKoZIhvcNAQcCoIIUyTCCFMUCAQ.........eaL6Z8h\",\n \
          \           \"issued_at\": \"2015-10-15T04:08:53.231576\",\n           \
          \ \"tenant\": {\n                \"allocation_id\": 170,\n             \
          \   \"description\": null,\n                \"enabled\": true,\n       \
          \         \"expires\": \"2018-07-01\",\n                \"id\": \"e4c1e4e82cd5495d89d52d694ea62e50sdadsweqe\"\
          ,\n                \"name\": \"Marine-VL\"\n            }\n        },\n\
          \        \"user\": {\n            \"id\": \"\",\n            \"name\": \"\
          \",\n            \"roles\": [\n                {\n                    \"\
          name\": \"Member\"\n                },\n                {\n            \
          \        \"name\": \"TenantManager\"\n                }\n            ],\n\
          \            \"roles_links\": [],\n            \"username\": \"\"\n    \
          \    }\n    }\n} \n ``` \n Then you can use the token obtained from this\
          \ output in the API for authentication. \n Following is an example of how\
          \ to use the token in using Nova API to list flavors: \n ``` \n curl -s\
          \ -H \\ \n         \"X-Auth-Token:token\" \\\n\n        http://8.21.28.222:8774/v2/tenant_id/flavors\
          \ \\\n\n        | python -m json.tool\n \n ``` \n You need to replace the\
          \ token and the URL. You can find the Nova API endpoint\nURL from the NeCTAR\
          \ Dashboard. The above request would return the\nfollowing output: \n ```\
          \ \n {\n    \"flavors\": [\n        {\n            \"id\": \"1\",\n    \
          \        \"links\": [\n                {\n                    \"href\":\
          \ \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/1\"\
          ,\n                    \"rel\": \"self\"\n                },\n         \
          \       {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/1\"\
          ,\n                    \"rel\": \"bookmark\"\n                }\n      \
          \      ],\n            \"name\": \"m1.tiny\"\n        },\n        {\n  \
          \          \"id\": \"2\",\n            \"links\": [\n                {\n\
          \                    \"href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/2\"\
          ,\n                    \"rel\": \"self\"\n                },\n         \
          \       {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/2\"\
          ,\n                    \"rel\": \"bookmark\"\n                }\n      \
          \      ],\n            \"name\": \"m1.small\"\n        },\n        {\n \
          \           \"id\": \"3\",\n            \"links\": [\n                {\n\
          \                    \"href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/3\"\
          ,\n                    \"rel\": \"self\"\n                },\n         \
          \       {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/3\"\
          ,\n                    \"rel\": \"bookmark\"\n                }\n      \
          \      ],\n            \"name\": \"m1.medium\"\n        },\n        {\n\
          \            \"id\": \"4\",\n            \"links\": [\n                {\n\
          \                    \"href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/4\"\
          ,\n                    \"rel\": \"self\"\n                },\n         \
          \       {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/4\"\
          ,\n                    \"rel\": \"bookmark\"\n                }\n      \
          \      ],\n            \"name\": \"m1.large\"\n        },\n        {\n \
          \           \"id\": \"5\",\n            \"links\": [\n                {\n\
          \                    \"href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/5\"\
          ,\n                    \"rel\": \"self\"\n                },\n         \
          \       {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/5\"\
          ,\n                    \"rel\": \"bookmark\"\n                }\n      \
          \      ],\n            \"name\": \"m1.xlarge\"\n        }\n    ]\n} \n ``` "
        description: "<h2>Debugging Dashboard Authentication</h2>\n<p>The NeCTAR Dashboard\
          \ uses <a href=\"http://aaf.edu.au/\">Australian Access Federation</a> for\
          \ its authentication.\nIf you have any problems with the login, you can\
          \ contact the IT helpdesk in your\nlocal organization or institution. You\
          \ can log a ticket in the NeCTAR\n<a href=\"https://support.nectar.org.au/support/home\"\
          >helpdesk</a>. You can also submit a help request to aaf\n<a href=\"http://support.aaf.edu.au/home\"\
          >helpdesk</a> for help.</p>\n<h2>Debugging API Authentication</h2>\n<p>You\
          \ must first send an authentication request to OpenStack Identity service\
          \ to\nget an authentication token before you can access API services. To\
          \ request an\nauthentication token, you must supply the credentials in the\
          \ authentication request.</p>\n<p>The credentials are a combination of username,\
          \ password and project name. You also\nneed to get the authentication URL\
          \ for credentials validation.</p>\n<p>You need to make sure you have the\
          \ correct Credentials download from the NeCTAR\nDashboard. Before you use\
          \ them, please check the username, projet name and the\nAPI endpoints. You\
          \ can reference these information from the script file you\nobtained from\
          \ the NeCTAR Dashboard.</p>\n<p>After you send the username/password and\
          \ project name to the authentication URL,\nYou will get a authentication\
          \ token. Then, you need to include the token in the\nX-Auth-Token HTTP header.\
          \ If you access multiple API services, you must get a\ntoken for each API\
          \ service. The token has a limited time and can become invalid\nfor other\
          \ reasons.</p>\n<h3>Authentication and API request workflow</h3>\n<ul>\n\
          <li>\n<p>Send a request with credentials to get a token from the Identity\
          \ endpoint. If\n the request succeeds, the server returns an authentication\
          \ token.</p>\n</li>\n<li>\n<p>Send API requests and include the token in\
          \ the X-Auth-Token HTTP header. The\n following HTTP requests use the same\
          \ token until the requests complete.</p>\n</li>\n<li>\n<p>If a 401 Unauthorized\
          \ error returned, the request requires a new token.</p>\n</li>\n</ul>\n\
          <h3>Debug Authentication</h3>\n<p>The below use cURL commands to show your\
          \ how to debug authentication request.\nFor information about cURL, see\
          \ <a href=\"http://curl.haxx.se/\">http://curl.haxx.se/</a>. For information\n\
          about the OpenStack APIs, see <a href=\"http://developer.openstack.org/api-ref.html\"\
          >OpenStack API Reference</a>.</p>\n<p>To get a valid token, you need 3 parameters:</p>\n\
          <ul>\n<li>\n<p>username</p>\n</li>\n<li>\n<p>password</p>\n</li>\n<li>\n\
          <p>project name/project id</p>\n</li>\n</ul>\n<p>The below shows a code\
          \ to get token:</p>\n<p>```</p>\n<p>curl -s -X POST https://keystone.rc.nectar.org.au:5000/v2.0/tokens\
          \ \\</p>\n<pre><code>        -H \"Content-Type: application/json\" \\\n\n\
          \        -d '{\"auth\": {\"tenantName\": \"'\"$OS_TENANT_NAME\"'\", \"passwordCredentials\"\
          :\n\n        {\"username\": \"'\"$OS_USERNAME\"'\", \"password\": \"'\"\
          $OS_PASSWORD\"'\"}}}' \\\n\n        | python -m json.tool\n</code></pre>\n\
          <p>```</p>\n<p>You need to replace the username, password and tenantname\
          \ with the values in\nthe authentication script file you obtained from the\
          \ NeCTAR Dashboard.</p>\n<p>The response would look like below:</p>\n<p>```</p>\n\
          <p>{\n    \"access\": {\n        \"metadata\": {\n            \"is_admin\"\
          : 0,\n            \"roles\": [\n                \"22\",\n              \
          \  \"143\"\n            ]\n        },\n        \"serviceCatalog\": [\n \
          \           {\n                \"endpoints\": [\n                    {\n\
          \                        \"adminURL\": \"https://nova.rc.abc:8774/v1.1/\"\
          ,\n                        \"internalURL\": \"https://nova.rc.abc:8774/v1.1/\"\
          ,\n                        \"publicURL\": \"https://nova.rc.abc:8774/v1.1/\"\
          ,\n                        \"region\": \"Melbourne\"\n                 \
          \   }\n                ],\n                \"endpoints_links\": [],\n  \
          \              \"name\": \"Compute Service\",\n                \"type\"\
          : \"compute\"\n            }\n        ],\n        \"token\": {\n       \
          \     \"audit_ids\": [\n                \"SUtsLIdWQJ634dfdsfdsffdszVe6D2ijg\"\
          \n            ],\n            \"expires\": \"2015-10-15T10:08:53Z\",\n \
          \           \"id\": \"MIIUsdfsfsd2AYJKoZIhvcNAQcCoIIUyTCCFMUCAQ.........eaL6Z8h\"\
          ,\n            \"issued_at\": \"2015-10-15T04:08:53.231576\",\n        \
          \    \"tenant\": {\n                \"allocation_id\": 170,\n          \
          \      \"description\": null,\n                \"enabled\": true,\n    \
          \            \"expires\": \"2018-07-01\",\n                \"id\": \"e4c1e4e82cd5495d89d52d694ea62e50sdadsweqe\"\
          ,\n                \"name\": \"Marine-VL\"\n            }\n        },\n\
          \        \"user\": {\n            \"id\": \"\",\n            \"name\": \"\
          \",\n            \"roles\": [\n                {\n                    \"\
          name\": \"Member\"\n                },\n                {\n            \
          \        \"name\": \"TenantManager\"\n                }\n            ],\n\
          \            \"roles_links\": [],\n            \"username\": \"\"\n    \
          \    }\n    }\n}</p>\n<p>```</p>\n<p>Then you can use the token obtained\
          \ from this output in the API for authentication.</p>\n<p>Following is an\
          \ example of how to use the token in using Nova API to list flavors:</p>\n\
          <p>```</p>\n<p>curl -s -H \\</p>\n<pre><code>        \"X-Auth-Token:token\"\
          \ \\\n\n        http://8.21.28.222:8774/v2/tenant_id/flavors \\\n\n    \
          \    | python -m json.tool\n</code></pre>\n<p>```</p>\n<p>You need to replace\
          \ the token and the URL. You can find the Nova API endpoint\nURL from the\
          \ NeCTAR <a href=\"https://dashboard.rc.nectar.org.au\">Dashboard</a>. The\
          \ above request would return the\nfollowing output:</p>\n<p>```</p>\n<p>{\n\
          \    \"flavors\": [\n        {\n            \"id\": \"1\",\n           \
          \ \"links\": [\n                {\n                    \"href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/1\"\
          ,\n                    \"rel\": \"self\"\n                },\n         \
          \       {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/1\"\
          ,\n                    \"rel\": \"bookmark\"\n                }\n      \
          \      ],\n            \"name\": \"m1.tiny\"\n        },\n        {\n  \
          \          \"id\": \"2\",\n            \"links\": [\n                {\n\
          \                    \"href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/2\"\
          ,\n                    \"rel\": \"self\"\n                },\n         \
          \       {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/2\"\
          ,\n                    \"rel\": \"bookmark\"\n                }\n      \
          \      ],\n            \"name\": \"m1.small\"\n        },\n        {\n \
          \           \"id\": \"3\",\n            \"links\": [\n                {\n\
          \                    \"href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/3\"\
          ,\n                    \"rel\": \"self\"\n                },\n         \
          \       {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/3\"\
          ,\n                    \"rel\": \"bookmark\"\n                }\n      \
          \      ],\n            \"name\": \"m1.medium\"\n        },\n        {\n\
          \            \"id\": \"4\",\n            \"links\": [\n                {\n\
          \                    \"href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/4\"\
          ,\n                    \"rel\": \"self\"\n                },\n         \
          \       {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/4\"\
          ,\n                    \"rel\": \"bookmark\"\n                }\n      \
          \      ],\n            \"name\": \"m1.large\"\n        },\n        {\n \
          \           \"id\": \"5\",\n            \"links\": [\n                {\n\
          \                    \"href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/5\"\
          ,\n                    \"rel\": \"self\"\n                },\n         \
          \       {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/5\"\
          ,\n                    \"rel\": \"bookmark\"\n                }\n      \
          \      ],\n            \"name\": \"m1.xlarge\"\n        }\n    ]\n}</p>\n\
          <p>```</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-09-03T01:28:01-04:00'
          customer_folders: []
          description: Authentication
          id: 6000190147
          is_default: false
          language_id: 6
          name: Authentication
          parent_id: 6000190147
          position: 3
          updated_at: '2015-09-03T01:28:01-04:00'
          visibility: 1
        folder_id: 6000190147
        hits: 2
        id: 6000078086
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-10-22T00:56:38-04:00'
        modified_by: null
        outdated: false
        parent_id: 6000078086
        position: 5
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Trouble Shooting
        updated_at: '2015-10-22T00:56:38-04:00'
        user_id: 6002464727
  html: "<h2>Debugging Dashboard Authentication</h2>\n<p>The NeCTAR Dashboard uses\
    \ <a href=\"http://aaf.edu.au/\">Australian Access Federation</a> for its authentication.\n\
    If you have any problems with the login, you can contact the IT helpdesk in your\n\
    local organization or institution. You can log a ticket in the NeCTAR\n<a href=\"\
    https://support.nectar.org.au/support/home\">helpdesk</a>. You can also submit\
    \ a help request to aaf\n<a href=\"http://support.aaf.edu.au/home\">helpdesk</a>\
    \ for help.</p>\n<h2>Debugging API Authentication</h2>\n<p>You must first send\
    \ an authentication request to OpenStack Identity service to\nget an authentication\
    \ token before you can access API services. To request an\nauthentication token,\
    \ you must supply the credentials in the authentication request.</p>\n<p>The credentials\
    \ are a combination of username, password and project name. You also\nneed to\
    \ get the authentication URL for credentials validation.</p>\n<p>You need to make\
    \ sure you have the correct Credentials download from the NeCTAR\nDashboard. Before\
    \ you use them, please check the username, projet name and the\nAPI endpoints.\
    \ You can reference these information from the script file you\nobtained from\
    \ the NeCTAR Dashboard.</p>\n<p>After you send the username/password and project\
    \ name to the authentication URL,\nYou will get a authentication token. Then,\
    \ you need to include the token in the\nX-Auth-Token HTTP header. If you access\
    \ multiple API services, you must get a\ntoken for each API service. The token\
    \ has a limited time and can become invalid\nfor other reasons.</p>\n<h3>Authentication\
    \ and API request workflow</h3>\n<ul>\n<li>\n<p>Send a request with credentials\
    \ to get a token from the Identity endpoint. If\n the request succeeds, the server\
    \ returns an authentication token.</p>\n</li>\n<li>\n<p>Send API requests and\
    \ include the token in the X-Auth-Token HTTP header. The\n following HTTP requests\
    \ use the same token until the requests complete.</p>\n</li>\n<li>\n<p>If a 401\
    \ Unauthorized error returned, the request requires a new token.</p>\n</li>\n\
    </ul>\n<h3>Debug Authentication</h3>\n<p>The below use cURL commands to show your\
    \ how to debug authentication request.\nFor information about cURL, see <a href=\"\
    http://curl.haxx.se/\">http://curl.haxx.se/</a>. For information\nabout the OpenStack\
    \ APIs, see <a href=\"http://developer.openstack.org/api-ref.html\">OpenStack\
    \ API Reference</a>.</p>\n<p>To get a valid token, you need 3 parameters:</p>\n\
    <ul>\n<li>\n<p>username</p>\n</li>\n<li>\n<p>password</p>\n</li>\n<li>\n<p>project\
    \ name/project id</p>\n</li>\n</ul>\n<p>The below shows a code to get token:</p>\n\
    <p>```</p>\n<p>curl -s -X POST https://keystone.rc.nectar.org.au:5000/v2.0/tokens\
    \ \\</p>\n<pre><code>        -H \"Content-Type: application/json\" \\\n\n    \
    \    -d '{\"auth\": {\"tenantName\": \"'\"$OS_TENANT_NAME\"'\", \"passwordCredentials\"\
    :\n\n        {\"username\": \"'\"$OS_USERNAME\"'\", \"password\": \"'\"$OS_PASSWORD\"\
    '\"}}}' \\\n\n        | python -m json.tool\n</code></pre>\n<p>```</p>\n<p>You\
    \ need to replace the username, password and tenantname with the values in\nthe\
    \ authentication script file you obtained from the NeCTAR Dashboard.</p>\n<p>The\
    \ response would look like below:</p>\n<p>```</p>\n<p>{\n    \"access\": {\n \
    \       \"metadata\": {\n            \"is_admin\": 0,\n            \"roles\":\
    \ [\n                \"22\",\n                \"143\"\n            ]\n       \
    \ },\n        \"serviceCatalog\": [\n            {\n                \"endpoints\"\
    : [\n                    {\n                        \"adminURL\": \"https://nova.rc.abc:8774/v1.1/\"\
    ,\n                        \"internalURL\": \"https://nova.rc.abc:8774/v1.1/\"\
    ,\n                        \"publicURL\": \"https://nova.rc.abc:8774/v1.1/\",\n\
    \                        \"region\": \"Melbourne\"\n                    }\n  \
    \              ],\n                \"endpoints_links\": [],\n                \"\
    name\": \"Compute Service\",\n                \"type\": \"compute\"\n        \
    \    }\n        ],\n        \"token\": {\n            \"audit_ids\": [\n     \
    \           \"SUtsLIdWQJ634dfdsfdsffdszVe6D2ijg\"\n            ],\n          \
    \  \"expires\": \"2015-10-15T10:08:53Z\",\n            \"id\": \"MIIUsdfsfsd2AYJKoZIhvcNAQcCoIIUyTCCFMUCAQ.........eaL6Z8h\"\
    ,\n            \"issued_at\": \"2015-10-15T04:08:53.231576\",\n            \"\
    tenant\": {\n                \"allocation_id\": 170,\n                \"description\"\
    : null,\n                \"enabled\": true,\n                \"expires\": \"2018-07-01\"\
    ,\n                \"id\": \"e4c1e4e82cd5495d89d52d694ea62e50sdadsweqe\",\n  \
    \              \"name\": \"Marine-VL\"\n            }\n        },\n        \"\
    user\": {\n            \"id\": \"\",\n            \"name\": \"\",\n          \
    \  \"roles\": [\n                {\n                    \"name\": \"Member\"\n\
    \                },\n                {\n                    \"name\": \"TenantManager\"\
    \n                }\n            ],\n            \"roles_links\": [],\n      \
    \      \"username\": \"\"\n        }\n    }\n}</p>\n<p>```</p>\n<p>Then you can\
    \ use the token obtained from this output in the API for authentication.</p>\n\
    <p>Following is an example of how to use the token in using Nova API to list flavors:</p>\n\
    <p>```</p>\n<p>curl -s -H \\</p>\n<pre><code>        \"X-Auth-Token:token\" \\\
    \n\n        http://8.21.28.222:8774/v2/tenant_id/flavors \\\n\n        | python\
    \ -m json.tool\n</code></pre>\n<p>```</p>\n<p>You need to replace the token and\
    \ the URL. You can find the Nova API endpoint\nURL from the NeCTAR <a href=\"\
    https://dashboard.rc.nectar.org.au\">Dashboard</a>. The above request would return\
    \ the\nfollowing output:</p>\n<p>```</p>\n<p>{\n    \"flavors\": [\n        {\n\
    \            \"id\": \"1\",\n            \"links\": [\n                {\n   \
    \                 \"href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/1\"\
    ,\n                    \"rel\": \"self\"\n                },\n               \
    \ {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/1\"\
    ,\n                    \"rel\": \"bookmark\"\n                }\n            ],\n\
    \            \"name\": \"m1.tiny\"\n        },\n        {\n            \"id\"\
    : \"2\",\n            \"links\": [\n                {\n                    \"\
    href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/2\"\
    ,\n                    \"rel\": \"self\"\n                },\n               \
    \ {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/2\"\
    ,\n                    \"rel\": \"bookmark\"\n                }\n            ],\n\
    \            \"name\": \"m1.small\"\n        },\n        {\n            \"id\"\
    : \"3\",\n            \"links\": [\n                {\n                    \"\
    href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/3\"\
    ,\n                    \"rel\": \"self\"\n                },\n               \
    \ {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/3\"\
    ,\n                    \"rel\": \"bookmark\"\n                }\n            ],\n\
    \            \"name\": \"m1.medium\"\n        },\n        {\n            \"id\"\
    : \"4\",\n            \"links\": [\n                {\n                    \"\
    href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/4\"\
    ,\n                    \"rel\": \"self\"\n                },\n               \
    \ {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/4\"\
    ,\n                    \"rel\": \"bookmark\"\n                }\n            ],\n\
    \            \"name\": \"m1.large\"\n        },\n        {\n            \"id\"\
    : \"5\",\n            \"links\": [\n                {\n                    \"\
    href\": \"http://8.21.28.222:8774/v2/f9828a18c6484624b571e85728780ba8/flavors/5\"\
    ,\n                    \"rel\": \"self\"\n                },\n               \
    \ {\n                    \"href\": \"http://8.21.28.222:8774/f9828a18c6484624b571e85728780ba8/flavors/5\"\
    ,\n                    \"rel\": \"bookmark\"\n                }\n            ],\n\
    \            \"name\": \"m1.xlarge\"\n        }\n    ]\n}</p>\n<p>```</p>"
  parent: 41
  sha1: 2fe4990b09f16547777dcccbc4d135ec6397c94b
  title: Trouble Shooting
83:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-03T22:17:26-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Quick reference for shell commands in the Cloud Basics articles\
          \ \n Although you can set up your VM with a remote desktop (see the NeCTAR\
          \ Training modules),\nthe most efficient way to use your linux VM is by\
          \ command-line. \n There are some excellent tutorials for basic shell commands\
          \ (also called unix or bash commands).\nCodecademy offers an excellent,\
          \ free, interactive tutorial that you can complete within your browser on\
          \ any operating system. \n You may also like to print off a cheatsheet of\
          \ shell commands, such as this simple one page sheet,\nor one of these more\
          \ thorough references: Learncodethehardway or GitHubGist \n Here are some\
          \ particular commands used in the Cloud Basics articles, for quick reference.\
          \ \n Commands to use on your Mac/Linux to set up your NeCTAR connection\
          \ \n\n\n\nCommand\nAction\n\n\n\n\nssh-keygen -t rsa -f Nectar_Key\ngenerate\
          \ a keypair locally\n\n\nchmod 600 ~/.ssh/Nectar_Key\nsecure your private\
          \ key\n\n\nssh -i Nectar_Key ubuntu@XX.XX.XX.XX\nSSH access to the VM\n\n\
          \n\n Commands to enter on your VM console during set-up \n\n\n\nCommand\n\
          Action\n\n\n\n\nsudo passwd ubuntu\nset a password for user 'ubuntu'\n\n\
          \nsudo chown ubuntu /mnt\nmake the ephemeral disk writable\n\n\nsudo mkfs.ext4\
          \ /dev/vdc\nformat a new, empty volume\n\n\nsudo mkdir /volume_name\ncreate\
          \ an empty directory for the volume\n\n\nsudo mount /dev/vdc /volume_name\
          \ -t auto\nmount the volume\n\n\nsudo chown ubuntu /volume_name\nmake the\
          \ mounted volume writable\n\n\nlsblk -l\nlist the block storage\n\n\ndf\
          \ -hT\ndisplay the disk usage\n\n\ndu -h <path/to/directory>\ndisplay directory\
          \ and file sizes\n\n\ntop\nactivity monitor for your VM\n\n\nps\nlist the\
          \ running processes on your VM (with PID#)\n\n\nkill <PID#>\nterminate the\
          \ process by PID number\n\n\ncontrol + 'c'\nstops a process running in your\
          \ terminal\n\n\nsudo apt-get update\nupdates the list of packages available\
          \ to install\n\n\nsudo apt-get upgrade\nupgrades the installed packages\n\
          \n\napt-cache search <name>\nsearch for a package to install\n\n\nsudo apt-get\
          \ install <name>\ninstall a package\n\n\nnohup <normal commands go here>\
          \ 2>&1 &\nkeep a job running in the background\n\n\njobs\nlist the active\
          \ jobs (with job numbers)\n\n\ncontrol + 'z'\npause a job running in the\
          \ foreground\n\n\ndisown %n\ndetach a (paused) job from the terminal session\
          \ (n=job number)\n\n\nbg %n\nmove a (paused) job to the background (n=job\
          \ number)\n\n\n"
        description: '<h2>Quick reference for shell commands in the Cloud Basics articles</h2>

          <p>Although you can set up your VM with a remote desktop (see the NeCTAR
          Training modules),

          the most efficient way to use your linux VM is by command-line.</p>

          <p>There are some excellent tutorials for basic shell commands (also called
          unix or bash commands).

          <a href="https://www.codecademy.com/learn/learn-the-command-line">Codecademy</a>
          offers an excellent, free, interactive tutorial that you can complete within
          your browser on any operating system.</p>

          <p>You may also like to print off a cheatsheet of shell commands, such as
          this <a href="https://ubuntudanmark.dk/filer/fwunixref.pdf">simple one page
          sheet</a>,

          or one of these more thorough references: <a href="http://cli.learncodethehardway.org/bash_cheat_sheet.pdf">Learncodethehardway</a>
          or <a href="https://gist.github.com/LeCoupa/122b12050f5fb267e75f">GitHubGist</a></p>

          <p>Here are some particular commands used in the Cloud Basics articles,
          for quick reference.</p>

          <h3>Commands to use on your Mac/Linux to set up your NeCTAR connection</h3>

          <table>

          <thead>

          <tr>

          <th>Command</th>

          <th>Action</th>

          </tr>

          </thead>

          <tbody>

          <tr>

          <td><code>ssh-keygen -t rsa -f Nectar_Key</code></td>

          <td>generate a keypair locally</td>

          </tr>

          <tr>

          <td><code>chmod 600 ~/.ssh/Nectar_Key</code></td>

          <td>secure your private key</td>

          </tr>

          <tr>

          <td><code>ssh -i Nectar_Key ubuntu@XX.XX.XX.XX</code></td>

          <td>SSH access to the VM</td>

          </tr>

          </tbody>

          </table>

          <h3>Commands to enter on your VM console during set-up</h3>

          <table>

          <thead>

          <tr>

          <th>Command</th>

          <th>Action</th>

          </tr>

          </thead>

          <tbody>

          <tr>

          <td><code>sudo passwd ubuntu</code></td>

          <td>set a password for user ''ubuntu''</td>

          </tr>

          <tr>

          <td><code>sudo chown ubuntu /mnt</code></td>

          <td>make the ephemeral disk writable</td>

          </tr>

          <tr>

          <td><code>sudo mkfs.ext4 /dev/vdc</code></td>

          <td>format a new, empty volume</td>

          </tr>

          <tr>

          <td><code>sudo mkdir /volume_name</code></td>

          <td>create an empty directory for the volume</td>

          </tr>

          <tr>

          <td><code>sudo mount /dev/vdc /volume_name -t auto</code></td>

          <td>mount the volume</td>

          </tr>

          <tr>

          <td><code>sudo chown ubuntu /volume_name</code></td>

          <td>make the mounted volume writable</td>

          </tr>

          <tr>

          <td><code>lsblk -l</code></td>

          <td>list the block storage</td>

          </tr>

          <tr>

          <td><code>df -hT</code></td>

          <td>display the disk usage</td>

          </tr>

          <tr>

          <td><code>du -h &lt;path/to/directory&gt;</code></td>

          <td>display directory and file sizes</td>

          </tr>

          <tr>

          <td><code>top</code></td>

          <td>activity monitor for your VM</td>

          </tr>

          <tr>

          <td><code>ps</code></td>

          <td>list the running processes on your VM (with PID#)</td>

          </tr>

          <tr>

          <td><code>kill &lt;PID#&gt;</code></td>

          <td>terminate the process by PID number</td>

          </tr>

          <tr>

          <td>control + ''c''</td>

          <td>stops a process running in your terminal</td>

          </tr>

          <tr>

          <td><code>sudo apt-get update</code></td>

          <td>updates the list of packages available to install</td>

          </tr>

          <tr>

          <td><code>sudo apt-get upgrade</code></td>

          <td>upgrades the installed packages</td>

          </tr>

          <tr>

          <td><code>apt-cache search &lt;name&gt;</code></td>

          <td>search for a package to install</td>

          </tr>

          <tr>

          <td><code>sudo apt-get install &lt;name&gt;</code></td>

          <td>install a package</td>

          </tr>

          <tr>

          <td><code>nohup &lt;normal commands go here&gt; 2&gt;&amp;1 &amp;</code></td>

          <td>keep a job running in the background</td>

          </tr>

          <tr>

          <td><code>jobs</code></td>

          <td>list the active jobs (with job numbers)</td>

          </tr>

          <tr>

          <td>control + ''z''</td>

          <td>pause a job running in the foreground</td>

          </tr>

          <tr>

          <td><code>disown %n</code></td>

          <td>detach a (paused) job from the terminal session (n=job number)</td>

          </tr>

          <tr>

          <td><code>bg %n</code></td>

          <td>move a (paused) job to the background (n=job number)</td>

          </tr>

          </tbody>

          </table>'
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 21
        id: 6000084190
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-08T22:20:33-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000084190
        position: 10
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Quick Reference for Commands
        updated_at: '2015-11-08T22:20:33-05:00'
        user_id: 6002464727
  html: '<h2>Quick reference for shell commands in the Cloud Basics articles</h2>

    <p>Although you can set up your VM with a remote desktop (see the NeCTAR Training
    modules),

    the most efficient way to use your linux VM is by command-line.</p>

    <p>There are some excellent tutorials for basic shell commands (also called unix
    or bash commands).

    <a href="https://www.codecademy.com/learn/learn-the-command-line">Codecademy</a>
    offers an excellent, free, interactive tutorial that you can complete within your
    browser on any operating system.</p>

    <p>You may also like to print off a cheatsheet of shell commands, such as this
    <a href="https://ubuntudanmark.dk/filer/fwunixref.pdf">simple one page sheet</a>,

    or one of these more thorough references: <a href="http://cli.learncodethehardway.org/bash_cheat_sheet.pdf">Learncodethehardway</a>
    or <a href="https://gist.github.com/LeCoupa/122b12050f5fb267e75f">GitHubGist</a></p>

    <p>Here are some particular commands used in the Cloud Basics articles, for quick
    reference.</p>

    <h3>Commands to use on your Mac/Linux to set up your NeCTAR connection</h3>

    <table>

    <thead>

    <tr>

    <th>Command</th>

    <th>Action</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>ssh-keygen -t rsa -f Nectar_Key</code></td>

    <td>generate a keypair locally</td>

    </tr>

    <tr>

    <td><code>chmod 600 ~/.ssh/Nectar_Key</code></td>

    <td>secure your private key</td>

    </tr>

    <tr>

    <td><code>ssh -i Nectar_Key ubuntu@XX.XX.XX.XX</code></td>

    <td>SSH access to the VM</td>

    </tr>

    </tbody>

    </table>

    <h3>Commands to enter on your VM console during set-up</h3>

    <table>

    <thead>

    <tr>

    <th>Command</th>

    <th>Action</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><code>sudo passwd ubuntu</code></td>

    <td>set a password for user ''ubuntu''</td>

    </tr>

    <tr>

    <td><code>sudo chown ubuntu /mnt</code></td>

    <td>make the ephemeral disk writable</td>

    </tr>

    <tr>

    <td><code>sudo mkfs.ext4 /dev/vdc</code></td>

    <td>format a new, empty volume</td>

    </tr>

    <tr>

    <td><code>sudo mkdir /volume_name</code></td>

    <td>create an empty directory for the volume</td>

    </tr>

    <tr>

    <td><code>sudo mount /dev/vdc /volume_name -t auto</code></td>

    <td>mount the volume</td>

    </tr>

    <tr>

    <td><code>sudo chown ubuntu /volume_name</code></td>

    <td>make the mounted volume writable</td>

    </tr>

    <tr>

    <td><code>lsblk -l</code></td>

    <td>list the block storage</td>

    </tr>

    <tr>

    <td><code>df -hT</code></td>

    <td>display the disk usage</td>

    </tr>

    <tr>

    <td><code>du -h &lt;path/to/directory&gt;</code></td>

    <td>display directory and file sizes</td>

    </tr>

    <tr>

    <td><code>top</code></td>

    <td>activity monitor for your VM</td>

    </tr>

    <tr>

    <td><code>ps</code></td>

    <td>list the running processes on your VM (with PID#)</td>

    </tr>

    <tr>

    <td><code>kill &lt;PID#&gt;</code></td>

    <td>terminate the process by PID number</td>

    </tr>

    <tr>

    <td>control + ''c''</td>

    <td>stops a process running in your terminal</td>

    </tr>

    <tr>

    <td><code>sudo apt-get update</code></td>

    <td>updates the list of packages available to install</td>

    </tr>

    <tr>

    <td><code>sudo apt-get upgrade</code></td>

    <td>upgrades the installed packages</td>

    </tr>

    <tr>

    <td><code>apt-cache search &lt;name&gt;</code></td>

    <td>search for a package to install</td>

    </tr>

    <tr>

    <td><code>sudo apt-get install &lt;name&gt;</code></td>

    <td>install a package</td>

    </tr>

    <tr>

    <td><code>nohup &lt;normal commands go here&gt; 2&gt;&amp;1 &amp;</code></td>

    <td>keep a job running in the background</td>

    </tr>

    <tr>

    <td><code>jobs</code></td>

    <td>list the active jobs (with job numbers)</td>

    </tr>

    <tr>

    <td>control + ''z''</td>

    <td>pause a job running in the foreground</td>

    </tr>

    <tr>

    <td><code>disown %n</code></td>

    <td>detach a (paused) job from the terminal session (n=job number)</td>

    </tr>

    <tr>

    <td><code>bg %n</code></td>

    <td>move a (paused) job to the background (n=job number)</td>

    </tr>

    </tbody>

    </table>'
  parent: 21
  sha1: 13c13cd4896f70425a317c11c3ca41da251485fc
  title: Quick Reference for Commands
84:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-05T20:19:42-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Contents \n \n Snapshot of an Instance \n Snapshot of Volume\
          \ Storage \n Backing Up Data \n \n See Training Module 9 for more detail\
          \ on snapshots and backups. \n About Snapshots \n A snapshot is a way to\
          \ create a copy of the disk state of your virtual machine (VM). \nThere\
          \ are two main reasons you would take a snapshot of your VM: \n \n To back-up\
          \ the VM set-up - you can restore an instance from the snapshot \n To create\
          \ a template image which can be used to launch instances which are already\
          \ set-up. \n \n NOTE: The snapshot only creates an image of the primary\
          \ 'root' disk, not the secondary 'ephemeral' storage or mounted volumes.\
          \ \n The primary 'root' disk is small (5-30GB) and is not suitable for storing\
          \ significant data. \nCreating an image of your VM is preserving the computer\
          \ set-up such as software installation,\nconfigurations and profiles. Backing\
          \ up data will be covered later in this article. \n \n Creating a Snapshot\
          \ of an Instance (an Image) \n \n Log on to the NeCTAR Dashboard and click\
          \ on the 'Instances' tab \n It is not necessary, but good practice, to 'pause\
          \ instance' from the 'Actions' drop down list. \n Click 'Create Snapshot'\
          \ from the 'Actions' drop down list. \n Enter a descriptive name for the\
          \ Snapshot \n It will now take some time to create the Snapshot.  \n The\
          \ snapshotted image will be saved in the 'Project' tab of the 'Images' section.\
          \ \n \n Launching an Instance from a saved Image \n \n On the NeCTAR Dashboard,\
          \ navigate to 'Images'\n \n Choose the 'Project' tab \n Click 'Launch' in\
          \ the 'Actions' list for the image you wish to restore. \n You can choose\
          \ a different 'Flavour' (i.e. size) of instance, but it must be large \n\
          \ enough to fit the image on the primary 'root' disk. \n Name the instance,\
          \ set the keypair and security groups in the 'Access and Security' tab,\n\
          \ and set the 'Availability Zone' if necessary (e.g. to ensure the same\
          \ zone as your volume storage). \n This is just like launching a new instance,\
          \ except that the new VM will already have the settings,\n configurations\
          \ and installations of the original VM. \n Access as per usual, with SSH\
          \ keys and the IP address of the new instance. \n \n NOTE: The new VM will\
          \ have a new, empty secondary 'ephemeral' storage disk. This will\nneed\
          \ to be made writable with the command: \nsudo chown ubuntu /mnt \n If required,\
          \ existing volume storage will need to be attached, mounted and made writable\
          \ also.  \nAttach on the NeCTAR Dashboard -> Volumes -> Edit Attachments\
          \ \nThen access the VM command line and enter: \nsudo mkdir /volume_name\
          \ \nsudo mount /dev/vdc /volume_name -t auto \nsudo chown ubuntu /volume_name\
          \ \n \n \n Snapshots of Volume Storage \n Snapshots can also be made to\
          \ copy the disk state of your Volume block storage.\nThis is useful for\
          \ preserving the state of your Volume in an image, in order to \ncreate\
          \ a new Volume from it at a later time. The volume snapshots use up your\
          \ volume\ndata allocation, for the full size of the volume. Volume snapshots\
          \ are not designed as a method of\nbacking up data - see data backup suggestions\
          \ later in this article. \n \n On the NeCTAR Dashboard, navigate to 'Volumes'\n\
          \ \n The volume should be unnattached from an instance: Click 'Edit Attachments'\n\
          \ in the 'Actions' list, then 'Detach Volume'. \n Click 'Create Snapshot'\
          \ in the 'Actions' list. \n \n The snapshot is found in the 'Volume Snapshots'\
          \ tab. \n \n \n In the 'Actions' drop down list, you can create a new volume\
          \ from the snapshot,\n edit the name, or delete the snapshot when it is\
          \ no longer needed (to recover the volume storage space it uses). \n \n\
          \ \n \n Backing Up your Data \n \n As discussed earlier in this article,\
          \ Instance snapshots don't copy the larger disks\nthat are used for data\
          \ storage, and Volume snapshots are inefficient as a data back-up strategy.\
          \ \n The source for the back-up will be the secondary 'ephemeral' storage\
          \ disk, or\nfrom volume block storage. \n The destination for the back-up\
          \ may be your local computer, or a data storage \nserver at your research\
          \ organisation. \n Compressed File Transfers \n The simplest back-up is\
          \ to compress a directory and transfer it from your VM to your back-up destination.\
          \ \n The general comand structure to compress files: \ntar -cvpzf <NameOfArchive>.tar.gz\
          \ <list of your files or folders> \n To copy a directory ( /mnt/data ) into\
          \ a single, compressed file ( data.tar.gz ):  \n tar -cvpzf data.tar.gz\
          \ /mnt/data \n The compressed file can be transferred to another computer\
          \ using FileZilla (for a local\ncomputer back-up), or SCP to back-up on\
          \ a remote server (see the Cloud Basics article: Transferring Data) \n scp\
          \ <Path_To_Source_File> <Path_to_Destination>   \n e.g. scp ~/data.tar.gz\
          \ username@remote.host.edu.au:data/directory \nor, scp -i path/to/key ~/data.tar.gz\
          \ username@remote.host.edu.au:data/directory  \n Backing up with RSYNC \n\
          \ This is a utility that creates incremental backups, such that the most\
          \ recent synced state \nof a source directory is 'mirrored' in a directory\
          \ on the destination storage device. \n Syncing is a more efficient way\
          \ of backing up data, as after the first sync, only modifications to the\
          \ files will be transferred. \n \n RSYNC must be installed on the source\
          \ computer (the VM) and the destination computer. \n RSYNC is pre-installed\
          \ on MacOSX \n On Ubuntu, enter sudo apt-get install rsync\n \n On Windows,\
          \ installation is through the Cygwin package and usage is more complicated.\
          \ \n \n The general command for creating or syncing the back-up:   \n rsync\
          \ -av <source directory> <destination directory> \nor, \nrsync -av -e -i\
          \ <path-to-private-key> <source directory> <destination directory> \n To\
          \ sync from the Terminal app. on your local computer, from the directory\
          \ you are syncing into: \n rsync -av ubuntu@NNN.NNN.NNN.NNN:/mnt/data/ dataCopy/\
          \  (this syncs data from the VM) \nrsync -av dataCopy/ ubuntu@NNN.NNN.NNN.NNN:/mnt/data/\
          \ (this will restore data to the VM) \n To sync from the VM command line\
          \ to a remote server: \nrsync -av /mnt/data/ username@remote.host.edu.au:data/directory/\
          \   \n and to restore:  \nrsync -av username@remote.host.edu.au:data/directory/\
          \ /mnt/data/   \n Backing up Volumes to the Object Storage \n This can be\
          \ done with OpenStack commands. See Training Module 10 for instructions\n\
          on using OpenStack commands to manage your cloud computing. "
        description: "<h2>Contents</h2>\n<ul>\n<li><a href=\"#Instance\">Snapshot\
          \ of an Instance</a></li>\n<li><a href=\"#Volume\">Snapshot of Volume Storage</a></li>\n\
          <li><a href=\"#Backup\">Backing Up Data</a></li>\n</ul>\n<p>See <a href=\"\
          http://training.nectar.org.au/package09/sections/index.html\">Training Module\
          \ 9</a> for more detail on snapshots and backups.</p>\n<h2>About Snapshots</h2>\n\
          <p>A snapshot is a way to create a copy of the disk state of your virtual\
          \ machine (VM).<br>\nThere are two main reasons you would take a snapshot\
          \ of your VM:</p>\n<ol>\n<li>To <strong>back-up the VM set-up</strong> -\
          \ you can restore an instance from the snapshot</li>\n<li>To create a <strong>template\
          \ image</strong> which can be used to launch instances which are already\
          \ set-up.</li>\n</ol>\n<p>NOTE: The snapshot only creates an image of the\
          \ primary 'root' disk, not the secondary 'ephemeral' storage or mounted\
          \ volumes.</p>\n<p>The primary 'root' disk is small (5-30GB) and is not\
          \ suitable for storing significant data. \nCreating an image of your VM\
          \ is preserving the computer set-up such as software installation,\nconfigurations\
          \ and profiles. <a href=\"#Backup\">Backing up data will be covered later\
          \ in this article</a>.</p>\n<p><a name=\"Instance\"></a></p>\n<h2>Creating\
          \ a Snapshot of an Instance (an Image)</h2>\n<ul>\n<li>Log on to the <a\
          \ href=\"https://dashboard.rc.nectar.org.au\">NeCTAR Dashboard</a> and click\
          \ on the <strong>'Instances'</strong> tab</li>\n<li>It is not necessary,\
          \ but good practice, to <strong>'pause instance'</strong> from the '<strong>Actions</strong>'\
          \ drop down list.</li>\n<li>Click '<strong>Create Snapshot</strong>' from\
          \ the 'Actions' drop down list.</li>\n<li>Enter a descriptive name for the\
          \ Snapshot</li>\n<li>It will now take some time to create the Snapshot.\
          \ </li>\n<li>The snapshotted image will be saved in the '<strong>Project</strong>'\
          \ tab of the '<strong>Images</strong>' section.</li>\n</ul>\n<h2>Launching\
          \ an Instance from a saved Image</h2>\n<ul>\n<li>On the <a href=\"https://dashboard.rc.nectar.org.au\"\
          >NeCTAR Dashboard</a>, navigate to <strong>'Images'</strong>\n</li>\n<li>Choose\
          \ the <strong>'Project'</strong> tab</li>\n<li>Click <strong>'Launch'</strong>\
          \ in the <strong>'Actions'</strong> list for the image you wish to restore.</li>\n\
          <li>You can choose a different <strong>'Flavour'</strong> (i.e. size) of\
          \ instance, but it must be large \n enough to fit the image on the primary\
          \ 'root' disk.</li>\n<li>Name the instance, set the keypair and security\
          \ groups in the <strong>'Access and Security'</strong> tab,\n and set the\
          \ <strong>'Availability Zone'</strong> if necessary (e.g. to ensure the\
          \ same zone as your volume storage).</li>\n<li>This is just like launching\
          \ a new instance, except that the new VM will already have the settings,\n\
          \ configurations and installations of the original VM.</li>\n<li>Access\
          \ as per usual, with SSH keys and the IP address of the new instance.</li>\n\
          </ul>\n<p>NOTE: The new VM will have a new, empty <strong>secondary 'ephemeral'\
          \ storage</strong> disk. This will\nneed to be made writable with the command:<br>\n\
          <code>sudo chown ubuntu /mnt</code></p>\n<p>If required, existing <strong>volume\
          \ storage</strong> will need to be attached, mounted and made writable also.\
          \ <br>\nAttach on the <a href=\"https://dashboard.rc.nectar.org.au\">NeCTAR\
          \ Dashboard</a> -&gt; <strong>Volumes</strong> -&gt; <strong>Edit Attachments</strong><br>\n\
          Then access the VM command line and enter:<br>\n<code>sudo mkdir /volume_name</code><br>\n\
          <code>sudo mount /dev/vdc /volume_name -t auto</code><br>\n<code>sudo chown\
          \ ubuntu /volume_name</code></p>\n<hr>\n<p><a name=\"Volume\"></a></p>\n\
          <h2>Snapshots of Volume Storage</h2>\n<p>Snapshots can also be made to copy\
          \ the disk state of your Volume block storage.\nThis is useful for preserving\
          \ the state of your Volume in an image, in order to \ncreate a new Volume\
          \ from it at a later time. The volume snapshots use up your volume\ndata\
          \ allocation, for the full size of the volume. Volume snapshots are not\
          \ designed as a method of\nbacking up data - <a href=\"#Backup\">see data\
          \ backup suggestions later in this article</a>.</p>\n<ul>\n<li>On the <a\
          \ href=\"https://dashboard.rc.nectar.org.au\">NeCTAR Dashboard</a>, navigate\
          \ to <strong>'Volumes'</strong>\n</li>\n<li>The volume should be unnattached\
          \ from an instance: Click '<strong>Edit Attachments</strong>'\n in the <strong>'Actions'</strong>\
          \ list, then '<strong>Detach Volume</strong>'.</li>\n<li>Click '<strong>Create\
          \ Snapshot</strong>' in the <strong>'Actions'</strong> list.</li>\n<li>\n\
          <p>The snapshot is found in the '<strong>Volume Snapshots</strong>' tab.</p>\n\
          </li>\n<li>\n<p>In the '<strong>Actions</strong>' drop down list, you can\
          \ <strong>create a new volume</strong> from the snapshot,\n edit the name,\
          \ or delete the snapshot when it is no longer needed (to recover the volume\
          \ storage space it uses).</p>\n</li>\n</ul>\n<hr>\n<h2>Backing Up your Data\
          \ <a name=\"Backup\"></a>\n</h2>\n<p>As discussed earlier in this article,\
          \ Instance snapshots don't copy the larger disks\nthat are used for data\
          \ storage, and Volume snapshots are inefficient as a data back-up strategy.</p>\n\
          <p>The <strong>source</strong> for the back-up will be the secondary 'ephemeral'\
          \ storage disk, or\nfrom volume block storage.</p>\n<p>The <strong>destination</strong>\
          \ for the back-up may be your local computer, or a data storage \nserver\
          \ at your research organisation.</p>\n<h3>Compressed File Transfers</h3>\n\
          <p>The simplest back-up is to compress a directory and transfer it from\
          \ your VM to your back-up destination.</p>\n<p>The general comand structure\
          \ to compress files:<br>\n<code>tar -cvpzf &lt;NameOfArchive&gt;.tar.gz\
          \ &lt;list of your files or folders&gt;</code></p>\n<p>To copy a directory\
          \ ( /mnt/data ) into a single, compressed file ( data.tar.gz ): </p>\n<p><code>tar\
          \ -cvpzf data.tar.gz /mnt/data</code></p>\n<p>The compressed file can be\
          \ transferred to another computer using FileZilla (for a local\ncomputer\
          \ back-up), or SCP to back-up on a remote server (see the Cloud Basics article:\
          \ Transferring Data)</p>\n<p><code>scp &lt;Path_To_Source_File&gt; &lt;Path_to_Destination&gt;</code>\
          \  </p>\n<p>e.g. <code>scp ~/data.tar.gz username@remote.host.edu.au:data/directory</code><br>\n\
          or, <code>scp -i path/to/key ~/data.tar.gz username@remote.host.edu.au:data/directory</code>\
          \ </p>\n<h3>Backing up with RSYNC</h3>\n<p>This is a utility that creates\
          \ incremental backups, such that the most recent synced state \nof a source\
          \ directory is 'mirrored' in a directory on the destination storage device.</p>\n\
          <p>Syncing is a more efficient way of backing up data, as after the first\
          \ sync, only modifications to the files will be transferred.</p>\n<ul>\n\
          <li>RSYNC must be installed on the source computer (the VM) and the destination\
          \ computer.</li>\n<li>RSYNC is pre-installed on MacOSX</li>\n<li>On Ubuntu,\
          \ enter <code>sudo apt-get install rsync</code>\n</li>\n<li>On Windows,\
          \ installation is through the <a href=\"https://www.cygwin.com/\">Cygwin\
          \ package</a> and usage is more complicated.</li>\n</ul>\n<p>The general\
          \ command for creating or syncing the back-up:  </p>\n<p><code>rsync -av\
          \ &lt;source directory&gt; &lt;destination directory&gt;</code><br>\nor,<br>\n\
          <code>rsync -av -e -i &lt;path-to-private-key&gt; &lt;source directory&gt;\
          \ &lt;destination directory&gt;</code></p>\n<p>To sync from the Terminal\
          \ app. on your local computer, from the directory you are syncing into:</p>\n\
          <p><code>rsync -av ubuntu@NNN.NNN.NNN.NNN:/mnt/data/ dataCopy/</code>  (this\
          \ syncs data from the VM)<br>\n<code>rsync -av dataCopy/ ubuntu@NNN.NNN.NNN.NNN:/mnt/data/</code>\
          \ (this will restore data to the VM)</p>\n<p>To sync from the VM command\
          \ line to a remote server:<br>\n<code>rsync -av /mnt/data/ username@remote.host.edu.au:data/directory/</code>\
          \  </p>\n<p>and to restore: <br>\n<code>rsync -av username@remote.host.edu.au:data/directory/\
          \ /mnt/data/</code>  </p>\n<h3>Backing up Volumes to the Object Storage</h3>\n\
          <p>This can be done with OpenStack commands. See <a href=\"http://training.nectar.org.au/package10/sections/managingVolumes.html\"\
          >Training Module 10</a> for instructions\non using OpenStack commands to\
          \ manage your cloud computing.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 5
        id: 6000085112
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-08T17:48:24-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000085112
        position: 11
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Back-up and Restore
        updated_at: '2015-11-08T17:48:24-05:00'
        user_id: 6002464727
  html: "<h2>Contents</h2>\n<ul>\n<li><a href=\"#Instance\">Snapshot of an Instance</a></li>\n\
    <li><a href=\"#Volume\">Snapshot of Volume Storage</a></li>\n<li><a href=\"#Backup\"\
    >Backing Up Data</a></li>\n</ul>\n<p>See <a href=\"http://training.nectar.org.au/package09/sections/index.html\"\
    >Training Module 9</a> for more detail on snapshots and backups.</p>\n<h2>About\
    \ Snapshots</h2>\n<p>A snapshot is a way to create a copy of the disk state of\
    \ your virtual machine (VM).<br>\nThere are two main reasons you would take a\
    \ snapshot of your VM:</p>\n<ol>\n<li>To <strong>back-up the VM set-up</strong>\
    \ - you can restore an instance from the snapshot</li>\n<li>To create a <strong>template\
    \ image</strong> which can be used to launch instances which are already set-up.</li>\n\
    </ol>\n<p>NOTE: The snapshot only creates an image of the primary 'root' disk,\
    \ not the secondary 'ephemeral' storage or mounted volumes.</p>\n<p>The primary\
    \ 'root' disk is small (5-30GB) and is not suitable for storing significant data.\
    \ \nCreating an image of your VM is preserving the computer set-up such as software\
    \ installation,\nconfigurations and profiles. <a href=\"#Backup\">Backing up data\
    \ will be covered later in this article</a>.</p>\n<p><a name='Instance'></a></p>\n\
    <h2>Creating a Snapshot of an Instance (an Image)</h2>\n<ul>\n<li>Log on to the\
    \ <a href=\"https://dashboard.rc.nectar.org.au\">NeCTAR Dashboard</a> and click\
    \ on the <strong>'Instances'</strong> tab</li>\n<li>It is not necessary, but good\
    \ practice, to <strong>'pause instance'</strong> from the '<strong>Actions</strong>'\
    \ drop down list.</li>\n<li>Click '<strong>Create Snapshot</strong>' from the\
    \ 'Actions' drop down list.</li>\n<li>Enter a descriptive name for the Snapshot</li>\n\
    <li>It will now take some time to create the Snapshot. </li>\n<li>The snapshotted\
    \ image will be saved in the '<strong>Project</strong>' tab of the '<strong>Images</strong>'\
    \ section.</li>\n</ul>\n<h2>Launching an Instance from a saved Image</h2>\n<ul>\n\
    <li>On the <a href=\"https://dashboard.rc.nectar.org.au\">NeCTAR Dashboard</a>,\
    \ navigate to <strong>'Images'</strong></li>\n<li>Choose the <strong>'Project'</strong>\
    \ tab</li>\n<li>Click <strong>'Launch'</strong> in the <strong>'Actions'</strong>\
    \ list for the image you wish to restore.</li>\n<li>You can choose a different\
    \ <strong>'Flavour'</strong> (i.e. size) of instance, but it must be large \n\
    \ enough to fit the image on the primary 'root' disk.</li>\n<li>Name the instance,\
    \ set the keypair and security groups in the <strong>'Access and Security'</strong>\
    \ tab,\n and set the <strong>'Availability Zone'</strong> if necessary (e.g. to\
    \ ensure the same zone as your volume storage).</li>\n<li>This is just like launching\
    \ a new instance, except that the new VM will already have the settings,\n configurations\
    \ and installations of the original VM.</li>\n<li>Access as per usual, with SSH\
    \ keys and the IP address of the new instance.</li>\n</ul>\n<p>NOTE: The new VM\
    \ will have a new, empty <strong>secondary 'ephemeral' storage</strong> disk.\
    \ This will\nneed to be made writable with the command:<br>\n<code>sudo chown\
    \ ubuntu /mnt</code></p>\n<p>If required, existing <strong>volume storage</strong>\
    \ will need to be attached, mounted and made writable also. <br>\nAttach on the\
    \ <a href=\"https://dashboard.rc.nectar.org.au\">NeCTAR Dashboard</a> -&gt; <strong>Volumes</strong>\
    \ -&gt; <strong>Edit Attachments</strong><br>\nThen access the VM command line\
    \ and enter:<br>\n<code>sudo mkdir /volume_name</code><br>\n<code>sudo mount /dev/vdc\
    \ /volume_name -t auto</code><br>\n<code>sudo chown ubuntu /volume_name</code></p>\n\
    <hr>\n<p><a name='Volume'></a></p>\n<h2>Snapshots of Volume Storage</h2>\n<p>Snapshots\
    \ can also be made to copy the disk state of your Volume block storage.\nThis\
    \ is useful for preserving the state of your Volume in an image, in order to \n\
    create a new Volume from it at a later time. The volume snapshots use up your\
    \ volume\ndata allocation, for the full size of the volume. Volume snapshots are\
    \ not designed as a method of\nbacking up data - <a href=\"#Backup\">see data\
    \ backup suggestions later in this article</a>.</p>\n<ul>\n<li>On the <a href=\"\
    https://dashboard.rc.nectar.org.au\">NeCTAR Dashboard</a>, navigate to <strong>'Volumes'</strong></li>\n\
    <li>The volume should be unnattached from an instance: Click '<strong>Edit Attachments</strong>'\n\
    \ in the <strong>'Actions'</strong> list, then '<strong>Detach Volume</strong>'.</li>\n\
    <li>Click '<strong>Create Snapshot</strong>' in the <strong>'Actions'</strong>\
    \ list.</li>\n<li>\n<p>The snapshot is found in the '<strong>Volume Snapshots</strong>'\
    \ tab.</p>\n</li>\n<li>\n<p>In the '<strong>Actions</strong>' drop down list,\
    \ you can <strong>create a new volume</strong> from the snapshot,\n edit the name,\
    \ or delete the snapshot when it is no longer needed (to recover the volume storage\
    \ space it uses).</p>\n</li>\n</ul>\n<hr>\n<h2>Backing Up your Data <a name='Backup'></a></h2>\n\
    <p>As discussed earlier in this article, Instance snapshots don't copy the larger\
    \ disks\nthat are used for data storage, and Volume snapshots are inefficient\
    \ as a data back-up strategy.</p>\n<p>The <strong>source</strong> for the back-up\
    \ will be the secondary 'ephemeral' storage disk, or\nfrom volume block storage.</p>\n\
    <p>The <strong>destination</strong> for the back-up may be your local computer,\
    \ or a data storage \nserver at your research organisation.</p>\n<h3>Compressed\
    \ File Transfers</h3>\n<p>The simplest back-up is to compress a directory and\
    \ transfer it from your VM to your back-up destination.</p>\n<p>The general comand\
    \ structure to compress files:<br>\n<code>tar -cvpzf &lt;NameOfArchive&gt;.tar.gz\
    \ &lt;list of your files or folders&gt;</code></p>\n<p>To copy a directory ( /mnt/data\
    \ ) into a single, compressed file ( data.tar.gz ): </p>\n<p><code>tar -cvpzf\
    \ data.tar.gz /mnt/data</code></p>\n<p>The compressed file can be transferred\
    \ to another computer using FileZilla (for a local\ncomputer back-up), or SCP\
    \ to back-up on a remote server (see the Cloud Basics article: Transferring Data)</p>\n\
    <p><code>scp &lt;Path_To_Source_File&gt; &lt;Path_to_Destination&gt;</code>  </p>\n\
    <p>e.g. <code>scp ~/data.tar.gz username@remote.host.edu.au:data/directory</code><br>\n\
    or, <code>scp -i path/to/key ~/data.tar.gz username@remote.host.edu.au:data/directory</code>\
    \ </p>\n<h3>Backing up with RSYNC</h3>\n<p>This is a utility that creates incremental\
    \ backups, such that the most recent synced state \nof a source directory is 'mirrored'\
    \ in a directory on the destination storage device.</p>\n<p>Syncing is a more\
    \ efficient way of backing up data, as after the first sync, only modifications\
    \ to the files will be transferred.</p>\n<ul>\n<li>RSYNC must be installed on\
    \ the source computer (the VM) and the destination computer.</li>\n<li>RSYNC is\
    \ pre-installed on MacOSX</li>\n<li>On Ubuntu, enter <code>sudo apt-get install\
    \ rsync</code></li>\n<li>On Windows, installation is through the <a href=\"https://www.cygwin.com/\"\
    >Cygwin package</a> and usage is more complicated.</li>\n</ul>\n<p>The general\
    \ command for creating or syncing the back-up:  </p>\n<p><code>rsync -av &lt;source\
    \ directory&gt; &lt;destination directory&gt;</code><br>\nor,<br>\n<code>rsync\
    \ -av -e -i &lt;path-to-private-key&gt; &lt;source directory&gt; &lt;destination\
    \ directory&gt;</code></p>\n<p>To sync from the Terminal app. on your local computer,\
    \ from the directory you are syncing into:</p>\n<p><code>rsync -av ubuntu@NNN.NNN.NNN.NNN:/mnt/data/\
    \ dataCopy/</code>  (this syncs data from the VM)<br>\n<code>rsync -av dataCopy/\
    \ ubuntu@NNN.NNN.NNN.NNN:/mnt/data/</code> (this will restore data to the VM)</p>\n\
    <p>To sync from the VM command line to a remote server:<br>\n<code>rsync -av /mnt/data/\
    \ username@remote.host.edu.au:data/directory/</code>  </p>\n<p>and to restore:\
    \ <br>\n<code>rsync -av username@remote.host.edu.au:data/directory/ /mnt/data/</code>\
    \  </p>\n<h3>Backing up Volumes to the Object Storage</h3>\n<p>This can be done\
    \ with OpenStack commands. See <a href=\"http://training.nectar.org.au/package10/sections/managingVolumes.html\"\
    >Training Module 10</a> for instructions\non using OpenStack commands to manage\
    \ your cloud computing.</p>"
  parent: 21
  sha1: 9331d018fb124e3564a5fe829f1f94f5334ebe3b
  title: Back-up and Restore
85:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-05T20:35:27-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Contents \n \n FileZilla: GUI sftp client \n SCP: secure copy\
          \ \n SFTP via the command line \n \n FileZilla \n \n FileZilla is one of\
          \ many programs that provides easy, point-and-click SFTP (secure file transfer\
          \ protocol).\nNot only can you easily transfer files between your local\
          \ computer and your virtual machine (VM),\nbut you can also open and edit\
          \ documents that are on your VM, using programs on your local computer.\
          \ \n Download and Install FileZilla \n \n For Ubuntu - Install from the\
          \ Ubuntu Software Centre app \n Mac and Windows - Download the program file\
          \ FileZilla\n \n Double click file - follow installation instructions for\
          \ Windows \n For Mac - drag the filezilla.app file to your Applications\
          \ folder. \n Open FileZilla \n \n SFTP connection to the VM \n \n \n Click\
          \ the menu options \nFileZilla OR Edit -> Settings OR Preferences -> Connection\
          \ -> SFTP \n \n \n Click Add key file and navigate to the folder storing\
          \ your SSH keys.  \n \n \n \n \n \n For Mac and Ubuntu: \n \n \n The keys\
          \ are in '.ssh/' which will be hidden from view. There is a button in\n\
          \  the window to allow you to type the address; enter '.ssh' in the input\
          \ bar). \n \n \n OR, open your terminal and enter the command ln -s ~/.ssh\
          \ ~/ssh to create a symbolic \n  link called 'ssh' which will appear in\
          \ file lists.* \n \n \n Choose your private key (choose the version with\
          \ '.ppk' extension if available).\n FileZilla might ask to convert the fileformat.\
          \ Click OK. \n \n \n \n \n \n Open  File -> Site Manager .  \n Click New\
          \ Site and give it a name.  \n Insert the IP address of the instance as\
          \ Host\n \n \nLogon Type is interactive \n The user is 'ubuntu' (or 'root'\
          \ if your VM has a different operating system) \n Click Connect\n \n \n\
          \ \n FileZilla connection \n The left side of the FileZilla window will\
          \ list the files of your computer. \nThe right side will contain the folders\
          \ and files on the VM. \n \n Remember your primary disk (where your home\
          \ directory is located) usually has very little storage space.\nIn the VM\
          \ file list, navigate to the secondary disk '/mnt' or an attached volume\
          \ if available (e.g. '/MyVolume'). \n Make sure you have made these disks\
          \ writable, or you will not be able to transfer \n  data onto them.  If\
          \ you have not already done so, enter the following command/s in the console\
          \ of your VM. \n sudo chown ubuntu /mnt  and/or \n sudo chown ubuntu /MyVolume\
          \  (If you have attached a volume to your instanced. \n  Replace '/MyVolume'\
          \ with the directory in which it is mounted (mount point).  \n  To check\
          \ the mount point, enter lsblk -l or df -hT) \n \n \n Navigate to your data\
          \ storage directory in the right side of the FileZilla screen. \n \n \n\
          \ Drag and drop files and directories between your local computer and the\
          \ VM. \n \n \n Right click in the file list area to: \n \n Create a directory\
          \ or text file \n Edit a text document (you may need to adjust \n  FileZilla/Edit\
          \ -> Settings/Preferences ->  File Editing to ensure documents open in your\
          \ local computer's default text editor. \n Delete, download or rename files\
          \ or directories, etc. \n \n \n \n \n SCP: secure copy \n \n SCP is a simple\
          \ method for transferring files between computers.  \n The basic command\
          \ for Secure Copy is like a UNIX cp, but adding a connection to a different\
          \ computer in the file path \n scp <Path_To_Source_File> <Path_to_Destination>\
          \ \n Between a local Mac/Linux and the VM \n Enter the command from your\
          \ local computer's Terminal app.  \n To upload a file to the VM: \n scp\
          \ -i ~/.ssh/Nectar_Key <local-file-path> ubuntu@NNN.NNN.NNN.NNN:<instance-file-path>\
          \ \n To download a file from your VM: \n scp -i ~/.ssh/Nectar_Key ubuntu@NNN.NNN.NNN.NNN:<instance-file-path>\
          \ <local-file-path> \n Between your VM and a data storage server \n If you\
          \ have data stored on a remote server, you can transfer files between it\
          \ and the VM through the command-line on the VM. \n You will need a host\
          \ address for the data storage server, and your username, plus usually a\
          \ password. \n scp username@host.address.edu.au:/data/myDirectory/file.txt\
          \ /mnt/data/ \nscp /mnt/data/results.zip username@host.address.edu.au:/data/myDirectory/\
          \ \n You will usually then be prompted to enter the password for your data\
          \ storage. \n n.b. use scp -i path/to/key ... if your remote server has\
          \ ssh keys rather than password access. \n \n SFTP via the Command Line\
          \ \n \n Secure file transfer is also available between the VM and remote\
          \ data storage. \n Enter the 'sftp' command on your VM, and you will have\
          \ access to the remote host. \n sftp username@host.address.edu.au   - you\
          \ will usually be prompted for a password. \n or \n sftp -i path/to/key\
          \ username@host.address.edu.au  - if the remote server has ssh key authentication\
          \ \n You are now accessing the remote data storage server, and you can navigate\
          \ the files on the server\nas per usual with commands like cd and ls. \n\
          \ The commands get and put will transfer data between the machines: \n get\
          \ <remote_server_file.txt> </mnt/localVM_destination/> \n put </mnt/localVM_destination/file.txt>\
          \ <remote_directory/> \n to close the sftp connection, type exit. "
        description: "<h2>Contents</h2>\n<ol>\n<li><a href=\"#filezilla\">FileZilla:\
          \ GUI sftp client</a></li>\n<li><a href=\"#scp\">SCP: secure copy</a></li>\n\
          <li><a href=\"#sftp\">SFTP via the command line</a></li>\n</ol>\n<h2>FileZilla\
          \ <a name=\"filezilla\"></a>\n</h2>\n<p>FileZilla is one of many programs\
          \ that provides easy, point-and-click SFTP (secure file transfer protocol).\n\
          Not only can you easily transfer files between your local computer and your\
          \ virtual machine (VM),\nbut you can also open and edit documents that are\
          \ on your VM, using programs on your local computer.</p>\n<h3>Download and\
          \ Install FileZilla</h3>\n<ol>\n<li>For Ubuntu - Install from the Ubuntu\
          \ Software Centre app</li>\n<li>Mac and Windows - Download the program file\
          \ <a href=\"https://filezilla-project.org/download.php?type=client\">FileZilla</a>\n\
          </li>\n<li>Double click file - follow installation instructions for Windows</li>\n\
          <li>For Mac - drag the filezilla.app file to your Applications folder.</li>\n\
          <li>Open FileZilla</li>\n</ol>\n<h3>SFTP connection to the VM</h3>\n<ul>\n\
          <li>\n<p>Click the menu options<br>\n<strong><em>FileZilla OR Edit -&gt;\
          \ Settings OR Preferences -&gt; Connection -&gt; SFTP</em></strong></p>\n\
          </li>\n<li>\n<p>Click <strong><em>Add key file</em></strong> and navigate\
          \ to the folder storing your SSH keys. </p>\n</li>\n</ul>\n<p><img alt=\"\
          \" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/FZ_add_keyfile.png?raw=true\"\
          ></p>\n<ul>\n<li>\n<p><em>For Mac and Ubuntu:</em></p>\n</li>\n<li>\n<p><em>The\
          \ keys are in '.ssh/' which will be hidden from view. There is a button\
          \ in\n  the window to allow you to type the address; enter '.ssh' in the\
          \ input bar).</em></p>\n</li>\n<li>\n<p>OR, <em>open your terminal and </em>enter\
          \ the command <code>ln -s ~/.ssh ~/ssh</code> to create a symbolic \n  link\
          \ called 'ssh' which will appear in file lists.*</p>\n</li>\n<li>\n<p>Choose\
          \ your private key (choose the version with '.ppk' extension if available).\n\
          \ FileZilla might ask to convert the fileformat. Click OK.</p>\n</li>\n\
          </ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/FZ_select_keyfile.png?raw=true\"\
          ></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/FZ_ppk_keyfile.png?raw=true\"\
          ></p>\n<ol>\n<li>Open  <strong><em>File -&gt; Site Manager</em></strong>\
          \ . </li>\n<li>Click <strong><em>New Site</em></strong> and give it a name.\
          \ </li>\n<li>Insert the <em>IP address</em> of the instance as <strong><em>Host</em></strong>\n\
          </li>\n<li>\n<strong><em>Logon Type</em></strong> is interactive</li>\n\
          <li>The user is <strong>'ubuntu'</strong> (or 'root' if your VM has a different\
          \ operating system)</li>\n<li>Click <strong><em>Connect</em></strong>\n\
          </li>\n</ol>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/FZ_site_manager.png?raw=true\"\
          ></p>\n<h3>FileZilla connection</h3>\n<p>The left side of the FileZilla\
          \ window will list the files of your computer.<br>\nThe right side will\
          \ contain the folders and files on the VM.</p>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/FZ_transfer_files.png?raw=true\"\
          ></p>\n<p>Remember your primary disk (where your home directory is located)\
          \ usually has very little storage space.\nIn the VM file list, navigate\
          \ to the secondary disk '<strong>/mnt</strong>' or an attached volume if\
          \ available (e.g. '<strong>/MyVolume</strong>').</p>\n<p><strong>Make sure\
          \ you have made these disks writable, or you will not be able to transfer\
          \ \n  data onto them.</strong>  If you have not already done so, enter the\
          \ following command/s in the console of your VM.</p>\n<p><code>sudo chown\
          \ ubuntu /mnt</code>  and/or</p>\n<p><code>sudo chown ubuntu /MyVolume</code>\
          \  (If you have attached a volume to your instanced.<br>\n  Replace '/MyVolume'\
          \ with the directory in which it is mounted (mount point). <br>\n  To check\
          \ the mount point, enter <code>lsblk -l</code> or <code>df -hT</code>)</p>\n\
          <ul>\n<li>\n<p>Navigate to your data storage directory in the right side\
          \ of the FileZilla screen.</p>\n</li>\n<li>\n<p>Drag and drop files and\
          \ directories between your local computer and the VM.</p>\n</li>\n<li>\n\
          <p>Right click in the file list area to:</p>\n</li>\n<li>Create a directory\
          \ or text file</li>\n<li>Edit a text document (you may need to adjust \n\
          \  <strong><em>FileZilla/Edit -&gt; Settings/Preferences -&gt;  File Editing</em></strong>\
          \ to ensure documents open in your local computer's default text editor.</li>\n\
          <li>Delete, download or rename files or directories, etc.</li>\n</ul>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/FZ_edit_files.png?raw=true\"\
          ></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/FZ_save_files.png?raw=true\"\
          ></p>\n<hr>\n<h2>SCP: secure copy <a name=\"scp\"></a>\n</h2>\n<p>SCP is\
          \ a simple method for transferring files between computers. </p>\n<p>The\
          \ basic command for Secure Copy is like a UNIX <code>cp</code>, but adding\
          \ a connection to a different computer in the file path</p>\n<p><code>scp\
          \ &lt;Path_To_Source_File&gt; &lt;Path_to_Destination&gt;</code></p>\n<h3>Between\
          \ a local Mac/Linux and the VM</h3>\n<p>Enter the command from your local\
          \ computer's Terminal app. </p>\n<p>To upload a file to the VM:</p>\n<p><code>scp\
          \ -i ~/.ssh/Nectar_Key &lt;local-file-path&gt; ubuntu@NNN.NNN.NNN.NNN:&lt;instance-file-path&gt;</code></p>\n\
          <p>To download a file from your VM:</p>\n<p><code>scp -i ~/.ssh/Nectar_Key\
          \ ubuntu@NNN.NNN.NNN.NNN:&lt;instance-file-path&gt; &lt;local-file-path&gt;</code></p>\n\
          <h3>Between your VM and a data storage server</h3>\n<p>If you have data\
          \ stored on a remote server, you can transfer files between it and the VM\
          \ through the command-line on the VM.</p>\n<p>You will need a host address\
          \ for the data storage server, and your username, plus usually a password.</p>\n\
          <p><code>scp username@host.address.edu.au:/data/myDirectory/file.txt /mnt/data/</code><br>\n\
          <code>scp /mnt/data/results.zip username@host.address.edu.au:/data/myDirectory/</code></p>\n\
          <p>You will usually then be prompted to enter the password for your data\
          \ storage.</p>\n<p>n.b. use <code>scp -i path/to/key ...</code> if your\
          \ remote server has ssh keys rather than password access.</p>\n<hr>\n<h2>SFTP\
          \ via the Command Line <a name=\"sftp\"></a>\n</h2>\n<p>Secure file transfer\
          \ is also available between the VM and remote data storage.</p>\n<p>Enter\
          \ the 'sftp' command on your VM, and you will have access to the remote\
          \ host.</p>\n<p><code>sftp username@host.address.edu.au</code>   - you will\
          \ usually be prompted for a password.</p>\n<p>or</p>\n<p><code>sftp -i path/to/key\
          \ username@host.address.edu.au</code>  - if the remote server has ssh key\
          \ authentication</p>\n<p>You are now accessing the remote data storage server,\
          \ and you can navigate the files on the server\nas per usual with commands\
          \ like <code>cd</code> and <code>ls</code>.</p>\n<p>The commands <code>get</code>\
          \ and <code>put</code> will transfer data between the machines:</p>\n<p><code>get\
          \ &lt;remote_server_file.txt&gt; &lt;/mnt/localVM_destination/&gt;</code></p>\n\
          <p><code>put &lt;/mnt/localVM_destination/file.txt&gt; &lt;remote_directory/&gt;</code></p>\n\
          <p>to close the sftp connection, type <code>exit</code>.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 48
        id: 6000085114
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2016-01-04T22:48:22-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000085114
        position: 7
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Transferring Data to your VM
        updated_at: '2016-01-04T22:48:22-05:00'
        user_id: 6002464727
  html: "<h2>Contents</h2>\n<ol>\n<li><a href=\"#filezilla\">FileZilla: GUI sftp client</a></li>\n\
    <li><a href=\"#scp\">SCP: secure copy</a></li>\n<li><a href=\"#sftp\">SFTP via\
    \ the command line</a></li>\n</ol>\n<h2>FileZilla <a name=\"filezilla\"></a></h2>\n\
    <p>FileZilla is one of many programs that provides easy, point-and-click SFTP\
    \ (secure file transfer protocol).\nNot only can you easily transfer files between\
    \ your local computer and your virtual machine (VM),\nbut you can also open and\
    \ edit documents that are on your VM, using programs on your local computer.</p>\n\
    <h3>Download and Install FileZilla</h3>\n<ol>\n<li>For Ubuntu - Install from the\
    \ Ubuntu Software Centre app</li>\n<li>Mac and Windows - Download the program\
    \ file <a href=\"https://filezilla-project.org/download.php?type=client\">FileZilla</a></li>\n\
    <li>Double click file - follow installation instructions for Windows</li>\n<li>For\
    \ Mac - drag the filezilla.app file to your Applications folder.</li>\n<li>Open\
    \ FileZilla</li>\n</ol>\n<h3>SFTP connection to the VM</h3>\n<ul>\n<li>\n<p>Click\
    \ the menu options<br>\n<strong><em>FileZilla OR Edit -&gt; Settings OR Preferences\
    \ -&gt; Connection -&gt; SFTP</em></strong></p>\n</li>\n<li>\n<p>Click <strong><em>Add\
    \ key file</em></strong> and navigate to the folder storing your SSH keys. </p>\n\
    </li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/FZ_add_keyfile.png?raw=true\"\
    ></p>\n<ul>\n<li>\n<p><em>For Mac and Ubuntu:</em></p>\n</li>\n<li>\n<p><em>The\
    \ keys are in '.ssh/' which will be hidden from view. There is a button in\n \
    \ the window to allow you to type the address; enter '.ssh' in the input bar).</em></p>\n\
    </li>\n<li>\n<p>OR, <em>open your terminal and </em>enter the command <code>ln\
    \ -s ~/.ssh ~/ssh</code> to create a symbolic \n  link called 'ssh' which will\
    \ appear in file lists.*</p>\n</li>\n<li>\n<p>Choose your private key (choose\
    \ the version with '.ppk' extension if available).\n FileZilla might ask to convert\
    \ the fileformat. Click OK.</p>\n</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/FZ_select_keyfile.png?raw=true\"\
    ></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/FZ_ppk_keyfile.png?raw=true\"\
    ></p>\n<ol>\n<li>Open  <strong><em>File -&gt; Site Manager</em></strong> . </li>\n\
    <li>Click <strong><em>New Site</em></strong> and give it a name. </li>\n<li>Insert\
    \ the <em>IP address</em> of the instance as <strong><em>Host</em></strong></li>\n\
    <li><strong><em>Logon Type</em></strong> is interactive</li>\n<li>The user is\
    \ <strong>'ubuntu'</strong> (or 'root' if your VM has a different operating system)</li>\n\
    <li>Click <strong><em>Connect</em></strong></li>\n</ol>\n<p><img alt=\"\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/FZ_site_manager.png?raw=true\"\
    ></p>\n<h3>FileZilla connection</h3>\n<p>The left side of the FileZilla window\
    \ will list the files of your computer.<br>\nThe right side will contain the folders\
    \ and files on the VM.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/FZ_transfer_files.png?raw=true\"\
    ></p>\n<p>Remember your primary disk (where your home directory is located) usually\
    \ has very little storage space.\nIn the VM file list, navigate to the secondary\
    \ disk '<strong>/mnt</strong>' or an attached volume if available (e.g. '<strong>/MyVolume</strong>').</p>\n\
    <p><strong>Make sure you have made these disks writable, or you will not be able\
    \ to transfer \n  data onto them.</strong>  If you have not already done so, enter\
    \ the following command/s in the console of your VM.</p>\n<p><code>sudo chown\
    \ ubuntu /mnt</code>  and/or</p>\n<p><code>sudo chown ubuntu /MyVolume</code>\
    \  (If you have attached a volume to your instanced.<br>\n  Replace '/MyVolume'\
    \ with the directory in which it is mounted (mount point). <br>\n  To check the\
    \ mount point, enter <code>lsblk -l</code> or <code>df -hT</code>)</p>\n<ul>\n\
    <li>\n<p>Navigate to your data storage directory in the right side of the FileZilla\
    \ screen.</p>\n</li>\n<li>\n<p>Drag and drop files and directories between your\
    \ local computer and the VM.</p>\n</li>\n<li>\n<p>Right click in the file list\
    \ area to:</p>\n</li>\n<li>Create a directory or text file</li>\n<li>Edit a text\
    \ document (you may need to adjust \n  <strong><em>FileZilla/Edit -&gt; Settings/Preferences\
    \ -&gt;  File Editing</em></strong> to ensure documents open in your local computer's\
    \ default text editor.</li>\n<li>Delete, download or rename files or directories,\
    \ etc.</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/FZ_edit_files.png?raw=true\"\
    ></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/FZ_save_files.png?raw=true\"\
    ></p>\n<hr>\n<h2>SCP: secure copy <a name=\"scp\"></a></h2>\n<p>SCP is a simple\
    \ method for transferring files between computers. </p>\n<p>The basic command\
    \ for Secure Copy is like a UNIX <code>cp</code>, but adding a connection to a\
    \ different computer in the file path</p>\n<p><code>scp &lt;Path_To_Source_File&gt;\
    \ &lt;Path_to_Destination&gt;</code></p>\n<h3>Between a local Mac/Linux and the\
    \ VM</h3>\n<p>Enter the command from your local computer's Terminal app. </p>\n\
    <p>To upload a file to the VM:</p>\n<p><code>scp -i ~/.ssh/Nectar_Key &lt;local-file-path&gt;\
    \ ubuntu@NNN.NNN.NNN.NNN:&lt;instance-file-path&gt;</code></p>\n<p>To download\
    \ a file from your VM:</p>\n<p><code>scp -i ~/.ssh/Nectar_Key ubuntu@NNN.NNN.NNN.NNN:&lt;instance-file-path&gt;\
    \ &lt;local-file-path&gt;</code></p>\n<h3>Between your VM and a data storage server</h3>\n\
    <p>If you have data stored on a remote server, you can transfer files between\
    \ it and the VM through the command-line on the VM.</p>\n<p>You will need a host\
    \ address for the data storage server, and your username, plus usually a password.</p>\n\
    <p><code>scp username@host.address.edu.au:/data/myDirectory/file.txt /mnt/data/</code><br>\n\
    <code>scp /mnt/data/results.zip username@host.address.edu.au:/data/myDirectory/</code></p>\n\
    <p>You will usually then be prompted to enter the password for your data storage.</p>\n\
    <p>n.b. use <code>scp -i path/to/key ...</code> if your remote server has ssh\
    \ keys rather than password access.</p>\n<hr>\n<h2>SFTP via the Command Line <a\
    \ name=\"sftp\"></a></h2>\n<p>Secure file transfer is also available between the\
    \ VM and remote data storage.</p>\n<p>Enter the 'sftp' command on your VM, and\
    \ you will have access to the remote host.</p>\n<p><code>sftp username@host.address.edu.au</code>\
    \   - you will usually be prompted for a password.</p>\n<p>or</p>\n<p><code>sftp\
    \ -i path/to/key username@host.address.edu.au</code>  - if the remote server has\
    \ ssh key authentication</p>\n<p>You are now accessing the remote data storage\
    \ server, and you can navigate the files on the server\nas per usual with commands\
    \ like <code>cd</code> and <code>ls</code>.</p>\n<p>The commands <code>get</code>\
    \ and <code>put</code> will transfer data between the machines:</p>\n<p><code>get\
    \ &lt;remote_server_file.txt&gt; &lt;/mnt/localVM_destination/&gt;</code></p>\n\
    <p><code>put &lt;/mnt/localVM_destination/file.txt&gt; &lt;remote_directory/&gt;</code></p>\n\
    <p>to close the sftp connection, type <code>exit</code>.</p>"
  parent: 21
  sha1: 9d23b8bbeb78ea67d27dc3a96969a27b2bda7fde
  title: Transferring Data to your VM
86:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-17T22:46:21-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Running Jobs on your VM \n Contents \n \n Keeping jobs running\
          \ when your SSH connection is lost \n 1) Nohup - detaching a job from the\
          \ terminal\n \n 2) GNU Screen - keeping the terminal session running\n \n\
          \ GNU Parallel - putting multiple processors to work \n Appendix - examples\
          \ of using the commands \n \n Two major features of Cloud Computing are:\
          \  \n \n Keeping long-running memory/CPU intensive processes running on\
          \ a dedicated server; and   \n The flexibility to launch a VM with a large\
          \ number of CPU (processors) to run \n  some processes more efficiently.\
          \ \n \n There are a few UNIX tricks that can help you use these features\
          \ effectively. \n Keeping jobs running  \n \n How to close your terminal/SSH\
          \ session, while keeping your processes running on the VM \n Generally,\
          \ your instance is kept running for long periods. Unlike your local computer,\
          \ \nthe VM's do not automatically go to sleep when there hasn't been input.\
          \  They are ideal for running \nlarge jobs that may take a long time to\
          \ complete. \n When running a process from the command-line in Terminal,\
          \ the default action is\nfor the job to be attached to the terminal session,\
          \ and to terminate if the terminal session ends.\nThis means that the jobs\
          \ will be terminated if your local computer goes to sleep, or drops the\
          \ SSH connection to the VM. \n There are two main methods to keep jobs processing\
          \ on the VM without the need to keep the \nSSH terminal session running\
          \ on your local computer. \n \n Detaching a job from the terminal session\
          \ ( nohup and disown ) \n Keeping a virtual terminal session running ( GNU\
          \ Screen ) \n \n 1. Detaching a job from the terminal  \n \n Background\
          \ and foreground jobs \n Usually we run processes in the foreground:  \n\
          \ \n Our terminal window is busy until the process is finished,  \n Standard\
          \ output and error messages are printed to the terminal window  \n If we\
          \ close the terminal window, the process will terminate. \n \n We can instruct\
          \ terminal to run processes in the background ( & ): \n \n The terminal\
          \ window is not involved in the process, it is available for other commands\
          \ \n The standard output and standard error are still printed to the window\
          \ \n If we close the window, the process will still terminate  \n just put\
          \ a space and \"&\" at the end of your usual command \n  e.g. sleep 20 -\
          \ the terminal window will be unresponsive for 20 seconds \nsleep 20 & -\
          \ sleep command executes in the background, and the window remains responsive\
          \ \n \n Nohup with background \n The command nohup ensures the command does\
          \ not receive a 'hang-up' signal \nwhen the terminal session ends. \n Using\
          \ nohup combined with background: \n \n The terminal window is available\
          \ for other commands \n Standard output is printed to file ('nohup.out')\
          \  \n Closing the terminal session will not terminate the process (nohup\
          \ = no hang-up) \n Modify commands as follows:   \n \n nohup <normal commands\
          \ go here> 2>&1 & \n nohup detaches the command from the terminal session\
          \ \n2>&1 sends the standard error and the standard output to the log file\
          \ 'nohup.out'. \n  You can enter 2> /dev/null < /dev/null instead to discard\
          \ standard error messages.\n& at the end send the process to the background.\
          \ \n Nohup in foreground \n The 'nohup' command can be used without running\
          \ the job in the background by omitting the '&' at the end.\nThis is useful\
          \ when you need to provide input after entering a command (such as a password).\
          \ \n To move any process to the background, pause the job with 'control'\
          \ + 'Z', then enter bg \n \n \nnohup <commands that start a job> 2>&1  \
          \ \n Enter any input at prompts (e.g. password, input parameters for a program)\
          \   \n 'control' + 'Z'  -  to pause the job   \n \nbg   \n check the job\
          \ is running with jobs or ps or top\n \n \n There is a detailed example\
          \ of this process at the end of this article  \n Disown: detaching a job\
          \ after it has started \n If you didn't  enter nohup at the beginning of\
          \ a command, but you want to ensure it keeps running when your SSH \nsession\
          \ ends, there is a command to detach an active job called disown. The job\
          \ needs to be paused with\n'control' + 'Z' before entering the command disown.\
          \ \n \n \n<command that starts a job>   \n 'control' + 'Z'  -  to pause\
          \ the job   \n \nbg   \n \ndisown   \n Check that the process is running\
          \ with ps or top\n \n \n There is a detailed example at the end of this\
          \ article \n \n 2. Keeping the terminal session running with Byobu / GNU\
          \ Screen \n \n There are a couple of utilties that provide a 'virtual terminal'\
          \ that will keep running \non the server without the user having the terminal\
          \ application open and actively\nengaged in SSH connection with the VM.\
          \ These utilities are GNU Screen and TMUX, and this article \nwill cover\
          \ using Screen with the front-end package Byobu. \n \n It keeps your terminal\
          \ session running perpetually, you can reconnect at any time  \n This includes\
          \ keeping active any running processes attached to the terminal session\
          \ \n It will preserve processes in the foreground, or in the background\
          \ \n The next time you log in, the terminal session will be preserved as\
          \ you left it \n It is a good idea to use it with nohup commands for extra\
          \ insurance \n \n Some VM users prefer not to use a virtual terminal utility\
          \ beacause: \n \n Learning curve : Byobu/Screen has its own set of commands\
          \ to familiarise yourself with. \n Running a virtual terminal is more memory\
          \ intensive than simply using nohup or disown\n \n \n To install and set-up:\
          \ \n \n \nsudo apt-get install screen byobu   \n byobu-select-backend screen\
          \ \n \n To start a session (and name it):  \nbyobu -S JoeyStructure  \n\
          \ (The first time you use it, enter 'control' + 'a' and select 'Screen commands')\
          \ \n When you've finished your terminal session, close the window or 'ctrl'\
          \ + 'a' then 'd'.\nTo log back into the session, just type byobu and select\
          \ your session from the list. \n 'control' + 'a' (^a) is used to access\
          \ the Screens commands during a Byobu session \n\n\n\nCommand\nAction\n\n\
          \n\n\n^a then 'd'\ndetach from the byobu session, you can resume it later\n\
          \n\n^a then '?'\nhelp (menu of commands)\n\n\n^a then 'c'\nopen a new tab\n\
          \n\n^a then 'n' or 'p'\nswitch to next/previous tab\n\n\n^a then 'k'\nkill\
          \ the current tab\n\n\n^a then 'A'\ngive the tab a title\n\n\n^a then '\\\
          '\nterminates the byobu session, permanently\n\n\nexit\nterminates the byobu\
          \ session, permanently\n\n\n\n Some other features in Byobu/Screen: \n \n\
          \ Easily swap between tabs of terminal windows in your session \n Save a\
          \ log file of activity from a terminal window (^a then H) \n Split screen\
          \ - multiple terminal shells in one window (^a then S) \n [and many more][https://help.ubuntu.com/community/Byobu]\
          \  \n \n \n Spreading jobs over multiple CPUs  \n \n A major advantage of\
          \ NeCTAR cloud computing, is the power to launch VM's with multiple \nprocessors\
          \ (CPUs), depending upon your allocation.\nMultiple CPUs can efficiently\
          \ process more jobs simultaneously. GNU parallel is a \ncommand-line utility\
          \ to manage the distribution of a list of jobs to the available \nCPU cores.\
          \ \n GNU Parallel \n The GNU parallel utility will allow the user to simultaneously\
          \ run as many processes as there are CPUs.    \n If there are 32 jobs to\
          \ do and 4 CPUs, parallel will send the first 4 to be done, \nand as each\
          \ job finishes a new one will commence. \n \n To install : sudo apt-get\
          \ install parallel \n Usage: enter 'parallel' with either a list of commands,\
          \ or a list of items to be\nused as input for a given command. \n Example\
          \ Commands with Parallel \n \n Using parallel to decompress all files ending\
          \ in .gz (these two commands are identical):   \n \nparallel gunzip :::\
          \ *.gz   \n \n ls -1 *.gz | parallel gunzip \n \n \n The input data can\
          \ be saved in a text file e.g. to download files from a list of URLs (these\
          \ two commands are identical):   \n \n parallel wget < list_of_URLs.txt\
          \ \n \n parallel -a list_of_URLs.txt wget \n \n \n The text file can contain\
          \ a list of commands, each line as it would be entered in the terminal:\
          \   \n \n \n parallel < list_of_commands.txt \n \n \n By default, parallel\
          \ uses all cores in the machine.   \n \n You can dictate how many cores\
          \ to use with parallel -j # (# is the required number of cores)       \n\
          \ \n parallel -j -1 uses all CPUs except one, which leaves a CPU available\
          \ for other tasks/users. \n \n \n NOTE: Don't run parallel programs in the\
          \ background, or they will all run at once.    \n \n The nohup command works\
          \ with parallel. e.g.:   \n \n nohup parallel < list_of_commands.txt 2>&1\
          \ \n \n \n If you want to see all the processes running in parallel, htop\
          \ is an excellent system monitor.   \n \n \nsudo apt-get install htop  \
          \ \n htop \n \n \n Appendix - more details and examples from this article\
          \ \n \n \n Appendix \n example of moving a nohup command to the background\
          \ \n example of using 'disown' \n the main Byobu / Screen commands \n summary\
          \ table \n \n example of moving a nohup command to the background  \n \n\
          \ An example would be downloading a large file from a password-protected\
          \ remote data storage server using scp. \n \n e.g. nohup scp username@host.address.edu.au:/data/files.tar.gz\
          \ /mnt/data/ 2>&1  \n Password is entered at the prompt \n Now the download\
          \ begins. There will be no prompt in the terminal, as it is busy\n  with\
          \ the foreground process. \n Press 'control' and 'Z' to pause the download.\
          \   \n There will be output like [1]+  Stopped    nohup scp ...\n \n Enter\
          \ bg to move the process to the background  \n You will see output like\
          \ [1]+ nohup scp ...... &\n \n The download will now resume in the background.\
          \ \n Use the command jobs to see that the download job is still active.\
          \ \n \n The terminal session can be terminated, and the download job will\
          \ continue on the VM. \n \n If the job is not active (this may show as [1]-\
          \ ....): \n  check for an error message in the output file :  less nohup.out\
          \  \n \n \n example of using 'disown' \n \n If you started a large download,\
          \ and wanted it to continue without keeping the SSH\nconnection with the\
          \ VM: \n \n e.g. scp username@host.address.edu.au:/data/files.tar.gz /mnt/data/\
          \ \n Password is entered at the prompt \n Now the download begins. The standard\
          \ output will appear in the terminal. \n Press 'control' and 'Z' to pause\
          \ the download.   \n There will be output like [1]+  Stopped    scp ...\n\
          \ \n Enter bg to move the process to the background  \n There will be output\
          \ like [1]+ nohup scp ..... &\n \n The download will resume in the background.\
          \ \n The command jobs will show that the download job is still active. \n\
          \ Enter disown\n \n Entering jobs will show that the download job is no\
          \ longer listed \n Entering ps shows that the processes involved in the\
          \ download (e.g. ssh and scp) are active \n \n The terminal session can\
          \ be terminated, and the download job will continue on the VM. \n \n The\
          \ Main Byobu / Screen Commands  \n \n 'control' + 'a' (^a) is used to access\
          \ the Screens commands during a Byobu session \n\n\n\nCommand\nAction\n\n\
          \n\n\nbyobu -S <name>\nstart a new virtual terminal session\n\n\nbyobu\n\
          select an existing session to resume\n\n\n^a then 'd'\ndetach from the byobu\
          \ session, you can resume it later\n\n\n^a then '?'\nhelp (menu of commands)\n\
          \n\n^a then 'c'\nopen a new tab\n\n\n^a then 'n' or 'p'\nswitch to next/previous\
          \ tab\n\n\n^a then 'k'\nkill the current tab\n\n\n^a then 'A'\ngive the\
          \ tab a title\n\n\n^a then '\\'\nterminates the byobu session, permanently\n\
          \n\nexit\nterminates the byobu session, permanently\n\n\n\n Table Summarising\
          \ Options for keeping Processes Running \n \n\n\n\nCommand type\nCommand\n\
          1.Use terminal\n2.Output\n3.Close window\n4.To terminate\n\n\n\n\n\nforeground\n\
          (default)\nno\nprinted\ntermination\nctrl c\n\n\n\nbackground\n.... &\n\
          yes\nprinted\ntermination\nkill[PID#]\n\n\n\nnohup\nnohup ...\nno\nsaved\n\
          no termination\nctrl c\n\n\n\nnohup + bg\nnohup .... &\nyes\nsaved\nno termination\n\
          kill [PID#]\n\n\n\nbyobu\nbyobu\nno (tabs)\nprinted\nno termination\nctrl\
          \ a then k\n\n\n\nbyobu + nohup\n(combine commands)\nyes\nsaved\nno termination\n\
          kill [PID#]\n\n\n\n\n \n Is the terminal window available while the process\
          \ is running;   \n Where is the standard output sent;    \n What happens\
          \ to the process when you close the screen;    \n How to terminate the process.\
          \  \n "
        description: "<p>Running Jobs on your VM</p>\n<h2>Contents</h2>\n<ul>\n<li><a\
          \ href=\"#running\">Keeping jobs running when your SSH connection is lost</a></li>\n\
          <li>1) <a href=\"#nohup\">Nohup - detaching a job from the terminal</a>\n\
          </li>\n<li>2) <a href=\"#screen\">GNU Screen - keeping the terminal session\
          \ running</a>\n</li>\n<li><a href=\"#parallel\">GNU Parallel - putting multiple\
          \ processors to work</a></li>\n<li><a href=\"#appendix\">Appendix - examples\
          \ of using the commands</a></li>\n</ul>\n<p>Two major features of Cloud\
          \ Computing are: </p>\n<ol>\n<li>Keeping long-running memory/CPU intensive\
          \ processes running on a dedicated server; and  </li>\n<li>The flexibility\
          \ to launch a VM with a large number of CPU (processors) to run \n  some\
          \ processes more efficiently.</li>\n</ol>\n<p>There are a few UNIX tricks\
          \ that can help you use these features effectively.</p>\n<h2>Keeping jobs\
          \ running  <a name=\"running\"></a>\n</h2>\n<h3>How to close your terminal/SSH\
          \ session, while keeping your processes running on the VM</h3>\n<p>Generally,\
          \ your instance is kept running for long periods. Unlike your local computer,\
          \ \nthe VM's do not automatically go to sleep when there hasn't been input.\
          \  They are ideal for running \nlarge jobs that may take a long time to\
          \ complete.</p>\n<p>When running a process from the command-line in Terminal,\
          \ the default action is\nfor the job to be attached to the terminal session,\
          \ and to terminate if the terminal session ends.\nThis means that the jobs\
          \ will be terminated if your local computer goes to sleep, or drops the\
          \ SSH connection to the VM.</p>\n<p>There are two main methods to keep jobs\
          \ processing on the VM without the need to keep the \nSSH terminal session\
          \ running on your local computer.</p>\n<ol>\n<li>Detaching a job from the\
          \ terminal session ( <code>nohup</code> and <code>disown</code> )</li>\n\
          <li>Keeping a virtual terminal session running ( GNU Screen )</li>\n</ol>\n\
          <h2>1. Detaching a job from the terminal  <a name=\"nohup\"></a>\n</h2>\n\
          <h3>Background and foreground jobs</h3>\n<p>Usually we run processes in\
          \ the <strong><em>foreground</em></strong>: </p>\n<ul>\n<li>Our terminal\
          \ window is busy until the process is finished, </li>\n<li>Standard output\
          \ and error messages are printed to the terminal window </li>\n<li>If we\
          \ close the terminal window, the process will terminate.</li>\n</ul>\n<p>We\
          \ can instruct terminal to run processes in the <strong><em>background</em></strong>\
          \ <strong>( <code>&amp;</code> )</strong>:</p>\n<ul>\n<li>The terminal window\
          \ is not involved in the process, it is available for other commands</li>\n\
          <li>The standard output and standard error are still printed to the window</li>\n\
          <li>If we close the window, the process will still terminate </li>\n<li>just\
          \ put a space and \"&amp;\" at the end of your usual command<br>\n  e.g.\
          \ <code>sleep 20</code> - the terminal window will be unresponsive for 20\
          \ seconds<br>\n<code>sleep 20 &amp;</code> - sleep command executes in the\
          \ background, and the window remains responsive</li>\n</ul>\n<h3>Nohup with\
          \ background</h3>\n<p>The command <strong><code>nohup</code></strong> ensures\
          \ the command does not receive a 'hang-up' signal \nwhen the terminal session\
          \ ends.</p>\n<p>Using <strong><em>nohup</em></strong> combined with background:</p>\n\
          <ul>\n<li>The terminal window is available for other commands</li>\n<li>Standard\
          \ output is printed to file ('nohup.out') </li>\n<li>Closing the terminal\
          \ session will not terminate the process (nohup = no hang-up)</li>\n<li>Modify\
          \ commands as follows:  </li>\n</ul>\n<p><code>nohup &lt;normal commands\
          \ go here&gt; 2&gt;&amp;1 &amp;</code></p>\n<p><strong><code>nohup</code></strong>\
          \ detaches the command from the terminal session \n<strong><code>2&gt;&amp;1</code></strong>\
          \ sends the standard error and the standard output to the log file 'nohup.out'.<br>\n\
          \  You can enter <code>2&gt; /dev/null &lt; /dev/null</code> instead to\
          \ discard standard error messages.\n<strong><code>&amp;</code></strong>\
          \ at the end send the process to the background.</p>\n<h3>Nohup in foreground</h3>\n\
          <p>The 'nohup' command can be used without running the job in the background\
          \ by omitting the '<code>&amp;</code>' at the end.\nThis is useful when\
          \ you need to provide input after entering a command (such as a password).</p>\n\
          <p>To move any process to the background, pause the job with <strong>'control'\
          \ + 'Z'</strong>, then enter <strong><code>bg</code></strong></p>\n<ul>\n\
          <li>\n<code>nohup &lt;commands that start a job&gt; 2&gt;&amp;1</code> \
          \ </li>\n<li>Enter any input at prompts (e.g. password, input parameters\
          \ for a program)  </li>\n<li>'control' + 'Z'  -  to pause the job  </li>\n\
          <li>\n<code>bg</code>  </li>\n<li>check the job is running with <code>jobs</code>\
          \ or <code>ps</code> or <code>top</code>\n</li>\n</ul>\n<p>There is a detailed\
          \ example of this process <a href=\"#egnohup\">at the end of this article</a>\
          \ </p>\n<h3>Disown: detaching a job after it has started</h3>\n<p>If you\
          \ didn't  enter <code>nohup</code> at the beginning of a command, but you\
          \ want to ensure it keeps running when your SSH \nsession ends, there is\
          \ a command to detach an active job called <strong><code>disown</code></strong>.\
          \ The job needs to be paused with\n'control' + 'Z' before entering the command\
          \ <code>disown</code>.</p>\n<ul>\n<li>\n<code>&lt;command that starts a\
          \ job&gt;</code>  </li>\n<li>'control' + 'Z'  -  to pause the job  </li>\n\
          <li>\n<code>bg</code>  </li>\n<li>\n<code>disown</code>  </li>\n<li>Check\
          \ that the process is running with <code>ps</code> or <code>top</code>\n\
          </li>\n</ul>\n<p>There is a detailed example at the <a href=\"#disown\"\
          >end of this article</a></p>\n<hr>\n<h2>2. Keeping the terminal session\
          \ running with Byobu / GNU Screen <a name=\"screen\"></a>\n</h2>\n<p>There\
          \ are a couple of utilties that provide a 'virtual terminal' that will keep\
          \ running \non the server without the user having the terminal application\
          \ open and actively\nengaged in SSH connection with the VM. These utilities\
          \ are GNU Screen and TMUX, and this article \nwill cover using Screen with\
          \ the front-end package Byobu.</p>\n<ul>\n<li>It keeps your terminal session\
          \ running perpetually, you can reconnect at any time </li>\n<li>This includes\
          \ keeping active any running processes attached to the terminal session</li>\n\
          <li>It will preserve processes in the foreground, or in the background</li>\n\
          <li>The next time you log in, the terminal session will be preserved as\
          \ you left it</li>\n<li>It is a good idea to use it with <code>nohup</code>\
          \ commands for extra insurance</li>\n</ul>\n<p>Some VM users prefer not\
          \ to use a virtual terminal utility beacause:</p>\n<ul>\n<li>Learning curve\
          \ : Byobu/Screen has its own set of <a href=\"#byobu\">commands</a> to familiarise\
          \ yourself with.</li>\n<li>Running a virtual terminal is more memory intensive\
          \ than simply using <code>nohup</code> or <code>disown</code>\n</li>\n</ul>\n\
          <p>To install and set-up:</p>\n<ul>\n<li>\n<code>sudo apt-get install screen\
          \ byobu</code>  </li>\n<li><code>byobu-select-backend screen</code></li>\n\
          </ul>\n<p>To start a session (and name it): <br>\n<code>byobu -S JoeyStructure</code>\
          \ </p>\n<p>(The first time you use it, enter 'control' + 'a' and select\
          \ 'Screen commands')</p>\n<p>When you've finished your terminal session,\
          \ close the window or 'ctrl' + 'a' then 'd'.\nTo log back into the session,\
          \ just type <code>byobu</code> and select your session from the list.</p>\n\
          <p>'control' + 'a' (<strong>^a</strong>) is used to access the Screens commands\
          \ during a Byobu session</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\"\
          >Command</th>\n<th align=\"left\">Action</th>\n</tr>\n</thead>\n<tbody>\n\
          <tr>\n<td align=\"left\">^a then 'd'</td>\n<td align=\"left\">detach from\
          \ the byobu session, you can resume it later</td>\n</tr>\n<tr>\n<td align=\"\
          left\">^a then '?'</td>\n<td align=\"left\"><strong>help (menu of commands)</strong></td>\n\
          </tr>\n<tr>\n<td align=\"left\">^a then 'c'</td>\n<td align=\"left\">open\
          \ a new tab</td>\n</tr>\n<tr>\n<td align=\"left\">^a then 'n' or 'p'</td>\n\
          <td align=\"left\">switch to next/previous tab</td>\n</tr>\n<tr>\n<td align=\"\
          left\">^a then 'k'</td>\n<td align=\"left\">kill the current tab</td>\n\
          </tr>\n<tr>\n<td align=\"left\">^a then 'A'</td>\n<td align=\"left\">give\
          \ the tab a title</td>\n</tr>\n<tr>\n<td align=\"left\">^a then '\\'</td>\n\
          <td align=\"left\">terminates the byobu session, permanently</td>\n</tr>\n\
          <tr>\n<td align=\"left\"><code>exit</code></td>\n<td align=\"left\">terminates\
          \ the byobu session, permanently</td>\n</tr>\n</tbody>\n</table>\n<p>Some\
          \ other features in Byobu/Screen:</p>\n<ul>\n<li>Easily swap between tabs\
          \ of terminal windows in your session</li>\n<li>Save a log file of activity\
          \ from a terminal window (^a then H)</li>\n<li>Split screen - multiple terminal\
          \ shells in one window (^a then S)</li>\n<li>[and many more][https://help.ubuntu.com/community/Byobu]\
          \ </li>\n</ul>\n<hr>\n<h2>Spreading jobs over multiple CPUs  <a name=\"\
          parallel\"></a>\n</h2>\n<p>A major advantage of NeCTAR cloud computing,\
          \ is the power to launch VM's with multiple \nprocessors (CPUs), depending\
          \ upon your allocation.\nMultiple CPUs can efficiently process more jobs\
          \ simultaneously. GNU parallel is a \ncommand-line utility to manage the\
          \ distribution of a list of jobs to the available \nCPU cores.</p>\n<h3>GNU\
          \ Parallel</h3>\n<p>The GNU parallel utility will allow the user to simultaneously\
          \ run as many processes as there are CPUs.   </p>\n<p>If there are 32 jobs\
          \ to do and 4 CPUs, parallel will send the first 4 to be done, \nand as\
          \ each job finishes a new one will commence.</p>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/parallel.png?raw=true\"\
          ></p>\n<p>To install : <code>sudo apt-get install parallel</code></p>\n\
          <p>Usage: enter 'parallel' with either a list of commands, or a list of\
          \ items to be\nused as input for a given command.</p>\n<h4>Example Commands\
          \ with Parallel</h4>\n<ul>\n<li>Using parallel to decompress all files ending\
          \ in .gz (these two commands are identical):  </li>\n<li>\n<code>parallel\
          \ gunzip ::: *.gz</code>  </li>\n<li>\n<p><code>ls -1 *.gz | parallel gunzip</code></p>\n\
          </li>\n<li>\n<p>The input data can be saved in a text file e.g. to download\
          \ files from a list of URLs (these two commands are identical):  </p>\n\
          </li>\n<li><code>parallel wget &lt; list_of_URLs.txt</code></li>\n<li>\n\
          <p><code>parallel -a list_of_URLs.txt wget</code></p>\n</li>\n<li>\n<p>The\
          \ text file can contain a list of commands, each line as it would be entered\
          \ in the terminal:  </p>\n</li>\n<li>\n<p><code>parallel &lt; list_of_commands.txt</code></p>\n\
          </li>\n<li>\n<p>By default, parallel uses all cores in the machine.  </p>\n\
          </li>\n<li>You can dictate how many cores to use with <code>parallel -j\
          \ #</code> (# is the required number of cores)      </li>\n<li>\n<p><code>parallel\
          \ -j -1</code> uses all CPUs except one, which leaves a CPU available for\
          \ other tasks/users.</p>\n</li>\n<li>\n<p><strong>NOTE:</strong> Don't run\
          \ parallel programs in the background, or they will all run at once.   </p>\n\
          </li>\n<li>The <strong>nohup</strong> command works with parallel. e.g.:\
          \  </li>\n<li>\n<p><code>nohup parallel &lt; list_of_commands.txt 2&gt;&amp;1</code></p>\n\
          </li>\n<li>\n<p>If you want to see all the processes running in parallel,\
          \ htop is an excellent system monitor.  </p>\n</li>\n<li>\n<code>sudo apt-get\
          \ install htop</code>  </li>\n<li><code>htop</code></li>\n</ul>\n<hr>\n\
          <h2>Appendix - more details and examples from this article <a name=\"appendix\"\
          ></a>\n</h2>\n<ul>\n<li>Appendix</li>\n<li><a href=\"#egnohup\">example\
          \ of moving a nohup command to the background</a></li>\n<li><a href=\"#disown\"\
          >example of using 'disown'</a></li>\n<li><a href=\"#byobu\">the main Byobu\
          \ / Screen commands</a></li>\n<li><a href=\"#table\">summary table</a></li>\n\
          </ul>\n<h3>example of moving a nohup command to the background  <a name=\"\
          egnohup\"></a>\n</h3>\n<p>An example would be downloading a large file from\
          \ a password-protected remote data storage server using <code>scp</code>.</p>\n\
          <ul>\n<li>e.g. <code>nohup scp username@host.address.edu.au:/data/files.tar.gz\
          \ /mnt/data/ 2&gt;&amp;1</code> </li>\n<li>Password is entered at the prompt</li>\n\
          <li>Now the download begins. There will be no prompt in the terminal, as\
          \ it is busy\n  with the foreground process.</li>\n<li>Press 'control' and\
          \ 'Z' to pause the download.  </li>\n<li>There will be output like <code>[1]+\
          \  Stopped    nohup scp ...</code>\n</li>\n<li>Enter <code>bg</code> to\
          \ move the process to the background </li>\n<li>You will see output like\
          \ <code>[1]+ nohup scp ...... &amp;</code>\n</li>\n<li>The download will\
          \ now resume in the background.</li>\n<li>Use the command <code>jobs</code>\
          \ to see that the download job is still active.</li>\n</ul>\n<p>The terminal\
          \ session can be terminated, and the download job will continue on the VM.</p>\n\
          <ul>\n<li>If the job is not active (this may show as <code>[1]- ....</code>):<br>\n\
          \  check for an error message in the output file :  <code>less nohup.out</code>\
          \ </li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/nohup_bg.png?raw=true\"\
          ></p>\n<h3>example of using 'disown' <a name=\"disown\"></a>\n</h3>\n<p>If\
          \ you started a large download, and wanted it to continue without keeping\
          \ the SSH\nconnection with the VM:</p>\n<ul>\n<li>e.g. scp username@host.address.edu.au:/data/files.tar.gz\
          \ /mnt/data/</li>\n<li>Password is entered at the prompt</li>\n<li>Now the\
          \ download begins. The standard output will appear in the terminal.</li>\n\
          <li>Press 'control' and 'Z' to pause the download.  </li>\n<li>There will\
          \ be output like <code>[1]+  Stopped    scp ...</code>\n</li>\n<li>Enter\
          \ <code>bg</code> to move the process to the background </li>\n<li>There\
          \ will be output like <code>[1]+ nohup scp ..... &amp;</code>\n</li>\n<li>The\
          \ download will resume in the background.</li>\n<li>The command <code>jobs</code>\
          \ will show that the download job is still active.</li>\n<li>Enter <code>disown</code>\n\
          </li>\n<li>Entering <code>jobs</code> will show that the download job is\
          \ no longer listed</li>\n<li>Entering <code>ps</code> shows that the processes\
          \ involved in the download (e.g. ssh and scp) are active</li>\n</ul>\n<p>The\
          \ terminal session can be terminated, and the download job will continue\
          \ on the VM.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Cloud%20Basics--DOCID21/images/disown.png?raw=true\"\
          ></p>\n<h3>The Main Byobu / Screen Commands  <a name=\"byobu\"></a>\n</h3>\n\
          <p>'control' + 'a' (<strong>^a</strong>) is used to access the Screens commands\
          \ during a Byobu session</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\"\
          >Command</th>\n<th align=\"left\">Action</th>\n</tr>\n</thead>\n<tbody>\n\
          <tr>\n<td align=\"left\"><code>byobu -S &lt;name&gt;</code></td>\n<td align=\"\
          left\">start a new virtual terminal session</td>\n</tr>\n<tr>\n<td align=\"\
          left\"><code>byobu</code></td>\n<td align=\"left\">select an existing session\
          \ to resume</td>\n</tr>\n<tr>\n<td align=\"left\">^a then 'd'</td>\n<td\
          \ align=\"left\">detach from the byobu session, you can resume it later</td>\n\
          </tr>\n<tr>\n<td align=\"left\">^a then '?'</td>\n<td align=\"left\"><strong>help\
          \ (menu of commands)</strong></td>\n</tr>\n<tr>\n<td align=\"left\">^a then\
          \ 'c'</td>\n<td align=\"left\">open a new tab</td>\n</tr>\n<tr>\n<td align=\"\
          left\">^a then 'n' or 'p'</td>\n<td align=\"left\">switch to next/previous\
          \ tab</td>\n</tr>\n<tr>\n<td align=\"left\">^a then 'k'</td>\n<td align=\"\
          left\">kill the current tab</td>\n</tr>\n<tr>\n<td align=\"left\">^a then\
          \ 'A'</td>\n<td align=\"left\">give the tab a title</td>\n</tr>\n<tr>\n\
          <td align=\"left\">^a then '\\'</td>\n<td align=\"left\">terminates the\
          \ byobu session, permanently</td>\n</tr>\n<tr>\n<td align=\"left\"><code>exit</code></td>\n\
          <td align=\"left\">terminates the byobu session, permanently</td>\n</tr>\n\
          </tbody>\n</table>\n<h3>Table Summarising Options for keeping Processes\
          \ Running <a name=\"table\"></a>\n</h3>\n<table>\n<thead>\n<tr>\n<th>Command\
          \ type</th>\n<th>Command</th>\n<th>1.Use terminal</th>\n<th>2.Output</th>\n\
          <th>3.Close window</th>\n<th>4.To terminate</th>\n<th></th>\n</tr>\n</thead>\n\
          <tbody>\n<tr>\n<td>foreground</td>\n<td>(default)</td>\n<td>no</td>\n<td>printed</td>\n\
          <td>termination</td>\n<td>ctrl c</td>\n<td></td>\n</tr>\n<tr>\n<td>background</td>\n\
          <td><code>.... &amp;</code></td>\n<td>yes</td>\n<td>printed</td>\n<td>termination</td>\n\
          <td>kill[PID#]</td>\n<td></td>\n</tr>\n<tr>\n<td>nohup</td>\n<td><code>nohup\
          \ ...</code></td>\n<td>no</td>\n<td>saved</td>\n<td>no termination</td>\n\
          <td>ctrl c</td>\n<td></td>\n</tr>\n<tr>\n<td>nohup + bg</td>\n<td><code>nohup\
          \ .... &amp;</code></td>\n<td>yes</td>\n<td>saved</td>\n<td>no termination</td>\n\
          <td>kill [PID#]</td>\n<td></td>\n</tr>\n<tr>\n<td>byobu</td>\n<td><code>byobu</code></td>\n\
          <td>no (tabs)</td>\n<td>printed</td>\n<td>no termination</td>\n<td>ctrl\
          \ a then k</td>\n<td></td>\n</tr>\n<tr>\n<td>byobu + nohup</td>\n<td>(combine\
          \ commands)</td>\n<td>yes</td>\n<td>saved</td>\n<td>no termination</td>\n\
          <td>kill [PID#]</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<ol>\n<li>Is\
          \ the terminal window available while the process is running;  </li>\n<li>Where\
          \ is the standard output sent;   </li>\n<li>What happens to the process\
          \ when you close the screen;   </li>\n<li>How to terminate the process.\
          \ </li>\n</ol>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 0
        id: 6000089713
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-17T22:46:21-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000089713
        position: 13
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Tips for Running Jobs on your VM
        updated_at: '2015-11-17T22:46:21-05:00'
        user_id: 6002464727
  html: "<p>Running Jobs on your VM</p>\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#running\"\
    >Keeping jobs running when your SSH connection is lost</a></li>\n<li>1) <a href=\"\
    #nohup\">Nohup - detaching a job from the terminal</a></li>\n<li>2) <a href=\"\
    #screen\">GNU Screen - keeping the terminal session running</a></li>\n<li><a href=\"\
    #parallel\">GNU Parallel - putting multiple processors to work</a></li>\n<li><a\
    \ href=\"#appendix\">Appendix - examples of using the commands</a></li>\n</ul>\n\
    <p>Two major features of Cloud Computing are: </p>\n<ol>\n<li>Keeping long-running\
    \ memory/CPU intensive processes running on a dedicated server; and  </li>\n<li>The\
    \ flexibility to launch a VM with a large number of CPU (processors) to run \n\
    \  some processes more efficiently.</li>\n</ol>\n<p>There are a few UNIX tricks\
    \ that can help you use these features effectively.</p>\n<h2>Keeping jobs running\
    \  <a name=\"running\"></a></h2>\n<h3>How to close your terminal/SSH session,\
    \ while keeping your processes running on the VM</h3>\n<p>Generally, your instance\
    \ is kept running for long periods. Unlike your local computer, \nthe VM's do\
    \ not automatically go to sleep when there hasn't been input.  They are ideal\
    \ for running \nlarge jobs that may take a long time to complete.</p>\n<p>When\
    \ running a process from the command-line in Terminal, the default action is\n\
    for the job to be attached to the terminal session, and to terminate if the terminal\
    \ session ends.\nThis means that the jobs will be terminated if your local computer\
    \ goes to sleep, or drops the SSH connection to the VM.</p>\n<p>There are two\
    \ main methods to keep jobs processing on the VM without the need to keep the\
    \ \nSSH terminal session running on your local computer.</p>\n<ol>\n<li>Detaching\
    \ a job from the terminal session ( <code>nohup</code> and <code>disown</code>\
    \ )</li>\n<li>Keeping a virtual terminal session running ( GNU Screen )</li>\n\
    </ol>\n<h2>1. Detaching a job from the terminal  <a name=\"nohup\"></a></h2>\n\
    <h3>Background and foreground jobs</h3>\n<p>Usually we run processes in the <strong><em>foreground</em></strong>:\
    \ </p>\n<ul>\n<li>Our terminal window is busy until the process is finished, </li>\n\
    <li>Standard output and error messages are printed to the terminal window </li>\n\
    <li>If we close the terminal window, the process will terminate.</li>\n</ul>\n\
    <p>We can instruct terminal to run processes in the <strong><em>background</em></strong>\
    \ <strong>( <code>&amp;</code> )</strong>:</p>\n<ul>\n<li>The terminal window\
    \ is not involved in the process, it is available for other commands</li>\n<li>The\
    \ standard output and standard error are still printed to the window</li>\n<li>If\
    \ we close the window, the process will still terminate </li>\n<li>just put a\
    \ space and \"&amp;\" at the end of your usual command<br>\n  e.g. <code>sleep\
    \ 20</code> - the terminal window will be unresponsive for 20 seconds<br>\n<code>sleep\
    \ 20 &amp;</code> - sleep command executes in the background, and the window remains\
    \ responsive</li>\n</ul>\n<h3>Nohup with background</h3>\n<p>The command <strong><code>nohup</code></strong>\
    \ ensures the command does not receive a 'hang-up' signal \nwhen the terminal\
    \ session ends.</p>\n<p>Using <strong><em>nohup</em></strong> combined with background:</p>\n\
    <ul>\n<li>The terminal window is available for other commands</li>\n<li>Standard\
    \ output is printed to file ('nohup.out') </li>\n<li>Closing the terminal session\
    \ will not terminate the process (nohup = no hang-up)</li>\n<li>Modify commands\
    \ as follows:  </li>\n</ul>\n<p><code>nohup &lt;normal commands go here&gt; 2&gt;&amp;1\
    \ &amp;</code></p>\n<p><strong><code>nohup</code></strong> detaches the command\
    \ from the terminal session \n<strong><code>2&gt;&amp;1</code></strong> sends\
    \ the standard error and the standard output to the log file 'nohup.out'.<br>\n\
    \  You can enter <code>2&gt; /dev/null &lt; /dev/null</code> instead to discard\
    \ standard error messages.\n<strong><code>&amp;</code></strong> at the end send\
    \ the process to the background.</p>\n<h3>Nohup in foreground</h3>\n<p>The 'nohup'\
    \ command can be used without running the job in the background by omitting the\
    \ '<code>&amp;</code>' at the end.\nThis is useful when you need to provide input\
    \ after entering a command (such as a password).</p>\n<p>To move any process to\
    \ the background, pause the job with <strong>'control' + 'Z'</strong>, then enter\
    \ <strong><code>bg</code></strong></p>\n<ul>\n<li><code>nohup &lt;commands that\
    \ start a job&gt; 2&gt;&amp;1</code>  </li>\n<li>Enter any input at prompts (e.g.\
    \ password, input parameters for a program)  </li>\n<li>'control' + 'Z'  -  to\
    \ pause the job  </li>\n<li><code>bg</code>  </li>\n<li>check the job is running\
    \ with <code>jobs</code> or <code>ps</code> or <code>top</code></li>\n</ul>\n\
    <p>There is a detailed example of this process <a href=\"#egnohup\">at the end\
    \ of this article</a> </p>\n<h3>Disown: detaching a job after it has started</h3>\n\
    <p>If you didn't  enter <code>nohup</code> at the beginning of a command, but\
    \ you want to ensure it keeps running when your SSH \nsession ends, there is a\
    \ command to detach an active job called <strong><code>disown</code></strong>.\
    \ The job needs to be paused with\n'control' + 'Z' before entering the command\
    \ <code>disown</code>.</p>\n<ul>\n<li><code>&lt;command that starts a job&gt;</code>\
    \  </li>\n<li>'control' + 'Z'  -  to pause the job  </li>\n<li><code>bg</code>\
    \  </li>\n<li><code>disown</code>  </li>\n<li>Check that the process is running\
    \ with <code>ps</code> or <code>top</code></li>\n</ul>\n<p>There is a detailed\
    \ example at the <a href=\"#disown\">end of this article</a></p>\n<hr>\n<h2>2.\
    \ Keeping the terminal session running with Byobu / GNU Screen <a name=\"screen\"\
    ></a></h2>\n<p>There are a couple of utilties that provide a 'virtual terminal'\
    \ that will keep running \non the server without the user having the terminal\
    \ application open and actively\nengaged in SSH connection with the VM. These\
    \ utilities are GNU Screen and TMUX, and this article \nwill cover using Screen\
    \ with the front-end package Byobu.</p>\n<ul>\n<li>It keeps your terminal session\
    \ running perpetually, you can reconnect at any time </li>\n<li>This includes\
    \ keeping active any running processes attached to the terminal session</li>\n\
    <li>It will preserve processes in the foreground, or in the background</li>\n\
    <li>The next time you log in, the terminal session will be preserved as you left\
    \ it</li>\n<li>It is a good idea to use it with <code>nohup</code> commands for\
    \ extra insurance</li>\n</ul>\n<p>Some VM users prefer not to use a virtual terminal\
    \ utility beacause:</p>\n<ul>\n<li>Learning curve : Byobu/Screen has its own set\
    \ of <a href=\"#byobu\">commands</a> to familiarise yourself with.</li>\n<li>Running\
    \ a virtual terminal is more memory intensive than simply using <code>nohup</code>\
    \ or <code>disown</code></li>\n</ul>\n<p>To install and set-up:</p>\n<ul>\n<li><code>sudo\
    \ apt-get install screen byobu</code>  </li>\n<li><code>byobu-select-backend screen</code></li>\n\
    </ul>\n<p>To start a session (and name it): <br>\n<code>byobu -S JoeyStructure</code>\
    \ </p>\n<p>(The first time you use it, enter 'control' + 'a' and select 'Screen\
    \ commands')</p>\n<p>When you've finished your terminal session, close the window\
    \ or 'ctrl' + 'a' then 'd'.\nTo log back into the session, just type <code>byobu</code>\
    \ and select your session from the list.</p>\n<p>'control' + 'a' (<strong>^a</strong>)\
    \ is used to access the Screens commands during a Byobu session</p>\n<table>\n\
    <thead>\n<tr>\n<th align=\"left\">Command</th>\n<th align=\"left\">Action</th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">^a then 'd'</td>\n<td align=\"\
    left\">detach from the byobu session, you can resume it later</td>\n</tr>\n<tr>\n\
    <td align=\"left\">^a then '?'</td>\n<td align=\"left\"><strong>help (menu of\
    \ commands)</strong></td>\n</tr>\n<tr>\n<td align=\"left\">^a then 'c'</td>\n\
    <td align=\"left\">open a new tab</td>\n</tr>\n<tr>\n<td align=\"left\">^a then\
    \ 'n' or 'p'</td>\n<td align=\"left\">switch to next/previous tab</td>\n</tr>\n\
    <tr>\n<td align=\"left\">^a then 'k'</td>\n<td align=\"left\">kill the current\
    \ tab</td>\n</tr>\n<tr>\n<td align=\"left\">^a then 'A'</td>\n<td align=\"left\"\
    >give the tab a title</td>\n</tr>\n<tr>\n<td align=\"left\">^a then '\\'</td>\n\
    <td align=\"left\">terminates the byobu session, permanently</td>\n</tr>\n<tr>\n\
    <td align=\"left\"><code>exit</code></td>\n<td align=\"left\">terminates the byobu\
    \ session, permanently</td>\n</tr>\n</tbody>\n</table>\n<p>Some other features\
    \ in Byobu/Screen:</p>\n<ul>\n<li>Easily swap between tabs of terminal windows\
    \ in your session</li>\n<li>Save a log file of activity from a terminal window\
    \ (^a then H)</li>\n<li>Split screen - multiple terminal shells in one window\
    \ (^a then S)</li>\n<li>[and many more][https://help.ubuntu.com/community/Byobu]\
    \ </li>\n</ul>\n<hr>\n<h2>Spreading jobs over multiple CPUs  <a name=\"parallel\"\
    ></a></h2>\n<p>A major advantage of NeCTAR cloud computing, is the power to launch\
    \ VM's with multiple \nprocessors (CPUs), depending upon your allocation.\nMultiple\
    \ CPUs can efficiently process more jobs simultaneously. GNU parallel is a \n\
    command-line utility to manage the distribution of a list of jobs to the available\
    \ \nCPU cores.</p>\n<h3>GNU Parallel</h3>\n<p>The GNU parallel utility will allow\
    \ the user to simultaneously run as many processes as there are CPUs.   </p>\n\
    <p>If there are 32 jobs to do and 4 CPUs, parallel will send the first 4 to be\
    \ done, \nand as each job finishes a new one will commence.</p>\n<p><img alt=\"\
    \" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/parallel.png?raw=true\"\
    ></p>\n<p>To install : <code>sudo apt-get install parallel</code></p>\n<p>Usage:\
    \ enter 'parallel' with either a list of commands, or a list of items to be\n\
    used as input for a given command.</p>\n<h4>Example Commands with Parallel</h4>\n\
    <ul>\n<li>Using parallel to decompress all files ending in .gz (these two commands\
    \ are identical):  </li>\n<li><code>parallel gunzip ::: *.gz</code>  </li>\n<li>\n\
    <p><code>ls -1 *.gz | parallel gunzip</code></p>\n</li>\n<li>\n<p>The input data\
    \ can be saved in a text file e.g. to download files from a list of URLs (these\
    \ two commands are identical):  </p>\n</li>\n<li><code>parallel wget &lt; list_of_URLs.txt</code></li>\n\
    <li>\n<p><code>parallel -a list_of_URLs.txt wget</code></p>\n</li>\n<li>\n<p>The\
    \ text file can contain a list of commands, each line as it would be entered in\
    \ the terminal:  </p>\n</li>\n<li>\n<p><code>parallel &lt; list_of_commands.txt</code></p>\n\
    </li>\n<li>\n<p>By default, parallel uses all cores in the machine.  </p>\n</li>\n\
    <li>You can dictate how many cores to use with <code>parallel -j #</code> (# is\
    \ the required number of cores)      </li>\n<li>\n<p><code>parallel -j -1</code>\
    \ uses all CPUs except one, which leaves a CPU available for other tasks/users.</p>\n\
    </li>\n<li>\n<p><strong>NOTE:</strong> Don't run parallel programs in the background,\
    \ or they will all run at once.   </p>\n</li>\n<li>The <strong>nohup</strong>\
    \ command works with parallel. e.g.:  </li>\n<li>\n<p><code>nohup parallel &lt;\
    \ list_of_commands.txt 2&gt;&amp;1</code></p>\n</li>\n<li>\n<p>If you want to\
    \ see all the processes running in parallel, htop is an excellent system monitor.\
    \  </p>\n</li>\n<li><code>sudo apt-get install htop</code>  </li>\n<li><code>htop</code></li>\n\
    </ul>\n<hr>\n<h2>Appendix - more details and examples from this article <a name=\"\
    appendix\"></a></h2>\n<ul>\n<li>Appendix</li>\n<li><a href=\"#egnohup\">example\
    \ of moving a nohup command to the background</a></li>\n<li><a href=\"#disown\"\
    >example of using 'disown'</a></li>\n<li><a href=\"#byobu\">the main Byobu / Screen\
    \ commands</a></li>\n<li><a href=\"#table\">summary table</a></li>\n</ul>\n<h3>example\
    \ of moving a nohup command to the background  <a name=\"egnohup\"></a></h3>\n\
    <p>An example would be downloading a large file from a password-protected remote\
    \ data storage server using <code>scp</code>.</p>\n<ul>\n<li>e.g. <code>nohup\
    \ scp username@host.address.edu.au:/data/files.tar.gz /mnt/data/ 2&gt;&amp;1</code>\
    \ </li>\n<li>Password is entered at the prompt</li>\n<li>Now the download begins.\
    \ There will be no prompt in the terminal, as it is busy\n  with the foreground\
    \ process.</li>\n<li>Press 'control' and 'Z' to pause the download.  </li>\n<li>There\
    \ will be output like <code>[1]+  Stopped    nohup scp ...</code></li>\n<li>Enter\
    \ <code>bg</code> to move the process to the background </li>\n<li>You will see\
    \ output like <code>[1]+ nohup scp ...... &amp;</code></li>\n<li>The download\
    \ will now resume in the background.</li>\n<li>Use the command <code>jobs</code>\
    \ to see that the download job is still active.</li>\n</ul>\n<p>The terminal session\
    \ can be terminated, and the download job will continue on the VM.</p>\n<ul>\n\
    <li>If the job is not active (this may show as <code>[1]- ....</code>):<br>\n\
    \  check for an error message in the output file :  <code>less nohup.out</code>\
    \ </li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/nohup_bg.png?raw=true\"\
    ></p>\n<h3>example of using 'disown' <a name=\"disown\"></a></h3>\n<p>If you started\
    \ a large download, and wanted it to continue without keeping the SSH\nconnection\
    \ with the VM:</p>\n<ul>\n<li>e.g. scp username@host.address.edu.au:/data/files.tar.gz\
    \ /mnt/data/</li>\n<li>Password is entered at the prompt</li>\n<li>Now the download\
    \ begins. The standard output will appear in the terminal.</li>\n<li>Press 'control'\
    \ and 'Z' to pause the download.  </li>\n<li>There will be output like <code>[1]+\
    \  Stopped    scp ...</code></li>\n<li>Enter <code>bg</code> to move the process\
    \ to the background </li>\n<li>There will be output like <code>[1]+ nohup scp\
    \ ..... &amp;</code></li>\n<li>The download will resume in the background.</li>\n\
    <li>The command <code>jobs</code> will show that the download job is still active.</li>\n\
    <li>Enter <code>disown</code></li>\n<li>Entering <code>jobs</code> will show that\
    \ the download job is no longer listed</li>\n<li>Entering <code>ps</code> shows\
    \ that the processes involved in the download (e.g. ssh and scp) are active</li>\n\
    </ul>\n<p>The terminal session can be terminated, and the download job will continue\
    \ on the VM.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Cloud Basics--DOCID21/images/disown.png?raw=true\"></p>\n\
    <h3>The Main Byobu / Screen Commands  <a name=\"byobu\"></a></h3>\n<p>'control'\
    \ + 'a' (<strong>^a</strong>) is used to access the Screens commands during a\
    \ Byobu session</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Command</th>\n\
    <th align=\"left\">Action</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\"\
    ><code>byobu -S &lt;name&gt;</code></td>\n<td align=\"left\">start a new virtual\
    \ terminal session</td>\n</tr>\n<tr>\n<td align=\"left\"><code>byobu</code></td>\n\
    <td align=\"left\">select an existing session to resume</td>\n</tr>\n<tr>\n<td\
    \ align=\"left\">^a then 'd'</td>\n<td align=\"left\">detach from the byobu session,\
    \ you can resume it later</td>\n</tr>\n<tr>\n<td align=\"left\">^a then '?'</td>\n\
    <td align=\"left\"><strong>help (menu of commands)</strong></td>\n</tr>\n<tr>\n\
    <td align=\"left\">^a then 'c'</td>\n<td align=\"left\">open a new tab</td>\n\
    </tr>\n<tr>\n<td align=\"left\">^a then 'n' or 'p'</td>\n<td align=\"left\">switch\
    \ to next/previous tab</td>\n</tr>\n<tr>\n<td align=\"left\">^a then 'k'</td>\n\
    <td align=\"left\">kill the current tab</td>\n</tr>\n<tr>\n<td align=\"left\"\
    >^a then 'A'</td>\n<td align=\"left\">give the tab a title</td>\n</tr>\n<tr>\n\
    <td align=\"left\">^a then '\\'</td>\n<td align=\"left\">terminates the byobu\
    \ session, permanently</td>\n</tr>\n<tr>\n<td align=\"left\"><code>exit</code></td>\n\
    <td align=\"left\">terminates the byobu session, permanently</td>\n</tr>\n</tbody>\n\
    </table>\n<h3>Table Summarising Options for keeping Processes Running <a name=\"\
    table\"></a></h3>\n<table>\n<thead>\n<tr>\n<th>Command type</th>\n<th>Command</th>\n\
    <th>1.Use terminal</th>\n<th>2.Output</th>\n<th>3.Close window</th>\n<th>4.To\
    \ terminate</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>foreground</td>\n\
    <td>(default)</td>\n<td>no</td>\n<td>printed</td>\n<td>termination</td>\n<td>ctrl\
    \ c</td>\n<td></td>\n</tr>\n<tr>\n<td>background</td>\n<td><code>.... &amp;</code></td>\n\
    <td>yes</td>\n<td>printed</td>\n<td>termination</td>\n<td>kill[PID#]</td>\n<td></td>\n\
    </tr>\n<tr>\n<td>nohup</td>\n<td><code>nohup ...</code></td>\n<td>no</td>\n<td>saved</td>\n\
    <td>no termination</td>\n<td>ctrl c</td>\n<td></td>\n</tr>\n<tr>\n<td>nohup +\
    \ bg</td>\n<td><code>nohup .... &amp;</code></td>\n<td>yes</td>\n<td>saved</td>\n\
    <td>no termination</td>\n<td>kill [PID#]</td>\n<td></td>\n</tr>\n<tr>\n<td>byobu</td>\n\
    <td><code>byobu</code></td>\n<td>no (tabs)</td>\n<td>printed</td>\n<td>no termination</td>\n\
    <td>ctrl a then k</td>\n<td></td>\n</tr>\n<tr>\n<td>byobu + nohup</td>\n<td>(combine\
    \ commands)</td>\n<td>yes</td>\n<td>saved</td>\n<td>no termination</td>\n<td>kill\
    \ [PID#]</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<ol>\n<li>Is the terminal\
    \ window available while the process is running;  </li>\n<li>Where is the standard\
    \ output sent;   </li>\n<li>What happens to the process when you close the screen;\
    \   </li>\n<li>How to terminate the process. </li>\n</ol>"
  parent: 21
  sha1: e407d13fe0a56c232cccf2d99f1cf6b56d8c1d2b
  title: Tips for Running Jobs on your VM
87:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-18T00:18:08-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " \n SA node service for users in South Australia \n \n Introduction\
          \ \n Cloud allocation \n Creating a security group \n Launching an instance\
          \ \n Connecting to the virtual machine remotely with Windows Remote Desktop\
          \ client \n Sharing files with the virtual machine \n Connecting from the\
          \ Dashboard \n \nGlossary of Terms  \n \n \n Introduction \n \n eResearchSA\
          \ is aiming to support South Australian users running \nWindows applications\
          \ in the NeCTAR Australian research cloud. We are currently trialling an\
          \ \napproach where users can access Windows virtual machines (VMs) in the\
          \ cloud using Remote Desktop. \n This is currently a pilot service which\
          \ uses short-term Windows trial licenses, but eRSA will be providing a production\
          \ service through a Microsoft Service Provider License Agreement (SPLA)\
          \ in early 2016. \n eRSA staff will need to set up your Windows VM image\
          \ for the cloud. Once the image \nis created, you can set up a Windows virtual\
          \ machine in the cloud by following the \nsteps specified below, or eRSA\
          \ staff can do it for you. Email eRSA Helpdesk \nand we will assist you\
          \ with getting started using Windows in the cloud. \n This service is designed\
          \ for: \n \n Researchers using software that is only available on Windows.\
          \ \n Researchers that are more comfortable using the familiar environment\
          \ of the windows\n  desktop for their cloud computing. \n \n Glossary of\
          \ Terms  \nTop of page \n \n \n Cloud allocation and Windows image \n The\
          \ Windows operating system is much larger than the standard Linux operating\
          \ systems that are usually used on NeCTAR VMs. \nYou will need to run the\
          \ Windows image on an 'm2' Instance type, which has a 30GB root\ndrive rather\
          \ than 10 GB. You will need to request a NeCTAR allocation beyond the standard\
          \ personal project\nresource. By requesting more 'cores', you can launch\
          \ instances that have enough storage to \ncope with the Windows operating\
          \ system as well as storing and processing data. \n Log in to the web dashboard\
          \ for the cloud \nand click on New Request under Allocations in the left\
          \ hand side menu. Email the \neRSA Helpdesk if you have questions about\
          \ any of the information in the form.\nNew requests can take a couple of\
          \ weeks to process, and allocations are merit-based. \n To access an image\
          \ with the Windows operating system, under current licensing agreements,\
          \ you need to be researching in South Australia\nand be registered with\
          \ eResearchSA. Email the eRSA Helpdesk\nto request an image to access Windows\
          \ in the Cloud, and supply your NeCTAR username (the email address you use\
          \ to \nlog on to NeCTAR services) and the name of the project which has\
          \ the allocations you \nhave requested.  You will be emailed a username\
          \ and password to access the Windows VM,\nand an image with the Windows\
          \ trial will be made available on your NeCTAR Dashboard. \n Glossary of\
          \ Terms \nTop of page \n \n \n Creating a security group \n \n \n First\
          \ you will need to create a security group to allow you to connect to the\
          \ \n  virtual machine remotely with Windows remote desktop.  \n \n \n Select\
          \ \"Access & Security\" under the left hand side pane under \"Compute\"\
          . \n \n \n  Select the \"Create Security Group\" button near the top right\
          \ corner \n \n \n Give your security group a name and description and click\
          \ the \"Create Security Group\" button \n \n \n \n Click \"Manage Rules\"\
          \ in the \"Actions\" drop-down menu \n \n \n  Click on the \"Add Rule\"\
          \ button near the top right corner  \n \n \n A small window should pop up.\
          \ Make sure the \"Rule\" is set to \"Custom TCP Rule\" \n  and \"Open Port\"\
          \ is set to \"Port\". Under the Port textbox enter \"3389\". Set \"Remote\"\
          \ \n  to \"CIDR\" and under the \"CIDR\" textbox enter one of the following\
          \ IP ranges as appropriate. \n \n 129.127.0.0/16 - University of Adelaide\
          \ \n 129.96.0.0/16 - Flinders \n 130.220.0.0/16 - UniSA   \n \n \n E.g.\
          \ for a user from the University of Adelaide: \n \n \n \n By specifying\
          \ these IP ranges, your Windows VM will be more secure as it can only be\
          \ accessed by computers in the University network, or using your university\
          \ VPN. To access the Windows virtual desktop from elsewhere, you can log\
          \ in via the console on the NeCTAR dashboard. \n \n Glossary of Terms  \n\
          Top of page \n \n \n Creating an instance with the Windows image \n \n \n\
          \ Select instance under the left hand side pane \n \n \n  Select the \"\
          Launch Instance\" button near the top right corner \n \n \n In the pop-up\
          \ window, assign a name to the Instance. Select a Flavor beginning with\
          \ 'm2',\n  and ensure it has a 'Root Disk' of 30 GB (look in Flavor Details\
          \ in the right column\n  of the window; we suggest m2.large or m2.xlarge\
          \ depending on how many processing cores and how much memory you need for\
          \ your work). \n  In 'Instance Boot Source', ensure 'Boot from image' is\
          \ selected. \n  Under 'Image Name', select the image that was set up for\
          \ you by eRSA. \n \n \n \n \n Under the \"Access & Security\" tab select\
          \ the security group you created earlier. \n  In this example it was \"\
          my_security_group\". \n \n \n \n Under the \"Availability Zone\" tab select\
          \ 'sa'; \n  Then click the blue 'Launch' button. \n \n \n Glossary of Terms\
          \  \nTop of page \n \n \n Connecting to the virtual machine remotely with\
          \ Windows Remote Desktop client \n \n \n Other operating systems have similar\
          \ remote desktop clients available that can be used almost\n  identically\
          \ (e.g. Microsoft remote desktop is available for Mac, and there is a remote\n\
          \  desktop client pre-installed on Ubuntu. \n \n \n Take note of the instance\
          \ IP address under the \"Instances\" page. You will need \n  this to connect\
          \ to the virtual machine via remote desktop \n \n \n On your local desktop,\
          \ start the Remote Desktop client (it is preinstalled - \n  search in the\
          \ start menu).  \n \n \n In the \"Computer\" field, enter the IP address\
          \ of the instance from the previous step, then click connect. \n \n \n \n\
          \ \n You will be prompted to enter a username and password. These were supplied\
          \ by eRSA when you requested the image for a Windows VM (this is not the\
          \ same as your eRSA username and password). \n \n \n \n You will likely\
          \ see a warning about accessing a remote computer, so tell your computer\
          \ that it is ok to trust the VM by clicking \"yes\" \n \n \n \n You should\
          \ have now connected to the Windows virtual machine \n \n \n Glossary of\
          \ Terms  \nTop of page \n \n \n Sharing files with the virtual machine \n\
          \ \n \n The remote desktop client allows you to share disk drives between\
          \ your local computer and the VM. \n \n \n At the remote dektop log-in window,\
          \ click Show Options, then choose the Local Resources tab and click More.\
          \ \n \n \n    \n \n \n Choose which local disk drives you want to make available\
          \ during your remote session and click 'OK' \n \n \n \n Now when you connect\
          \ to the windows VM, you will see the local drive amongst your devices.\
          \ \n \n \n Glossary of Terms  \nTop of page \n \n \n Allowing connections\
          \ from the NeCTAR Dashboard \n \n To have easy access to the remote desktop\
          \ through your web browser from any computer, \n  you can use the console\
          \ option in the Instances* page of the NeCTAR Dasboard. \n \n \n \n Log\
          \ in to the virtual machine using the username and password supplied by\
          \ eRSA \n  when you requested a Windows VM.\n  (Note: these are NOT the\
          \ same as the username and password for your eRSA account) \n \n \n \n \n\
          \ When you are finished, log off the virtual machine via Start button ->\
          \ Log off \n \n   \n Top of page \n \n \n Glossary \n Availability Zone\
          \ \n \n A logical grouping of compute nodes within a region. \n \n Dashboard\
          \ \n \n The NeCTAR Dashboard is the main web-based interface for managing\
          \ NeCTAR virtuals. \n \n ERSA \n \n eResearch SA runs the South Australian\
          \ node of the NeCTAR research cloud. \n \n Flavor \n \n An OpenStack term\
          \ for an instance sizing specification. Gives the amount \nof memory, number\
          \ of VCPUs and ephemeral disc size. \n \n Image \n \n An image (or system\
          \ image) is a copy of the entire state of a computer system \nsaved as a\
          \ file. Images are used in two ways in NeCTAR. Firstly as a template for\
          \ \nVirtual Machines (VMs). You can launch a VM based on an image. \nThe\
          \ second use of images is to preserve the state of a VM as configured by\
          \ you as end user. \nThis type of image is usually referred to as a snapshot.\
          \ \n \n Instance \n \n An instance is a VM hosted on the NeCTAR OpenStack\
          \ infrastructure. \n \n Project \n \n The NeCTAR term for a \"resource container\"\
          ; i.e. what you get when you \nare granted a NeCTAR allocation. A project\
          \ \"owns\" virtual machine instances, snapshots \nand various kinds of storage,\
          \ and may be shared by multiple users. \n \n Security Group \n \n A set\
          \ of access rules that may be applied to one or more instances. \nAn access\
          \ rule allows network access to an instance from other hosts with a \nspecified\
          \ combination of protocol family (e.g. TCP, UDP, UCMP), port number and\
          \ address range. \n \n Virtual Machine \n \n A virtual machine (VM) is an\
          \ operating system (OS) or application environment that \nis installed on\
          \ software which imitates dedicated hardware. The end user has the same\
          \ \nexperience on a virtual machine as they would have on dedicated hardware.\
          \ \n \n Volume Storage \n \n Data Storage in your Virtual Machine that works\
          \ like a hard-drive on your PC or \nlaptop does. Volume storage is automatically\
          \ available in your VM as the storage \nspace for you system drive. Some\
          \ flavors of VMs include an amount of ephemeral volume \nstorage. Depending\
          \ on your allocation you can have persistent volume storage attached to\
          \ your VM. \n \n Full Glossary Page \nNeCTAR FAQ - general inormation \n\
          For more help, contact the eRSA Helpdesk or NeCTAR support   \n Top of page "
        description: "<p><a name=\"top\"></a></p>\n<h2>SA node service for users in\
          \ South Australia</h2>\n<ul>\n<li><a href=\"#intro\">Introduction</a></li>\n\
          <li><a href=\"#alloc\">Cloud allocation</a></li>\n<li><a href=\"#security\"\
          >Creating a security group</a></li>\n<li><a href=\"#instance\">Launching\
          \ an instance</a></li>\n<li><a href=\"#desktop\">Connecting to the virtual\
          \ machine remotely with Windows Remote Desktop client</a></li>\n<li><a href=\"\
          #transferfiles\">Sharing files with the virtual machine</a></li>\n<li><a\
          \ href=\"#connection\">Connecting from the Dashboard</a></li>\n<li>\n<a\
          \ href=\"#glossary\">Glossary of Terms</a> </li>\n</ul>\n<hr>\n<h2>Introduction\
          \ <a name=\"intro\"></a>\n</h2>\n<p><a href=\"https://www.ersa.edu.au/\"\
          >eResearchSA</a> is aiming to support South Australian users running \n\
          Windows applications in the NeCTAR Australian research cloud. We are currently\
          \ trialling an \napproach where users can access Windows virtual machines\
          \ (VMs) in the cloud using Remote Desktop.</p>\n<p>This is currently a pilot\
          \ service which uses short-term Windows trial licenses, but eRSA will be\
          \ providing a production service through a Microsoft Service Provider License\
          \ Agreement (SPLA) in early 2016.</p>\n<p>eRSA staff will need to set up\
          \ your Windows VM image for the cloud. Once the image \nis created, you\
          \ can set up a Windows virtual machine in the cloud by following the \n\
          steps specified below, or eRSA staff can do it for you. Email <a href=\"\
          mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a> \nand we will assist\
          \ you with getting started using Windows in the cloud.</p>\n<p>This service\
          \ is designed for:</p>\n<ul>\n<li>Researchers using software that is only\
          \ available on Windows.</li>\n<li>Researchers that are more comfortable\
          \ using the familiar environment of the windows\n  desktop for their cloud\
          \ computing.</li>\n</ul>\n<p><a href=\"#glossary\">Glossary of Terms</a>\
          \ <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"alloc\"\
          ></a></p>\n<h2>Cloud allocation and Windows image</h2>\n<p>The Windows operating\
          \ system is much larger than the standard Linux operating systems that are\
          \ usually used on NeCTAR VMs. \nYou will need to run the Windows image on\
          \ an '<strong>m2</strong>' Instance type, which has a 30GB root\ndrive rather\
          \ than 10 GB. You will need to request a <a href=\"https://dashboard.rc.nectar.org.au/project/request/\"\
          >NeCTAR allocation</a> beyond the standard personal project\nresource. By\
          \ requesting more 'cores', you can launch instances that have enough storage\
          \ to \ncope with the Windows operating system as well as storing and processing\
          \ data.</p>\n<p>Log in to the <a href=\"https://dashboard.rc.nectar.org.au/\"\
          >web dashboard</a> for the cloud \nand click on <strong>New Request</strong>\
          \ under <strong>Allocations</strong> in the left hand side menu. Email the\
          \ \n<a href=\"mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a> if you\
          \ have questions about any of the information in the form.\nNew requests\
          \ can take a couple of weeks to process, and allocations are merit-based.</p>\n\
          <p>To access an image with the Windows operating system, under current licensing\
          \ agreements, you need to be researching in South Australia\nand be <a href=\"\
          https://register.ersa.edu.au/\">registered with eResearchSA</a>. Email the\
          \ <a href=\"mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a>\nto request\
          \ an image to access Windows in the Cloud, and supply your NeCTAR username\
          \ (the email address you use to \nlog on to NeCTAR services) and the name\
          \ of the project which has the allocations you \nhave requested.  You will\
          \ be emailed a username and password to access the Windows VM,\nand an image\
          \ with the Windows trial will be made available on your NeCTAR Dashboard.</p>\n\
          <p><a href=\"#glossary\">Glossary of Terms</a><br>\n<a href=\"#top\">Top\
          \ of page</a></p>\n<hr>\n<p><a name=\"security\"></a></p>\n<h2>Creating\
          \ a security group</h2>\n<ul>\n<li>\n<p>First you will need to create a\
          \ security group to allow you to connect to the \n  virtual machine remotely\
          \ with Windows remote desktop. </p>\n</li>\n<li>\n<p>Select \"Access &amp;\
          \ Security\" under the left hand side pane under \"Compute\".</p>\n</li>\n\
          <li>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_sg_createbutton.png?raw=true\"\
          > Select the \"Create Security Group\" button near the top right corner</p>\n\
          </li>\n<li>\n<p>Give your security group a name and description and click\
          \ the \"Create Security Group\" button</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_sg_createwindow.png?raw=true\"\
          ></p>\n</li>\n<li>\n<p>Click \"Manage Rules\" in the \"Actions\" drop-down\
          \ menu</p>\n</li>\n<li>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_sg_rulebutton.png?raw=true\"\
          > Click on the \"Add Rule\" button near the top right corner </p>\n</li>\n\
          <li>\n<p>A small window should pop up. Make sure the \"Rule\" is set to\
          \ \"Custom TCP Rule\" \n  and \"Open Port\" is set to \"Port\". Under the\
          \ Port textbox enter \"<strong>3389</strong>\". Set \"Remote\" \n  to \"\
          CIDR\" and under the \"CIDR\" textbox enter one of the following IP ranges\
          \ as appropriate.</p>\n<ul>\n<li>129.127.0.0/16 - University of Adelaide</li>\n\
          <li>129.96.0.0/16 - Flinders</li>\n<li>130.220.0.0/16 - UniSA  </li>\n</ul>\n\
          </li>\n<li>E.g. for a user from the University of Adelaide:</li>\n</ul>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_sg_rulewindow.png?raw=true\"\
          ></p>\n<ul>\n<li>By specifying these IP ranges, your Windows VM will be\
          \ more secure as it can only be accessed by computers in the University\
          \ network, or using your university VPN. To access the Windows virtual desktop\
          \ from elsewhere, you can log in via the <a href=\"#connection\">console\
          \ on the NeCTAR dashboard</a>.</li>\n</ul>\n<p><a href=\"#glossary\">Glossary\
          \ of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"\
          instance\"></a></p>\n<h2>Creating an instance with the Windows image</h2>\n\
          <ul>\n<li>\n<p>Select instance under the left hand side pane</p>\n</li>\n\
          <li>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_launch.png?raw=true\"\
          > Select the \"Launch Instance\" button near the top right corner</p>\n\
          </li>\n<li>\n<p>In the pop-up window, assign a name to the Instance. Select\
          \ a <strong>Flavor</strong> beginning with '<strong>m2</strong>',\n  and\
          \ ensure it has a 'Root Disk' of 30 GB (look in Flavor Details in the right\
          \ column\n  of the window; we suggest m2.large or m2.xlarge depending on\
          \ how many processing cores and how much memory you need for your work).\
          \ \n  In 'Instance Boot Source', ensure 'Boot from image' is selected. \n\
          \  Under 'Image Name', select the image that was set up for you by eRSA.</p>\n\
          </li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_tab_details.png?raw=true\"\
          ></p>\n<ul>\n<li>Under the \"<strong>Access &amp; Security</strong>\" tab\
          \ select the security group you created earlier. \n  In this example it\
          \ was \"my_security_group\".</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_tab_security.png?raw=true\"\
          ></p>\n<ul>\n<li>Under the \"Availability Zone\" tab select '<strong>sa</strong>';<br>\n\
          \  Then click the blue 'Launch' button.</li>\n</ul>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_tab_zone.png?raw=true\"\
          ></p>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\"\
          >Top of page</a></p>\n<hr>\n<p><a name=\"desktop\"></a></p>\n<h2>Connecting\
          \ to the virtual machine remotely with Windows Remote Desktop client</h2>\n\
          <ul>\n<li>\n<p>Other operating systems have similar remote desktop clients\
          \ available that can be used almost\n  identically (e.g. <a href=\"https://itunes.apple.com/us/app/microsoft-remote-desktop/id715768417\"\
          >Microsoft remote desktop</a> is available for Mac, and there is a remote\n\
          \  desktop client pre-installed on Ubuntu.</p>\n</li>\n<li>\n<p>Take note\
          \ of the instance IP address under the \"Instances\" page. You will need\
          \ \n  this to connect to the virtual machine via remote desktop</p>\n</li>\n\
          <li>\n<p>On your local desktop, start the Remote Desktop client (it is preinstalled\
          \ - \n  search in the start menu). </p>\n</li>\n<li>\n<p>In the \"Computer\"\
          \ field, enter the IP address of the instance from the previous step, then\
          \ click connect.</p>\n</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_rdp1.png?raw=true\"\
          ></p>\n<ul>\n<li>You will be prompted to enter a username and password.\
          \ These were supplied by eRSA when you requested the image for a Windows\
          \ VM (this is not the same as your eRSA username and password).</li>\n</ul>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_rdp2.png?raw=true\"\
          ></p>\n<ul>\n<li>You will likely see a warning about accessing a remote\
          \ computer, so tell your computer that it is ok to trust the VM by clicking\
          \ \"yes\"</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_rdp3.png?raw=true\"\
          ></p>\n<ul>\n<li>You should have now connected to the Windows virtual machine</li>\n\
          </ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_rdp4.png?raw=true\"\
          ></p>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\"\
          >Top of page</a></p>\n<hr>\n<p><a name=\"transferfiles\"></a></p>\n<h2>Sharing\
          \ files with the virtual machine</h2>\n<ul>\n<li>\n<p>The remote desktop\
          \ client allows you to share disk drives between your local computer and\
          \ the VM.</p>\n</li>\n<li>\n<p>At the remote dektop log-in window, click\
          \ <strong>Show Options</strong>, then choose the <strong>Local Resources</strong>\
          \ tab and click <strong>More</strong>.</p>\n</li>\n</ul>\n<p><img alt=\"\
          \" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_share_1.png?raw=true\"\
          >  </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_share_2.png?raw=true\"\
          ></p>\n<ul>\n<li>Choose which local disk drives you want to make available\
          \ during your remote session and click 'OK'</li>\n</ul>\n<p><img alt=\"\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_share_3.png?raw=true\"\
          ></p>\n<ul>\n<li>Now when you connect to the windows VM, you will see the\
          \ local drive amongst your devices.</li>\n</ul>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_share_4.png?raw=true\"\
          ></p>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\"\
          >Top of page</a></p>\n<hr>\n<p><a name=\"connection\"></a></p>\n<h2>Allowing\
          \ connections from the NeCTAR Dashboard</h2>\n<ul>\n<li>To have easy access\
          \ to the remote desktop through your web browser from any computer, \n \
          \ you can use the <strong>console</strong> option in the <em>Instances</em>*\
          \ page of the <a href=\"https://dashboard.rc.nectar.org.au/\">NeCTAR Dasboard</a>.</li>\n\
          </ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_new_instance_coonsole.png?raw=true\"\
          ></p>\n<ul>\n<li>Log in to the virtual machine using the username and password\
          \ supplied by eRSA \n  when you requested a Windows VM.\n  (Note: these\
          \ are NOT the same as the username and password for your eRSA account)</li>\n\
          </ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_login.png?raw=true\"\
          ></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_login2.png?raw=true\"\
          ></p>\n<ul>\n<li>When you are finished, log off the virtual machine via\
          \ Start button -&gt; Log off</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/windowsDOCID87_instance_logoff.png?raw=true\"\
          > </p>\n<p><a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"glossary\"\
          ></a></p>\n<h3>Glossary</h3>\n<p><strong>Availability Zone</strong></p>\n\
          <blockquote>\n<p>A logical grouping of compute nodes within a region.</p>\n\
          </blockquote>\n<p><strong>Dashboard</strong></p>\n<blockquote>\n<p>The NeCTAR\
          \ Dashboard is the main web-based interface for managing NeCTAR virtuals.</p>\n\
          </blockquote>\n<p><strong>ERSA</strong></p>\n<blockquote>\n<p>eResearch\
          \ SA runs the South Australian node of the NeCTAR research cloud.</p>\n\
          </blockquote>\n<p><strong>Flavor</strong></p>\n<blockquote>\n<p>An OpenStack\
          \ term for an instance sizing specification. Gives the amount \nof memory,\
          \ number of VCPUs and ephemeral disc size.</p>\n</blockquote>\n<p><strong>Image</strong></p>\n\
          <blockquote>\n<p>An image (or system image) is a copy of the entire state\
          \ of a computer system \nsaved as a file. Images are used in two ways in\
          \ NeCTAR. Firstly as a template for \nVirtual Machines (VMs). You can launch\
          \ a VM based on an image. \nThe second use of images is to preserve the\
          \ state of a VM as configured by you as end user. \nThis type of image is\
          \ usually referred to as a snapshot.</p>\n</blockquote>\n<p><strong>Instance</strong></p>\n\
          <blockquote>\n<p>An instance is a VM hosted on the NeCTAR OpenStack infrastructure.</p>\n\
          </blockquote>\n<p><strong>Project</strong></p>\n<blockquote>\n<p>The NeCTAR\
          \ term for a \"resource container\"; i.e. what you get when you \nare granted\
          \ a NeCTAR allocation. A project \"owns\" virtual machine instances, snapshots\
          \ \nand various kinds of storage, and may be shared by multiple users.</p>\n\
          </blockquote>\n<p><strong>Security Group</strong></p>\n<blockquote>\n<p>A\
          \ set of access rules that may be applied to one or more instances. \nAn\
          \ access rule allows network access to an instance from other hosts with\
          \ a \nspecified combination of protocol family (e.g. TCP, UDP, UCMP), port\
          \ number and address range.</p>\n</blockquote>\n<p><strong>Virtual Machine</strong></p>\n\
          <blockquote>\n<p>A virtual machine (VM) is an operating system (OS) or application\
          \ environment that \nis installed on software which imitates dedicated hardware.\
          \ The end user has the same \nexperience on a virtual machine as they would\
          \ have on dedicated hardware.</p>\n</blockquote>\n<p><strong>Volume Storage</strong></p>\n\
          <blockquote>\n<p>Data Storage in your Virtual Machine that works like a\
          \ hard-drive on your PC or \nlaptop does. Volume storage is automatically\
          \ available in your VM as the storage \nspace for you system drive. Some\
          \ flavors of VMs include an amount of ephemeral volume \nstorage. Depending\
          \ on your allocation you can have persistent volume storage attached to\
          \ your VM.</p>\n</blockquote>\n<p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000055445-glossary\"\
          >Full Glossary Page</a><br>\n<a href=\"http://cloud.nectar.org.au/faq/\"\
          >NeCTAR FAQ - general inormation</a><br>\nFor more help, contact the <a\
          \ href=\"mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a> or <a href=\"\
          https://support.nectar.org.au/support/tickets/new\">NeCTAR support</a> \
          \ </p>\n<p><a href=\"#top\">Top of page</a></p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 42
        id: 6000089734
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-30T20:00:06-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000089734
        position: 3
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: eRSA Windows in the Cloud - user guide
        updated_at: '2015-11-30T20:00:06-05:00'
        user_id: 6002464727
  html: "<p><a name=\"top\"></a></p>\n<h2>SA node service for users in South Australia</h2>\n\
    <ul>\n<li><a href=\"#intro\">Introduction</a></li>\n<li><a href=\"#alloc\">Cloud\
    \ allocation</a></li>\n<li><a href=\"#security\">Creating a security group</a></li>\n\
    <li><a href=\"#instance\">Launching an instance</a></li>\n<li><a href=\"#desktop\"\
    >Connecting to the virtual machine remotely with Windows Remote Desktop client</a></li>\n\
    <li><a href=\"#transferfiles\">Sharing files with the virtual machine</a></li>\n\
    <li><a href=\"#connection\">Connecting from the Dashboard</a></li>\n<li><a href=\"\
    #glossary\">Glossary of Terms</a> </li>\n</ul>\n<hr>\n<h2>Introduction <a name=\"\
    intro\"></a></h2>\n<p><a href=\"https://www.ersa.edu.au/\">eResearchSA</a> is\
    \ aiming to support South Australian users running \nWindows applications in the\
    \ NeCTAR Australian research cloud. We are currently trialling an \napproach where\
    \ users can access Windows virtual machines (VMs) in the cloud using Remote Desktop.</p>\n\
    <p>This is currently a pilot service which uses short-term Windows trial licenses,\
    \ but eRSA will be providing a production service through a Microsoft Service\
    \ Provider License Agreement (SPLA) in early 2016.</p>\n<p>eRSA staff will need\
    \ to set up your Windows VM image for the cloud. Once the image \nis created,\
    \ you can set up a Windows virtual machine in the cloud by following the \nsteps\
    \ specified below, or eRSA staff can do it for you. Email <a href=\"mailto:servicedesk@ersa.edu.au\"\
    >eRSA Helpdesk</a> \nand we will assist you with getting started using Windows\
    \ in the cloud.</p>\n<p>This service is designed for:</p>\n<ul>\n<li>Researchers\
    \ using software that is only available on Windows.</li>\n<li>Researchers that\
    \ are more comfortable using the familiar environment of the windows\n  desktop\
    \ for their cloud computing.</li>\n</ul>\n<p><a href=\"#glossary\">Glossary of\
    \ Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"alloc\"\
    ></a></p>\n<h2>Cloud allocation and Windows image</h2>\n<p>The Windows operating\
    \ system is much larger than the standard Linux operating systems that are usually\
    \ used on NeCTAR VMs. \nYou will need to run the Windows image on an '<strong>m2</strong>'\
    \ Instance type, which has a 30GB root\ndrive rather than 10 GB. You will need\
    \ to request a <a href=\"https://dashboard.rc.nectar.org.au/project/request/\"\
    >NeCTAR allocation</a> beyond the standard personal project\nresource. By requesting\
    \ more 'cores', you can launch instances that have enough storage to \ncope with\
    \ the Windows operating system as well as storing and processing data.</p>\n<p>Log\
    \ in to the <a href=\"https://dashboard.rc.nectar.org.au/\">web dashboard</a>\
    \ for the cloud \nand click on <strong>New Request</strong> under <strong>Allocations</strong>\
    \ in the left hand side menu. Email the \n<a href=\"mailto:servicedesk@ersa.edu.au\"\
    >eRSA Helpdesk</a> if you have questions about any of the information in the form.\n\
    New requests can take a couple of weeks to process, and allocations are merit-based.</p>\n\
    <p>To access an image with the Windows operating system, under current licensing\
    \ agreements, you need to be researching in South Australia\nand be <a href=\"\
    https://register.ersa.edu.au/\">registered with eResearchSA</a>. Email the <a\
    \ href=\"mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a>\nto request an image\
    \ to access Windows in the Cloud, and supply your NeCTAR username (the email address\
    \ you use to \nlog on to NeCTAR services) and the name of the project which has\
    \ the allocations you \nhave requested.  You will be emailed a username and password\
    \ to access the Windows VM,\nand an image with the Windows trial will be made\
    \ available on your NeCTAR Dashboard.</p>\n<p><a href=\"#glossary\">Glossary of\
    \ Terms</a><br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"security\"\
    ></a></p>\n<h2>Creating a security group</h2>\n<ul>\n<li>\n<p>First you will need\
    \ to create a security group to allow you to connect to the \n  virtual machine\
    \ remotely with Windows remote desktop. </p>\n</li>\n<li>\n<p>Select \"Access\
    \ &amp; Security\" under the left hand side pane under \"Compute\".</p>\n</li>\n\
    <li>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_sg_createbutton.png?raw=true\"\
    > Select the \"Create Security Group\" button near the top right corner</p>\n\
    </li>\n<li>\n<p>Give your security group a name and description and click the\
    \ \"Create Security Group\" button</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_sg_createwindow.png?raw=true\"\
    ></p>\n</li>\n<li>\n<p>Click \"Manage Rules\" in the \"Actions\" drop-down menu</p>\n\
    </li>\n<li>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_sg_rulebutton.png?raw=true\"\
    > Click on the \"Add Rule\" button near the top right corner </p>\n</li>\n<li>\n\
    <p>A small window should pop up. Make sure the \"Rule\" is set to \"Custom TCP\
    \ Rule\" \n  and \"Open Port\" is set to \"Port\". Under the Port textbox enter\
    \ \"<strong>3389</strong>\". Set \"Remote\" \n  to \"CIDR\" and under the \"CIDR\"\
    \ textbox enter one of the following IP ranges as appropriate.</p>\n<ul>\n<li>129.127.0.0/16\
    \ - University of Adelaide</li>\n<li>129.96.0.0/16 - Flinders</li>\n<li>130.220.0.0/16\
    \ - UniSA  </li>\n</ul>\n</li>\n<li>E.g. for a user from the University of Adelaide:</li>\n\
    </ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_sg_rulewindow.png?raw=true\"\
    ></p>\n<ul>\n<li>By specifying these IP ranges, your Windows VM will be more secure\
    \ as it can only be accessed by computers in the University network, or using\
    \ your university VPN. To access the Windows virtual desktop from elsewhere, you\
    \ can log in via the <a href=\"#connection\">console on the NeCTAR dashboard</a>.</li>\n\
    </ul>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top\
    \ of page</a></p>\n<hr>\n<p><a name=\"instance\"></a></p>\n<h2>Creating an instance\
    \ with the Windows image</h2>\n<ul>\n<li>\n<p>Select instance under the left hand\
    \ side pane</p>\n</li>\n<li>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_launch.png?raw=true\"\
    > Select the \"Launch Instance\" button near the top right corner</p>\n</li>\n\
    <li>\n<p>In the pop-up window, assign a name to the Instance. Select a <strong>Flavor</strong>\
    \ beginning with '<strong>m2</strong>',\n  and ensure it has a 'Root Disk' of\
    \ 30 GB (look in Flavor Details in the right column\n  of the window; we suggest\
    \ m2.large or m2.xlarge depending on how many processing cores and how much memory\
    \ you need for your work). \n  In 'Instance Boot Source', ensure 'Boot from image'\
    \ is selected. \n  Under 'Image Name', select the image that was set up for you\
    \ by eRSA.</p>\n</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_tab_details.png?raw=true\"\
    ></p>\n<ul>\n<li>Under the \"<strong>Access &amp; Security</strong>\" tab select\
    \ the security group you created earlier. \n  In this example it was \"my_security_group\"\
    .</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_tab_security.png?raw=true\"\
    ></p>\n<ul>\n<li>Under the \"Availability Zone\" tab select '<strong>sa</strong>';<br>\n\
    \  Then click the blue 'Launch' button.</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_tab_zone.png?raw=true\"\
    ></p>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top\
    \ of page</a></p>\n<hr>\n<p><a name=\"desktop\"></a></p>\n<h2>Connecting to the\
    \ virtual machine remotely with Windows Remote Desktop client</h2>\n<ul>\n<li>\n\
    <p>Other operating systems have similar remote desktop clients available that\
    \ can be used almost\n  identically (e.g. <a href=\"https://itunes.apple.com/us/app/microsoft-remote-desktop/id715768417\"\
    >Microsoft remote desktop</a> is available for Mac, and there is a remote\n  desktop\
    \ client pre-installed on Ubuntu.</p>\n</li>\n<li>\n<p>Take note of the instance\
    \ IP address under the \"Instances\" page. You will need \n  this to connect to\
    \ the virtual machine via remote desktop</p>\n</li>\n<li>\n<p>On your local desktop,\
    \ start the Remote Desktop client (it is preinstalled - \n  search in the start\
    \ menu). </p>\n</li>\n<li>\n<p>In the \"Computer\" field, enter the IP address\
    \ of the instance from the previous step, then click connect.</p>\n</li>\n</ul>\n\
    <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_rdp1.png?raw=true\"\
    ></p>\n<ul>\n<li>You will be prompted to enter a username and password. These\
    \ were supplied by eRSA when you requested the image for a Windows VM (this is\
    \ not the same as your eRSA username and password).</li>\n</ul>\n<p><img alt=\"\
    \" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_rdp2.png?raw=true\"\
    ></p>\n<ul>\n<li>You will likely see a warning about accessing a remote computer,\
    \ so tell your computer that it is ok to trust the VM by clicking \"yes\"</li>\n\
    </ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_rdp3.png?raw=true\"\
    ></p>\n<ul>\n<li>You should have now connected to the Windows virtual machine</li>\n\
    </ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_rdp4.png?raw=true\"\
    ></p>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top\
    \ of page</a></p>\n<hr>\n<p><a name=\"transferfiles\"></a></p>\n<h2>Sharing files\
    \ with the virtual machine</h2>\n<ul>\n<li>\n<p>The remote desktop client allows\
    \ you to share disk drives between your local computer and the VM.</p>\n</li>\n\
    <li>\n<p>At the remote dektop log-in window, click <strong>Show Options</strong>,\
    \ then choose the <strong>Local Resources</strong> tab and click <strong>More</strong>.</p>\n\
    </li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_share_1.png?raw=true\"\
    >  </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_share_2.png?raw=true\"\
    ></p>\n<ul>\n<li>Choose which local disk drives you want to make available during\
    \ your remote session and click 'OK'</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_share_3.png?raw=true\"\
    ></p>\n<ul>\n<li>Now when you connect to the windows VM, you will see the local\
    \ drive amongst your devices.</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_share_4.png?raw=true\"\
    ></p>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top\
    \ of page</a></p>\n<hr>\n<p><a name=\"connection\"></a></p>\n<h2>Allowing connections\
    \ from the NeCTAR Dashboard</h2>\n<ul>\n<li>To have easy access to the remote\
    \ desktop through your web browser from any computer, \n  you can use the <strong>console</strong>\
    \ option in the <em>Instances</em>* page of the <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >NeCTAR Dasboard</a>.</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_new_instance_coonsole.png?raw=true\"\
    ></p>\n<ul>\n<li>Log in to the virtual machine using the username and password\
    \ supplied by eRSA \n  when you requested a Windows VM.\n  (Note: these are NOT\
    \ the same as the username and password for your eRSA account)</li>\n</ul>\n<p><img\
    \ alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_login.png?raw=true\"\
    ></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_login2.png?raw=true\"\
    ></p>\n<ul>\n<li>When you are finished, log off the virtual machine via Start\
    \ button -&gt; Log off</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/windowsDOCID87_instance_logoff.png?raw=true\"\
    > </p>\n<p><a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"glossary\"\
    ></a></p>\n<h3>Glossary</h3>\n<p><strong>Availability Zone</strong></p>\n<blockquote>\n\
    <p>A logical grouping of compute nodes within a region.</p>\n</blockquote>\n<p><strong>Dashboard</strong></p>\n\
    <blockquote>\n<p>The NeCTAR Dashboard is the main web-based interface for managing\
    \ NeCTAR virtuals.</p>\n</blockquote>\n<p><strong>ERSA</strong></p>\n<blockquote>\n\
    <p>eResearch SA runs the South Australian node of the NeCTAR research cloud.</p>\n\
    </blockquote>\n<p><strong>Flavor</strong></p>\n<blockquote>\n<p>An OpenStack term\
    \ for an instance sizing specification. Gives the amount \nof memory, number of\
    \ VCPUs and ephemeral disc size.</p>\n</blockquote>\n<p><strong>Image</strong></p>\n\
    <blockquote>\n<p>An image (or system image) is a copy of the entire state of a\
    \ computer system \nsaved as a file. Images are used in two ways in NeCTAR. Firstly\
    \ as a template for \nVirtual Machines (VMs). You can launch a VM based on an\
    \ image. \nThe second use of images is to preserve the state of a VM as configured\
    \ by you as end user. \nThis type of image is usually referred to as a snapshot.</p>\n\
    </blockquote>\n<p><strong>Instance</strong></p>\n<blockquote>\n<p>An instance\
    \ is a VM hosted on the NeCTAR OpenStack infrastructure.</p>\n</blockquote>\n\
    <p><strong>Project</strong></p>\n<blockquote>\n<p>The NeCTAR term for a \"resource\
    \ container\"; i.e. what you get when you \nare granted a NeCTAR allocation. A\
    \ project \"owns\" virtual machine instances, snapshots \nand various kinds of\
    \ storage, and may be shared by multiple users.</p>\n</blockquote>\n<p><strong>Security\
    \ Group</strong></p>\n<blockquote>\n<p>A set of access rules that may be applied\
    \ to one or more instances. \nAn access rule allows network access to an instance\
    \ from other hosts with a \nspecified combination of protocol family (e.g. TCP,\
    \ UDP, UCMP), port number and address range.</p>\n</blockquote>\n<p><strong>Virtual\
    \ Machine</strong></p>\n<blockquote>\n<p>A virtual machine (VM) is an operating\
    \ system (OS) or application environment that \nis installed on software which\
    \ imitates dedicated hardware. The end user has the same \nexperience on a virtual\
    \ machine as they would have on dedicated hardware.</p>\n</blockquote>\n<p><strong>Volume\
    \ Storage</strong></p>\n<blockquote>\n<p>Data Storage in your Virtual Machine\
    \ that works like a hard-drive on your PC or \nlaptop does. Volume storage is\
    \ automatically available in your VM as the storage \nspace for you system drive.\
    \ Some flavors of VMs include an amount of ephemeral volume \nstorage. Depending\
    \ on your allocation you can have persistent volume storage attached to your VM.</p>\n\
    </blockquote>\n<p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000055445-glossary\"\
    >Full Glossary Page</a><br>\n<a href=\"http://cloud.nectar.org.au/faq/\">NeCTAR\
    \ FAQ - general inormation</a><br>\nFor more help, contact the <a href=\"mailto:servicedesk@ersa.edu.au\"\
    >eRSA Helpdesk</a> or <a href=\"https://support.nectar.org.au/support/tickets/new\"\
    >NeCTAR support</a>  </p>\n<p><a href=\"#top\">Top of page</a></p>"
  parent: 24
  sha1: c44ddaf6c9149cba165937d9c41e0bac293c9d92
  title: eRSA Windows in the Cloud - user guide
88:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-18T01:00:13-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Twitter Scraper User Guide \n Description \n Twitter Scraper\
          \ is a tool developed by Intersect for use in collecting data directly from\
          \ the Twitter Stream API based on a variety of parameters, including hashtags\
          \ and phrases, users, location and language, and outputs matching tweets\
          \ to a comma separated values (.csv) spreadsheet for analysis. \n Target\
          \ Audience \n Twitter Scraper is available for use by any researcher with\
          \ an account at an Australian research institution that subscribes to the\
          \ Australian Access Federation (see the full list of AAF subscribers). Researchers\
          \ who want to incorporate data from Twitter into their research are encouraged\
          \ to use Twitter Scraper as a powerful, though relatively easy, service\
          \ which can be run on the NeCTAR Research Cloud. NeCTAR offer VMs to researchers\
          \ for free for a trial period, or longer periods under a merit allocation\
          \ scheme. Twitter Scraper itself is completely free for researchers. \n\
          \ How to Launch \n Twitter Scraper is deployed through Launchpod, a web\
          \ utility for configuring and deploying virtual machines (VMs) onto the\
          \ NeCTAR Research Cloud. Launchpod allows for users with little or no experience\
          \ with cloud computing to configure and deploy Twitter Scraper easily and\
          \ quickly. Before deploying Twitter Scraper, please refer to the documentation\
          \ for deploying VMs using Launchpod. \n If you intend to log into Twitter\
          \ Scraper via SSH, for example to modify the harvester settings after it\
          \ has been deployed, you must specify an SSH keypair in Launchpod. Please\
          \ follow the instructions in the Launchpod user guide or at NeCTAR Research\
          \ Cloud on how to do so. \n Obtaining Twitter access credentials \n Important:\
          \ The steps to obtain your Twitter access tokens and consumer API keys only\
          \ need to be done once. If you intend to deploy more Twitter Scrapers, you\
          \ should use the same access tokens and credentials. You can always log\
          \ into the Twitter Applications Development site to get access tokens you've\
          \ already generated, or you can keep them in a safe place for later use.\
          \ \n Twitter Scraper uses your Twitter account to monitor the constant stream\
          \ of tweets and find those matching your specified search terms. Before\
          \ you can use Twitter Scraper, you need to create an \u2018application\u2019\
          \ within Twitter, and then obtain the Consumer Key and the Consumer Secret\
          \ from this application, as well as your Access Token and Access Token Secret.\
          \ \n First, navigate to the Twitter Applications Development site and log\
          \ in with your Twitter credentials. From here you will create the \u2018\
          application\u2019. This page is typically used by developers to register\
          \ apps that they have created and which people can download. Most of the\
          \ information is actually irrelevant for Twitter Scraper, but it needs to\
          \ be entered in order to create the access credentials that Twitter Scraper\
          \ needs. As of mid-2015, you need to have a mobile phone number associated\
          \ with your Twitter account to register an application. If you don't have\
          \ a mobile number, go to your Twitter profile and enter one. \n Click Create\
          \ New App and provide a name (such as \u2018Twitter Scraper\u2019) and a\
          \ brief description (such as \u2018this is an app to harvest tweets\u2019\
          ). You also need to provide a URL. It does not have to be a real website,\
          \ but it does have to begin with http://. A dummy URL like http://www.example.com\
          \ is sufficient. Scroll to the end of the page and select 'Yes, I agree\
          \ to the Developer Agreement'. Finally, click 'Create your Twitter Application'.\
          \ \n Once your app has been created, navigate to the \u2018Keys and Access\
          \ Tokens\u2019 tab of the app settings. This page will display two of the\
          \ four settings you need, the Consumer Key (API Key) and the Consumer Secret\
          \ (API Secret). You can copy these straight out of Twitter and into a note\
          \ or document for use later, or put them directly into the relevant fields\
          \ in Launchpod. \n \n To generate the other two credentials, scroll to the\
          \ bottom of the same page and under 'Your Access Token' click the button\
          \ 'Create my access token'. The page will reload, and the Access Token and\
          \ the Access Token Secret will be displayed at the end. Make sure when copying\
          \ the Access Token that you copy the whole line including the 9-digit number\
          \ at the front, which is the same as your owner ID. The Launchpod Twitter\
          \ Scraper will not function without this. \n \n Now that you have all of\
          \ the access credentials needed to deploy Twitter Scraper, you can begin\
          \ configuring the tweet harvesting parameters. \n Specifying Harvest Parameters\
          \ \n Twitter Scraper search parameters need to be configured prior to the\
          \ deployment of the server. Once it is deployed, you cannot change the search\
          \ settings without logging in to the VM via SSH. Harvest parameters are\
          \ split into two categories: Matching Options, what Twitter Scraper will\
          \ search for; and Output Options, how Twitter Scraper will format and configure\
          \ the output CSV file. \n Matching options \n Phrases \n This is where you\
          \ will enter the search terms and hashtags that Twitter Scraper will monitor\
          \ the Twitter stream for. You can set search phrases in a number of ways.\
          \ To search for an individual word, enter a single word and hit return.\
          \ If you want to search for tweets that contain multiple words in any order,\
          \ enter each word and hit return. If you want to search for an exact phrase,\
          \ enclose the phrase in double quotes before hitting return. The example\
          \ below will return any tweet that contains the word \u2018Launchpod\u2019\
          , in addition to any tweet that contains both the words \u2018Intersect\u2019\
          \ and \u2018Australia\u2019, in addition to any tweet that contains the\
          \ exact phrase \u2018Twitter Scraper\u2019. \n \n In other words, each search\
          \ term is separated by an implicit OR operation, and every word inside a\
          \ search term (such as \u2018Intersect Australia\u2019 above) is separated\
          \ by an implicit AND operation. Lastly, any phrase in double quotes will\
          \ match only those tweets that contain that exact phrase. You can also mix\
          \ multiple words and exact phrases in a single search term, such as the\
          \ search term below, which will return only tweets that contain the exact\
          \ phrase \u2018Twitter Scraper\u2019 as well as both words \u2018Intersect\u2019\
          \ and \u2018Australia\u2019. \n \n Exclude Phrases \n This field is used\
          \ to block the persistence of tweets that match the pattern. Exclusion overrules\
          \ inclusion, meaning that even if a tweet matches every inclusion parameter,\
          \ if it matches a single exclusion parameter, it will not be included in\
          \ the output. The excluded phrases field works exactly like the phrases\
          \ field in the interpretation of terms. \n Users \n You may also specify\
          \ particular users you want to include in your search using the users field.\
          \ If you leave this blank, the effect will be that all users are included\
          \ in the harvest. If you have just one username entered, only tweets from\
          \ that user will be included in the output. If you need to include a large\
          \ list of usernames, you can paste a list of usernames separated by commas.\
          \ \n If you specify both a set of users and a set of phrases for your harvest\
          \ parameters, both criteria must be satisfied for a tweet to be harvested.\
          \ In otherwords, only tweets by users specified in your Users and which\
          \ satisfy your phrase search will be harvested. You may specify a set of\
          \ users, or just a single user, without specifying search phrases, in which\
          \ case all tweets by those users will be harvested. \n Location \n Checking\
          \ the \u2018Set Location Bounds\u2019 will open a map window in which you\
          \ can define a bounding box. Only tweets that are geocoded as originating\
          \ from inside that box will be included in the output. Tweets that originated\
          \ from outside the bounding box will not be harvested, nor will tweets that\
          \ are not geocoded. Remember that users can switch off geocoding, and many\
          \ do for privacy reasons. \n Languages \n You can use the Languages field\
          \ to restrict your search to tweets in that language. You can also select\
          \ multiple languages. The effect of selecting no language here is analogous\
          \ to selecting no users; any tweet will match irrespective of its language\
          \ value. Tweets are identified as being in a particular language automatically\
          \ by machine detection, and this may not work perfectly. \n Output Options\
          \ \n Output Fields \n The output fields allows you to customise the spreadsheet\
          \ output containing the tweets. By default, all elements are included, but\
          \ you can uncheck any of the checkboxes if you do not want to include a\
          \ particular tweet attribute in your output. \n Treat Hashtags Independently\
          \ \n This setting modified the behaviour of Twitter Scraper when tweets\
          \ contain multiple hashtags. Hashtags are parsed out of the content of the\
          \ tweet body and sent to a separate column of the spreadsheet output. If\
          \ this box is left unchecked, a tweet containing more than one tweet will\
          \ occur once in the spreadsheet, and both hashtags will be written to the\
          \ hashtag column. If this box is checked, then the tweet will be repeated\
          \ in the output spreadsheet, once for each hashtag, and the hashtag column\
          \ will contain only one hashtag. This may be useful if you intend to process\
          \ the output of the scraper using hashtags. If you only intend to analyse\
          \ the tweet body, you may want to leave this box unchecked so as not to\
          \ have repeats of the tweet. \n De-Identify \n This checkbox allows you\
          \ to de-identify the tweets captured by the scraper, which can be useful\
          \ for research ethics and privacy concerns. When this box is checked, the\
          \ username column of the output will be replaced by a string so that you\
          \ cannot identify the user. However, since the same username will be replaced\
          \ by the same string each time, meaning you are still able to track particular\
          \ users\u2019 tweets. Note that selecting the de-identify checkbox does\
          \ not obscure usernames within the body text of tweets. \n Period \n The\
          \ period refers to the time interval between each time Twitter Scraper writes\
          \ the data out to a spreadsheet. The output works by filling a cached buffer\
          \ of tweets as they emerge in the Twitter stream and are captured by the\
          \ scraper. The buffer can fit a few dozen tweets. When the buffer fills,\
          \ the content is appended to a spreadsheet. When the period ends and the\
          \ next period begins (that is, the next hour if you select \u2018hourly\u2019\
          ), then a new spreadsheet will be commenced. If you select \u2018none\u2019\
          \ as the period, then every matching tweet will be written to the same spreadsheet.\
          \ If your scrape settings are broad and capture a lot of tweets, the spreadsheet\
          \ can blow out in size very quickly. Depending on how many tweets you expect\
          \ to match your search settings, you may want to set the period to daily,\
          \ or even hourly, to manage the size of the output spreadsheet. \n After\
          \ you have configured Twitter Scraper, you can now deploy it by clicking\
          \ \u2018Deploy\u2019. The process should only take around three minutes,\
          \ after which you will be sent an email letting you know that your Twitter\
          \ Scraper instance has been deployed. This email will also let you know\
          \ how you can access the data. \n Accessing Data \n Twitter Scraper allows\
          \ for two methods of accessing the data that it generates: over http using\
          \ a browser, or by logging in to the VM using SSH. Access the machine via\
          \ SSH also enables you to undertake further configuration and advanced usage,\
          \ such as modifying the harvest settings, restarting the harvester or configuring\
          \ additional harvests. \n How to Access Data via Web \n While Twitter Scraper\
          \ is operational, it will continue to extract tweets from the Twitter Stream\
          \ and, every time its buffer fills, write those tweets to the csv file.\
          \ A link to the location of the spreadsheet, consisting of the IP address\
          \ of the machine and a directory, such as {IP address}/1, will be included\
          \ in the email that Launchpod sends you. Clicking this link will take you\
          \ to a web view of a directory on the VM containing a spreadsheet (or more)\
          \ of Twitter Scraper's output data. If you selected a time period, then\
          \ you will see one spreadsheet corresponding to each of that period that\
          \ has begun since the VM was deployed.  \n \n Due to the way Twitter Scraper\
          \ is deployed, there are no easy ways to see if it is working, until tweets\
          \ begin to appear in the spreadsheet, which, depending on the harvest settings,\
          \ could be a long time. That is, if you specific very specific search terms,\
          \ you might be waiting a long time for the buffer to fill and for the tweets\
          \ to be written to the spreadsheet, and in the meantime, you have no way\
          \ of knowing whether the lack of output is due to an error or a lack of\
          \ matching tweets. There is a log file which can be accessed by navigating\
          \ to the IP of the machine (sent to your email) followed by /logs. If the\
          \ scraper is working, this log file will display lines like: \n 2015-04-15\
          \ 00:05:41,925 INFO  (LoggerTweetProcessor.java:42) - [1] Processed 10 tweets\
          \ \n If the log file shows an error or java exception instead, then you\
          \ may have configured the machine incorrectly. You should delete the instance\
          \ and try again, paying particular attention to the Twitter API Access Tokens\
          \ and Consumer Keys. Alternatively, you can log into the machine using SSH\
          \ and troubleshoot the problem. \n How to Access Data via SSH \n Launchpod\
          \ enables you to access the VM directly via SSH in order to modify the configuration\
          \ file  \n Configuration Guide \n The options selected within Launchpod\
          \ are used to populate Twitter Scraper's configuration file. Advanced users\
          \ may log into the VM using their ssh key and modify the configuration file\
          \ after deploying via Launchpod. The config file is located at /home/devel/twitterScraper-{version}/config.ini.\
          \  \n If the config file is modified, the harvester must be restarted before\
          \ any changes take effect. Restart the harvester using the command sudo\
          \ supervisorctl restart twitter_scraper. It is a good idea to change the\
          \ ouput path if you change the harvester settings, since Twitter Scraper\
          \ will overwrite an existing output spreadsheet if its output will have\
          \ the same name. \n Here is a sample configuration file: \n ```\n[main]\n\
          ; The [main] section contains the access tokens and consumer keys for the\
          \ Twitter application.\n; These are created and obtained from http://apps.twitter.com.\
          \ Each is required in order for\n; Twitter Scraper to work \n consumerKey\
          \ =\nconsumerSecret =\ntoken =\ntokenSecret = \n ; The following section\
          \ is an example. Additional sections can be added with [2], [3], and so\
          \ forth. \n; Each section must have a unique outDir and at least one of:\
          \ phrase, location or user, in order for\n; Twitter Scraper to function.\
          \ \n [1] \n ; At least one of phrase, user or location is mandatory. \n\
          ; Multiple phrase, exclude, user, location and language are accepted on\
          \ unique lines. That is,\n; no more than one property per line. \n phrase\
          \ = \n; Not case-sensitive. Will match substring. Multiple lines beginning\
          \ with 'phrase =' will persist \n; all tweets that match any phrase. Multiple\
          \ words in one phrase property will persist tweets that\n; contain all words\
          \ in that property in any order. A phrase property in quotation marks will\
          \ only match \n; tweets that contain that exact phrase.\n;\n; Example:\n\
          ; phrase = Phrase1\n; phrase = Phrase2\n; will match tweets that contain\
          \ either Phrase1 or Phrase2.\n;\n; phrase = Phrase1 Phrase2\n; will match\
          \ tweets that contain both Phrase1 and Phrase2.\n;\n; phrase = \"Phrase1\
          \ Phrase2\"\n; will match tweets that contain the exact string \"Phrase1\
          \ Phrase2\"\n;\n; As phrases will match a substring, searching for hashtags\
          \ need not include the hash character. Example:\n; phrase = hashtag\n; will\
          \ return tweets containing the string hashtag and #hashtag, whereas\n; phrase\
          \ = #hashtag\n; will not necessarily return tweets containing the string\
          \ hashtag (unless they are matched by another\n; property) \n exclude =\
          \ \n; Works exactly like the phrase property, but instead of persisting\
          \ its matches, exclude blocks them from \n; persisting. Tweets that match\
          \ a phrase property will out persist if they also match an exclude property.\n\
          ; Exclude cannot be the only matching property. \n user =\n; Not case-sensitive.\
          \ Will not match substring. Each user property must be a Twitter username.\n\
          ; Must not be preceded with @, or it will not match the desired user. \n\
          ; user = foo will match all tweets by user @foo. \n location = S,W,N,E\n\
          ; The location property can be used to match tweets that are geotagged and\
          \ fall inside a specified rectangle.\n; The location property takes exactly\
          \ four arguments, each a number between -180 and +180. The arguments \n\
          ; correspond to the south-most extent, the west-most, the north-most and\
          \ the east-most, and they must occur \n; in that exact order.\n; Given that\
          \ many users do not geotag their tweets due to privacy concerns, setting\
          \ this option may\n; severely limit the number of tweets harvested. \n language\
          \ =\n; The language property can be used to restrict the output to tweets\
          \ in a particular language as determined\n; by Twitter's language detection\
          \ system. Languages are represented by their 2-digit identifier. The list\n\
          ; of supported languages is  \n ; If distinct matching properties are used\
          \ in conjunction with one another, each matching option serves to \n; restrict\
          \ the others.\n;\n; Example:\n; user = foo\n; phrase = bar\n; will only\
          \ match tweets by the user '@foo' that contain the string 'bar', rather\
          \ than all tweets by user \n; '@foo' and all tweets containing 'bar'  \n\
          \ outPeriod = [hourly|daily|weekly|monthly] \n; Period to which a single\
          \ output csv file will correspond to. If this property is not included in\
          \ the config\n; file, all tweets will be appended to a single csv spreadsheet.\
          \ \n outField = (createdAt|hashTags|urls|language|text|username|coordinates|place|retweetCount|isRetweet|originalUsername)\n\
          ; The outfield property configures the elements of each tweet that are output\
          \ to the csv file, and the order of\n; the columns. \n outDir = /home/devel/twitterScraper-1.0.39/output/1\n\
          ; The outDir property is the path to the directory in which the harvested\
          \ tweets will be written to a csv file.\n; The actual name of the csv file\
          \ will depend on the section number in the config file and the outPeriod.\n\
          ``` \n Contact \n If you are having trouble launching Twitter Scraper, please\
          \ contact Intersect, or your university\u2019s eResearch Analyst. \n Support\
          \ \n Code Repository \n The code repository is not currently publicly released.\
          \ Twitter Scraper is currently only available through Launchpod. \n Known\
          \ Issues \n \n Twitter Scraper has no way of warning or alerting errors\
          \ to the user. This may make it difficult to troubleshoot problems.  \n\
          \ Twitter Scraper uses the Twitter Stream API to harvest tweets in realtime.\
          \ It does not use the Search API which is for finding statuses that have\
          \ already been posted to Twitter. This means that Twitter Scraper is unable\
          \ to harvest historical tweets. \n If a tweet is deleted by a user from\
          \ their timeline, an instruction to disregard the status is sent via the\
          \ Stream API. Due to the way Twitter Scraper outputs tweets, by appending\
          \ them to a csv text file, the instruction to disregard a tweet cannot be\
          \ honoured. This means that tweets that have harvested and then deleted\
          \ by the originating user will still appear in the output. \n \n Troubleshooting\
          \ \n\n\n\nSymptom\nPossible Problem\nSolution\n\n\n\n\nLaunchpod failed\
          \ to deply\nSome availability zones may experience problems launching machines\n\
          Try again using another availability zone\n\n\n"
        description: "<h1>Twitter Scraper User Guide</h1>\n<h2>Description</h2>\n\
          <p>Twitter Scraper is a tool developed by Intersect for use in collecting\
          \ data directly from the Twitter Stream API based on a variety of parameters,\
          \ including hashtags and phrases, users, location and language, and outputs\
          \ matching tweets to a comma separated values (.csv) spreadsheet for analysis.</p>\n\
          <h2>Target Audience</h2>\n<p>Twitter Scraper is available for use by any\
          \ researcher with an account at an Australian research institution that\
          \ subscribes to the <a href=\"http://aaf.edu.au\">Australian Access Federation</a>\
          \ (see the <a href=\"http://aaf.edu.au/subscribe/subscribers/\">full list\
          \ of AAF subscribers</a>). Researchers who want to incorporate data from\
          \ Twitter into their research are encouraged to use Twitter Scraper as a\
          \ powerful, though relatively easy, service which can be run on the <a href=\"\
          http://cloud.nectar.org.au/\">NeCTAR Research Cloud</a>. NeCTAR offer VMs\
          \ to researchers for free for a trial period, or longer periods under a\
          \ merit allocation scheme. Twitter Scraper itself is completely free for\
          \ researchers.</p>\n<h2>How to Launch</h2>\n<p>Twitter Scraper is deployed\
          \ through <a href=\"http://launchpod.intersect.org.au\">Launchpod</a>, a\
          \ web utility for configuring and deploying virtual machines (VMs) onto\
          \ the NeCTAR Research Cloud. Launchpod allows for users with little or no\
          \ experience with cloud computing to configure and deploy Twitter Scraper\
          \ easily and quickly. Before deploying Twitter Scraper, please refer to\
          \ the <a href=\"../Launchpod-doc\">documentation</a> for deploying VMs using\
          \ Launchpod.</p>\n<p>If you intend to log into Twitter Scraper via SSH,\
          \ for example to modify the harvester settings after it has been deployed,\
          \ you must specify an SSH keypair in Launchpod. Please follow the instructions\
          \ in the <a href=\"../Launchpod-doc\">Launchpod user guide</a> or at <a\
          \ href=\"http://cloud.nectar.org.au/\">NeCTAR Research Cloud</a> on how\
          \ to do so.</p>\n<h3>Obtaining Twitter access credentials</h3>\n<p><strong>Important:</strong>\
          \ <em>The steps to obtain your Twitter access tokens and consumer API keys\
          \ only need to be done once. If you intend to deploy more Twitter Scrapers,\
          \ you should use the same access tokens and credentials. You can always\
          \ log into the Twitter Applications Development site to get access tokens\
          \ you've already generated, or you can keep them in a safe place for later\
          \ use.</em></p>\n<p>Twitter Scraper uses your Twitter account to monitor\
          \ the constant stream of tweets and find those matching your specified search\
          \ terms. Before you can use Twitter Scraper, you need to create an \u2018\
          application\u2019 within Twitter, and then obtain the Consumer Key and the\
          \ Consumer Secret from this application, as well as your Access Token and\
          \ Access Token Secret.</p>\n<p>First, navigate to the <a href=\"https://apps.twitter.com\"\
          >Twitter Applications Development</a> site and log in with your Twitter\
          \ credentials. From here you will create the \u2018application\u2019. This\
          \ page is typically used by developers to register apps that they have created\
          \ and which people can download. Most of the information is actually irrelevant\
          \ for Twitter Scraper, but it needs to be entered in order to create the\
          \ access credentials that Twitter Scraper needs. As of mid-2015, you need\
          \ to have a mobile phone number associated with your Twitter account to\
          \ register an application. If you don't have a mobile number, go to your\
          \ Twitter profile and enter one.</p>\n<p>Click Create New App and provide\
          \ a name (such as \u2018Twitter Scraper\u2019) and a brief description (such\
          \ as \u2018this is an app to harvest tweets\u2019). You also need to provide\
          \ a URL. It does not have to be a real website, but it does have to begin\
          \ with <code>http://</code>. A dummy URL like <code>http://www.example.com</code>\
          \ is sufficient. Scroll to the end of the page and select 'Yes, I agree\
          \ to the Developer Agreement'. Finally, click 'Create your Twitter Application'.</p>\n\
          <p>Once your app has been created, navigate to the \u2018Keys and Access\
          \ Tokens\u2019 tab of the app settings. This page will display two of the\
          \ four settings you need, the Consumer Key (API Key) and the Consumer Secret\
          \ (API Secret). You can copy these straight out of Twitter and into a note\
          \ or document for use later, or put them directly into the relevant fields\
          \ in Launchpod.</p>\n<p><img alt=\"screenshot_consumerKey\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/twitterDOCID88_consumerKey.png?raw=true\"\
          \ title=\"Consumer Key\"></p>\n<p>To generate the other two credentials,\
          \ scroll to the bottom of the same page and under 'Your Access Token' click\
          \ the button 'Create my access token'. The page will reload, and the Access\
          \ Token and the Access Token Secret will be displayed at the end. Make sure\
          \ when copying the Access Token that you copy the whole line including the\
          \ 9-digit number at the front, which is the same as your owner ID. The Launchpod\
          \ Twitter Scraper will not function without this.</p>\n<p><img alt=\"screenshot_accessToken\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/twitterDOCID88_accessToken.png?raw=true\"\
          \ title=\"Access Token\"></p>\n<p>Now that you have all of the access credentials\
          \ needed to deploy Twitter Scraper, you can begin configuring the tweet\
          \ harvesting parameters.</p>\n<h3>Specifying Harvest Parameters</h3>\n<p>Twitter\
          \ Scraper search parameters need to be configured prior to the deployment\
          \ of the server. Once it is deployed, you cannot change the search settings\
          \ without logging in to the VM via SSH. Harvest parameters are split into\
          \ two categories: <a href=\"#matching-options\">Matching Options</a>, what\
          \ Twitter Scraper will search for; and <a href=\"#output-options\">Output\
          \ Options</a>, how Twitter Scraper will format and configure the output\
          \ CSV file.</p>\n<h4>Matching options</h4>\n<h5>Phrases</h5>\n<p>This is\
          \ where you will enter the search terms and hashtags that Twitter Scraper\
          \ will monitor the Twitter stream for. You can set search phrases in a number\
          \ of ways. To search for an individual word, enter a single word and hit\
          \ return. If you want to search for tweets that contain multiple words in\
          \ any order, enter each word and hit return. If you want to search for an\
          \ exact phrase, enclose the phrase in double quotes before hitting return.\
          \ The example below will return any tweet that contains the word \u2018\
          Launchpod\u2019, in addition to any tweet that contains both the words \u2018\
          Intersect\u2019 and \u2018Australia\u2019, in addition to any tweet that\
          \ contains the exact phrase \u2018Twitter Scraper\u2019.</p>\n<p><img alt=\"\
          screenshot_include_1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/twitterDOCID88_include_1.png?raw=true\"\
          \ title=\"Included phrases\"></p>\n<p>In other words, each search term is\
          \ separated by an implicit OR operation, and every word inside a search\
          \ term (such as \u2018Intersect Australia\u2019 above) is separated by an\
          \ implicit AND operation. Lastly, any phrase in double quotes will match\
          \ only those tweets that contain that exact phrase. You can also mix multiple\
          \ words and exact phrases in a single search term, such as the search term\
          \ below, which will return only tweets that contain the exact phrase \u2018\
          Twitter Scraper\u2019 as well as both words \u2018Intersect\u2019 and \u2018\
          Australia\u2019.</p>\n<p><img alt=\"screenshot_include_2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/twitterDOCID88_include_2.png?raw=true\"\
          \ title=\"Included phrases\"></p>\n<h5>Exclude Phrases</h5>\n<p>This field\
          \ is used to block the persistence of tweets that match the pattern. Exclusion\
          \ overrules inclusion, meaning that even if a tweet matches every inclusion\
          \ parameter, if it matches a single exclusion parameter, it will not be\
          \ included in the output. The excluded phrases field works exactly like\
          \ the phrases field in the interpretation of terms.</p>\n<h5>Users</h5>\n\
          <p>You may also specify particular users you want to include in your search\
          \ using the users field. If you leave this blank, the effect will be that\
          \ all users are included in the harvest. If you have just one username entered,\
          \ only tweets from that user will be included in the output. If you need\
          \ to include a large list of usernames, you can paste a list of usernames\
          \ separated by commas.</p>\n<p>If you specify both a set of users and a\
          \ set of phrases for your harvest parameters, both criteria must be satisfied\
          \ for a tweet to be harvested. In otherwords, only tweets by users specified\
          \ in your Users <em>and</em> which satisfy your phrase search will be harvested.\
          \ You may specify a set of users, or just a single user, without specifying\
          \ search phrases, in which case all tweets by those users will be harvested.</p>\n\
          <h5>Location</h5>\n<p>Checking the \u2018Set Location Bounds\u2019 will\
          \ open a map window in which you can define a bounding box. Only tweets\
          \ that are geocoded as originating from inside that box will be included\
          \ in the output. Tweets that originated from outside the bounding box will\
          \ not be harvested, nor will tweets that are not geocoded. Remember that\
          \ users can switch off geocoding, and many do for privacy reasons.</p>\n\
          <h5>Languages</h5>\n<p>You can use the Languages field to restrict your\
          \ search to tweets in that language. You can also select multiple languages.\
          \ The effect of selecting no language here is analogous to selecting no\
          \ users; any tweet will match irrespective of its language value. Tweets\
          \ are identified as being in a particular language automatically by machine\
          \ detection, and this may not work perfectly.</p>\n<h4>Output Options</h4>\n\
          <h5>Output Fields</h5>\n<p>The output fields allows you to customise the\
          \ spreadsheet output containing the tweets. By default, all elements are\
          \ included, but you can uncheck any of the checkboxes if you do not want\
          \ to include a particular tweet attribute in your output.</p>\n<h5>Treat\
          \ Hashtags Independently</h5>\n<p>This setting modified the behaviour of\
          \ Twitter Scraper when tweets contain multiple hashtags. Hashtags are parsed\
          \ out of the content of the tweet body and sent to a separate column of\
          \ the spreadsheet output. If this box is left unchecked, a tweet containing\
          \ more than one tweet will occur once in the spreadsheet, and both hashtags\
          \ will be written to the hashtag column. If this box is checked, then the\
          \ tweet will be repeated in the output spreadsheet, once for each hashtag,\
          \ and the hashtag column will contain only one hashtag. This may be useful\
          \ if you intend to process the output of the scraper using hashtags. If\
          \ you only intend to analyse the tweet body, you may want to leave this\
          \ box unchecked so as not to have repeats of the tweet.</p>\n<h5>De-Identify</h5>\n\
          <p>This checkbox allows you to de-identify the tweets captured by the scraper,\
          \ which can be useful for research ethics and privacy concerns. When this\
          \ box is checked, the username column of the output will be replaced by\
          \ a string so that you cannot identify the user. However, since the same\
          \ username will be replaced by the same string each time, meaning you are\
          \ still able to track particular users\u2019 tweets. Note that selecting\
          \ the de-identify checkbox does not obscure usernames within the body text\
          \ of tweets.</p>\n<h5>Period</h5>\n<p>The period refers to the time interval\
          \ between each time Twitter Scraper writes the data out to a spreadsheet.\
          \ The output works by filling a cached buffer of tweets as they emerge in\
          \ the Twitter stream and are captured by the scraper. The buffer can fit\
          \ a few dozen tweets. When the buffer fills, the content is appended to\
          \ a spreadsheet. When the period ends and the next period begins (that is,\
          \ the next hour if you select \u2018hourly\u2019), then a new spreadsheet\
          \ will be commenced. If you select \u2018none\u2019 as the period, then\
          \ every matching tweet will be written to the same spreadsheet. If your\
          \ scrape settings are broad and capture a lot of tweets, the spreadsheet\
          \ can blow out in size very quickly. Depending on how many tweets you expect\
          \ to match your search settings, you may want to set the period to daily,\
          \ or even hourly, to manage the size of the output spreadsheet.</p>\n<p>After\
          \ you have configured Twitter Scraper, you can now deploy it by clicking\
          \ \u2018Deploy\u2019. The process should only take around three minutes,\
          \ after which you will be sent an email letting you know that your Twitter\
          \ Scraper instance has been deployed. This email will also let you know\
          \ how you can access the data.</p>\n<h2>Accessing Data</h2>\n<p>Twitter\
          \ Scraper allows for two methods of accessing the data that it generates:\
          \ over http using a browser, or by logging in to the VM using SSH. Access\
          \ the machine via SSH also enables you to undertake further configuration\
          \ and advanced usage, such as modifying the harvest settings, restarting\
          \ the harvester or configuring additional harvests.</p>\n<h3>How to Access\
          \ Data via Web</h3>\n<p>While Twitter Scraper is operational, it will continue\
          \ to extract tweets from the Twitter Stream and, every time its buffer fills,\
          \ write those tweets to the csv file. A link to the location of the spreadsheet,\
          \ consisting of the IP address of the machine and a directory, such as <code>{IP\
          \ address}/1</code>, will be included in the email that Launchpod sends\
          \ you. Clicking this link will take you to a web view of a directory on\
          \ the VM containing a spreadsheet (or more) of Twitter Scraper's output\
          \ data. If you selected a time period, then you will see one spreadsheet\
          \ corresponding to each of that period that has begun since the VM was deployed.\
          \ </p>\n<p><img alt=\"screenshot_output\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/twitterDOCID88_output.png?raw=true\"\
          \ title=\"Sample output\"></p>\n<p>Due to the way Twitter Scraper is deployed,\
          \ there are no easy ways to see if it is working, until tweets begin to\
          \ appear in the spreadsheet, which, depending on the harvest settings, could\
          \ be a long time. That is, if you specific very specific search terms, you\
          \ might be waiting a long time for the buffer to fill and for the tweets\
          \ to be written to the spreadsheet, and in the meantime, you have no way\
          \ of knowing whether the lack of output is due to an error or a lack of\
          \ matching tweets. There is a log file which can be accessed by navigating\
          \ to the IP of the machine (sent to your email) followed by <code>/logs</code>.\
          \ If the scraper is working, this log file will display lines like:</p>\n\
          <p><code>2015-04-15 00:05:41,925 INFO  (LoggerTweetProcessor.java:42) -\
          \ [1] Processed 10 tweets</code></p>\n<p>If the log file shows an error\
          \ or java exception instead, then you may have configured the machine incorrectly.\
          \ You should delete the instance and try again, paying particular attention\
          \ to the Twitter API Access Tokens and Consumer Keys. Alternatively, you\
          \ can log into the machine using SSH and <a href=\"#troubleshooting\">troubleshoot</a>\
          \ the problem.</p>\n<h3>How to Access Data via SSH</h3>\n<p>Launchpod enables\
          \ you to access the VM directly via SSH in order to modify the <a href=\"\
          #configuration-guide\">configuration</a> file </p>\n<h2>Configuration Guide</h2>\n\
          <p>The options selected within Launchpod are used to populate Twitter Scraper's\
          \ configuration file. Advanced users may log into the VM using their ssh\
          \ key and modify the configuration file after deploying via Launchpod. The\
          \ config file is located at <code>/home/devel/twitterScraper-{version}/config.ini</code>.\
          \ </p>\n<p>If the config file is modified, the harvester must be restarted\
          \ before any changes take effect. Restart the harvester using the command\
          \ <code>sudo supervisorctl restart twitter_scraper</code>. It is a good\
          \ idea to change the ouput path if you change the harvester settings, since\
          \ Twitter Scraper will overwrite an existing output spreadsheet if its output\
          \ will have the same name.</p>\n<p>Here is a sample configuration file:</p>\n\
          <p>```\n[main]\n; The [main] section contains the access tokens and consumer\
          \ keys for the Twitter application.\n; These are created and obtained from\
          \ http://apps.twitter.com. Each is required in order for\n; Twitter Scraper\
          \ to work</p>\n<p>consumerKey =\nconsumerSecret =\ntoken =\ntokenSecret\
          \ =</p>\n<p>; The following section is an example. Additional sections can\
          \ be added with [2], [3], and so forth. \n; Each section must have a unique\
          \ outDir and at least one of: phrase, location or user, in order for\n;\
          \ Twitter Scraper to function.</p>\n<p>[1]</p>\n<p>; At least one of phrase,\
          \ user or location is mandatory. \n; Multiple phrase, exclude, user, location\
          \ and language are accepted on unique lines. That is,\n; no more than one\
          \ property per line.</p>\n<p>phrase = \n; Not case-sensitive. Will match\
          \ substring. Multiple lines beginning with 'phrase =' will persist \n; all\
          \ tweets that match any phrase. Multiple words in one phrase property will\
          \ persist tweets that\n; contain all words in that property in any order.\
          \ A phrase property in quotation marks will only match \n; tweets that contain\
          \ that exact phrase.\n;\n; Example:\n; phrase = Phrase1\n; phrase = Phrase2\n\
          ; will match tweets that contain either Phrase1 or Phrase2.\n;\n; phrase\
          \ = Phrase1 Phrase2\n; will match tweets that contain both Phrase1 and Phrase2.\n\
          ;\n; phrase = \"Phrase1 Phrase2\"\n; will match tweets that contain the\
          \ exact string \"Phrase1 Phrase2\"\n;\n; As phrases will match a substring,\
          \ searching for hashtags need not include the hash character. Example:\n\
          ; phrase = hashtag\n; will return tweets containing the string hashtag and\
          \ #hashtag, whereas\n; phrase = #hashtag\n; will not necessarily return\
          \ tweets containing the string hashtag (unless they are matched by another\n\
          ; property)</p>\n<p>exclude = \n; Works exactly like the phrase property,\
          \ but instead of persisting its matches, exclude blocks them from \n; persisting.\
          \ Tweets that match a phrase property will out persist if they also match\
          \ an exclude property.\n; Exclude cannot be the only matching property.</p>\n\
          <p>user =\n; Not case-sensitive. Will not match substring. Each user property\
          \ must be a Twitter username.\n; Must not be preceded with @, or it will\
          \ not match the desired user. \n; user = foo will match all tweets by user\
          \ @foo.</p>\n<p>location = S,W,N,E\n; The location property can be used\
          \ to match tweets that are geotagged and fall inside a specified rectangle.\n\
          ; The location property takes exactly four arguments, each a number between\
          \ -180 and +180. The arguments \n; correspond to the south-most extent,\
          \ the west-most, the north-most and the east-most, and they must occur \n\
          ; in that exact order.\n; Given that many users do not geotag their tweets\
          \ due to privacy concerns, setting this option may\n; severely limit the\
          \ number of tweets harvested.</p>\n<p>language =\n; The language property\
          \ can be used to restrict the output to tweets in a particular language\
          \ as determined\n; by Twitter's language detection system. Languages are\
          \ represented by their 2-digit identifier. The list\n; of supported languages\
          \ is </p>\n<p>; If distinct matching properties are used in conjunction\
          \ with one another, each matching option serves to \n; restrict the others.\n\
          ;\n; Example:\n; user = foo\n; phrase = bar\n; will only match tweets by\
          \ the user '@foo' that contain the string 'bar', rather than all tweets\
          \ by user \n; '@foo' and all tweets containing 'bar' </p>\n<p>outPeriod\
          \ = [hourly|daily|weekly|monthly] \n; Period to which a single output csv\
          \ file will correspond to. If this property is not included in the config\n\
          ; file, all tweets will be appended to a single csv spreadsheet.</p>\n<p>outField\
          \ = (createdAt|hashTags|urls|language|text|username|coordinates|place|retweetCount|isRetweet|originalUsername)\n\
          ; The outfield property configures the elements of each tweet that are output\
          \ to the csv file, and the order of\n; the columns.</p>\n<p>outDir = /home/devel/twitterScraper-1.0.39/output/1\n\
          ; The outDir property is the path to the directory in which the harvested\
          \ tweets will be written to a csv file.\n; The actual name of the csv file\
          \ will depend on the section number in the config file and the outPeriod.\n\
          ```</p>\n<h2>Contact</h2>\n<p>If you are having trouble launching Twitter\
          \ Scraper, please <a href=\"mailto:help@intersect.org.au?subject=Assistance%20with%20Twitter%20Scraper\"\
          >contact Intersect</a>, or your university\u2019s <a href=\"http://intersect.org.au/content/eresearch-analysts\"\
          >eResearch Analyst</a>.</p>\n<h2>Support</h2>\n<h2>Code Repository</h2>\n\
          <p>The code repository is not currently publicly released. Twitter Scraper\
          \ is currently only available through <a href=\"http://launchpod.intersect.org.au\"\
          >Launchpod</a>.</p>\n<h2>Known Issues</h2>\n<ul>\n<li>Twitter Scraper has\
          \ no way of warning or alerting errors to the user. This may make it difficult\
          \ to troubleshoot problems. </li>\n<li>Twitter Scraper uses the Twitter\
          \ Stream API to harvest tweets in realtime. It does not use the Search API\
          \ which is for finding statuses that have already been posted to Twitter.\
          \ This means that Twitter Scraper is unable to harvest historical tweets.</li>\n\
          <li>If a tweet is deleted by a user from their timeline, an instruction\
          \ to disregard the status is sent via the Stream API. Due to the way Twitter\
          \ Scraper outputs tweets, by appending them to a csv text file, the instruction\
          \ to disregard a tweet cannot be honoured. This means that tweets that have\
          \ harvested and then deleted by the originating user will still appear in\
          \ the output.</li>\n</ul>\n<h2>Troubleshooting</h2>\n<table>\n<thead>\n\
          <tr>\n<th align=\"left\">Symptom</th>\n<th align=\"left\">Possible Problem</th>\n\
          <th align=\"left\">Solution</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"\
          left\">Launchpod failed to deply</td>\n<td align=\"left\">Some availability\
          \ zones may experience problems launching machines</td>\n<td align=\"left\"\
          >Try again using another availability zone</td>\n</tr>\n</tbody>\n</table>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 5
        id: 6000089738
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-18T17:31:34-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000089738
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Intersect Twitter Scraper User Guide
        updated_at: '2015-11-18T17:31:34-05:00'
        user_id: 6002464727
  html: "<h1>Twitter Scraper User Guide</h1>\n<h2>Description</h2>\n<p>Twitter Scraper\
    \ is a tool developed by Intersect for use in collecting data directly from the\
    \ Twitter Stream API based on a variety of parameters, including hashtags and\
    \ phrases, users, location and language, and outputs matching tweets to a comma\
    \ separated values (.csv) spreadsheet for analysis.</p>\n<h2>Target Audience</h2>\n\
    <p>Twitter Scraper is available for use by any researcher with an account at an\
    \ Australian research institution that subscribes to the <a href=\"http://aaf.edu.au\"\
    >Australian Access Federation</a> (see the <a href=\"http://aaf.edu.au/subscribe/subscribers/\"\
    >full list of AAF subscribers</a>). Researchers who want to incorporate data from\
    \ Twitter into their research are encouraged to use Twitter Scraper as a powerful,\
    \ though relatively easy, service which can be run on the <a href=\"http://cloud.nectar.org.au/\"\
    >NeCTAR Research Cloud</a>. NeCTAR offer VMs to researchers for free for a trial\
    \ period, or longer periods under a merit allocation scheme. Twitter Scraper itself\
    \ is completely free for researchers.</p>\n<h2>How to Launch</h2>\n<p>Twitter\
    \ Scraper is deployed through <a href=\"http://launchpod.intersect.org.au\">Launchpod</a>,\
    \ a web utility for configuring and deploying virtual machines (VMs) onto the\
    \ NeCTAR Research Cloud. Launchpod allows for users with little or no experience\
    \ with cloud computing to configure and deploy Twitter Scraper easily and quickly.\
    \ Before deploying Twitter Scraper, please refer to the <a href=\"../Launchpod-doc\"\
    >documentation</a> for deploying VMs using Launchpod.</p>\n<p>If you intend to\
    \ log into Twitter Scraper via SSH, for example to modify the harvester settings\
    \ after it has been deployed, you must specify an SSH keypair in Launchpod. Please\
    \ follow the instructions in the <a href=\"../Launchpod-doc\">Launchpod user guide</a>\
    \ or at <a href=\"http://cloud.nectar.org.au/\">NeCTAR Research Cloud</a> on how\
    \ to do so.</p>\n<h3>Obtaining Twitter access credentials</h3>\n<p><strong>Important:</strong>\
    \ <em>The steps to obtain your Twitter access tokens and consumer API keys only\
    \ need to be done once. If you intend to deploy more Twitter Scrapers, you should\
    \ use the same access tokens and credentials. You can always log into the Twitter\
    \ Applications Development site to get access tokens you've already generated,\
    \ or you can keep them in a safe place for later use.</em></p>\n<p>Twitter Scraper\
    \ uses your Twitter account to monitor the constant stream of tweets and find\
    \ those matching your specified search terms. Before you can use Twitter Scraper,\
    \ you need to create an \u2018application\u2019 within Twitter, and then obtain\
    \ the Consumer Key and the Consumer Secret from this application, as well as your\
    \ Access Token and Access Token Secret.</p>\n<p>First, navigate to the <a href=\"\
    https://apps.twitter.com\">Twitter Applications Development</a> site and log in\
    \ with your Twitter credentials. From here you will create the \u2018application\u2019\
    . This page is typically used by developers to register apps that they have created\
    \ and which people can download. Most of the information is actually irrelevant\
    \ for Twitter Scraper, but it needs to be entered in order to create the access\
    \ credentials that Twitter Scraper needs. As of mid-2015, you need to have a mobile\
    \ phone number associated with your Twitter account to register an application.\
    \ If you don't have a mobile number, go to your Twitter profile and enter one.</p>\n\
    <p>Click Create New App and provide a name (such as \u2018Twitter Scraper\u2019\
    ) and a brief description (such as \u2018this is an app to harvest tweets\u2019\
    ). You also need to provide a URL. It does not have to be a real website, but\
    \ it does have to begin with <code>http://</code>. A dummy URL like <code>http://www.example.com</code>\
    \ is sufficient. Scroll to the end of the page and select 'Yes, I agree to the\
    \ Developer Agreement'. Finally, click 'Create your Twitter Application'.</p>\n\
    <p>Once your app has been created, navigate to the \u2018Keys and Access Tokens\u2019\
    \ tab of the app settings. This page will display two of the four settings you\
    \ need, the Consumer Key (API Key) and the Consumer Secret (API Secret). You can\
    \ copy these straight out of Twitter and into a note or document for use later,\
    \ or put them directly into the relevant fields in Launchpod.</p>\n<p><img alt=\"\
    screenshot_consumerKey\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/twitterDOCID88_consumerKey.png?raw=true\"\
    \ title=\"Consumer Key\"></p>\n<p>To generate the other two credentials, scroll\
    \ to the bottom of the same page and under 'Your Access Token' click the button\
    \ 'Create my access token'. The page will reload, and the Access Token and the\
    \ Access Token Secret will be displayed at the end. Make sure when copying the\
    \ Access Token that you copy the whole line including the 9-digit number at the\
    \ front, which is the same as your owner ID. The Launchpod Twitter Scraper will\
    \ not function without this.</p>\n<p><img alt=\"screenshot_accessToken\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/twitterDOCID88_accessToken.png?raw=true\"\
    \ title=\"Access Token\"></p>\n<p>Now that you have all of the access credentials\
    \ needed to deploy Twitter Scraper, you can begin configuring the tweet harvesting\
    \ parameters.</p>\n<h3>Specifying Harvest Parameters</h3>\n<p>Twitter Scraper\
    \ search parameters need to be configured prior to the deployment of the server.\
    \ Once it is deployed, you cannot change the search settings without logging in\
    \ to the VM via SSH. Harvest parameters are split into two categories: <a href=\"\
    #matching-options\">Matching Options</a>, what Twitter Scraper will search for;\
    \ and <a href=\"#output-options\">Output Options</a>, how Twitter Scraper will\
    \ format and configure the output CSV file.</p>\n<h4>Matching options</h4>\n<h5>Phrases</h5>\n\
    <p>This is where you will enter the search terms and hashtags that Twitter Scraper\
    \ will monitor the Twitter stream for. You can set search phrases in a number\
    \ of ways. To search for an individual word, enter a single word and hit return.\
    \ If you want to search for tweets that contain multiple words in any order, enter\
    \ each word and hit return. If you want to search for an exact phrase, enclose\
    \ the phrase in double quotes before hitting return. The example below will return\
    \ any tweet that contains the word \u2018Launchpod\u2019, in addition to any tweet\
    \ that contains both the words \u2018Intersect\u2019 and \u2018Australia\u2019\
    , in addition to any tweet that contains the exact phrase \u2018Twitter Scraper\u2019\
    .</p>\n<p><img alt=\"screenshot_include_1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/twitterDOCID88_include_1.png?raw=true\"\
    \ title=\"Included phrases\"></p>\n<p>In other words, each search term is separated\
    \ by an implicit OR operation, and every word inside a search term (such as \u2018\
    Intersect Australia\u2019 above) is separated by an implicit AND operation. Lastly,\
    \ any phrase in double quotes will match only those tweets that contain that exact\
    \ phrase. You can also mix multiple words and exact phrases in a single search\
    \ term, such as the search term below, which will return only tweets that contain\
    \ the exact phrase \u2018Twitter Scraper\u2019 as well as both words \u2018Intersect\u2019\
    \ and \u2018Australia\u2019.</p>\n<p><img alt=\"screenshot_include_2\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/twitterDOCID88_include_2.png?raw=true\"\
    \ title=\"Included phrases\"></p>\n<h5>Exclude Phrases</h5>\n<p>This field is\
    \ used to block the persistence of tweets that match the pattern. Exclusion overrules\
    \ inclusion, meaning that even if a tweet matches every inclusion parameter, if\
    \ it matches a single exclusion parameter, it will not be included in the output.\
    \ The excluded phrases field works exactly like the phrases field in the interpretation\
    \ of terms.</p>\n<h5>Users</h5>\n<p>You may also specify particular users you\
    \ want to include in your search using the users field. If you leave this blank,\
    \ the effect will be that all users are included in the harvest. If you have just\
    \ one username entered, only tweets from that user will be included in the output.\
    \ If you need to include a large list of usernames, you can paste a list of usernames\
    \ separated by commas.</p>\n<p>If you specify both a set of users and a set of\
    \ phrases for your harvest parameters, both criteria must be satisfied for a tweet\
    \ to be harvested. In otherwords, only tweets by users specified in your Users\
    \ <em>and</em> which satisfy your phrase search will be harvested. You may specify\
    \ a set of users, or just a single user, without specifying search phrases, in\
    \ which case all tweets by those users will be harvested.</p>\n<h5>Location</h5>\n\
    <p>Checking the \u2018Set Location Bounds\u2019 will open a map window in which\
    \ you can define a bounding box. Only tweets that are geocoded as originating\
    \ from inside that box will be included in the output. Tweets that originated\
    \ from outside the bounding box will not be harvested, nor will tweets that are\
    \ not geocoded. Remember that users can switch off geocoding, and many do for\
    \ privacy reasons.</p>\n<h5>Languages</h5>\n<p>You can use the Languages field\
    \ to restrict your search to tweets in that language. You can also select multiple\
    \ languages. The effect of selecting no language here is analogous to selecting\
    \ no users; any tweet will match irrespective of its language value. Tweets are\
    \ identified as being in a particular language automatically by machine detection,\
    \ and this may not work perfectly.</p>\n<h4>Output Options</h4>\n<h5>Output Fields</h5>\n\
    <p>The output fields allows you to customise the spreadsheet output containing\
    \ the tweets. By default, all elements are included, but you can uncheck any of\
    \ the checkboxes if you do not want to include a particular tweet attribute in\
    \ your output.</p>\n<h5>Treat Hashtags Independently</h5>\n<p>This setting modified\
    \ the behaviour of Twitter Scraper when tweets contain multiple hashtags. Hashtags\
    \ are parsed out of the content of the tweet body and sent to a separate column\
    \ of the spreadsheet output. If this box is left unchecked, a tweet containing\
    \ more than one tweet will occur once in the spreadsheet, and both hashtags will\
    \ be written to the hashtag column. If this box is checked, then the tweet will\
    \ be repeated in the output spreadsheet, once for each hashtag, and the hashtag\
    \ column will contain only one hashtag. This may be useful if you intend to process\
    \ the output of the scraper using hashtags. If you only intend to analyse the\
    \ tweet body, you may want to leave this box unchecked so as not to have repeats\
    \ of the tweet.</p>\n<h5>De-Identify</h5>\n<p>This checkbox allows you to de-identify\
    \ the tweets captured by the scraper, which can be useful for research ethics\
    \ and privacy concerns. When this box is checked, the username column of the output\
    \ will be replaced by a string so that you cannot identify the user. However,\
    \ since the same username will be replaced by the same string each time, meaning\
    \ you are still able to track particular users\u2019 tweets. Note that selecting\
    \ the de-identify checkbox does not obscure usernames within the body text of\
    \ tweets.</p>\n<h5>Period</h5>\n<p>The period refers to the time interval between\
    \ each time Twitter Scraper writes the data out to a spreadsheet. The output works\
    \ by filling a cached buffer of tweets as they emerge in the Twitter stream and\
    \ are captured by the scraper. The buffer can fit a few dozen tweets. When the\
    \ buffer fills, the content is appended to a spreadsheet. When the period ends\
    \ and the next period begins (that is, the next hour if you select \u2018hourly\u2019\
    ), then a new spreadsheet will be commenced. If you select \u2018none\u2019 as\
    \ the period, then every matching tweet will be written to the same spreadsheet.\
    \ If your scrape settings are broad and capture a lot of tweets, the spreadsheet\
    \ can blow out in size very quickly. Depending on how many tweets you expect to\
    \ match your search settings, you may want to set the period to daily, or even\
    \ hourly, to manage the size of the output spreadsheet.</p>\n<p>After you have\
    \ configured Twitter Scraper, you can now deploy it by clicking \u2018Deploy\u2019\
    . The process should only take around three minutes, after which you will be sent\
    \ an email letting you know that your Twitter Scraper instance has been deployed.\
    \ This email will also let you know how you can access the data.</p>\n<h2>Accessing\
    \ Data</h2>\n<p>Twitter Scraper allows for two methods of accessing the data that\
    \ it generates: over http using a browser, or by logging in to the VM using SSH.\
    \ Access the machine via SSH also enables you to undertake further configuration\
    \ and advanced usage, such as modifying the harvest settings, restarting the harvester\
    \ or configuring additional harvests.</p>\n<h3>How to Access Data via Web</h3>\n\
    <p>While Twitter Scraper is operational, it will continue to extract tweets from\
    \ the Twitter Stream and, every time its buffer fills, write those tweets to the\
    \ csv file. A link to the location of the spreadsheet, consisting of the IP address\
    \ of the machine and a directory, such as <code>{IP address}/1</code>, will be\
    \ included in the email that Launchpod sends you. Clicking this link will take\
    \ you to a web view of a directory on the VM containing a spreadsheet (or more)\
    \ of Twitter Scraper's output data. If you selected a time period, then you will\
    \ see one spreadsheet corresponding to each of that period that has begun since\
    \ the VM was deployed. </p>\n<p><img alt=\"screenshot_output\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/twitterDOCID88_output.png?raw=true\"\
    \ title=\"Sample output\"></p>\n<p>Due to the way Twitter Scraper is deployed,\
    \ there are no easy ways to see if it is working, until tweets begin to appear\
    \ in the spreadsheet, which, depending on the harvest settings, could be a long\
    \ time. That is, if you specific very specific search terms, you might be waiting\
    \ a long time for the buffer to fill and for the tweets to be written to the spreadsheet,\
    \ and in the meantime, you have no way of knowing whether the lack of output is\
    \ due to an error or a lack of matching tweets. There is a log file which can\
    \ be accessed by navigating to the IP of the machine (sent to your email) followed\
    \ by <code>/logs</code>. If the scraper is working, this log file will display\
    \ lines like:</p>\n<p><code>2015-04-15 00:05:41,925 INFO  (LoggerTweetProcessor.java:42)\
    \ - [1] Processed 10 tweets</code></p>\n<p>If the log file shows an error or java\
    \ exception instead, then you may have configured the machine incorrectly. You\
    \ should delete the instance and try again, paying particular attention to the\
    \ Twitter API Access Tokens and Consumer Keys. Alternatively, you can log into\
    \ the machine using SSH and <a href=\"#troubleshooting\">troubleshoot</a> the\
    \ problem.</p>\n<h3>How to Access Data via SSH</h3>\n<p>Launchpod enables you\
    \ to access the VM directly via SSH in order to modify the <a href=\"#configuration-guide\"\
    >configuration</a> file </p>\n<h2>Configuration Guide</h2>\n<p>The options selected\
    \ within Launchpod are used to populate Twitter Scraper's configuration file.\
    \ Advanced users may log into the VM using their ssh key and modify the configuration\
    \ file after deploying via Launchpod. The config file is located at <code>/home/devel/twitterScraper-{version}/config.ini</code>.\
    \ </p>\n<p>If the config file is modified, the harvester must be restarted before\
    \ any changes take effect. Restart the harvester using the command <code>sudo\
    \ supervisorctl restart twitter_scraper</code>. It is a good idea to change the\
    \ ouput path if you change the harvester settings, since Twitter Scraper will\
    \ overwrite an existing output spreadsheet if its output will have the same name.</p>\n\
    <p>Here is a sample configuration file:</p>\n<p>```\n[main]\n; The [main] section\
    \ contains the access tokens and consumer keys for the Twitter application.\n\
    ; These are created and obtained from http://apps.twitter.com. Each is required\
    \ in order for\n; Twitter Scraper to work</p>\n<p>consumerKey =\nconsumerSecret\
    \ =\ntoken =\ntokenSecret =</p>\n<p>; The following section is an example. Additional\
    \ sections can be added with [2], [3], and so forth. \n; Each section must have\
    \ a unique outDir and at least one of: phrase, location or user, in order for\n\
    ; Twitter Scraper to function.</p>\n<p>[1]</p>\n<p>; At least one of phrase, user\
    \ or location is mandatory. \n; Multiple phrase, exclude, user, location and language\
    \ are accepted on unique lines. That is,\n; no more than one property per line.</p>\n\
    <p>phrase = \n; Not case-sensitive. Will match substring. Multiple lines beginning\
    \ with 'phrase =' will persist \n; all tweets that match any phrase. Multiple\
    \ words in one phrase property will persist tweets that\n; contain all words in\
    \ that property in any order. A phrase property in quotation marks will only match\
    \ \n; tweets that contain that exact phrase.\n;\n; Example:\n; phrase = Phrase1\n\
    ; phrase = Phrase2\n; will match tweets that contain either Phrase1 or Phrase2.\n\
    ;\n; phrase = Phrase1 Phrase2\n; will match tweets that contain both Phrase1 and\
    \ Phrase2.\n;\n; phrase = \"Phrase1 Phrase2\"\n; will match tweets that contain\
    \ the exact string \"Phrase1 Phrase2\"\n;\n; As phrases will match a substring,\
    \ searching for hashtags need not include the hash character. Example:\n; phrase\
    \ = hashtag\n; will return tweets containing the string hashtag and #hashtag,\
    \ whereas\n; phrase = #hashtag\n; will not necessarily return tweets containing\
    \ the string hashtag (unless they are matched by another\n; property)</p>\n<p>exclude\
    \ = \n; Works exactly like the phrase property, but instead of persisting its\
    \ matches, exclude blocks them from \n; persisting. Tweets that match a phrase\
    \ property will out persist if they also match an exclude property.\n; Exclude\
    \ cannot be the only matching property.</p>\n<p>user =\n; Not case-sensitive.\
    \ Will not match substring. Each user property must be a Twitter username.\n;\
    \ Must not be preceded with @, or it will not match the desired user. \n; user\
    \ = foo will match all tweets by user @foo.</p>\n<p>location = S,W,N,E\n; The\
    \ location property can be used to match tweets that are geotagged and fall inside\
    \ a specified rectangle.\n; The location property takes exactly four arguments,\
    \ each a number between -180 and +180. The arguments \n; correspond to the south-most\
    \ extent, the west-most, the north-most and the east-most, and they must occur\
    \ \n; in that exact order.\n; Given that many users do not geotag their tweets\
    \ due to privacy concerns, setting this option may\n; severely limit the number\
    \ of tweets harvested.</p>\n<p>language =\n; The language property can be used\
    \ to restrict the output to tweets in a particular language as determined\n; by\
    \ Twitter's language detection system. Languages are represented by their 2-digit\
    \ identifier. The list\n; of supported languages is </p>\n<p>; If distinct matching\
    \ properties are used in conjunction with one another, each matching option serves\
    \ to \n; restrict the others.\n;\n; Example:\n; user = foo\n; phrase = bar\n;\
    \ will only match tweets by the user '@foo' that contain the string 'bar', rather\
    \ than all tweets by user \n; '@foo' and all tweets containing 'bar' </p>\n<p>outPeriod\
    \ = [hourly|daily|weekly|monthly] \n; Period to which a single output csv file\
    \ will correspond to. If this property is not included in the config\n; file,\
    \ all tweets will be appended to a single csv spreadsheet.</p>\n<p>outField =\
    \ (createdAt|hashTags|urls|language|text|username|coordinates|place|retweetCount|isRetweet|originalUsername)\n\
    ; The outfield property configures the elements of each tweet that are output\
    \ to the csv file, and the order of\n; the columns.</p>\n<p>outDir = /home/devel/twitterScraper-1.0.39/output/1\n\
    ; The outDir property is the path to the directory in which the harvested tweets\
    \ will be written to a csv file.\n; The actual name of the csv file will depend\
    \ on the section number in the config file and the outPeriod.\n```</p>\n<h2>Contact</h2>\n\
    <p>If you are having trouble launching Twitter Scraper, please <a href=\"mailto:help@intersect.org.au?subject=Assistance\
    \ with Twitter Scraper\">contact Intersect</a>, or your university\u2019s <a href=\"\
    http://intersect.org.au/content/eresearch-analysts\">eResearch Analyst</a>.</p>\n\
    <h2>Support</h2>\n<h2>Code Repository</h2>\n<p>The code repository is not currently\
    \ publicly released. Twitter Scraper is currently only available through <a href=\"\
    http://launchpod.intersect.org.au\">Launchpod</a>.</p>\n<h2>Known Issues</h2>\n\
    <ul>\n<li>Twitter Scraper has no way of warning or alerting errors to the user.\
    \ This may make it difficult to troubleshoot problems. </li>\n<li>Twitter Scraper\
    \ uses the Twitter Stream API to harvest tweets in realtime. It does not use the\
    \ Search API which is for finding statuses that have already been posted to Twitter.\
    \ This means that Twitter Scraper is unable to harvest historical tweets.</li>\n\
    <li>If a tweet is deleted by a user from their timeline, an instruction to disregard\
    \ the status is sent via the Stream API. Due to the way Twitter Scraper outputs\
    \ tweets, by appending them to a csv text file, the instruction to disregard a\
    \ tweet cannot be honoured. This means that tweets that have harvested and then\
    \ deleted by the originating user will still appear in the output.</li>\n</ul>\n\
    <h2>Troubleshooting</h2>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Symptom</th>\n\
    <th align=\"left\">Possible Problem</th>\n<th align=\"left\">Solution</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td align=\"left\">Launchpod failed to deply</td>\n<td\
    \ align=\"left\">Some availability zones may experience problems launching machines</td>\n\
    <td align=\"left\">Try again using another availability zone</td>\n</tr>\n</tbody>\n\
    </table>"
  parent: 24
  sha1: e4cb7e4fc3faf091a40f153c83c9e0228d1485f7
  title: Intersect Twitter Scraper User Guide
89:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-22T23:57:07-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " \n SA node service for users in South Australia \n \n Introduction\
          \ \n Cloud allocation \n Contact eRSA to obtain the image ID \n Creating\
          \ a security group \n Launching an instance \n Loading the pre-installed\
          \ software packages \n Sharing files with the virtual machine \n The CentOS\
          \ operating system \n \nGlossary of Terms  \n \n \n Introduction \n \n Description\
          \  \n Since cloud Virtual Machine (VM) images are restricted in size, it\
          \ is not possible to have a generic image containing all the different application\
          \ software that is available on high-performance computing (HPC) systems,\
          \ such as eResearchSA's Tizard supercomputer. Users have therefore needed\
          \ to find VM images that contain the software they need, or install it themselves.\
          \  \n eResearchSA has deployed a distributed software repository that enables\
          \ cloud virtual machines to easily access all the software applications\
          \ that are available on the Tizard supercomputer. Users can run any of this\
          \ software on the cloud virtual machine, just as they can on Tizard. \n\
          \ This service is designed for: \n \n Researchers who want to use cloud\
          \ virtual machines to run compute-intensive software applications \n Situations\
          \ where a single virtual machine image containing all the required software\
          \ is not available, and the researcher does not want to install the software\
          \ themselves. \n This service is currently only available for South Australian\
          \ users as it uses the eResearch SA software repository. \n \n CVMFS \n\
          \ The system makes use of a read-only, http-based distributed virtual file\
          \ system called the CERN VM File System (CVMFS), which CERN developed to\
          \ enable researchers to access their standard software packages at many\
          \ sites around the world. eRSA has set up a CVMFS server that provides access\
          \ to a repository of all the open-source software that is installed on eRSA's\
          \ HPC systems, and a NeCTAR cloud virtual machine image that contains a\
          \ CVMFS client that can access the software in the repository.  \n When\
          \ a user runs a software application on the cloud virtual machine, the software\
          \ is automatically downloaded from the CVMFS repository and stored locally\
          \ on the VM. The next time the same software is used, CVMFS uses the local\
          \ copy of the software so it will start up faster, without having to wait\
          \ for the download. \n For the user, this all happens transparently, it\
          \ appears as though all the application software is installed on the cloud\
          \ virtual machine. \n Glossary of Terms  \nTop of page \n \n Register for\
          \ an eRSA account \n To access the eRSA cloud software repository, you will\
          \ need to be [registered with eResearchSA].  Email the [eRSA Helpdesk][ServiceDesk]\
          \ with any queries. \n \n \n Getting a Project Allocation \n Researchers\
          \ will by default have a trial allocation on NeCTAR (project name pt-XXXXX;\
          \ 2 cores for 3 months). \n You will need to request a project allocation\
          \ for further resources if: \n \n you require more computing power or longer\
          \ term usage \n you wish to share cloud computing resources with your research\
          \ group \n \n Log in to the NeCTAR dashboard and click on New Request under\
          \ Allocations in the left hand side menu. Email the eRSA Helpdesk if you\
          \ have questions about any of the information in the form. New requests\
          \ can take a couple of weeks to process, and allocations are merit-based.\
          \ \n Managing an Allocation page \nGlossary of Terms \nTop of page \n \n\
          \ \n Contact eRSA to help set-up your instance \n Accessing the Cloud software\
          \ repository is as simple as launching an instance using a specific image\
          \ designed by eRSA staff, and knowing a few basic commands.   \n Email the\
          \ eRSA Helpdesk to inform them you want to set up a VM with access to the\
          \ software repository, and a support member will give you the name of the\
          \ current image that you will use.  You can use this information to launch\
          \ an instance, following the instructions below, or you can request that\
          \ eRSA set up the VM for you. \n Add your eRSA support contact to your project\
          \ users group \n After you have received a project allocation, you can add\
          \ collaborators as users to the project by selecting the Users tab in the\
          \ project menu on the dashboard and entering the institutional (AAF) email\
          \ address of your co-workers. \n It is recommended that you add the eRSA\
          \ email address of your eRSA support contact to the users of your project.\
          \ If you need any assistance in setting up or managing your VM, eRSA staff\
          \ will need to be a user on the project in order to provide some types of\
          \ assistance. \n Glossary of Terms \nTop of page \n \n \n Creating a security\
          \ group \n \n \n If you have not already done so, you will need to create\
          \ a security group with port 22 open for SSH access.  \n \n \n On the NeCTAR\
          \ dashboard, ensure you are in the correct project. \n \n \n \n \n Select\
          \ \"Access & Security\" under the left hand side pane under \"Compute\"\
          . \n \n Select the \"Create Security Group\" button near the top right corner\
          \ \n Give your security group a name and description and click the \"Create\
          \ Security Group\" button \n Click \"Manage Rules\" in the \"Actions\" drop-down\
          \ menu \n \n  Click on the \"Add Rule\" button near the top right corner\
          \  \n \n \n A small window should pop up. Make sure the \"Rule\" is set\
          \ to \"Custom TCP Rule\" \n  and \"Open Port\" is set to \"Port\". Under\
          \ the Port textbox enter \"22\". Set \"Remote\" \n  to \"CIDR\" and under\
          \ the \"CIDR\" textbox enter one of the following IP ranges as appropriate.\
          \ \n \n 129.127.0.0/16 - University of Adelaide \n 129.96.0.0/16 - Flinders\
          \ \n 130.220.0.0/16 - UniSA   \n \n \n E.g. for a user from the University\
          \ of Adelaide: \n \n \n Security and Access Tip: Using the IP ranges above\
          \ will limit VM access to computers connected to your university network.\
          \ If you would like to access the computers from home or elsewhere, you\
          \ will have to do this through a VPN connection with your university computer.\
          \ Alternatively, you can set the CIDR to '0.0.0.0/0' which will allow any\
          \ IP address to connect to the VM. This will reduce the security of your\
          \ VM, but you will be able to get SSH access with any computer at any location.\
          \ \n Security Groups page \nGlossary of Terms  \nTop of page \n \n \n Creating\
          \ an instance with access to the software repository \n See this training\
          \ module or this guide for detailed instructions on launching an instance\
          \ if it is your first time and/or you haven't yet set up SSH keypairs. \n\
          \ \n \n In your project allocation on the NeCTAR dashboard, navigate to\
          \ the 'Instances' tab in the 'Compute' menu. \n \n \n  Select the \"Launch\
          \ Instance\" button near the top right corner \n \n \n Fill in a name for\
          \ the VM, choose an appropriate size (Flavor), then select the image name\
          \ provided by eRSA (the screenshot shows the image used for CVMFS access\
          \ at the time of writing this document). \n \n \n \n \n Click the 'Access\
          \ and Security' tab. Select your SSH keypair and select the security group\
          \ which allows access through port 22 for SSH (set up in the previous step).\
          \ \n \n \n \n Click the 'Availability Zone' tab and select 'sa', Then click\
          \ 'Launch' \n \n \n \n Once the Instance is running, use the IP Address\
          \ to connect to the VM via SSH in the usual way, as outlined in the Accessing\
          \ Instances support page and the training module Launching and Connecting.\
          \ \n \n Launching an Instance \nGlossary of Terms  \nTop of page \n \n \n\
          \ Loading the pre-installed software packages \n There are a few simple\
          \ commands to find software packages in the repository and load the environment\
          \ for the version of the software that you want. This is done using the\
          \ Environment Modules package. You must first load the module (using the\
          \ module load command) for the software you want before you run the software.\
          \ \n\n\n\nCommand\nAction\n\n\n\n\nmodule --help\nhelp page for the 'module'\
          \ commands\n\n\nmodule avail\nlist all available packages in the repository\n\
          \n\nmodule avail <search term>\nlist package names containing the search\
          \ term\n\n\nmodule list\nlist the packages that are already loaded on the\
          \ VM\n\n\nmodule show <name>\nshow info on the package, and lists the required\
          \ modules to pre-load\n\n\nmodule load <name>\nload the package onto the\
          \ VM\n\n\nmodule unload <name>\nremove the package 'cache' from the VM\n\
          \n\n\n An example of loading the package 'Stacks'.  \n \n NOTE: If there\
          \ is software that you would like to access that is not already in the CVMFS\
          \ software repository, email the eRSA Helpdesk and request that it be added.\
          \ Ensure you mention that you would like to access it through cloud computing\
          \ on your VM. \n Glossary of Terms  \nTop of page \n \n \n Sharing files\
          \ with the virtual machine \n There is a training module and a support guide\
          \ with comprehensive details on transferring data between your VM and your\
          \ local computer or remote storage servers. Using programs like FileZilla\
          \ or WinSCP is an easy method of transferring data from your local computer.\
          \  \n The following information outlines commands that can be entered on\
          \ your VM in order to transfer data to and from remote data storage, such\
          \ as the storage offered by eRSA. There is also an eRSA support page with\
          \ more detail on transferring data from eRSA storage. \n Secure Copy (SCP)\
          \ between the VM and a data storage server \n If you have data stored on\
          \ a remote server, you can transfer files between it and the VM through\
          \ the command-line on the VM. \n You will need a host address for the data\
          \ storage server, your username, and your password. \n scp <source> <destination>\
          \ \n scp username@sftp.ersa.edu.au:/data/myDirectory/file.txt /mnt/data/\
          \ \nscp /mnt/data/results.zip username@sftp.ersa.edu.au:/data/myDirectory/\
          \ \n You will usually then be prompted to enter the password for your data\
          \ storage. \n \n SFTP via the Command Line \n Secure file transfer is also\
          \ available between the VM and remote data storage. This is useful when\
          \ you aren't sure of the file structure on the remote server, because it\
          \ allows you to navigate to a file before you download it. \n Enter the\
          \ 'sftp' command while logged on to your VM, and you will have access to\
          \ the remote storage server. \n sftp username@sftp.ersa.edu.au   - you will\
          \ be prompted for a password. \n You are now accessing the remote data storage\
          \ server, and you can navigate the files on the server as per usual with\
          \ commands like cd and ls. \nThe commands get and put will transfer data\
          \ between the machines:\n  \n   \n to close the sftp connection, type exit.\
          \ \n Glossary of Terms  \nTop of page \n \n \n The CentOS operating system\
          \ \n The VM image that allows access to the CVMFS software repository is\
          \ a Linux distribution called CentOS. Most of the documentation available\
          \ about using your Linux VM in the NeCTAR cloud assumes that you have an\
          \ Ubuntu operating system.  There is very little difference for the user\
          \ between these Linux operating systems, but there is one main difference\
          \ to be aware of. \n CentOS uses the package manager 'yum' instead of 'apt-get'.\
          \ If you need to install packages on your VM that aren't in the CVMFS software\
          \ repository, you need to use the 'yum' command wherever there would be\
          \ an 'apt-get' command in Ubuntu. e.g. \n \n yum search <package name> \n\
          \ sudo yum install <package name> \n sudo yum update \n \n Top of page \n\
          \ \n \n Glossary \n Availability Zone \n \n A logical grouping of compute\
          \ nodes within a region. \n \n Dashboard \n \n The NeCTAR Dashboard is the\
          \ main web-based interface for managing NeCTAR virtuals. \n \n ERSA \n \n\
          \ eResearch SA runs the South Australian node of the NeCTAR research cloud.\
          \ \n \n Flavor \n \n An OpenStack term for an instance sizing specification.\
          \ Gives the amount \nof memory, number of VCPUs and ephemeral disk size.\
          \ \n \n Image \n \n An image (or system image) is a copy of the entire state\
          \ of a computer system \nsaved as a file. Images are used in two ways in\
          \ NeCTAR. Firstly as a template for \nVirtual Machines (VMs). You can launch\
          \ a VM based on an image. \nThe second use of images is to preserve the\
          \ state of a VM as configured by you as end user. \nThis type of image is\
          \ usually referred to as a snapshot. \n \n Instance \n \n An instance is\
          \ a VM hosted on the NeCTAR OpenStack infrastructure. \n \n Modules \n \n\
          \ Environment modules are used to configure a users environment to allow\
          \ use of the software packages available on the server. The module commands\
          \ are used to find information on the available packages, and to load the\
          \ packages for use. \n \n Node (compute node)  \n \n OpenStack terminology\
          \ for a physical computer used to run virtual machines. It will typically\
          \ have multiple CPUs and shared memory, and one or more network interfaces.\
          \ It may also have on-node disk storage. \n \n Project \n \n The NeCTAR\
          \ term for a \"resource container\"; i.e. what you get when you \nare granted\
          \ a NeCTAR allocation. A project \"owns\" virtual machine instances, snapshots\
          \ \nand various kinds of storage, and may be shared by multiple users. \n\
          \ \n Security Group \n \n A set of access rules that may be applied to one\
          \ or more instances. \nAn access rule allows network access to an instance\
          \ from other hosts with a \nspecified combination of protocol family (e.g.\
          \ TCP, UDP, UCMP), port number and address range. Security Groups page \n\
          \ \n SSH \n \n A protocol and tools for establishing secure \"shell\" sessions\
          \ over the network. SSH encrypts the data transferred, and supports user\
          \ authentication using public/private keys. \n \n Tizard \n \n Tizard is\
          \ eRSA's high performance computing server that can be used for complex\
          \ data processing and analysis jobs that standard desktop computers would\
          \ find it difficult or impossible to perform. It enables users to run many\
          \ processing jobs with different parameters or input files more quickly.\
          \ \n \n Virtual Machine \n \n A virtual machine (VM) is an operating system\
          \ (OS) or application environment that \nis installed on software which\
          \ imitates dedicated hardware. The end user has the same \nexperience on\
          \ a virtual machine as they would have on dedicated hardware. \n \n Volume\
          \ Storage \n \n Data Storage in your Virtual Machine that works like a hard-drive\
          \ on your PC or \nlaptop does. Volume storage is automatically available\
          \ in your VM as the storage \nspace for you system drive. Some flavors of\
          \ VMs include an amount of ephemeral volume \nstorage. Depending on your\
          \ allocation you can have persistent volume storage attached to your VM.\
          \ \n \n Full Glossary Page \nNeCTAR FAQ - general inormation \nFor more\
          \ help, contact the eRSA Helpdesk \n Top of page "
        description: "<p><a name=\"top\"></a></p>\n<h2>SA node service for users in\
          \ South Australia</h2>\n<ul>\n<li><a href=\"#intro\">Introduction</a></li>\n\
          <li><a href=\"#alloc\">Cloud allocation</a></li>\n<li><a href=\"#setup\"\
          >Contact eRSA to obtain the image ID</a></li>\n<li><a href=\"#security\"\
          >Creating a security group</a></li>\n<li><a href=\"#instance\">Launching\
          \ an instance</a></li>\n<li><a href=\"#modules\">Loading the pre-installed\
          \ software packages</a></li>\n<li><a href=\"#transferfiles\">Sharing files\
          \ with the virtual machine</a></li>\n<li><a href=\"#os\">The CentOS operating\
          \ system</a></li>\n<li>\n<a href=\"#glossary\">Glossary of Terms</a> </li>\n\
          </ul>\n<hr>\n<h2>Introduction <a name=\"intro\"></a>\n</h2>\n<p>Description\
          \ </p>\n<p>Since cloud Virtual Machine (VM) images are restricted in size,\
          \ it is not possible to have a generic image containing all the different\
          \ application software that is available on high-performance computing (HPC)\
          \ systems, such as eResearchSA's <a href=\"https://www.ersa.edu.au/tizard/\"\
          >Tizard supercomputer</a>. Users have therefore needed to find VM images\
          \ that contain the software they need, or install it themselves. </p>\n\
          <p><a href=\"https://www.ersa.edu.au/\">eResearchSA</a> has deployed a distributed\
          \ software repository that enables cloud virtual machines to easily access\
          \ all the software applications that are available on the Tizard supercomputer.\
          \ Users can run any of this software on the cloud virtual machine, just\
          \ as they can on Tizard.</p>\n<p>This service is designed for:</p>\n<ul>\n\
          <li>Researchers who want to use cloud virtual machines to run compute-intensive\
          \ software applications</li>\n<li>Situations where a single virtual machine\
          \ image containing all the required software is not available, and the researcher\
          \ does not want to install the software themselves.</li>\n<li>This service\
          \ is currently only available for South Australian users as it uses the\
          \ eResearch SA software repository.</li>\n</ul>\n<h2>CVMFS</h2>\n<p>The\
          \ system makes use of a read-only, http-based distributed virtual file system\
          \ called the <a href=\"http://cernvm.cern.ch/portal/startcvmfs\">CERN VM\
          \ File System</a> (CVMFS), which CERN developed to enable researchers to\
          \ access their standard software packages at many sites around the world.\
          \ eRSA has set up a CVMFS server that provides access to a repository of\
          \ all the open-source software that is installed on eRSA's HPC systems,\
          \ and a NeCTAR cloud virtual machine image that contains a CVMFS client\
          \ that can access the software in the repository. </p>\n<p>When a user runs\
          \ a software application on the cloud virtual machine, the software is automatically\
          \ downloaded from the CVMFS repository and stored locally on the VM. The\
          \ next time the same software is used, CVMFS uses the local copy of the\
          \ software so it will start up faster, without having to wait for the download.</p>\n\
          <p>For the user, this all happens transparently, it appears as though all\
          \ the application software is installed on the cloud virtual machine.</p>\n\
          <p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top\
          \ of page</a></p>\n<hr>\n<h2>Register for an eRSA account</h2>\n<p>To access\
          \ the eRSA cloud software repository, you will need to be [registered with\
          \ eResearchSA].  Email the [eRSA Helpdesk][ServiceDesk] with any queries.</p>\n\
          <hr>\n<p><a name=\"alloc\"></a></p>\n<h2>Getting a Project Allocation</h2>\n\
          <p>Researchers will by default have a trial allocation on NeCTAR (project\
          \ name pt-XXXXX; 2 cores for 3 months).</p>\n<p>You will need to request\
          \ a project allocation for further resources if:</p>\n<ul>\n<li>you require\
          \ more computing power or longer term usage</li>\n<li>you wish to share\
          \ cloud computing resources with your research group</li>\n</ul>\n<p>Log\
          \ in to the <a href=\"https://dashboard.rc.nectar.org.au/project/request/\"\
          >NeCTAR dashboard</a> and click on <strong>New Request</strong> under <strong>Allocations</strong>\
          \ in the left hand side menu. Email the <a href=\"mailto:servicedesk@ersa.edu.au\"\
          >eRSA Helpdesk</a> if you have questions about any of the information in\
          \ the form. New requests can take a couple of weeks to process, and allocations\
          \ are merit-based.</p>\n<p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
          >Managing an Allocation page</a><br>\n<a href=\"#glossary\">Glossary of\
          \ Terms</a><br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"\
          setup\"></a></p>\n<h2>Contact eRSA to help set-up your instance</h2>\n<p>Accessing\
          \ the Cloud software repository is as simple as launching an instance using\
          \ a specific image designed by eRSA staff, and knowing a few <a href=\"\
          #modules\">basic commands</a>.  </p>\n<p>Email the <a href=\"mailto:servicedesk@ersa.edu.au\"\
          >eRSA Helpdesk</a> to inform them you want to set up a VM with access to\
          \ the software repository, and a support member will give you the name of\
          \ the current image that you will use.  You can use this information to\
          \ launch an instance, following the instructions below, or you can request\
          \ that eRSA set up the VM for you.</p>\n<h2>Add your eRSA support contact\
          \ to your project users group</h2>\n<p>After you have received a project\
          \ allocation, you can add collaborators as users to the project by selecting\
          \ the <a href=\"https://dashboard.rc.nectar.org.au/project/members/\">Users</a>\
          \ tab in the project menu on the dashboard and entering the institutional\
          \ (<a href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
          >AAF</a>) email address of your co-workers.</p>\n<p>It is recommended that\
          \ you add the eRSA email address of your eRSA support contact to the users\
          \ of your project. If you need any assistance in setting up or managing\
          \ your VM, eRSA staff will need to be a user on the project in order to\
          \ provide some types of assistance.</p>\n<p><a href=\"#glossary\">Glossary\
          \ of Terms</a><br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"\
          security\"></a></p>\n<h2>Creating a security group</h2>\n<ul>\n<li>\n<p>If\
          \ you have not already done so, you will need to create a security group\
          \ with port 22 open for SSH access. </p>\n</li>\n<li>\n<p>On the NeCTAR\
          \ <a href=\"https://dashboard.rc.nectar.org.au/project/access_and_security/\"\
          >dashboard</a>, ensure you are in the correct project.</p>\n</li>\n</ul>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_choose_project.png?raw=true\"\
          ></p>\n<ul>\n<li>Select \"Access &amp; Security\" under the left hand side\
          \ pane under \"Compute\".</li>\n<li>\n<img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_createsecuritybutton.png?raw=true\"\
          > Select the \"Create Security Group\" button near the top right corner</li>\n\
          <li>Give your security group a name and description and click the \"Create\
          \ Security Group\" button</li>\n<li>Click \"Manage Rules\" in the \"Actions\"\
          \ drop-down menu</li>\n<li>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_addrulebutton.png?raw=true\"\
          > Click on the \"Add Rule\" button near the top right corner </p>\n</li>\n\
          <li>\n<p>A small window should pop up. Make sure the \"Rule\" is set to\
          \ \"Custom TCP Rule\" \n  and \"Open Port\" is set to \"Port\". Under the\
          \ Port textbox enter \"<strong>22</strong>\". Set \"Remote\" \n  to \"CIDR\"\
          \ and under the \"CIDR\" textbox enter one of the following IP ranges as\
          \ appropriate.</p>\n<ul>\n<li>129.127.0.0/16 - University of Adelaide</li>\n\
          <li>129.96.0.0/16 - Flinders</li>\n<li>130.220.0.0/16 - UniSA  </li>\n</ul>\n\
          </li>\n<li>E.g. for a user from the University of Adelaide:</li>\n</ul>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_security_rule.png?raw=true\"\
          ></p>\n<p><strong>Security and Access Tip:</strong> Using the IP ranges\
          \ above will limit VM access to computers connected to your university network.\
          \ If you would like to access the computers from home or elsewhere, you\
          \ will have to do this through a VPN connection with your university computer.\
          \ Alternatively, you can set the CIDR to '0.0.0.0/0' which will allow any\
          \ IP address to connect to the VM. This will reduce the security of your\
          \ VM, but you will be able to get SSH access with any computer at any location.</p>\n\
          <p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000055387-security-groups\"\
          >Security Groups page</a><br>\n<a href=\"#glossary\">Glossary of Terms</a>\
          \ <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"instance\"\
          ></a></p>\n<h2>Creating an instance with access to the software repository</h2>\n\
          <p>See this <a href=\"http://training.nectar.org.au/package07/sections/index.html\"\
          >training module</a> or this <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055376-launching-virtual-machines\"\
          >guide</a> for detailed instructions on launching an instance if it is your\
          \ first time and/or you haven't yet set up SSH keypairs.</p>\n<ul>\n<li>\n\
          <p>In your project allocation on the NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/project/instances/\"\
          >dashboard</a>, navigate to the 'Instances' tab in the 'Compute' menu.</p>\n\
          </li>\n<li>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_launchInstance_button.png?raw=true\"\
          > Select the \"Launch Instance\" button near the top right corner</p>\n\
          </li>\n<li>\n<p>Fill in a name for the VM, choose an appropriate size (Flavor),\
          \ then select the image name provided by eRSA (the screenshot shows the\
          \ image used for CVMFS access at the time of writing this document).</p>\n\
          </li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_launchInstance.png?raw=true\"\
          ></p>\n<ul>\n<li>Click the 'Access and Security' tab. Select your SSH keypair\
          \ and select the security group which allows access through port 22 for\
          \ SSH (set up in the previous step).</li>\n</ul>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_access_security.png?raw=true\"\
          ></p>\n<ul>\n<li>Click the 'Availability Zone' tab and select '<strong>sa</strong>',\
          \ Then click '<strong>Launch</strong>'</li>\n</ul>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_avail_zone.png?raw=true\"\
          ></p>\n<ul>\n<li>Once the Instance is running, use the IP Address to connect\
          \ to the VM via SSH in the usual way, as outlined in the <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055446-accessing-instances\"\
          >Accessing Instances</a> support page and the training module <a href=\"\
          http://training.nectar.org.au/package07/sections/connectViaSSH.html\">Launching\
          \ and Connecting</a>.</li>\n</ul>\n<p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000055376-launching-virtual-machines\"\
          >Launching an Instance</a><br>\n<a href=\"#glossary\">Glossary of Terms</a>\
          \ <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"modules\"\
          ></a></p>\n<h2>Loading the pre-installed software packages</h2>\n<p>There\
          \ are a few simple commands to find software packages in the repository\
          \ and load the environment for the version of the software that you want.\
          \ This is done using the <a href=\"http://modules.sourceforge.net/\">Environment\
          \ Modules package</a>. You must first load the module (using the <a href=\"\
          http://support.ersa.edu.au/hpc/module-commands.html\">module load command</a>)\
          \ for the software you want before you run the software.</p>\n<table>\n\
          <thead>\n<tr>\n<th>Command</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody>\n\
          <tr>\n<td><code>module --help</code></td>\n<td>help page for the 'module'\
          \ commands</td>\n</tr>\n<tr>\n<td><code>module avail</code></td>\n<td>list\
          \ all available packages in the repository</td>\n</tr>\n<tr>\n<td><code>module\
          \ avail &lt;search term&gt;</code></td>\n<td>list package names containing\
          \ the search term</td>\n</tr>\n<tr>\n<td><code>module list</code></td>\n\
          <td>list the packages that are already loaded on the VM</td>\n</tr>\n<tr>\n\
          <td><code>module show &lt;name&gt;</code></td>\n<td>show info on the package,\
          \ and lists the required modules to pre-load</td>\n</tr>\n<tr>\n<td><code>module\
          \ load &lt;name&gt;</code></td>\n<td>load the package onto the VM</td>\n\
          </tr>\n<tr>\n<td><code>module unload &lt;name&gt;</code></td>\n<td>remove\
          \ the package 'cache' from the VM</td>\n</tr>\n</tbody>\n</table>\n<p>An\
          \ example of loading the package 'Stacks'. </p>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_module_load_stacks_full.png?raw=true\"\
          ></p>\n<p><strong>NOTE:</strong> If there is software that you would like\
          \ to access that is not already in the CVMFS software repository, email\
          \ the <a href=\"mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a> and request\
          \ that it be added. Ensure you mention that you would like to access it\
          \ through cloud computing on your VM.</p>\n<p><a href=\"#glossary\">Glossary\
          \ of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"\
          transferfiles\"></a></p>\n<h2>Sharing files with the virtual machine</h2>\n\
          <p>There is a <a href=\"http://training.nectar.org.au/package07/sections/copyFiles.html\"\
          >training module</a> and a <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
          >support guide</a> with comprehensive details on transferring data between\
          \ your VM and your local computer or remote storage servers. Using programs\
          \ like FileZilla or WinSCP is an easy method of transferring data from your\
          \ local computer. </p>\n<p>The following information outlines commands that\
          \ can be entered on your VM in order to transfer data to and from remote\
          \ data storage, such as the <a href=\"https://www.ersa.edu.au/service/data-storage/\"\
          >storage</a> offered by eRSA. There is also an <a href=\"http://support.ersa.edu.au/storage/quick-start.html\"\
          >eRSA support page</a> with more detail on transferring data from eRSA storage.</p>\n\
          <h3>Secure Copy (SCP) between the VM and a data storage server</h3>\n<p>If\
          \ you have data stored on a remote server, you can transfer files between\
          \ it and the VM through the command-line on the VM.</p>\n<p>You will need\
          \ a host address for the data storage server, your username, and your password.</p>\n\
          <p><code>scp &lt;source&gt; &lt;destination&gt;</code></p>\n<p><code>scp\
          \ username@sftp.ersa.edu.au:/data/myDirectory/file.txt /mnt/data/</code><br>\n\
          <code>scp /mnt/data/results.zip username@sftp.ersa.edu.au:/data/myDirectory/</code></p>\n\
          <p>You will usually then be prompted to enter the password for your data\
          \ storage.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_scp_demo.png?raw=true\"\
          ></p>\n<h3>SFTP via the Command Line</h3>\n<p>Secure file transfer is also\
          \ available between the VM and remote data storage. This is useful when\
          \ you aren't sure of the file structure on the remote server, because it\
          \ allows you to navigate to a file before you download it.</p>\n<p>Enter\
          \ the 'sftp' command while logged on to your VM, and you will have access\
          \ to the remote storage server.</p>\n<p><code>sftp username@sftp.ersa.edu.au</code>\
          \   - you will be prompted for a password.</p>\n<p>You are now accessing\
          \ the remote data storage server, and you can navigate the files on the\
          \ server as per usual with commands like <code>cd</code> and <code>ls</code>.<br>\n\
          The commands <code>get</code> and <code>put</code> will transfer data between\
          \ the machines:\n  <img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_sftp_get.png?raw=true\"\
          >\n  <img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/software_sftp_put.png?raw=true\"\
          ></p>\n<p>to close the sftp connection, type <code>exit</code>.</p>\n<p><a\
          \ href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top of\
          \ page</a></p>\n<hr>\n<p><a name=\"os\"></a></p>\n<h2>The CentOS operating\
          \ system</h2>\n<p>The VM image that allows access to the CVMFS software\
          \ repository is a Linux distribution called CentOS. Most of the documentation\
          \ available about using your Linux VM in the NeCTAR cloud assumes that you\
          \ have an Ubuntu operating system.  There is very little difference for\
          \ the user between these Linux operating systems, but there is one main\
          \ difference to be aware of.</p>\n<p>CentOS uses the package manager '<strong>yum</strong>'\
          \ instead of '<strong>apt-get</strong>'. If you need to install packages\
          \ on your VM that aren't in the CVMFS software repository, you need to use\
          \ the 'yum' command wherever there would be an 'apt-get' command in Ubuntu.\
          \ e.g.</p>\n<ul>\n<li><code>yum search &lt;package name&gt;</code></li>\n\
          <li><code>sudo yum install &lt;package name&gt;</code></li>\n<li><code>sudo\
          \ yum update</code></li>\n</ul>\n<p><a href=\"#top\">Top of page</a></p>\n\
          <hr>\n<p><a name=\"glossary\"></a></p>\n<h2>Glossary</h2>\n<p><strong>Availability\
          \ Zone</strong></p>\n<blockquote>\n<p>A logical grouping of compute nodes\
          \ within a region.</p>\n</blockquote>\n<p><strong>Dashboard</strong></p>\n\
          <blockquote>\n<p>The NeCTAR Dashboard is the main web-based interface for\
          \ managing NeCTAR virtuals.</p>\n</blockquote>\n<p><strong>ERSA</strong></p>\n\
          <blockquote>\n<p>eResearch SA runs the South Australian node of the NeCTAR\
          \ research cloud.</p>\n</blockquote>\n<p><strong>Flavor</strong></p>\n<blockquote>\n\
          <p>An OpenStack term for an instance sizing specification. Gives the amount\
          \ \nof memory, number of VCPUs and ephemeral disk size.</p>\n</blockquote>\n\
          <p><strong>Image</strong></p>\n<blockquote>\n<p>An image (or system image)\
          \ is a copy of the entire state of a computer system \nsaved as a file.\
          \ Images are used in two ways in NeCTAR. Firstly as a template for \nVirtual\
          \ Machines (VMs). You can launch a VM based on an image. \nThe second use\
          \ of images is to preserve the state of a VM as configured by you as end\
          \ user. \nThis type of image is usually referred to as a snapshot.</p>\n\
          </blockquote>\n<p><strong>Instance</strong></p>\n<blockquote>\n<p>An instance\
          \ is a VM hosted on the NeCTAR OpenStack infrastructure.</p>\n</blockquote>\n\
          <p><strong>Modules</strong></p>\n<blockquote>\n<p><a href=\"http://modules.sourceforge.net/\"\
          >Environment modules</a> are used to configure a users environment to allow\
          \ use of the software packages available on the server. The module commands\
          \ are used to find information on the available packages, and to load the\
          \ packages for use.</p>\n</blockquote>\n<p><strong>Node</strong> (compute\
          \ node) </p>\n<blockquote>\n<p>OpenStack terminology for a physical computer\
          \ used to run virtual machines. It will typically have multiple CPUs and\
          \ shared memory, and one or more network interfaces. It may also have on-node\
          \ disk storage.</p>\n</blockquote>\n<p><strong>Project</strong></p>\n<blockquote>\n\
          <p>The NeCTAR term for a \"resource container\"; i.e. what you get when\
          \ you \nare granted a NeCTAR allocation. A project \"owns\" virtual machine\
          \ instances, snapshots \nand various kinds of storage, and may be shared\
          \ by multiple users.</p>\n</blockquote>\n<p><strong>Security Group</strong></p>\n\
          <blockquote>\n<p>A set of access rules that may be applied to one or more\
          \ instances. \nAn access rule allows network access to an instance from\
          \ other hosts with a \nspecified combination of protocol family (e.g. TCP,\
          \ UDP, UCMP), port number and address range. <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055387-security-groups\"\
          >Security Groups page</a></p>\n</blockquote>\n<p><strong>SSH</strong></p>\n\
          <blockquote>\n<p>A protocol and tools for establishing secure \"shell\"\
          \ sessions over the network. SSH encrypts the data transferred, and supports\
          \ user authentication using public/private keys.</p>\n</blockquote>\n<p><strong>Tizard</strong></p>\n\
          <blockquote>\n<p><a href=\"https://www.ersa.edu.au/tizard/\">Tizard</a>\
          \ is eRSA's high performance computing server that can be used for complex\
          \ data processing and analysis jobs that standard desktop computers would\
          \ find it difficult or impossible to perform. It enables users to run many\
          \ processing jobs with different parameters or input files more quickly.</p>\n\
          </blockquote>\n<p><strong>Virtual Machine</strong></p>\n<blockquote>\n<p>A\
          \ virtual machine (VM) is an operating system (OS) or application environment\
          \ that \nis installed on software which imitates dedicated hardware. The\
          \ end user has the same \nexperience on a virtual machine as they would\
          \ have on dedicated hardware.</p>\n</blockquote>\n<p><strong>Volume Storage</strong></p>\n\
          <blockquote>\n<p>Data Storage in your Virtual Machine that works like a\
          \ hard-drive on your PC or \nlaptop does. Volume storage is automatically\
          \ available in your VM as the storage \nspace for you system drive. Some\
          \ flavors of VMs include an amount of ephemeral volume \nstorage. Depending\
          \ on your allocation you can have persistent volume storage attached to\
          \ your VM.</p>\n</blockquote>\n<p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000055445-glossary\"\
          >Full Glossary Page</a><br>\n<a href=\"http://cloud.nectar.org.au/faq/\"\
          >NeCTAR FAQ - general inormation</a><br>\nFor more help, contact the <a\
          \ href=\"mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a></p>\n<p><a href=\"\
          #top\">Top of page</a></p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 20
        id: 6000090905
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-30T20:00:04-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000090905
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: eRSA Cloud Software Repository - user guide
        updated_at: '2015-11-30T20:00:04-05:00'
        user_id: 6002464727
  html: "<p><a name=\"top\"></a></p>\n<h2>SA node service for users in South Australia</h2>\n\
    <ul>\n<li><a href=\"#intro\">Introduction</a></li>\n<li><a href=\"#alloc\">Cloud\
    \ allocation</a></li>\n<li><a href=\"#setup\">Contact eRSA to obtain the image\
    \ ID</a></li>\n<li><a href=\"#security\">Creating a security group</a></li>\n\
    <li><a href=\"#instance\">Launching an instance</a></li>\n<li><a href=\"#modules\"\
    >Loading the pre-installed software packages</a></li>\n<li><a href=\"#transferfiles\"\
    >Sharing files with the virtual machine</a></li>\n<li><a href=\"#os\">The CentOS\
    \ operating system</a></li>\n<li><a href=\"#glossary\">Glossary of Terms</a> </li>\n\
    </ul>\n<hr>\n<h2>Introduction <a name=\"intro\"></a></h2>\n<p>Description </p>\n\
    <p>Since cloud Virtual Machine (VM) images are restricted in size, it is not possible\
    \ to have a generic image containing all the different application software that\
    \ is available on high-performance computing (HPC) systems, such as eResearchSA's\
    \ <a href=\"https://www.ersa.edu.au/tizard/\">Tizard supercomputer</a>. Users\
    \ have therefore needed to find VM images that contain the software they need,\
    \ or install it themselves. </p>\n<p><a href=\"https://www.ersa.edu.au/\">eResearchSA</a>\
    \ has deployed a distributed software repository that enables cloud virtual machines\
    \ to easily access all the software applications that are available on the Tizard\
    \ supercomputer. Users can run any of this software on the cloud virtual machine,\
    \ just as they can on Tizard.</p>\n<p>This service is designed for:</p>\n<ul>\n\
    <li>Researchers who want to use cloud virtual machines to run compute-intensive\
    \ software applications</li>\n<li>Situations where a single virtual machine image\
    \ containing all the required software is not available, and the researcher does\
    \ not want to install the software themselves.</li>\n<li>This service is currently\
    \ only available for South Australian users as it uses the eResearch SA software\
    \ repository.</li>\n</ul>\n<h2>CVMFS</h2>\n<p>The system makes use of a read-only,\
    \ http-based distributed virtual file system called the <a href=\"http://cernvm.cern.ch/portal/startcvmfs\"\
    >CERN VM File System</a> (CVMFS), which CERN developed to enable researchers to\
    \ access their standard software packages at many sites around the world. eRSA\
    \ has set up a CVMFS server that provides access to a repository of all the open-source\
    \ software that is installed on eRSA's HPC systems, and a NeCTAR cloud virtual\
    \ machine image that contains a CVMFS client that can access the software in the\
    \ repository. </p>\n<p>When a user runs a software application on the cloud virtual\
    \ machine, the software is automatically downloaded from the CVMFS repository\
    \ and stored locally on the VM. The next time the same software is used, CVMFS\
    \ uses the local copy of the software so it will start up faster, without having\
    \ to wait for the download.</p>\n<p>For the user, this all happens transparently,\
    \ it appears as though all the application software is installed on the cloud\
    \ virtual machine.</p>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n\
    <a href=\"#top\">Top of page</a></p>\n<hr>\n<h2>Register for an eRSA account</h2>\n\
    <p>To access the eRSA cloud software repository, you will need to be [registered\
    \ with eResearchSA].  Email the [eRSA Helpdesk][ServiceDesk] with any queries.</p>\n\
    <hr>\n<p><a name=\"alloc\"></a></p>\n<h2>Getting a Project Allocation</h2>\n<p>Researchers\
    \ will by default have a trial allocation on NeCTAR (project name pt-XXXXX; 2\
    \ cores for 3 months).</p>\n<p>You will need to request a project allocation for\
    \ further resources if:</p>\n<ul>\n<li>you require more computing power or longer\
    \ term usage</li>\n<li>you wish to share cloud computing resources with your research\
    \ group</li>\n</ul>\n<p>Log in to the <a href=\"https://dashboard.rc.nectar.org.au/project/request/\"\
    >NeCTAR dashboard</a> and click on <strong>New Request</strong> under <strong>Allocations</strong>\
    \ in the left hand side menu. Email the <a href=\"mailto:servicedesk@ersa.edu.au\"\
    >eRSA Helpdesk</a> if you have questions about any of the information in the form.\
    \ New requests can take a couple of weeks to process, and allocations are merit-based.</p>\n\
    <p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
    >Managing an Allocation page</a><br>\n<a href=\"#glossary\">Glossary of Terms</a><br>\n\
    <a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"setup\"></a></p>\n<h2>Contact\
    \ eRSA to help set-up your instance</h2>\n<p>Accessing the Cloud software repository\
    \ is as simple as launching an instance using a specific image designed by eRSA\
    \ staff, and knowing a few <a href=\"#modules\">basic commands</a>.  </p>\n<p>Email\
    \ the <a href=\"mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a> to inform them\
    \ you want to set up a VM with access to the software repository, and a support\
    \ member will give you the name of the current image that you will use.  You can\
    \ use this information to launch an instance, following the instructions below,\
    \ or you can request that eRSA set up the VM for you.</p>\n<h2>Add your eRSA support\
    \ contact to your project users group</h2>\n<p>After you have received a project\
    \ allocation, you can add collaborators as users to the project by selecting the\
    \ <a href=\"https://dashboard.rc.nectar.org.au/project/members/\">Users</a> tab\
    \ in the project menu on the dashboard and entering the institutional (<a href=\"\
    https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
    >AAF</a>) email address of your co-workers.</p>\n<p>It is recommended that you\
    \ add the eRSA email address of your eRSA support contact to the users of your\
    \ project. If you need any assistance in setting up or managing your VM, eRSA\
    \ staff will need to be a user on the project in order to provide some types of\
    \ assistance.</p>\n<p><a href=\"#glossary\">Glossary of Terms</a><br>\n<a href=\"\
    #top\">Top of page</a></p>\n<hr>\n<p><a name=\"security\"></a></p>\n<h2>Creating\
    \ a security group</h2>\n<ul>\n<li>\n<p>If you have not already done so, you will\
    \ need to create a security group with port 22 open for SSH access. </p>\n</li>\n\
    <li>\n<p>On the NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/project/access_and_security/\"\
    >dashboard</a>, ensure you are in the correct project.</p>\n</li>\n</ul>\n<p><img\
    \ alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_choose_project.png?raw=true\"\
    ></p>\n<ul>\n<li>Select \"Access &amp; Security\" under the left hand side pane\
    \ under \"Compute\".</li>\n<li><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_createsecuritybutton.png?raw=true\"\
    > Select the \"Create Security Group\" button near the top right corner</li>\n\
    <li>Give your security group a name and description and click the \"Create Security\
    \ Group\" button</li>\n<li>Click \"Manage Rules\" in the \"Actions\" drop-down\
    \ menu</li>\n<li>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_addrulebutton.png?raw=true\"\
    > Click on the \"Add Rule\" button near the top right corner </p>\n</li>\n<li>\n\
    <p>A small window should pop up. Make sure the \"Rule\" is set to \"Custom TCP\
    \ Rule\" \n  and \"Open Port\" is set to \"Port\". Under the Port textbox enter\
    \ \"<strong>22</strong>\". Set \"Remote\" \n  to \"CIDR\" and under the \"CIDR\"\
    \ textbox enter one of the following IP ranges as appropriate.</p>\n<ul>\n<li>129.127.0.0/16\
    \ - University of Adelaide</li>\n<li>129.96.0.0/16 - Flinders</li>\n<li>130.220.0.0/16\
    \ - UniSA  </li>\n</ul>\n</li>\n<li>E.g. for a user from the University of Adelaide:</li>\n\
    </ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_security_rule.png?raw=true\"\
    ></p>\n<p><strong>Security and Access Tip:</strong> Using the IP ranges above\
    \ will limit VM access to computers connected to your university network. If you\
    \ would like to access the computers from home or elsewhere, you will have to\
    \ do this through a VPN connection with your university computer. Alternatively,\
    \ you can set the CIDR to '0.0.0.0/0' which will allow any IP address to connect\
    \ to the VM. This will reduce the security of your VM, but you will be able to\
    \ get SSH access with any computer at any location.</p>\n<p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000055387-security-groups\"\
    >Security Groups page</a><br>\n<a href=\"#glossary\">Glossary of Terms</a> <br>\n\
    <a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"instance\"></a></p>\n\
    <h2>Creating an instance with access to the software repository</h2>\n<p>See this\
    \ <a href=\"http://training.nectar.org.au/package07/sections/index.html\">training\
    \ module</a> or this <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055376-launching-virtual-machines\"\
    >guide</a> for detailed instructions on launching an instance if it is your first\
    \ time and/or you haven't yet set up SSH keypairs.</p>\n<ul>\n<li>\n<p>In your\
    \ project allocation on the NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/project/instances/\"\
    >dashboard</a>, navigate to the 'Instances' tab in the 'Compute' menu.</p>\n</li>\n\
    <li>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_launchInstance_button.png?raw=true\"\
    > Select the \"Launch Instance\" button near the top right corner</p>\n</li>\n\
    <li>\n<p>Fill in a name for the VM, choose an appropriate size (Flavor), then\
    \ select the image name provided by eRSA (the screenshot shows the image used\
    \ for CVMFS access at the time of writing this document).</p>\n</li>\n</ul>\n\
    <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_launchInstance.png?raw=true\"\
    ></p>\n<ul>\n<li>Click the 'Access and Security' tab. Select your SSH keypair\
    \ and select the security group which allows access through port 22 for SSH (set\
    \ up in the previous step).</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_access_security.png?raw=true\"\
    ></p>\n<ul>\n<li>Click the 'Availability Zone' tab and select '<strong>sa</strong>',\
    \ Then click '<strong>Launch</strong>'</li>\n</ul>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_avail_zone.png?raw=true\"\
    ></p>\n<ul>\n<li>Once the Instance is running, use the IP Address to connect to\
    \ the VM via SSH in the usual way, as outlined in the <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055446-accessing-instances\"\
    >Accessing Instances</a> support page and the training module <a href=\"http://training.nectar.org.au/package07/sections/connectViaSSH.html\"\
    >Launching and Connecting</a>.</li>\n</ul>\n<p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000055376-launching-virtual-machines\"\
    >Launching an Instance</a><br>\n<a href=\"#glossary\">Glossary of Terms</a> <br>\n\
    <a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"modules\"></a></p>\n\
    <h2>Loading the pre-installed software packages</h2>\n<p>There are a few simple\
    \ commands to find software packages in the repository and load the environment\
    \ for the version of the software that you want. This is done using the <a href=\"\
    http://modules.sourceforge.net/\">Environment Modules package</a>. You must first\
    \ load the module (using the <a href=\"http://support.ersa.edu.au/hpc/module-commands.html\"\
    >module load command</a>) for the software you want before you run the software.</p>\n\
    <table>\n<thead>\n<tr>\n<th>Command</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td><code>module --help</code></td>\n<td>help page for the 'module' commands</td>\n\
    </tr>\n<tr>\n<td><code>module avail</code></td>\n<td>list all available packages\
    \ in the repository</td>\n</tr>\n<tr>\n<td><code>module avail &lt;search term&gt;</code></td>\n\
    <td>list package names containing the search term</td>\n</tr>\n<tr>\n<td><code>module\
    \ list</code></td>\n<td>list the packages that are already loaded on the VM</td>\n\
    </tr>\n<tr>\n<td><code>module show &lt;name&gt;</code></td>\n<td>show info on\
    \ the package, and lists the required modules to pre-load</td>\n</tr>\n<tr>\n\
    <td><code>module load &lt;name&gt;</code></td>\n<td>load the package onto the\
    \ VM</td>\n</tr>\n<tr>\n<td><code>module unload &lt;name&gt;</code></td>\n<td>remove\
    \ the package 'cache' from the VM</td>\n</tr>\n</tbody>\n</table>\n<p>An example\
    \ of loading the package 'Stacks'. </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_module_load_stacks_full.png?raw=true\"\
    ></p>\n<p><strong>NOTE:</strong> If there is software that you would like to access\
    \ that is not already in the CVMFS software repository, email the <a href=\"mailto:servicedesk@ersa.edu.au\"\
    >eRSA Helpdesk</a> and request that it be added. Ensure you mention that you would\
    \ like to access it through cloud computing on your VM.</p>\n<p><a href=\"#glossary\"\
    >Glossary of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a\
    \ name=\"transferfiles\"></a></p>\n<h2>Sharing files with the virtual machine</h2>\n\
    <p>There is a <a href=\"http://training.nectar.org.au/package07/sections/copyFiles.html\"\
    >training module</a> and a <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
    >support guide</a> with comprehensive details on transferring data between your\
    \ VM and your local computer or remote storage servers. Using programs like FileZilla\
    \ or WinSCP is an easy method of transferring data from your local computer. </p>\n\
    <p>The following information outlines commands that can be entered on your VM\
    \ in order to transfer data to and from remote data storage, such as the <a href=\"\
    https://www.ersa.edu.au/service/data-storage/\">storage</a> offered by eRSA. There\
    \ is also an <a href=\"http://support.ersa.edu.au/storage/quick-start.html\">eRSA\
    \ support page</a> with more detail on transferring data from eRSA storage.</p>\n\
    <h3>Secure Copy (SCP) between the VM and a data storage server</h3>\n<p>If you\
    \ have data stored on a remote server, you can transfer files between it and the\
    \ VM through the command-line on the VM.</p>\n<p>You will need a host address\
    \ for the data storage server, your username, and your password.</p>\n<p><code>scp\
    \ &lt;source&gt; &lt;destination&gt;</code></p>\n<p><code>scp username@sftp.ersa.edu.au:/data/myDirectory/file.txt\
    \ /mnt/data/</code><br>\n<code>scp /mnt/data/results.zip username@sftp.ersa.edu.au:/data/myDirectory/</code></p>\n\
    <p>You will usually then be prompted to enter the password for your data storage.</p>\n\
    <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_scp_demo.png?raw=true\"\
    ></p>\n<h3>SFTP via the Command Line</h3>\n<p>Secure file transfer is also available\
    \ between the VM and remote data storage. This is useful when you aren't sure\
    \ of the file structure on the remote server, because it allows you to navigate\
    \ to a file before you download it.</p>\n<p>Enter the 'sftp' command while logged\
    \ on to your VM, and you will have access to the remote storage server.</p>\n\
    <p><code>sftp username@sftp.ersa.edu.au</code>   - you will be prompted for a\
    \ password.</p>\n<p>You are now accessing the remote data storage server, and\
    \ you can navigate the files on the server as per usual with commands like <code>cd</code>\
    \ and <code>ls</code>.<br>\nThe commands <code>get</code> and <code>put</code>\
    \ will transfer data between the machines:\n  <img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_sftp_get.png?raw=true\"\
    >\n  <img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/software_sftp_put.png?raw=true\"\
    ></p>\n<p>to close the sftp connection, type <code>exit</code>.</p>\n<p><a href=\"\
    #glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n\
    <hr>\n<p><a name=\"os\"></a></p>\n<h2>The CentOS operating system</h2>\n<p>The\
    \ VM image that allows access to the CVMFS software repository is a Linux distribution\
    \ called CentOS. Most of the documentation available about using your Linux VM\
    \ in the NeCTAR cloud assumes that you have an Ubuntu operating system.  There\
    \ is very little difference for the user between these Linux operating systems,\
    \ but there is one main difference to be aware of.</p>\n<p>CentOS uses the package\
    \ manager '<strong>yum</strong>' instead of '<strong>apt-get</strong>'. If you\
    \ need to install packages on your VM that aren't in the CVMFS software repository,\
    \ you need to use the 'yum' command wherever there would be an 'apt-get' command\
    \ in Ubuntu. e.g.</p>\n<ul>\n<li><code>yum search &lt;package name&gt;</code></li>\n\
    <li><code>sudo yum install &lt;package name&gt;</code></li>\n<li><code>sudo yum\
    \ update</code></li>\n</ul>\n<p><a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a\
    \ name=\"glossary\"></a></p>\n<h2>Glossary</h2>\n<p><strong>Availability Zone</strong></p>\n\
    <blockquote>\n<p>A logical grouping of compute nodes within a region.</p>\n</blockquote>\n\
    <p><strong>Dashboard</strong></p>\n<blockquote>\n<p>The NeCTAR Dashboard is the\
    \ main web-based interface for managing NeCTAR virtuals.</p>\n</blockquote>\n\
    <p><strong>ERSA</strong></p>\n<blockquote>\n<p>eResearch SA runs the South Australian\
    \ node of the NeCTAR research cloud.</p>\n</blockquote>\n<p><strong>Flavor</strong></p>\n\
    <blockquote>\n<p>An OpenStack term for an instance sizing specification. Gives\
    \ the amount \nof memory, number of VCPUs and ephemeral disk size.</p>\n</blockquote>\n\
    <p><strong>Image</strong></p>\n<blockquote>\n<p>An image (or system image) is\
    \ a copy of the entire state of a computer system \nsaved as a file. Images are\
    \ used in two ways in NeCTAR. Firstly as a template for \nVirtual Machines (VMs).\
    \ You can launch a VM based on an image. \nThe second use of images is to preserve\
    \ the state of a VM as configured by you as end user. \nThis type of image is\
    \ usually referred to as a snapshot.</p>\n</blockquote>\n<p><strong>Instance</strong></p>\n\
    <blockquote>\n<p>An instance is a VM hosted on the NeCTAR OpenStack infrastructure.</p>\n\
    </blockquote>\n<p><strong>Modules</strong></p>\n<blockquote>\n<p><a href=\"http://modules.sourceforge.net/\"\
    >Environment modules</a> are used to configure a users environment to allow use\
    \ of the software packages available on the server. The module commands are used\
    \ to find information on the available packages, and to load the packages for\
    \ use.</p>\n</blockquote>\n<p><strong>Node</strong> (compute node) </p>\n<blockquote>\n\
    <p>OpenStack terminology for a physical computer used to run virtual machines.\
    \ It will typically have multiple CPUs and shared memory, and one or more network\
    \ interfaces. It may also have on-node disk storage.</p>\n</blockquote>\n<p><strong>Project</strong></p>\n\
    <blockquote>\n<p>The NeCTAR term for a \"resource container\"; i.e. what you get\
    \ when you \nare granted a NeCTAR allocation. A project \"owns\" virtual machine\
    \ instances, snapshots \nand various kinds of storage, and may be shared by multiple\
    \ users.</p>\n</blockquote>\n<p><strong>Security Group</strong></p>\n<blockquote>\n\
    <p>A set of access rules that may be applied to one or more instances. \nAn access\
    \ rule allows network access to an instance from other hosts with a \nspecified\
    \ combination of protocol family (e.g. TCP, UDP, UCMP), port number and address\
    \ range. <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055387-security-groups\"\
    >Security Groups page</a></p>\n</blockquote>\n<p><strong>SSH</strong></p>\n<blockquote>\n\
    <p>A protocol and tools for establishing secure \"shell\" sessions over the network.\
    \ SSH encrypts the data transferred, and supports user authentication using public/private\
    \ keys.</p>\n</blockquote>\n<p><strong>Tizard</strong></p>\n<blockquote>\n<p><a\
    \ href=\"https://www.ersa.edu.au/tizard/\">Tizard</a> is eRSA's high performance\
    \ computing server that can be used for complex data processing and analysis jobs\
    \ that standard desktop computers would find it difficult or impossible to perform.\
    \ It enables users to run many processing jobs with different parameters or input\
    \ files more quickly.</p>\n</blockquote>\n<p><strong>Virtual Machine</strong></p>\n\
    <blockquote>\n<p>A virtual machine (VM) is an operating system (OS) or application\
    \ environment that \nis installed on software which imitates dedicated hardware.\
    \ The end user has the same \nexperience on a virtual machine as they would have\
    \ on dedicated hardware.</p>\n</blockquote>\n<p><strong>Volume Storage</strong></p>\n\
    <blockquote>\n<p>Data Storage in your Virtual Machine that works like a hard-drive\
    \ on your PC or \nlaptop does. Volume storage is automatically available in your\
    \ VM as the storage \nspace for you system drive. Some flavors of VMs include\
    \ an amount of ephemeral volume \nstorage. Depending on your allocation you can\
    \ have persistent volume storage attached to your VM.</p>\n</blockquote>\n<p><a\
    \ href=\"https://support.nectar.org.au/support/solutions/articles/6000055445-glossary\"\
    >Full Glossary Page</a><br>\n<a href=\"http://cloud.nectar.org.au/faq/\">NeCTAR\
    \ FAQ - general inormation</a><br>\nFor more help, contact the <a href=\"mailto:servicedesk@ersa.edu.au\"\
    >eRSA Helpdesk</a></p>\n<p><a href=\"#top\">Top of page</a></p>"
  parent: 24
  sha1: 8cd94a617ddb1393c793efdab7bec35a8464d4f7
  title: eRSA Cloud Software Repository - user guide
90:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-22T23:58:49-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Using remote desktop in the NeCTAR cloud is the easiest way\
          \ to start\nincorporating cloud computing into you research practice. The\
          \ cloud can enable\nyou to access your computing from anywhere, have it\
          \ running 24/7, and provide a\nbasic space to collaborate, whether your\
          \ collaborators are down the hall, or many\ntime zones away.  \n TPAC provides\
          \ and maintains a number of server images that make \u2018owning\u2019 a\
          \ remote\ndesktop very easy. This document is about the TPAC RStudio image.\
          \ By following the\ninstructions below you can quickly have an RStudio remote\
          \ desktop running in the\nNeCTAR cloud. \n What you need \n Aside from computer\
          \ and network access, you will need to be an Australian Access Federation\n\
          eligible researcher to access the NeCTAR cloud. You will also have to use\
          \ key-pair\nsecurity for your virtual machine authentication.\nUpon first\
          \ NeCTAR cloud use, AAF eligible researchers are issued with a limited\n\
          trial allocation that will do just fine for trialling the\nTPAC RStudio\
          \ in the research cloud. If you need more resources, such as CPU, data\n\
          storage space, or you need it for longer than your trial allocation, then\
          \ you can\nrequest a NeCTAR allocation. \n Launch an RStudio remote desktop\
          \ \n To launch an RStudio remote desktop follow these steps: \n Log in to\
          \ your NeCTAR Dashboard, and if you have access to more than\none allocation,\
          \ ensure that your project selector (top left on the Dashboard, is\nset\
          \ to the project of your choice). \n There are a few variations of launching\
          \ a VM instance from an image, here we will\nnavigate to images under Compute\
          \ on the left hand side of the Dashboard. The Images\nlist displays, you\
          \ will need to the Public images filter button on the top right\nof the\
          \ list. In the list of Public images, find the image named \u201CTPAC rstudio.xxx\
          \ yyyyy\u201D\nwhere xxx and yyyyy are mere version numbers. On the right\
          \ in this image table,\nclick the image\u2019s Launch action button.  \n\
          \ \n The Launch Instance dialog displays.  \n On the Details tab of the\
          \ dialog, enter the instance Name, and select a Flavor\nwith a minimum of\
          \ 10GB root disk (Flavor is Nectar for size of your VM). The Image\nname\
          \ \"TPAC rstudio.xxx ...\" is already selected. \n On the Access & Security\
          \ tab, select your key pair, and select one or more security\ngroups to\
          \ apply to your VM. To complete the instructions in this document, you will\n\
          need a security group that allows SSH \n If you have any specific reason\
          \ to run your VM in a specific availability zone, \nyou can select it on\
          \ the Availability Zone tab. Alternatively you can let NeCTAR\ndecide where\
          \ best to host your VM by leaving the selector on \u201CAny availability\
          \ zone\u201D. \n You don\u2019t have to change anything on the \u201Cpost-Creation\
          \ and Advanced Options tabs. \n Click Launch. Launching should complete\
          \ in minutes. When your instance has\nsuccessfully launched, the Dashboard\
          \ will show your the IP Address of your VM.  \n \n Connecting to your RStudio\
          \ remote desktop using X2Go \n The RStudio you launched using the TPAC Rstudio\
          \ image has the X2Go remote desktop\nservice and the MATE GUI provider preinstalled.\
          \ So your VM is ready for for it. \n Your local computer will need the X2Go\
          \ client software installed. If you don\u2019t\nalready have the X2Go Client\
          \ on your machine, you can find the instructions for\nyou Operating System\
          \ under X2Go Client Installation in Getting Started with TPAC\nremote desktop.\
          \ \n When you have the X2Go client installed you will need to create a \u201C\
          Session\u201D. At\nits most basic you will need the IP Address of the remote\
          \ desktop RStudio VM\nyou\u2019ve launched, the user name for your VM (TPAC\
          \ RStudio image provides you with\nthe ubuntu username by default) and your\
          \ private key. Detailed instructions can be\nfound under Use X2Go Client\
          \ in document TPAC Remote Desktop X2Go, but the\nscreenshot below should\
          \ give you the basic idea. \n \n When you're successfully connected, you\
          \ can find the RStudio in the menu (top left)\nunder Applications | Programming\
          \ \n \n What\u2019s on my RStudio remote desktop instance \n In the building\
          \ process for the TPAC RStudio image, the software that will be\ninstalled\
          \ will be the latest as provided by NeCTAR, Linux package managers or\n\
          software providers.  \n \n \n NeCTAR Ubuntu LTS release \n \n \n Mate desktop\
          \ \n \n \n X2Go server \n \n \n RStudio  \n \n \n Additional R packages\n\
          rgdal, rgeos, ncdf4, raster, abind, ade4, adehabitatHR, adehabitatLT, adehabitatMA,\n\
          akima, animation, bit, bitops, brew, caTools, changepoint, CircStats, coda,\
          \ colorspace,\ncrawl, deldir, devtools, dichromat, digest, dismo, diveMove,\
          \ evaluate, ff, FNN, foreach,\nformatR, gdalUtils, GeoLight, geometry, geosphere,\
          \ ggplot2, gstat, gtable, highr,\nhtmltools, httpuv, httr, intervals, iterators,\
          \ jsonlite, knitr, labeling, magic,\nmapdata, maps, maptools, markdown,\
          \ memoise, mime, misc3d, munsell, mvtnorm, ncdf,\nncdf4, plyr, polyclip,\
          \ proto, quantreg, R6, raster, RColorBrewer, Rcpp, RCurl,\nreshape2, rgdal,\
          \ rgeos, RJSONIO, R.methodsS3, RNetCDF, R.oo, roxygen2, rstudioapi,\nR.utils,\
          \ scales, shiny, sp, spacetime, SparseM, stringr, tensor, testthat, trip,\n\
          whisker, XML, xtable, xts, yaml, zoo, rgl \n What next \n If you want to\
          \ use your VM as collaboration space, you will need to do some user\nmanagement.\
          \ For this you can refer to \u201CAdd Accounts on The X2Go Server\u201D\
          \ in TPAC\nRemote Desktop X2go documentation. On top of that, your collaborators\
          \ will need\nto install their own X2Go client, refer above. \n Your TPAC\
          \ image based RStudio remote desktop instance is also an RStudio Server.\n\
          With some user management, and some NeCTAR security settings, you can get\
          \ or\ngive access to your RStudio VM using a web-browser. For more info\
          \ on this you can\nview skip to the bottom of Step 2 of the instructions\
          \ at TPAC RStudio Server \n Additionally your VM is also a Shiny Server\
          \ for interactive R-backed web applications. \nLearn more at the Shiny Server\
          \ websiteshiny. You will need to some allow connections to\ntcp port 3838\
          \ in the Nectar security settings to allow access to your Shiny Server\n\
          on your VM. \n You can create a Shared Data Folder on the Remote Server.\
          \ Head over to here to\nfind out how. \n Contact \n If you have trouble\
          \ with TPAC R-Studio image, please contact TPAC help desk via\nhelpdesk@tpac.org.au,\
          \ or any help desks from your local Eresearch service providers. "
        description: "<p>Using remote desktop in the NeCTAR cloud is the easiest way\
          \ to start\nincorporating cloud computing into you research practice. The\
          \ cloud can enable\nyou to access your computing from anywhere, have it\
          \ running 24/7, and provide a\nbasic space to collaborate, whether your\
          \ collaborators are down the hall, or many\ntime zones away. </p>\n<p>TPAC\
          \ provides and maintains a number of server images that make \u2018owning\u2019\
          \ a remote\ndesktop very easy. This document is about the TPAC RStudio image.\
          \ By following the\ninstructions below you can quickly have an RStudio remote\
          \ desktop running in the\nNeCTAR cloud.</p>\n<h2>What you need</h2>\n<p>Aside\
          \ from computer and network access, you will need to be an <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
          >Australian Access Federation</a>\neligible researcher to access the NeCTAR\
          \ cloud. You will also have to use key-pair\nsecurity for your <a href=\"\
          https://support.nectar.org.au/support/solutions/articles/6000077794-getting-started\"\
          >virtual machine authentication</a>.\nUpon first NeCTAR cloud use, AAF eligible\
          \ researchers are issued with a limited\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000055380-resources-available-to-you\"\
          >trial allocation</a> that will do just fine for trialling the\nTPAC RStudio\
          \ in the research cloud. If you need more resources, such as CPU, data\n\
          storage space, or you need it for longer than your trial allocation, then\
          \ you can\nrequest a <a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
          >NeCTAR allocation</a>.</p>\n<h2>Launch an RStudio remote desktop</h2>\n\
          <p>To launch an RStudio remote desktop follow these steps:</p>\n<p>Log in\
          \ to your NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/\">Dashboard</a>,\
          \ and if you have access to more than\none allocation, ensure that your\
          \ project selector (top left on the Dashboard, is\nset to the project of\
          \ your choice).</p>\n<p>There are a few variations of launching a VM instance\
          \ from an image, here we will\nnavigate to images under Compute on the left\
          \ hand side of the Dashboard. The Images\nlist displays, you will need to\
          \ the Public images filter button on the top right\nof the list. In the\
          \ list of Public images, find the image named \u201CTPAC rstudio.xxx yyyyy\u201D\
          \nwhere xxx and yyyyy are mere version numbers. On the right in this image\
          \ table,\nclick the image\u2019s Launch action button. </p>\n<p><img alt=\"\
          snapshot1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-rstudio-1.png?raw=true\"\
          ></p>\n<p>The Launch Instance dialog displays. </p>\n<p>On the Details tab\
          \ of the dialog, enter the instance Name, and select a Flavor\nwith a minimum\
          \ of 10GB root disk (Flavor is Nectar for size of your VM). The Image\n\
          name \"TPAC rstudio.xxx ...\" is already selected.</p>\n<p>On the Access\
          \ &amp; Security tab, select your key pair, and select one or more security\n\
          groups to apply to your VM. To complete the instructions in this document,\
          \ you will\nneed a security group that allows SSH</p>\n<p>If you have any\
          \ specific reason to run your VM in a specific availability zone, \nyou\
          \ can select it on the Availability Zone tab. Alternatively you can let\
          \ NeCTAR\ndecide where best to host your VM by leaving the selector on \u201C\
          Any availability zone\u201D.</p>\n<p>You don\u2019t have to change anything\
          \ on the \u201Cpost-Creation and Advanced Options tabs.</p>\n<p>Click Launch.\
          \ Launching should complete in minutes. When your instance has\nsuccessfully\
          \ launched, the Dashboard will show your the IP Address of your VM. </p>\n\
          <p><img alt=\"snapshot2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-rstudio-2.png?raw=true\"\
          ></p>\n<h2>Connecting to your RStudio remote desktop using X2Go</h2>\n<p>The\
          \ RStudio you launched using the TPAC Rstudio image has the X2Go remote\
          \ desktop\nservice and the MATE GUI provider preinstalled. So your VM is\
          \ ready for for it.</p>\n<p>Your local computer will need the X2Go client\
          \ software installed. If you don\u2019t\nalready have the X2Go Client on\
          \ your machine, you can find the instructions for\nyou Operating System\
          \ under X2Go Client Installation in Getting Started with TPAC\nremote desktop.</p>\n\
          <p>When you have the X2Go client installed you will need to create a \u201C\
          Session\u201D. At\nits most basic you will need the IP Address of the remote\
          \ desktop RStudio VM\nyou\u2019ve launched, the user name for your VM (TPAC\
          \ RStudio image provides you with\nthe ubuntu username by default) and your\
          \ private key. Detailed instructions can be\nfound under Use X2Go Client\
          \ in document TPAC Remote Desktop X2Go, but the\nscreenshot below should\
          \ give you the basic idea.</p>\n<p><img alt=\"snapshot3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-rstudio-3.png?raw=true\"\
          ></p>\n<p>When you're successfully connected, you can find the RStudio in\
          \ the menu (top left)\nunder Applications | Programming</p>\n<p><img alt=\"\
          snapshot4\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-rstudio-4.png?raw=true\"\
          ></p>\n<h2>What\u2019s on my RStudio remote desktop instance</h2>\n<p>In\
          \ the building process for the TPAC RStudio image, the software that will\
          \ be\ninstalled will be the latest as provided by NeCTAR, Linux package\
          \ managers or\nsoftware providers. </p>\n<ul>\n<li>\n<p>NeCTAR Ubuntu LTS\
          \ release</p>\n</li>\n<li>\n<p>Mate desktop</p>\n</li>\n<li>\n<p>X2Go server</p>\n\
          </li>\n<li>\n<p>RStudio </p>\n</li>\n</ul>\n<p>Additional R packages\nrgdal,\
          \ rgeos, ncdf4, raster, abind, ade4, adehabitatHR, adehabitatLT, adehabitatMA,\n\
          akima, animation, bit, bitops, brew, caTools, changepoint, CircStats, coda,\
          \ colorspace,\ncrawl, deldir, devtools, dichromat, digest, dismo, diveMove,\
          \ evaluate, ff, FNN, foreach,\nformatR, gdalUtils, GeoLight, geometry, geosphere,\
          \ ggplot2, gstat, gtable, highr,\nhtmltools, httpuv, httr, intervals, iterators,\
          \ jsonlite, knitr, labeling, magic,\nmapdata, maps, maptools, markdown,\
          \ memoise, mime, misc3d, munsell, mvtnorm, ncdf,\nncdf4, plyr, polyclip,\
          \ proto, quantreg, R6, raster, RColorBrewer, Rcpp, RCurl,\nreshape2, rgdal,\
          \ rgeos, RJSONIO, R.methodsS3, RNetCDF, R.oo, roxygen2, rstudioapi,\nR.utils,\
          \ scales, shiny, sp, spacetime, SparseM, stringr, tensor, testthat, trip,\n\
          whisker, XML, xtable, xts, yaml, zoo, rgl</p>\n<h2>What next</h2>\n<p>If\
          \ you want to use your VM as collaboration space, you will need to do some\
          \ user\nmanagement. For this you can refer to \u201CAdd Accounts on The\
          \ X2Go Server\u201D in TPAC\nRemote Desktop X2go documentation. On top of\
          \ that, your collaborators will need\nto install their own X2Go client,\
          \ refer above.</p>\n<p>Your TPAC image based RStudio remote desktop instance\
          \ is also an RStudio Server.\nWith some user management, and some NeCTAR\
          \ security settings, you can get or\ngive access to your RStudio VM using\
          \ a web-browser. For more info on this you can\nview skip to the bottom\
          \ of Step 2 of the instructions at <a href=\"http://www.tpac.org.au/resources/nectar-compute-cloud/r-studio-server-in-the-cloud/\"\
          >TPAC RStudio Server</a></p>\n<p>Additionally your VM is also a Shiny Server\
          \ for interactive R-backed web applications. \nLearn more at the Shiny Server\
          \ website<a href=\"https://www.rstudio.com/products/shiny/shiny-server/\"\
          >shiny</a>. You will need to some allow connections to\ntcp port 3838 in\
          \ the Nectar security settings to allow access to your Shiny Server\non\
          \ your VM.</p>\n<p>You can create a Shared Data Folder on the Remote Server.\
          \ Head over to here to\nfind out how.</p>\n<h2>Contact</h2>\n<p>If you have\
          \ trouble with TPAC R-Studio image, please contact TPAC help desk via\n\
          helpdesk@tpac.org.au, or any help desks from your local Eresearch service\
          \ providers.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 24
        id: 6000090906
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-14T22:14:48-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000090906
        position: 14
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: TPAC R-Studio with Remote Desktop
        updated_at: '2015-12-14T22:14:48-05:00'
        user_id: 6002464727
  html: "<p>Using remote desktop in the NeCTAR cloud is the easiest way to start\n\
    incorporating cloud computing into you research practice. The cloud can enable\n\
    you to access your computing from anywhere, have it running 24/7, and provide\
    \ a\nbasic space to collaborate, whether your collaborators are down the hall,\
    \ or many\ntime zones away. </p>\n<p>TPAC provides and maintains a number of server\
    \ images that make \u2018owning\u2019 a remote\ndesktop very easy. This document\
    \ is about the TPAC RStudio image. By following the\ninstructions below you can\
    \ quickly have an RStudio remote desktop running in the\nNeCTAR cloud.</p>\n<h2>What\
    \ you need</h2>\n<p>Aside from computer and network access, you will need to be\
    \ an <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
    >Australian Access Federation</a>\neligible researcher to access the NeCTAR cloud.\
    \ You will also have to use key-pair\nsecurity for your <a href=\"https://support.nectar.org.au/support/solutions/articles/6000077794-getting-started\"\
    >virtual machine authentication</a>.\nUpon first NeCTAR cloud use, AAF eligible\
    \ researchers are issued with a limited\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000055380-resources-available-to-you\"\
    >trial allocation</a> that will do just fine for trialling the\nTPAC RStudio in\
    \ the research cloud. If you need more resources, such as CPU, data\nstorage space,\
    \ or you need it for longer than your trial allocation, then you can\nrequest\
    \ a <a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
    >NeCTAR allocation</a>.</p>\n<h2>Launch an RStudio remote desktop</h2>\n<p>To\
    \ launch an RStudio remote desktop follow these steps:</p>\n<p>Log in to your\
    \ NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/\">Dashboard</a>, and if\
    \ you have access to more than\none allocation, ensure that your project selector\
    \ (top left on the Dashboard, is\nset to the project of your choice).</p>\n<p>There\
    \ are a few variations of launching a VM instance from an image, here we will\n\
    navigate to images under Compute on the left hand side of the Dashboard. The Images\n\
    list displays, you will need to the Public images filter button on the top right\n\
    of the list. In the list of Public images, find the image named \u201CTPAC rstudio.xxx\
    \ yyyyy\u201D\nwhere xxx and yyyyy are mere version numbers. On the right in this\
    \ image table,\nclick the image\u2019s Launch action button. </p>\n<p><img alt=\"\
    snapshot1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-rstudio-1.png?raw=true\"\
    ></p>\n<p>The Launch Instance dialog displays. </p>\n<p>On the Details tab of\
    \ the dialog, enter the instance Name, and select a Flavor\nwith a minimum of\
    \ 10GB root disk (Flavor is Nectar for size of your VM). The Image\nname \"TPAC\
    \ rstudio.xxx ...\" is already selected.</p>\n<p>On the Access &amp; Security\
    \ tab, select your key pair, and select one or more security\ngroups to apply\
    \ to your VM. To complete the instructions in this document, you will\nneed a\
    \ security group that allows SSH</p>\n<p>If you have any specific reason to run\
    \ your VM in a specific availability zone, \nyou can select it on the Availability\
    \ Zone tab. Alternatively you can let NeCTAR\ndecide where best to host your VM\
    \ by leaving the selector on \u201CAny availability zone\u201D.</p>\n<p>You don\u2019\
    t have to change anything on the \u201Cpost-Creation and Advanced Options tabs.</p>\n\
    <p>Click Launch. Launching should complete in minutes. When your instance has\n\
    successfully launched, the Dashboard will show your the IP Address of your VM.\
    \ </p>\n<p><img alt=\"snapshot2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-rstudio-2.png?raw=true\"\
    ></p>\n<h2>Connecting to your RStudio remote desktop using X2Go</h2>\n<p>The RStudio\
    \ you launched using the TPAC Rstudio image has the X2Go remote desktop\nservice\
    \ and the MATE GUI provider preinstalled. So your VM is ready for for it.</p>\n\
    <p>Your local computer will need the X2Go client software installed. If you don\u2019\
    t\nalready have the X2Go Client on your machine, you can find the instructions\
    \ for\nyou Operating System under X2Go Client Installation in Getting Started\
    \ with TPAC\nremote desktop.</p>\n<p>When you have the X2Go client installed you\
    \ will need to create a \u201CSession\u201D. At\nits most basic you will need\
    \ the IP Address of the remote desktop RStudio VM\nyou\u2019ve launched, the user\
    \ name for your VM (TPAC RStudio image provides you with\nthe ubuntu username\
    \ by default) and your private key. Detailed instructions can be\nfound under\
    \ Use X2Go Client in document TPAC Remote Desktop X2Go, but the\nscreenshot below\
    \ should give you the basic idea.</p>\n<p><img alt=\"snapshot3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-rstudio-3.png?raw=true\"\
    ></p>\n<p>When you're successfully connected, you can find the RStudio in the\
    \ menu (top left)\nunder Applications | Programming</p>\n<p><img alt=\"snapshot4\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-rstudio-4.png?raw=true\"\
    ></p>\n<h2>What\u2019s on my RStudio remote desktop instance</h2>\n<p>In the building\
    \ process for the TPAC RStudio image, the software that will be\ninstalled will\
    \ be the latest as provided by NeCTAR, Linux package managers or\nsoftware providers.\
    \ </p>\n<ul>\n<li>\n<p>NeCTAR Ubuntu LTS release</p>\n</li>\n<li>\n<p>Mate desktop</p>\n\
    </li>\n<li>\n<p>X2Go server</p>\n</li>\n<li>\n<p>RStudio </p>\n</li>\n</ul>\n\
    <p>Additional R packages\nrgdal, rgeos, ncdf4, raster, abind, ade4, adehabitatHR,\
    \ adehabitatLT, adehabitatMA,\nakima, animation, bit, bitops, brew, caTools, changepoint,\
    \ CircStats, coda, colorspace,\ncrawl, deldir, devtools, dichromat, digest, dismo,\
    \ diveMove, evaluate, ff, FNN, foreach,\nformatR, gdalUtils, GeoLight, geometry,\
    \ geosphere, ggplot2, gstat, gtable, highr,\nhtmltools, httpuv, httr, intervals,\
    \ iterators, jsonlite, knitr, labeling, magic,\nmapdata, maps, maptools, markdown,\
    \ memoise, mime, misc3d, munsell, mvtnorm, ncdf,\nncdf4, plyr, polyclip, proto,\
    \ quantreg, R6, raster, RColorBrewer, Rcpp, RCurl,\nreshape2, rgdal, rgeos, RJSONIO,\
    \ R.methodsS3, RNetCDF, R.oo, roxygen2, rstudioapi,\nR.utils, scales, shiny, sp,\
    \ spacetime, SparseM, stringr, tensor, testthat, trip,\nwhisker, XML, xtable,\
    \ xts, yaml, zoo, rgl</p>\n<h2>What next</h2>\n<p>If you want to use your VM as\
    \ collaboration space, you will need to do some user\nmanagement. For this you\
    \ can refer to \u201CAdd Accounts on The X2Go Server\u201D in TPAC\nRemote Desktop\
    \ X2go documentation. On top of that, your collaborators will need\nto install\
    \ their own X2Go client, refer above.</p>\n<p>Your TPAC image based RStudio remote\
    \ desktop instance is also an RStudio Server.\nWith some user management, and\
    \ some NeCTAR security settings, you can get or\ngive access to your RStudio VM\
    \ using a web-browser. For more info on this you can\nview skip to the bottom\
    \ of Step 2 of the instructions at <a href=\"http://www.tpac.org.au/resources/nectar-compute-cloud/r-studio-server-in-the-cloud/\"\
    >TPAC RStudio Server</a></p>\n<p>Additionally your VM is also a Shiny Server for\
    \ interactive R-backed web applications. \nLearn more at the Shiny Server website<a\
    \ href=\"https://www.rstudio.com/products/shiny/shiny-server/\">shiny</a>. You\
    \ will need to some allow connections to\ntcp port 3838 in the Nectar security\
    \ settings to allow access to your Shiny Server\non your VM.</p>\n<p>You can create\
    \ a Shared Data Folder on the Remote Server. Head over to here to\nfind out how.</p>\n\
    <h2>Contact</h2>\n<p>If you have trouble with TPAC R-Studio image, please contact\
    \ TPAC help desk via\nhelpdesk@tpac.org.au, or any help desks from your local\
    \ Eresearch service providers.</p>"
  parent: 24
  sha1: 2046451b0669cf00d8b8e004b9db03579307f6bc
  title: TPAC R-Studio with Remote Desktop
91:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-22T23:59:45-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " \n Introduction \n Software and packages in the image \n What\
          \ you need \n Launch a Virtual Machine With TPAC Matlab image \n Use Matlab\
          \ in MATE Desktop \n What Next \n Security \n Upgrades and software installation\
          \ \n Contact \n \n Introduction \n \n TPAC provides an image in NeCTAR Cloud\
          \ with Matlab 2013 installed. The image\nalso includes X2Go server that\
          \ allow users to run MATLAB in the remote desktop\nenvironment and access\
          \ the Matlab from anywhere through the Internet. MATE desktop\nis installed\
          \ and it provides GUI support for the Matlab and facilities better user\n\
          experience that console access. For more information about how to use X2Go\
          \ and\nMATE desktop, please refer to the article \u2018TPAC Remote Desktop\
          \ X2Go\u2019. \n Software and packages in the image \n \n The below lists\
          \ what software packages have been pre-installed on the TPAC Matlab\nwith\
          \ remote desktop image: \n \n \n Ubuntu 14.04 (operating system) \n \n \n\
          \ X2Go Server (remote desktop server) \n \n \n Mate 1.8.1 (GUI desktop)\
          \ \n \n \n Matlab 2013 \n \n \n Python 2.7.6 and Python 3.4 \n \n \n openjdk-7\
          \ \n \n \n nano \n \n \n gcc 4.8, g++ 4.8 \n \n \n gimp \n \n \n What you\
          \ need \n \n Aside from computer and network access, you will need to be\
          \ an Australian Access Federation\neligible researcher to access the NeCTAR\
          \ cloud. You will also have to use key-pair\nsecurity for your virtual machine\
          \ authentication.\nUpon first NeCTAR cloud use, AAF eligible researchers\
          \ are issued with a limited\ntrial allocation that will do just fine for\
          \ trying the\nTPAC RStudio in the research cloud. If you need more resources,\
          \ such as CPU, data\nstorage space, or you need it for longer than your\
          \ trial allocation, then you can\nrequest a NeCTAR allocation. \n Launch\
          \ a Virtual Machine With TPAC Matlab image \n \n The below provides instruction\
          \ about how to launch a virtual machine in NecTAR\nusing TPAC pre-build\
          \ image with Matlab, X2Go and MATE. \n \n Login to NeCTAR Dashboard with\
          \ your AAF credentials. Select your\n project name, click the \u2018Images\u2019\
          \ and then click tab \u2018Public\u2019. You should see the\n below screenshot:\
          \ \n \n \n \n After clicking the tab 'Public', You will see all available\
          \ public images on\n screen. Scroll down the list and find the image with\
          \ name 'TPAC matlab.001 1447740833'\n and click the \u2018Launch\u2019 button.\
          \ You should see a pop\n up window like below: \n \n \n \n \n In this pop\
          \ up window, provide some information for the virtual machine, such\n as\
          \ name and flavour. Please  note, the desktop application such as MATE requires\n\
          \ larger root disk size, so it is prefered to use flavour m2.small, m2.medium,\n\
          \ m2.large and m2.xlarge as these flavours have 30G root disk. \n \n \n\
          \ Click 'Access & Security' tab. In this pop up window, provide your key\
          \ and\n security group. You also need to open port 22, as X2Go uses it for\
          \ communication\n between X2Go Server and Client. So make sure you tick\
          \ a security group with port\n 22 open. See below screenshot. \n \n \n \n\
          \ \n Click 'Availability Zone' tab. As the license requirement, the availability\
          \ zone\n is restricted to Tasmania Zone. So please make sure you launch\
          \  a virtual machine\n in the Tasmania Zone. Otherwise the Matlab won\u2019\
          t work properly. See below screenshot: \n \n \n \n After clicking the \u2018\
          Launch\u2019 button, the virtual machine will be ready in a few\n minutes.\
          \ Please write down the IP address of the newly created virtual machine\
          \ as\n it will be used later in the X2Go Client to connect to the virtual\
          \ machine. \n \n For details of how to launch a virtual machine in NeCTAR\
          \ Cloud, please refer to this link. \n Note, TPAC Matlab image only works\
          \ if the availability zone of the virtual machine\nis Tasmania Zone as the\
          \ Matlab uses University of Tasmania Site License. The\nMatlab will not\
          \ run if the availability zone is not in Tasmania. \n Use Matlab in MATE\
          \ Desktop \n \n To use the Matlab in the launched virtual machine, you need\
          \ to use the X20Go\nClient to connect to it.  \n Configure the X20Go client\
          \ with the information you obtained from the launched\nvirtual machine,\
          \ such as IP address, the default user account, in this case it\nshould\
          \ be Ubuntu and the private key used for authentication. Please refer to\n\
          TPAC Remote Desktop User Guide for more information. \n So the simple steps\
          \ are: \n \n \n Configure the X20Go client to create a session for the virtual\
          \ machine \n \n \n Double Click the session and get connection to the virtual\
          \ machine \n \n \n If everything goes well, you should see the MATE desktop.\
          \ See the below screenshot: \n \n \n \n \n \n Once you are in the MATE desktop,\
          \ click \u2018Application\u2019 menu on the top left corner\n and move mouse\
          \ cursor over the \u2018Programming\u2019 menu \n \n \n A submenu will come\
          \ out and move mouse over \u2018Matlab r2013b\u2019 and click \n \n \n The\
          \ Matlab main window should appear \n \n \n For details about how to connect\
          \ to X2Go Server using X2Go client, please refer\nto the 'TPAC Remote Desktop\
          \ X2Go'.  \n What Next \n \n If you want to use your Matlab virtual machine\
          \ as a collaboration space, you will\nneed to do some user management. For\
          \ this you can refer to \u201CAdd Accounts on The\nX2Go Server\u201D in\
          \ 'TPAC Remote Desktop X2Go' documentation. On top of that, your\ncollaborators\
          \ will need to install their own X2Go client, refer to the same document.\
          \ \n You can also share data between your local machine with X2Go Client\
          \ installed and\nMatlab virtual machine with X2Go Server installed. You\
          \ can find how from this document. \n Security \n \n By default, there is\
          \ only one default user 'ubuntu' and it uses key based\nauthentication.\
          \ If you want to create more users to use the virtual machine, please\n\
          use key based authentication rather than password based authentication.\
          \ For a quick\nsecurity check list, please refer to here.  \n Upgrades and\
          \ software installation \n \n User initialed upgrades for Matlab and Ubuntu\
          \ are not encouraged. TPAC will\npublish upgraded version of Matlab and\
          \ Ubuntu in new image. Please contact TPAC help\ndesk at helpdesk@tpac.org.au\
          \ to see whether any latest version of Matlab and Ubuntu\nis available.\
          \ Other software installation and upgrade can be done via the common\ninstallation\
          \ tools such as apt-get and appititude. Packages can be also installed\n\
          through the Mate Desktop environment. Please refer to InstallingSoftware\n\
          and Mate. \n Contact \n \n If you have problems with TPAC Matlab image and\
          \ using it, please contact TPAC help\ndesk via helpdesk@tpac.org.au, or\
          \ any help desks from your local Eresearch service\nproviders. "
        description: "<ul>\n<li><a href=\"#intro\">Introduction</a></li>\n<li><a href=\"\
          #image\">Software and packages in the image</a></li>\n<li><a href=\"#need\"\
          >What you need</a></li>\n<li><a href=\"#launch\">Launch a Virtual Machine\
          \ With TPAC Matlab image</a></li>\n<li><a href=\"#desktop\">Use Matlab in\
          \ MATE Desktop</a></li>\n<li><a href=\"#next\">What Next</a></li>\n<li><a\
          \ href=\"#security\">Security</a></li>\n<li><a href=\"#upgrade\">Upgrades\
          \ and software installation</a></li>\n<li><a href=\"#contact\">Contact</a></li>\n\
          </ul>\n<h2>Introduction <a name=\"intro\"></a>\n</h2>\n<p>TPAC provides\
          \ an image in NeCTAR Cloud with Matlab 2013 installed. The image\nalso includes\
          \ X2Go server that allow users to run MATLAB in the remote desktop\nenvironment\
          \ and access the Matlab from anywhere through the Internet. MATE desktop\n\
          is installed and it provides GUI support for the Matlab and facilities better\
          \ user\nexperience that console access. For more information about how to\
          \ use X2Go and\nMATE desktop, please refer to the article \u2018TPAC Remote\
          \ Desktop X2Go\u2019.</p>\n<h2>Software and packages in the image <a name=\"\
          image\"></a>\n</h2>\n<p>The below lists what software packages have been\
          \ pre-installed on the TPAC Matlab\nwith remote desktop image:</p>\n<ul>\n\
          <li>\n<p>Ubuntu 14.04 (operating system)</p>\n</li>\n<li>\n<p>X2Go Server\
          \ (remote desktop server)</p>\n</li>\n<li>\n<p>Mate 1.8.1 (GUI desktop)</p>\n\
          </li>\n<li>\n<p>Matlab 2013</p>\n</li>\n<li>\n<p>Python 2.7.6 and Python\
          \ 3.4</p>\n</li>\n<li>\n<p>openjdk-7</p>\n</li>\n<li>\n<p>nano</p>\n</li>\n\
          <li>\n<p>gcc 4.8, g++ 4.8</p>\n</li>\n<li>\n<p>gimp</p>\n</li>\n</ul>\n\
          <h2>What you need <a name=\"need\"></a>\n</h2>\n<p>Aside from computer and\
          \ network access, you will need to be an <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
          >Australian Access Federation</a>\neligible researcher to access the NeCTAR\
          \ cloud. You will also have to use key-pair\nsecurity for your <a href=\"\
          https://support.nectar.org.au/support/solutions/articles/6000077794-getting-started\"\
          >virtual machine authentication</a>.\nUpon first NeCTAR cloud use, AAF eligible\
          \ researchers are issued with a limited\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000055380-resources-available-to-you\"\
          >trial allocation</a> that will do just fine for trying the\nTPAC RStudio\
          \ in the research cloud. If you need more resources, such as CPU, data\n\
          storage space, or you need it for longer than your trial allocation, then\
          \ you can\nrequest a <a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
          >NeCTAR allocation</a>.</p>\n<h2>Launch a Virtual Machine With TPAC Matlab\
          \ image <a name=\"launch\"></a>\n</h2>\n<p>The below provides instruction\
          \ about how to launch a virtual machine in NecTAR\nusing TPAC pre-build\
          \ image with Matlab, X2Go and MATE.</p>\n<ul>\n<li>Login to NeCTAR <a href=\"\
          https://dashboard.rc.nectar.org.au/\">Dashboard</a> with your AAF credentials.\
          \ Select your\n project name, click the \u2018Images\u2019 and then click\
          \ tab \u2018Public\u2019. You should see the\n below screenshot:</li>\n\
          </ul>\n<p><img alt=\"snapshot1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-matlab-1.png?raw=true\"\
          ></p>\n<ul>\n<li>After clicking the tab 'Public', You will see all available\
          \ public images on\n screen. Scroll down the list and find the image with\
          \ name 'TPAC matlab.001 1447740833'\n and click the \u2018Launch\u2019 button.\
          \ You should see a pop\n up window like below:</li>\n</ul>\n<p><img alt=\"\
          snapshot2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-matlab-2.png?raw=true\"\
          ></p>\n<ul>\n<li>\n<p>In this pop up window, provide some information for\
          \ the virtual machine, such\n as name and flavour. Please  note, the desktop\
          \ application such as MATE requires\n larger root disk size, so it is prefered\
          \ to use flavour m2.small, m2.medium,\n m2.large and m2.xlarge as these\
          \ flavours have 30G root disk.</p>\n</li>\n<li>\n<p>Click 'Access &amp;\
          \ Security' tab. In this pop up window, provide your key and\n security\
          \ group. You also need to open port 22, as X2Go uses it for communication\n\
          \ between X2Go Server and Client. So make sure you tick a security group\
          \ with port\n 22 open. See below screenshot.</p>\n</li>\n</ul>\n<p><img\
          \ alt=\"snapshot3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-matlab-3.png?raw=true\"\
          ></p>\n<ul>\n<li>Click 'Availability Zone' tab. As the license requirement,\
          \ the availability zone\n is restricted to Tasmania Zone. So please make\
          \ sure you launch  a virtual machine\n in the Tasmania Zone. Otherwise the\
          \ Matlab won\u2019t work properly. See below screenshot:</li>\n</ul>\n<p><img\
          \ alt=\"snapshot4\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-matlab-4.png?raw=true\"\
          ></p>\n<ul>\n<li>After clicking the \u2018Launch\u2019 button, the virtual\
          \ machine will be ready in a few\n minutes. Please write down the IP address\
          \ of the newly created virtual machine as\n it will be used later in the\
          \ X2Go Client to connect to the virtual machine.</li>\n</ul>\n<p>For details\
          \ of how to launch a virtual machine in NeCTAR Cloud, please refer to this\
          \ <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055376-launching-virtual-machines\"\
          >link</a>.</p>\n<p>Note, TPAC Matlab image only works if the availability\
          \ zone of the virtual machine\nis Tasmania Zone as the Matlab uses University\
          \ of Tasmania Site License. The\nMatlab will not run if the availability\
          \ zone is not in Tasmania.</p>\n<h2>Use Matlab in MATE Desktop <a name=\"\
          desktop\"></a>\n</h2>\n<p>To use the Matlab in the launched virtual machine,\
          \ you need to use the X20Go\nClient to connect to it. </p>\n<p>Configure\
          \ the X20Go client with the information you obtained from the launched\n\
          virtual machine, such as IP address, the default user account, in this case\
          \ it\nshould be Ubuntu and the private key used for authentication. Please\
          \ refer to\nTPAC Remote Desktop User Guide for more information.</p>\n<p>So\
          \ the simple steps are:</p>\n<ul>\n<li>\n<p>Configure the X20Go client to\
          \ create a session for the virtual machine</p>\n</li>\n<li>\n<p>Double Click\
          \ the session and get connection to the virtual machine</p>\n</li>\n<li>\n\
          <p>If everything goes well, you should see the MATE desktop. See the below\
          \ screenshot:</p>\n</li>\n</ul>\n<p><img alt=\"snapshot5\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-matlab-5.png?raw=true\"\
          ></p>\n<ul>\n<li>\n<p>Once you are in the MATE desktop, click \u2018Application\u2019\
          \ menu on the top left corner\n and move mouse cursor over the \u2018Programming\u2019\
          \ menu</p>\n</li>\n<li>\n<p>A submenu will come out and move mouse over\
          \ \u2018Matlab r2013b\u2019 and click</p>\n</li>\n<li>\n<p>The Matlab main\
          \ window should appear</p>\n</li>\n</ul>\n<p>For details about how to connect\
          \ to X2Go Server using X2Go client, please refer\nto the 'TPAC Remote Desktop\
          \ X2Go'. </p>\n<h2>What Next <a name=\"next\"></a>\n</h2>\n<p>If you want\
          \ to use your Matlab virtual machine as a collaboration space, you will\n\
          need to do some user management. For this you can refer to \u201CAdd Accounts\
          \ on The\nX2Go Server\u201D in 'TPAC Remote Desktop X2Go' documentation.\
          \ On top of that, your\ncollaborators will need to install their own X2Go\
          \ client, refer to the same document.</p>\n<p>You can also share data between\
          \ your local machine with X2Go Client installed and\nMatlab virtual machine\
          \ with X2Go Server installed. You can find how from this document.</p>\n\
          <h2>Security <a name=\"security\"></a>\n</h2>\n<p>By default, there is only\
          \ one default user 'ubuntu' and it uses key based\nauthentication. If you\
          \ want to create more users to use the virtual machine, please\nuse key\
          \ based authentication rather than password based authentication. For a\
          \ quick\nsecurity check list, please refer to <a href=\"https://support.nectar.org.au/support/solutions/articles/6000091906-security-compromise-checklist\"\
          >here</a>. </p>\n<h2>Upgrades and software installation <a name=\"upgrade\"\
          ></a>\n</h2>\n<p>User initialed upgrades for Matlab and Ubuntu are not encouraged.\
          \ TPAC will\npublish upgraded version of Matlab and Ubuntu in new image.\
          \ Please contact TPAC help\ndesk at helpdesk@tpac.org.au to see whether\
          \ any latest version of Matlab and Ubuntu\nis available. Other software\
          \ installation and upgrade can be done via the common\ninstallation tools\
          \ such as apt-get and appititude. Packages can be also installed\nthrough\
          \ the Mate Desktop environment. Please refer to <a href=\"https://help.ubuntu.com/community/InstallingSoftware\"\
          >InstallingSoftware</a>\nand <a href=\"http://mate-desktop.org/\">Mate</a>.</p>\n\
          <h2>Contact <a name=\"contact\"></a>\n</h2>\n<p>If you have problems with\
          \ TPAC Matlab image and using it, please contact TPAC help\ndesk via helpdesk@tpac.org.au,\
          \ or any help desks from your local Eresearch service\nproviders.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 14
        id: 6000090908
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-01T23:21:49-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000090908
        position: 8
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: TPAC Matlab with Remote Desktop
        updated_at: '2015-12-01T23:21:49-05:00'
        user_id: 6002464727
  html: "<ul>\n<li><a href=\"#intro\">Introduction</a></li>\n<li><a href=\"#image\"\
    >Software and packages in the image</a></li>\n<li><a href=\"#need\">What you need</a></li>\n\
    <li><a href=\"#launch\">Launch a Virtual Machine With TPAC Matlab image</a></li>\n\
    <li><a href=\"#desktop\">Use Matlab in MATE Desktop</a></li>\n<li><a href=\"#next\"\
    >What Next</a></li>\n<li><a href=\"#security\">Security</a></li>\n<li><a href=\"\
    #upgrade\">Upgrades and software installation</a></li>\n<li><a href=\"#contact\"\
    >Contact</a></li>\n</ul>\n<h2>Introduction <a name=\"intro\"></a></h2>\n<p>TPAC\
    \ provides an image in NeCTAR Cloud with Matlab 2013 installed. The image\nalso\
    \ includes X2Go server that allow users to run MATLAB in the remote desktop\n\
    environment and access the Matlab from anywhere through the Internet. MATE desktop\n\
    is installed and it provides GUI support for the Matlab and facilities better\
    \ user\nexperience that console access. For more information about how to use\
    \ X2Go and\nMATE desktop, please refer to the article \u2018TPAC Remote Desktop\
    \ X2Go\u2019.</p>\n<h2>Software and packages in the image <a name=\"image\"></a></h2>\n\
    <p>The below lists what software packages have been pre-installed on the TPAC\
    \ Matlab\nwith remote desktop image:</p>\n<ul>\n<li>\n<p>Ubuntu 14.04 (operating\
    \ system)</p>\n</li>\n<li>\n<p>X2Go Server (remote desktop server)</p>\n</li>\n\
    <li>\n<p>Mate 1.8.1 (GUI desktop)</p>\n</li>\n<li>\n<p>Matlab 2013</p>\n</li>\n\
    <li>\n<p>Python 2.7.6 and Python 3.4</p>\n</li>\n<li>\n<p>openjdk-7</p>\n</li>\n\
    <li>\n<p>nano</p>\n</li>\n<li>\n<p>gcc 4.8, g++ 4.8</p>\n</li>\n<li>\n<p>gimp</p>\n\
    </li>\n</ul>\n<h2>What you need <a name=\"need\"></a></h2>\n<p>Aside from computer\
    \ and network access, you will need to be an <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
    >Australian Access Federation</a>\neligible researcher to access the NeCTAR cloud.\
    \ You will also have to use key-pair\nsecurity for your <a href=\"https://support.nectar.org.au/support/solutions/articles/6000077794-getting-started\"\
    >virtual machine authentication</a>.\nUpon first NeCTAR cloud use, AAF eligible\
    \ researchers are issued with a limited\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000055380-resources-available-to-you\"\
    >trial allocation</a> that will do just fine for trying the\nTPAC RStudio in the\
    \ research cloud. If you need more resources, such as CPU, data\nstorage space,\
    \ or you need it for longer than your trial allocation, then you can\nrequest\
    \ a <a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
    >NeCTAR allocation</a>.</p>\n<h2>Launch a Virtual Machine With TPAC Matlab image\
    \ <a name=\"launch\"></a></h2>\n<p>The below provides instruction about how to\
    \ launch a virtual machine in NecTAR\nusing TPAC pre-build image with Matlab,\
    \ X2Go and MATE.</p>\n<ul>\n<li>Login to NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >Dashboard</a> with your AAF credentials. Select your\n project name, click the\
    \ \u2018Images\u2019 and then click tab \u2018Public\u2019. You should see the\n\
    \ below screenshot:</li>\n</ul>\n<p><img alt=\"snapshot1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-matlab-1.png?raw=true\"\
    ></p>\n<ul>\n<li>After clicking the tab 'Public', You will see all available public\
    \ images on\n screen. Scroll down the list and find the image with name 'TPAC\
    \ matlab.001 1447740833'\n and click the \u2018Launch\u2019 button. You should\
    \ see a pop\n up window like below:</li>\n</ul>\n<p><img alt=\"snapshot2\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-matlab-2.png?raw=true\"\
    ></p>\n<ul>\n<li>\n<p>In this pop up window, provide some information for the\
    \ virtual machine, such\n as name and flavour. Please  note, the desktop application\
    \ such as MATE requires\n larger root disk size, so it is prefered to use flavour\
    \ m2.small, m2.medium,\n m2.large and m2.xlarge as these flavours have 30G root\
    \ disk.</p>\n</li>\n<li>\n<p>Click 'Access &amp; Security' tab. In this pop up\
    \ window, provide your key and\n security group. You also need to open port 22,\
    \ as X2Go uses it for communication\n between X2Go Server and Client. So make\
    \ sure you tick a security group with port\n 22 open. See below screenshot.</p>\n\
    </li>\n</ul>\n<p><img alt=\"snapshot3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-matlab-3.png?raw=true\"\
    ></p>\n<ul>\n<li>Click 'Availability Zone' tab. As the license requirement, the\
    \ availability zone\n is restricted to Tasmania Zone. So please make sure you\
    \ launch  a virtual machine\n in the Tasmania Zone. Otherwise the Matlab won\u2019\
    t work properly. See below screenshot:</li>\n</ul>\n<p><img alt=\"snapshot4\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-matlab-4.png?raw=true\"\
    ></p>\n<ul>\n<li>After clicking the \u2018Launch\u2019 button, the virtual machine\
    \ will be ready in a few\n minutes. Please write down the IP address of the newly\
    \ created virtual machine as\n it will be used later in the X2Go Client to connect\
    \ to the virtual machine.</li>\n</ul>\n<p>For details of how to launch a virtual\
    \ machine in NeCTAR Cloud, please refer to this <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055376-launching-virtual-machines\"\
    >link</a>.</p>\n<p>Note, TPAC Matlab image only works if the availability zone\
    \ of the virtual machine\nis Tasmania Zone as the Matlab uses University of Tasmania\
    \ Site License. The\nMatlab will not run if the availability zone is not in Tasmania.</p>\n\
    <h2>Use Matlab in MATE Desktop <a name=\"desktop\"></a></h2>\n<p>To use the Matlab\
    \ in the launched virtual machine, you need to use the X20Go\nClient to connect\
    \ to it. </p>\n<p>Configure the X20Go client with the information you obtained\
    \ from the launched\nvirtual machine, such as IP address, the default user account,\
    \ in this case it\nshould be Ubuntu and the private key used for authentication.\
    \ Please refer to\nTPAC Remote Desktop User Guide for more information.</p>\n\
    <p>So the simple steps are:</p>\n<ul>\n<li>\n<p>Configure the X20Go client to\
    \ create a session for the virtual machine</p>\n</li>\n<li>\n<p>Double Click the\
    \ session and get connection to the virtual machine</p>\n</li>\n<li>\n<p>If everything\
    \ goes well, you should see the MATE desktop. See the below screenshot:</p>\n\
    </li>\n</ul>\n<p><img alt=\"snapshot5\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-matlab-5.png?raw=true\"\
    ></p>\n<ul>\n<li>\n<p>Once you are in the MATE desktop, click \u2018Application\u2019\
    \ menu on the top left corner\n and move mouse cursor over the \u2018Programming\u2019\
    \ menu</p>\n</li>\n<li>\n<p>A submenu will come out and move mouse over \u2018\
    Matlab r2013b\u2019 and click</p>\n</li>\n<li>\n<p>The Matlab main window should\
    \ appear</p>\n</li>\n</ul>\n<p>For details about how to connect to X2Go Server\
    \ using X2Go client, please refer\nto the 'TPAC Remote Desktop X2Go'. </p>\n<h2>What\
    \ Next <a name=\"next\"></a></h2>\n<p>If you want to use your Matlab virtual machine\
    \ as a collaboration space, you will\nneed to do some user management. For this\
    \ you can refer to \u201CAdd Accounts on The\nX2Go Server\u201D in 'TPAC Remote\
    \ Desktop X2Go' documentation. On top of that, your\ncollaborators will need to\
    \ install their own X2Go client, refer to the same document.</p>\n<p>You can also\
    \ share data between your local machine with X2Go Client installed and\nMatlab\
    \ virtual machine with X2Go Server installed. You can find how from this document.</p>\n\
    <h2>Security <a name=\"security\"></a></h2>\n<p>By default, there is only one\
    \ default user 'ubuntu' and it uses key based\nauthentication. If you want to\
    \ create more users to use the virtual machine, please\nuse key based authentication\
    \ rather than password based authentication. For a quick\nsecurity check list,\
    \ please refer to <a href=\"https://support.nectar.org.au/support/solutions/articles/6000091906-security-compromise-checklist\"\
    >here</a>. </p>\n<h2>Upgrades and software installation <a name=\"upgrade\"></a></h2>\n\
    <p>User initialed upgrades for Matlab and Ubuntu are not encouraged. TPAC will\n\
    publish upgraded version of Matlab and Ubuntu in new image. Please contact TPAC\
    \ help\ndesk at helpdesk@tpac.org.au to see whether any latest version of Matlab\
    \ and Ubuntu\nis available. Other software installation and upgrade can be done\
    \ via the common\ninstallation tools such as apt-get and appititude. Packages\
    \ can be also installed\nthrough the Mate Desktop environment. Please refer to\
    \ <a href=\"https://help.ubuntu.com/community/InstallingSoftware\">InstallingSoftware</a>\n\
    and <a href=\"http://mate-desktop.org/\">Mate</a>.</p>\n<h2>Contact <a name=\"\
    contact\"></a></h2>\n<p>If you have problems with TPAC Matlab image and using\
    \ it, please contact TPAC help\ndesk via helpdesk@tpac.org.au, or any help desks\
    \ from your local Eresearch service\nproviders.</p>"
  parent: 24
  sha1: f6f9841777a9c3afaa24f5fbbe9ae8c166fb07a1
  title: TPAC Matlab with Remote Desktop
92:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-23T00:01:45-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " \n Introduction \n X2Go Remote Desktop \n TPAC Remote Desktop\
          \ Image \n TPAC Remote Desktop (X2Go) User Guide \n Security \n Remote Desktop\
          \ Server Installation \n Contact \n \n Introduction \n \n A remote desktop\
          \ is a service that allows a user to access and view an operating\nsystem\u2019\
          s desktop session that is running on another computer in another\ngeographical\
          \ location.  The access occurs via the Internet or through local area\n\
          network and enables users to  interact with at system as if they were physically\n\
          at their own computer.  \n In a remote desktop setup, the local computer\
          \ receives a copy of the desktop\nimage from the remote computer updated\
          \ regularly or when a change is detected.\nThe local computer\u2019s keyboard\
          \ and mouse inputs are transferred to the remote\ncomputer, where the remote\
          \ desktop software implements the instructions\naccordingly.  \n Protocols\
          \ for remote desktop include Remote Desktop Protocol(RDP), virtual\nnetwork\
          \ computing (VNC) and NX technology. \n Virtual machines running in the\
          \ Nectar Cloud can be accessed via a remote\ndesktop service, which allows\
          \ users to access the virtual machines through a\ndesktop GUI rather than\
          \ a traditional command line console. \n Accessing virtual machine through\
          \ a remote desktop provides many benefits over\ntraditional local computer\
          \ access: \n \n \n Allowing users to access a \u2018workplace\u2019 computer\
          \ from any location \n \n \n More computing power than is available in user\u2019\
          s local computer \n \n \n Easy to share data and to collaborate among users\
          \ \n \n \n More reliable computer system that offers 24 hours access \n\
          \ \n \n More storage options and larger disk size \n \n \n Better technical\
          \ supports as the virtual machine can be easily accessed by a\n system administrator\
          \ \n \n \n Enables running GUI applications (e.g.Matlab, R-Studio desktop\
          \ edition) in the\n Cloud  \n \n \n Multiple users can access the remote\
          \ computer at the same time \n \n \n X2Go Remote Desktop \n \n x2go is a\
          \ free remote desktop tool using NX technology for low latency access to\n\
          graphical applications running on remote computers (such as NeCTAR virtual\n\
          machines).  It's much more elegant and easier to use than VNC over ssh,\
          \ or\nfreeNX or the like.  Features include: \n \n \n Simple installation\
          \ \n \n \n Client supports windows, mac and linux \n \n \n Traffic is securely\
          \ tunneled over SSH \n \n \n Very fast window redraw, low latency feedback\
          \ on user input. \n \n \n Dynamic window re-scaling (you can drag the x2go\
          \ window to resize it, and the\n remote windows resize too) \n \n \n Supports\
          \ multiple desktop environments (MAte, GNOME, KDE, etc.) \n \n \n Copy and\
          \ paste passthrough \n \n \n Sound, printing and remote file sharing (all\
          \ untested at this stage) \n \n \n For more information about X2Go, please\
          \ refer to its offical websitex2go \n X20Go Client \n The X2Go Client is\
          \ the client application that connects to a remote server and a\ndisplay\
          \ a graphical desktop on a local machine. The client requires X11 Server\n\
          installed on the local machine. On windows, the X11 Server has included\
          \ in the\ninstallation. On Linux, the client uses the local Xorg Server.\
          \ On Mac, XQuartz\nX11 server is required in order for the client to function.\
          \ \n X2Go Server \n The X2Go server is the server application that runs\
          \ on the remote machine. It\nstarts the application desktop sessions and\
          \ transfers the desktop to the client,\nwhich is the X20Go client.  \n For\
          \ more information about X2G0, please visit X2Go official website \n TPAC\
          \ Remote Desktop Image \n \n You can install X2Go server on any supported\
          \ Linux distributions on the virtual\nmachines in NecTAR Cloud and access\
          \ that machines from anywhere over a network.\nCurrently, TPAC provides\
          \ a Image in NecTAR Cloud with X2Go Server pre-installed.\nUsers can utilize\
          \ this image to launch a Virtual Machine for their applications\nrequire\
          \ remote desktop. The image also contains a GUI desktop application (Mate),\n\
          that provides the GUI environment for users to images applications in Ubuntu.\n\
          The below lists what software packages have been pre-installed: \n \n \n\
          \ Ubuntu 14.04 (operating system) \n \n \n X2Go Server (remote desktop server)\
          \ \n \n \n Mate 1.8.1 (GUI desktop) \n \n \n Python 2.7.6 and Python 3.4\
          \ \n \n \n openjdk-7 \n \n \n nano \n \n \n gcc 4.8, g++ 4.8 \n \n \n gimp\
          \ \n \n \n TPAC Remote Desktop (X2Go) User Guide \n \n TPAC recommends X2Go\
          \ and MATE desktop environment for providing remote desktop\ncapability\
          \ to NeCTAR virtual machines. This guide is about how to install and\nuse\
          \ three components to make an X2Go remote desktop run in your virtual machine.\
          \ \nThe GUI provider (MATE) (on your virtual machine), the X2Go server (on\
          \ your\nvirtual machine), and the X2Go client (on your local machine). If\
          \ you use one of\nthe TPAC provided X2Go/MATE enabled images as the basis\
          \ of your VM, then you\nonly need to ensure the you have an X2Go Client\
          \ installed; the X2Go Server and\nthe MATE GUI provider are already installed\
          \ for you.  \n General requirements: \n \n \n A supported Linux operating\
          \ system on the remote host \n \n \n Windows, OSX or Linux on the client\
          \ side. \n \n \n X2Go server installed on the remote host, no further configuration\
          \ is required.\n You can use TPAC rebuild image to launch a virtual machine\
          \ as it has pre-installed\n the X2Go Server and MATE Desktop. \n \n \n An\
          \ account with ssh access on the remote host (either via certificates or\
          \ password) \n \n \n X2Go client installed and configured to talk to the\
          \ remote host \n \n \n What you need \n Aside from computer and network\
          \ access, you will need to be an Australian Access Federation\neligible\
          \ researcher to access the NeCTAR cloud. You will also have to use key-pair\n\
          security for your virtual machine authentication.\nUpon first NeCTAR cloud\
          \ use, AAF eligible researchers are issued with a limited\ntrial allocation\
          \ that will do just fine for trying the\nTPAC RStudio in the research cloud.\
          \ If you need more resources, such as CPU, data\nstorage space, or you need\
          \ it for longer than your trial allocation, then you can\nrequest a NeCTAR\
          \ allocation. \n X2Go Client Installation \n X2Go Client on Windows \n Install\
          \ X2Go Client on Windows is straightforward. You can go to this link\nto\
          \ download the windows executable file. After the download, double click\
          \ the\nexecutable file and follow the instructions on the screen. Once you\
          \ have finished\nthe installation, you can double click the X2Go icon to\
          \ start the client. \n X2Go Client on OS X \n You need to install OS X X11\
          \ server first before you can use the X2go Is Client.\nThe X2Go OS X client\
          \ use OS X X11 server and you can obtain it(.dmg) from xquartz. \n To install\
          \ x2Go Client on OS X, please go to this link to download the\ninstallation\
          \ packages (.dmg) matching your IOS version. \n The below instruction shows\
          \ how to install a .dmf file: \n \n \n double click the .dmf file to make\
          \ its content available \n \n \n drag the application from the .dmf window\
          \ into /Applications to install \n \n \n wait for the copy process to finish\
          \ \n \n \n eject the .dmf file \n \n \n delete the .dmf file \n \n \n X2Go\
          \ Client on Linux \n Ubuntu/Debian\napt-get install x2goclient \n Fedora\n\
          yum install x2goclient \n Redhat\nPlease go to this link for detailed instruction.\
          \ \n Use X2Go Client \n The below instruction shows how to set up X2Go Client\
          \ to connect to a remote\nvirtual machine with X2Go client preinstalled\
          \ in windows environment. For\ninstructions in Linux and OS X, please refer\
          \ to X2Go official website. \n \n Double click X2Go Client icon on the desktop,\
          \ or you can search it through windows search function.\n You should see\
          \ the below screenshot: \n \n \n \n You need to create a session to connect\
          \ to the remote virtual machine desktop.\n Click \u2018session\u2019 menu\
          \ and then click \u2018New session\u2019 menu time. You should see the\n\
          \ below screenshot: \n \n \n \n You can provide a Session name, the IP of\
          \ the virtual machine in Host field\n and the user account in Login field.\
          \ In Use RSA/DSA key for ssh connection\n field, put the private key matching\
          \ the public key used when launching the\n virtual machine in NecTAR Cloud.\
          \ In the Session type list, select MATE as your\n desktop. You can also\
          \ select other desktop type if it is installed on your\n virtual machine.\
          \ Then, click OK and you should see something like the below\n screenshot:\
          \ \n \n \n \n Double click that new icon on the right hand side of X2Go\
          \ window, you should\n see the mate desktop \n \n \n Launch a Virtual Machine\
          \ With X2Go \n You can follow the below instruction to launch a virtual\
          \ machine in NeCTAR cloud\nusing the TPAC pre-build X2Go Image. For details\
          \ how to launch a virtual machine\nin NeCTAR cloud, you can refer to this\
          \ link. \n \n \n Go to NeCTAR Dashboard \n \n \n Select a project \n \n\
          \ \n Click \u2018Images\u2019 and in the image list find image \u2018TPAC\
          \ core.003 1448253981\u2019 \n \n \n \n \n Click associated \u2018Launch\u2019\
          \ button and follow the instructions on the pop up\n window. Provide some\
          \ information for the virtual machine, such as name and flavour.\n The desktop\
          \ application such as Mate requires larger root disk size, so it is\n preferred\
          \ to use flavour m2.small, m2.medium, m2.large and m2.xlarge as these\n\
          \ flavours have 30G root disk.  \n \n \n \n Click 'Access & Security' tab,\
          \ select the key pair for authentication and the\n security group. For how\
          \ to generate a key pair in NecTAR Dashboard, please refer to\n this link.\
          \ You also need to open port 22, as X2Go uses it for communication\n between\
          \ X2Go Server and Client. So please ensure ticking the security group with\
          \ ssh\n 22 open. \n \n \n \n Click 'Availability Zone 'tab. Select the required\
          \ location of virtualm achine.\n Click \u2018Launch\u2019 button. It might\
          \ take various minutes to launch a virtual\n machine up to the chosen availability\
          \ zone. \n \n \n Now, you should have a working X2Go server and you can\
          \ use X2Go client (refer\nto above document) to connect to it. The X2Go\
          \ has a default user account\navailable which is same as the image default\
          \ account. For Ubuntu image, the\ndefault user is ubuntu. You can find more\
          \ default users for other operating\nsystems at this link. \n Introduction\
          \ to MATE Desktop \n The TPAC pre-build X2Go image has Mate Desktop installed\
          \ as its default desktop\napplication. The MATE Desktop Environment is derived\
          \ from GNOME 2 and it provides\nan attractive and user-friendly interface\
          \ for Linux. The below note explains how\nto use the MATE interface and\
          \ how to start applications, and how to explore the\nfile system. \n For\
          \ more information about Mate Desktop, please refer to Mate Desktop official\n\
          website. \n Elements of the MATE Desktop \n The MATE Desktop contains a\
          \ link to your home directory file browser and the Edge\nPanel on the right\
          \ top corner. The Edge Panel has a calendar, a power off button\nand a network\
          \ monitor. On the left top corner is the Applications menu, where you\n\
          can start installed applications. See the below screenshot: \n \n Launching\
          \ Applications with the Application Menu \n The Applications menu is where\
          \ you find and launch applications. Move your mouse\npointer over the Application\
          \ Menu and click to open the menu. All applications\nare grouped by a name\
          \ such as Accessories and System Tools. To start an application\nsuch as\
          \ \u2018MATE Terminal\u2019, move mouse pointer over the group name, in\
          \ this case it\nis \u2018System Tools\u2019 and this expands the menu to\
          \ contain a sub menu. From the sub\nmenu, move mouse pointer over the \u2018\
          MATE Terminal\u2019 and click. It is possible to\nhave have more level of\
          \ sub-menus and the launching process is the same. \n \n Managing File System\
          \ \n The MATE Desktop contains a link to your home directory and you can\
          \ simply double\nclick that to open the file browser. You can also find\
          \ the file browser from the\n\u2018Application menu\u2019 under the \u2018\
          System Tools\u2019 group. The menu item name is \u2018Caja\u2019. \n \n\
          \ The file browser shown above displays all files and folders under the\
          \ account\nubuntu\u2019s home directory. If you right click your mouse and\
          \ this should bring the\ncontext menu, see above screenshot. You can click\
          \ the \u2018Empty File\u2019 menu item\nunder the \u2018Create Document\u2019\
          \ to create a new empty file or click \u2018Create Folder\u2019\nto create\
          \ a new folder. On the left hand side has a list of folders under your\n\
          home folder for your convenience. You can also click the left arrow button\
          \ on the\ntoolbar to navigate to parent folder. \n Change System settings\
          \ \n Besides the Applications menu, there is a System menu, which you can\
          \ use to\nperform system related functions such as change the Fonts and\
          \ Desktop appearances.\nAll these functions are under Preferences menu.\
          \ \n \n Add Accounts on The X2Go Server \n The MATE Desktop session is associated\
          \ with the system user account. By default\nin Ubuntu, this user account\
          \ is ubuntu. If you want to add more accounts to\naccess the X2Go Desktop,\
          \ you can add more system user accounts and X2Go will\nautomatically link\
          \ the accounts to the X2Go Desktop session. The below note shows\nhow to\
          \ add a user account to Ubuntu. For other operating systems, please refer\
          \ to the relevant documents. \n \n \n Open a \u2018Mate Terminal\u2019 and\
          \ type \u2018sudo adduser test\u2019 \n \n \n The console prompts a series\
          \ of questions. The procedure will be: \n \n \n Assign and confirm a password\
          \ \n \n \n Enter any additional information about the new user account \n\
          \ \n \n Type \u2018Y\u2019 to confirm and create the new user account \n\
          \ \n \n You can also add user to sudo group to give the user account sudo\
          \ permission.\n Type sudo usermod -aG sudo username \n \n \n Note, by default,\
          \ user password authentication is disabled and you need to enable\nit first\
          \ before you can use password to login. Please edit the /etc/ssh/sshd_config\n\
          file and set keyword PasswordAuthentication to yes to enable it. \n Now\
          \ you should have a new user created. To use this account to login to X2Go\
          \ session,\nsimply create a new session in the X2Go Client and add the new\
          \ username in the Login\nfield. Once you have created the session, you can\
          \ double click the session and type\nin the password. You should see the\
          \ MATE desktop after that. \n Create a Shared Data Folder on the Remote\
          \ Server \n X2Go provides a feature to allow folder on a local computer\
          \ such as a Laptop to\nbe shared with the X2Go server. That means you can\
          \ easily share your data and\nfiles between the X2Go Client and Server.\
          \ The below note demonstrates how to\nenable this feature using X2Go Windows\
          \ Client. \n \n \n Double click the the X2Go icon on the Windows Desktop\
          \ \n \n \n This brings up the X2Go Client window. Click the \u2018Session\u2019\
          \ menu and click the\n \u2018Session management\u2018. This should bring\
          \ you the screenshot like below: \n \n \n \n \n Find the session you want\
          \ to share folder with the X2Go Server and double click\n the session name.\
          \ On the pop out window, click \u2018Shared folders\u2019 tab and this\n\
          \ should bring you the below screenshot. Please refer to the above document\
          \ to\n find out how to create a new session \n \n \n \n \n Click the \u2018\
          file browser\u2019 button and in the pop up window, select the local\n folder\
          \ you want to share and click \u2018Select Folder\u2019 button. \n \n \n\
          \ Click the \u2018Add button\u2019 and the folder name should be appeared\
          \ in the list. Then\n tick Automount checkbox. See below screenshot: \n\
          \ \n \n \n \n \n Click \u2018Ok\u2019 button and client setup has been finished\
          \ \n \n \n You can double click the session and open a new connection to\
          \ X2Go Server. On\n the MATE Desktop, you should see a icon below the \u2018\
          ubuntu\u2019Home\u2019 icon. Double\n click the icon and it should open\
          \ a file browser window. \n \n \n \n \n Now, if you copy files to your shared\
          \ local folder, these files will be appeared\n on your X2Go Server as well\
          \ and vice verse. \n \n Note, folder on your local computer should has read/write\
          \ permission for X2Go\nClient. Otherwise, the shared local fold cannot be\
          \ accessed by X2Go Server. \n Upload and Download Files \n Besides the shared\
          \ local folder function, you can also use a SFTP client to upload\nand download\
          \ files from the X2Go Server. The below note shows you how to use a\nSFTP\
          \ client in Windows environment. \n \n \n Go to WinSCP official websiteto\
          \ download the installer \n \n \n Double click the downloaded executable\
          \ file and follow the instructions to\n install the software \n \n \n After\
          \ launching the software, you should see the below login window \n \n \n\
          \ \n \n On the login window, you can type in the IP address of the Virtual\
          \ Machine\n (X2Go Server) in the \u2018Host name\u2019 field and account\
          \ name in the \u2018User name\u2019 field.\n You can type in the password\
          \ if the user account uses password authentication or\n click \u2018Advanced\u2019\
          \ button to load a private key for authentication. See the below\n screenshot.\
          \ After you click the \u2018Authentication\u2019 under the SSH section,\
          \ click the\n file browser button located under \u2018Private key file\u2019\
          \ and then you can select the\n private key and click \u2018Open\u2019 button.\
          \ After that, click \u2018Ok\u2019 button to go back to\n the login window.\
          \ \n \n \n \n \n You can then click the Login button to connect to the virtual\
          \ machine (X2Go Server).\n You can also click the save button to save the\
          \ login session for reuse. \n \n \n After the connection is successfully\
          \ established. You should see the below window.\n On this window, you can\
          \ drag and drop files to be copied from the Client to the\n Server or vice\
          \ versa. You can also browse folder structure and select which\n folder\
          \ to be the current folder. \n \n \n \n Security \n \n By default, there\
          \ is only one default user 'ubuntu' and it uses key based\nauthentication.\
          \ If you want to create more users to use the virtual machine, please\n\
          use key based authentication rather than password based authentication.\
          \ For a quick\nsecurity check list, please refer to here. \n Remote Desktop\
          \ Server Installation  \n \n If you would like to install an X2Go/MATE remote\
          \ desktop on your existing instance,\nthen you can find some instructions\
          \ below. It assumes that you uses Ubuntu as the\noperating system in your\
          \ existing virtual machine and TPAC has only tested it on\nUbuntu 14.04.\
          \ \n Install the Mate GUI \n Use your terminal application (e.g. Putty)\
          \ to ssh to the remote host\n(i.e. your virtual machine). \n Run the following\
          \ commands: \n ``` \n sudo apt-add-repository ppa:ubuntu-mate-dev/ppa\n\
          sudo apt-add-repository ppa:ubuntu-mate-dev/trusty-mate\nsudo apt-get update\n\
          sudo apt-get upgrade\nsudo apt-get install --no-install-recommends ubuntu-mate-core\
          \ ubuntu-mate-desktop\nsudo reboot \n ``` \n Install x2Go on the remote\
          \ host \n Use your terminal application (e.g. Putty) to ssh to the remote\
          \ host\n(i.e. your virtual machine). \n Run the following commands: \n ```\
          \ \n sudo apt-get update\nsudo apt-get install software-properties-common\n\
          sudo add-apt-repository ppa:x2go/stable\nsudo apt-get update\nsudo apt-get\
          \ install x2goserver x2goserver-xsession \n ``` \n For more information,\
          \ please visit X2Go official website \n Contact \n \n If you have problems\
          \ with TPAC X2Go image, please contact TPAC help desk via\nhelpdesk@tpac.org.au,\
          \ or any help desks from your local Eresearch service providers. "
        description: "<ul>\n<li><a href=\"#intro\">Introduction</a></li>\n<li><a href=\"\
          #desktop\">X2Go Remote Desktop</a></li>\n<li><a href=\"#image\">TPAC Remote\
          \ Desktop Image</a></li>\n<li><a href=\"#guide\">TPAC Remote Desktop (X2Go)\
          \ User Guide</a></li>\n<li><a href=\"#security\">Security</a></li>\n<li><a\
          \ href=\"#installation\">Remote Desktop Server Installation</a></li>\n<li><a\
          \ href=\"#contact\">Contact</a></li>\n</ul>\n<h2>Introduction <a name=\"\
          intro\"></a>\n</h2>\n<p>A remote desktop is a service that allows a user\
          \ to access and view an operating\nsystem\u2019s desktop session that is\
          \ running on another computer in another\ngeographical location.  The access\
          \ occurs via the Internet or through local area\nnetwork and enables users\
          \ to  interact with at system as if they were physically\nat their own computer.\
          \ </p>\n<p>In a remote desktop setup, the local computer receives a copy\
          \ of the desktop\nimage from the remote computer updated regularly or when\
          \ a change is detected.\nThe local computer\u2019s keyboard and mouse inputs\
          \ are transferred to the remote\ncomputer, where the remote desktop software\
          \ implements the instructions\naccordingly. </p>\n<p>Protocols for remote\
          \ desktop include Remote Desktop Protocol(RDP), virtual\nnetwork computing\
          \ (VNC) and NX technology.</p>\n<p>Virtual machines running in the Nectar\
          \ Cloud can be accessed via a remote\ndesktop service, which allows users\
          \ to access the virtual machines through a\ndesktop GUI rather than a traditional\
          \ command line console.</p>\n<p>Accessing virtual machine through a remote\
          \ desktop provides many benefits over\ntraditional local computer access:</p>\n\
          <ul>\n<li>\n<p>Allowing users to access a \u2018workplace\u2019 computer\
          \ from any location</p>\n</li>\n<li>\n<p>More computing power than is available\
          \ in user\u2019s local computer</p>\n</li>\n<li>\n<p>Easy to share data\
          \ and to collaborate among users</p>\n</li>\n<li>\n<p>More reliable computer\
          \ system that offers 24 hours access</p>\n</li>\n<li>\n<p>More storage options\
          \ and larger disk size</p>\n</li>\n<li>\n<p>Better technical supports as\
          \ the virtual machine can be easily accessed by a\n system administrator</p>\n\
          </li>\n<li>\n<p>Enables running GUI applications (e.g.Matlab, R-Studio desktop\
          \ edition) in the\n Cloud </p>\n</li>\n<li>\n<p>Multiple users can access\
          \ the remote computer at the same time</p>\n</li>\n</ul>\n<h2>X2Go Remote\
          \ Desktop <a name=\"desktop\"></a>\n</h2>\n<p>x2go is a free remote desktop\
          \ tool using NX technology for low latency access to\ngraphical applications\
          \ running on remote computers (such as NeCTAR virtual\nmachines).  It's\
          \ much more elegant and easier to use than VNC over ssh, or\nfreeNX or the\
          \ like.  Features include:</p>\n<ul>\n<li>\n<p>Simple installation</p>\n\
          </li>\n<li>\n<p>Client supports windows, mac and linux</p>\n</li>\n<li>\n\
          <p>Traffic is securely tunneled over SSH</p>\n</li>\n<li>\n<p>Very fast\
          \ window redraw, low latency feedback on user input.</p>\n</li>\n<li>\n\
          <p>Dynamic window re-scaling (you can drag the x2go window to resize it,\
          \ and the\n remote windows resize too)</p>\n</li>\n<li>\n<p>Supports multiple\
          \ desktop environments (MAte, GNOME, KDE, etc.)</p>\n</li>\n<li>\n<p>Copy\
          \ and paste passthrough</p>\n</li>\n<li>\n<p>Sound, printing and remote\
          \ file sharing (all untested at this stage)</p>\n</li>\n</ul>\n<p>For more\
          \ information about X2Go, please refer to its offical website<a href=\"\
          http://wiki.x2go.org/doku.php/doc:newtox2go\">x2go</a></p>\n<h3>X20Go Client</h3>\n\
          <p>The X2Go Client is the client application that connects to a remote server\
          \ and a\ndisplay a graphical desktop on a local machine. The client requires\
          \ X11 Server\ninstalled on the local machine. On windows, the X11 Server\
          \ has included in the\ninstallation. On Linux, the client uses the local\
          \ Xorg Server. On Mac, XQuartz\nX11 server is required in order for the\
          \ client to function.</p>\n<h3>X2Go Server</h3>\n<p>The X2Go server is the\
          \ server application that runs on the remote machine. It\nstarts the application\
          \ desktop sessions and transfers the desktop to the client,\nwhich is the\
          \ X20Go client. </p>\n<p>For more information about X2G0, please visit X2Go\
          \ official <a href=\"http://wiki.x2go.org/doku.php/doc:newtox2go\">website</a></p>\n\
          <h2>TPAC Remote Desktop Image <a name=\"image\"></a>\n</h2>\n<p>You can\
          \ install X2Go server on any supported Linux distributions on the virtual\n\
          machines in NecTAR Cloud and access that machines from anywhere over a network.\n\
          Currently, TPAC provides a Image in NecTAR Cloud with X2Go Server pre-installed.\n\
          Users can utilize this image to launch a Virtual Machine for their applications\n\
          require remote desktop. The image also contains a GUI desktop application\
          \ (Mate),\nthat provides the GUI environment for users to images applications\
          \ in Ubuntu.\nThe below lists what software packages have been pre-installed:</p>\n\
          <ul>\n<li>\n<p>Ubuntu 14.04 (operating system)</p>\n</li>\n<li>\n<p>X2Go\
          \ Server (remote desktop server)</p>\n</li>\n<li>\n<p>Mate 1.8.1 (GUI desktop)</p>\n\
          </li>\n<li>\n<p>Python 2.7.6 and Python 3.4</p>\n</li>\n<li>\n<p>openjdk-7</p>\n\
          </li>\n<li>\n<p>nano</p>\n</li>\n<li>\n<p>gcc 4.8, g++ 4.8</p>\n</li>\n\
          <li>\n<p>gimp</p>\n</li>\n</ul>\n<h2>TPAC Remote Desktop (X2Go) User Guide\
          \ <a name=\"guide\"></a>\n</h2>\n<p>TPAC recommends X2Go and MATE desktop\
          \ environment for providing remote desktop\ncapability to NeCTAR virtual\
          \ machines. This guide is about how to install and\nuse three components\
          \ to make an X2Go remote desktop run in your virtual machine. \nThe GUI\
          \ provider (MATE) (on your virtual machine), the X2Go server (on your\n\
          virtual machine), and the X2Go client (on your local machine). If you use\
          \ one of\nthe TPAC provided X2Go/MATE enabled images as the basis of your\
          \ VM, then you\nonly need to ensure the you have an X2Go Client installed;\
          \ the X2Go Server and\nthe MATE GUI provider are already installed for you.\
          \ </p>\n<p>General requirements:</p>\n<ul>\n<li>\n<p>A supported Linux operating\
          \ system on the remote host</p>\n</li>\n<li>\n<p>Windows, OSX or Linux on\
          \ the client side.</p>\n</li>\n<li>\n<p>X2Go server installed on the remote\
          \ host, no further configuration is required.\n You can use TPAC rebuild\
          \ image to launch a virtual machine as it has pre-installed\n the X2Go Server\
          \ and MATE Desktop.</p>\n</li>\n<li>\n<p>An account with ssh access on the\
          \ remote host (either via certificates or password)</p>\n</li>\n<li>\n<p>X2Go\
          \ client installed and configured to talk to the remote host</p>\n</li>\n\
          </ul>\n<h3>What you need</h3>\n<p>Aside from computer and network access,\
          \ you will need to be an <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
          >Australian Access Federation</a>\neligible researcher to access the NeCTAR\
          \ cloud. You will also have to use key-pair\nsecurity for your <a href=\"\
          https://support.nectar.org.au/support/solutions/articles/6000077794-getting-started\"\
          >virtual machine authentication</a>.\nUpon first NeCTAR cloud use, AAF eligible\
          \ researchers are issued with a limited\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000055380-resources-available-to-you\"\
          >trial allocation</a> that will do just fine for trying the\nTPAC RStudio\
          \ in the research cloud. If you need more resources, such as CPU, data\n\
          storage space, or you need it for longer than your trial allocation, then\
          \ you can\nrequest a <a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
          >NeCTAR allocation</a>.</p>\n<h3>X2Go Client Installation</h3>\n<h4>X2Go\
          \ Client on Windows</h4>\n<p>Install X2Go Client on Windows is straightforward.\
          \ You can go to this <a href=\"http://code.x2go.org/releases/binary-win32/x2goclient/releases/4.0.5.0-2015.07.31/\"\
          >link</a>\nto download the windows executable file. After the download,\
          \ double click the\nexecutable file and follow the instructions on the screen.\
          \ Once you have finished\nthe installation, you can double click the X2Go\
          \ icon to start the client.</p>\n<h4>X2Go Client on OS X</h4>\n<p>You need\
          \ to install OS X X11 server first before you can use the X2go Is Client.\n\
          The X2Go OS X client use OS X X11 server and you can obtain it(.dmg) from\
          \ <a href=\"http://www.xquartz.org/\">xquartz</a>.</p>\n<p>To install x2Go\
          \ Client on OS X, please go to this <a href=\"http://code.x2go.org/releases/binary-macosx/x2goclient/\"\
          >link</a> to download the\ninstallation packages (.dmg) matching your IOS\
          \ version.</p>\n<p>The below instruction shows how to install a .dmf file:</p>\n\
          <ul>\n<li>\n<p>double click the .dmf file to make its content available</p>\n\
          </li>\n<li>\n<p>drag the application from the .dmf window into /Applications\
          \ to install</p>\n</li>\n<li>\n<p>wait for the copy process to finish</p>\n\
          </li>\n<li>\n<p>eject the .dmf file</p>\n</li>\n<li>\n<p>delete the .dmf\
          \ file</p>\n</li>\n</ul>\n<h4>X2Go Client on Linux</h4>\n<p>Ubuntu/Debian\n\
          apt-get install x2goclient</p>\n<p>Fedora\nyum install x2goclient</p>\n\
          <p>Redhat\nPlease go to this <a href=\"http://wiki.x2go.org/doku.php/wiki:repositories:redhat\"\
          >link</a> for detailed instruction.</p>\n<h3>Use X2Go Client</h3>\n<p>The\
          \ below instruction shows how to set up X2Go Client to connect to a remote\n\
          virtual machine with X2Go client preinstalled in windows environment. For\n\
          instructions in Linux and OS X, please refer to X2Go official <a href=\"\
          http://wiki.x2go.org/doku.php/doc:newtox2go\">website</a>.</p>\n<ul>\n<li>Double\
          \ click X2Go Client icon on the desktop, or you can search it through windows\
          \ search function.\n You should see the below screenshot:</li>\n</ul>\n\
          <p><img alt=\"snapshot1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-1.png?raw=true\"\
          ></p>\n<ul>\n<li>You need to create a session to connect to the remote virtual\
          \ machine desktop.\n Click \u2018session\u2019 menu and then click \u2018\
          New session\u2019 menu time. You should see the\n below screenshot:</li>\n\
          </ul>\n<p><img alt=\"snapshot2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-2.png?raw=true\"\
          ></p>\n<ul>\n<li>You can provide a Session name, the IP of the virtual machine\
          \ in Host field\n and the user account in Login field. In Use RSA/DSA key\
          \ for ssh connection\n field, put the private key matching the public key\
          \ used when launching the\n virtual machine in NecTAR Cloud. In the Session\
          \ type list, select MATE as your\n desktop. You can also select other desktop\
          \ type if it is installed on your\n virtual machine. Then, click OK and\
          \ you should see something like the below\n screenshot:</li>\n</ul>\n<p><img\
          \ alt=\"snapshot3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-3.png?raw=true\"\
          ></p>\n<ul>\n<li>Double click that new icon on the right hand side of X2Go\
          \ window, you should\n see the mate desktop</li>\n</ul>\n<p><img alt=\"\
          snapshot4\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-4.png?raw=true\"\
          ></p>\n<h3>Launch a Virtual Machine With X2Go</h3>\n<p>You can follow the\
          \ below instruction to launch a virtual machine in NeCTAR cloud\nusing the\
          \ TPAC pre-build X2Go Image. For details how to launch a virtual machine\n\
          in NeCTAR cloud, you can refer to this <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055376-launching-virtual-machines\"\
          >link</a>.</p>\n<ul>\n<li>\n<p>Go to NeCTAR <a href=\"https://dashboard.rc.nectar.org.au\"\
          >Dashboard</a></p>\n</li>\n<li>\n<p>Select a project</p>\n</li>\n<li>\n\
          <p>Click \u2018Images\u2019 and in the image list find image \u2018TPAC\
          \ core.003 1448253981\u2019</p>\n</li>\n</ul>\n<p><img alt=\"snapshot15\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-15.png?raw=true\"\
          ></p>\n<ul>\n<li>Click associated \u2018Launch\u2019 button and follow the\
          \ instructions on the pop up\n window. Provide some information for the\
          \ virtual machine, such as name and flavour.\n The desktop application such\
          \ as Mate requires larger root disk size, so it is\n preferred to use flavour\
          \ m2.small, m2.medium, m2.large and m2.xlarge as these\n flavours have 30G\
          \ root disk. </li>\n</ul>\n<p><img alt=\"snapshot16\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-16.png?raw=true\"\
          ></p>\n<ul>\n<li>Click 'Access &amp; Security' tab, select the key pair\
          \ for authentication and the\n security group. For how to generate a key\
          \ pair in NecTAR Dashboard, please refer to\n this <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055376-launching-virtual-machines\"\
          >link</a>. You also need to open port 22, as X2Go uses it for communication\n\
          \ between X2Go Server and Client. So please ensure ticking the security\
          \ group with ssh\n 22 open.</li>\n</ul>\n<p><img alt=\"snapshot17\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-17.png?raw=true\"\
          ></p>\n<ul>\n<li>Click 'Availability Zone 'tab. Select the required location\
          \ of virtualm achine.\n Click \u2018Launch\u2019 button. It might take various\
          \ minutes to launch a virtual\n machine up to the chosen availability zone.</li>\n\
          </ul>\n<p><img alt=\"snapshot18\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-18.png?raw=true\"\
          ></p>\n<p>Now, you should have a working X2Go server and you can use X2Go\
          \ client (refer\nto above document) to connect to it. The X2Go has a default\
          \ user account\navailable which is same as the image default account. For\
          \ Ubuntu image, the\ndefault user is ubuntu. You can find more default users\
          \ for other operating\nsystems at this <a href=\"https://wiki.rc.nectar.org.au/wiki/Image_Catalog\"\
          >link</a>.</p>\n<h3>Introduction to MATE Desktop</h3>\n<p>The TPAC pre-build\
          \ X2Go image has Mate Desktop installed as its default desktop\napplication.\
          \ The MATE Desktop Environment is derived from GNOME 2 and it provides\n\
          an attractive and user-friendly interface for Linux. The below note explains\
          \ how\nto use the MATE interface and how to start applications, and how\
          \ to explore the\nfile system.</p>\n<p>For more information about Mate Desktop,\
          \ please refer to Mate Desktop official\n<a href=\"http://mate-desktop.org/\"\
          >website</a>.</p>\n<h4>Elements of the MATE Desktop</h4>\n<p>The MATE Desktop\
          \ contains a link to your home directory file browser and the Edge\nPanel\
          \ on the right top corner. The Edge Panel has a calendar, a power off button\n\
          and a network monitor. On the left top corner is the Applications menu,\
          \ where you\ncan start installed applications. See the below screenshot:</p>\n\
          <p><img alt=\"snapshot4\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-4.png?raw=true\"\
          ></p>\n<h4>Launching Applications with the Application Menu</h4>\n<p>The\
          \ Applications menu is where you find and launch applications. Move your\
          \ mouse\npointer over the Application Menu and click to open the menu. All\
          \ applications\nare grouped by a name such as Accessories and System Tools.\
          \ To start an application\nsuch as \u2018MATE Terminal\u2019, move mouse\
          \ pointer over the group name, in this case it\nis \u2018System Tools\u2019\
          \ and this expands the menu to contain a sub menu. From the sub\nmenu, move\
          \ mouse pointer over the \u2018MATE Terminal\u2019 and click. It is possible\
          \ to\nhave have more level of sub-menus and the launching process is the\
          \ same.</p>\n<p><img alt=\"snapshot5\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-5.png?raw=true\"\
          ></p>\n<h4>Managing File System</h4>\n<p>The MATE Desktop contains a link\
          \ to your home directory and you can simply double\nclick that to open the\
          \ file browser. You can also find the file browser from the\n\u2018Application\
          \ menu\u2019 under the \u2018System Tools\u2019 group. The menu item name\
          \ is \u2018Caja\u2019.</p>\n<p><img alt=\"snapshot6\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-6.png?raw=true\"\
          ></p>\n<p>The file browser shown above displays all files and folders under\
          \ the account\nubuntu\u2019s home directory. If you right click your mouse\
          \ and this should bring the\ncontext menu, see above screenshot. You can\
          \ click the \u2018Empty File\u2019 menu item\nunder the \u2018Create Document\u2019\
          \ to create a new empty file or click \u2018Create Folder\u2019\nto create\
          \ a new folder. On the left hand side has a list of folders under your\n\
          home folder for your convenience. You can also click the left arrow button\
          \ on the\ntoolbar to navigate to parent folder.</p>\n<h4>Change System settings</h4>\n\
          <p>Besides the Applications menu, there is a System menu, which you can\
          \ use to\nperform system related functions such as change the Fonts and\
          \ Desktop appearances.\nAll these functions are under Preferences menu.</p>\n\
          <p><img alt=\"snapshot7\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-7.png?raw=true\"\
          ></p>\n<h3>Add Accounts on The X2Go Server</h3>\n<p>The MATE Desktop session\
          \ is associated with the system user account. By default\nin Ubuntu, this\
          \ user account is ubuntu. If you want to add more accounts to\naccess the\
          \ X2Go Desktop, you can add more system user accounts and X2Go will\nautomatically\
          \ link the accounts to the X2Go Desktop session. The below note shows\n\
          how to add a user account to Ubuntu. For other operating systems, please\
          \ refer to the relevant documents.</p>\n<ul>\n<li>\n<p>Open a \u2018Mate\
          \ Terminal\u2019 and type \u2018sudo adduser test\u2019</p>\n</li>\n<li>\n\
          <p>The console prompts a series of questions. The procedure will be:</p>\n\
          </li>\n<li>\n<p>Assign and confirm a password</p>\n</li>\n<li>\n<p>Enter\
          \ any additional information about the new user account</p>\n</li>\n<li>\n\
          <p>Type \u2018Y\u2019 to confirm and create the new user account</p>\n</li>\n\
          <li>\n<p>You can also add user to sudo group to give the user account sudo\
          \ permission.\n Type sudo usermod -aG sudo username</p>\n</li>\n</ul>\n\
          <p>Note, by default, user password authentication is disabled and you need\
          \ to enable\nit first before you can use password to login. Please edit\
          \ the /etc/ssh/sshd_config\nfile and set keyword PasswordAuthentication\
          \ to yes to enable it.</p>\n<p>Now you should have a new user created. To\
          \ use this account to login to X2Go session,\nsimply create a new session\
          \ in the X2Go Client and add the new username in the Login\nfield. Once\
          \ you have created the session, you can double click the session and type\n\
          in the password. You should see the MATE desktop after that.</p>\n<h3>Create\
          \ a Shared Data Folder on the Remote Server</h3>\n<p>X2Go provides a feature\
          \ to allow folder on a local computer such as a Laptop to\nbe shared with\
          \ the X2Go server. That means you can easily share your data and\nfiles\
          \ between the X2Go Client and Server. The below note demonstrates how to\n\
          enable this feature using X2Go Windows Client.</p>\n<ul>\n<li>\n<p>Double\
          \ click the the X2Go icon on the Windows Desktop</p>\n</li>\n<li>\n<p>This\
          \ brings up the X2Go Client window. Click the \u2018Session\u2019 menu and\
          \ click the\n \u2018Session management\u2018. This should bring you the\
          \ screenshot like below:</p>\n</li>\n</ul>\n<p><img alt=\"snapshot8\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-8.png?raw=true\"\
          ></p>\n<ul>\n<li>Find the session you want to share folder with the X2Go\
          \ Server and double click\n the session name. On the pop out window, click\
          \ \u2018Shared folders\u2019 tab and this\n should bring you the below screenshot.\
          \ Please refer to the above document to\n find out how to create a new session</li>\n\
          </ul>\n<p><img alt=\"snapshot9\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-9.png?raw=true\"\
          ></p>\n<ul>\n<li>\n<p>Click the \u2018file browser\u2019 button and in the\
          \ pop up window, select the local\n folder you want to share and click \u2018\
          Select Folder\u2019 button.</p>\n</li>\n<li>\n<p>Click the \u2018Add button\u2019\
          \ and the folder name should be appeared in the list. Then\n tick Automount\
          \ checkbox. See below screenshot:</p>\n</li>\n</ul>\n<p><img alt=\"snapshot10\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-10.png?raw=true\"\
          ></p>\n<ul>\n<li>\n<p>Click \u2018Ok\u2019 button and client setup has been\
          \ finished</p>\n</li>\n<li>\n<p>You can double click the session and open\
          \ a new connection to X2Go Server. On\n the MATE Desktop, you should see\
          \ a icon below the \u2018ubuntu\u2019Home\u2019 icon. Double\n click the\
          \ icon and it should open a file browser window.</p>\n</li>\n</ul>\n<p><img\
          \ alt=\"snapshot11\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-11.png?raw=true\"\
          ></p>\n<ul>\n<li>Now, if you copy files to your shared local folder, these\
          \ files will be appeared\n on your X2Go Server as well and vice verse.</li>\n\
          </ul>\n<p>Note, folder on your local computer should has read/write permission\
          \ for X2Go\nClient. Otherwise, the shared local fold cannot be accessed\
          \ by X2Go Server.</p>\n<h3>Upload and Download Files</h3>\n<p>Besides the\
          \ shared local folder function, you can also use a SFTP client to upload\n\
          and download files from the X2Go Server. The below note shows you how to\
          \ use a\nSFTP client in Windows environment.</p>\n<ul>\n<li>\n<p>Go to WinSCP\
          \ official <a href=\"https://winscp.net/eng/download.php\">website</a>to\
          \ download the installer</p>\n</li>\n<li>\n<p>Double click the downloaded\
          \ executable file and follow the instructions to\n install the software</p>\n\
          </li>\n<li>\n<p>After launching the software, you should see the below login\
          \ window</p>\n</li>\n</ul>\n<p><img alt=\"snapshot12\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-12.png?raw=true\"\
          ></p>\n<ul>\n<li>On the login window, you can type in the IP address of\
          \ the Virtual Machine\n (X2Go Server) in the \u2018Host name\u2019 field\
          \ and account name in the \u2018User name\u2019 field.\n You can type in\
          \ the password if the user account uses password authentication or\n click\
          \ \u2018Advanced\u2019 button to load a private key for authentication.\
          \ See the below\n screenshot. After you click the \u2018Authentication\u2019\
          \ under the SSH section, click the\n file browser button located under \u2018\
          Private key file\u2019 and then you can select the\n private key and click\
          \ \u2018Open\u2019 button. After that, click \u2018Ok\u2019 button to go\
          \ back to\n the login window.</li>\n</ul>\n<p><img alt=\"snapshot13\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-13.png?raw=true\"\
          ></p>\n<ul>\n<li>\n<p>You can then click the Login button to connect to\
          \ the virtual machine (X2Go Server).\n You can also click the save button\
          \ to save the login session for reuse.</p>\n</li>\n<li>\n<p>After the connection\
          \ is successfully established. You should see the below window.\n On this\
          \ window, you can drag and drop files to be copied from the Client to the\n\
          \ Server or vice versa. You can also browse folder structure and select\
          \ which\n folder to be the current folder.</p>\n</li>\n</ul>\n<p><img alt=\"\
          snapshot14\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/tpac-remote-desktop-14.png?raw=true\"\
          ></p>\n<h2>Security <a name=\"security\"></a>\n</h2>\n<p>By default, there\
          \ is only one default user 'ubuntu' and it uses key based\nauthentication.\
          \ If you want to create more users to use the virtual machine, please\n\
          use key based authentication rather than password based authentication.\
          \ For a quick\nsecurity check list, please refer to <a href=\"https://support.nectar.org.au/support/solutions/articles/6000091906-security-compromise-checklist\"\
          >here</a>.</p>\n<h2>Remote Desktop Server Installation  <a name=\"installation\"\
          ></a>\n</h2>\n<p>If you would like to install an X2Go/MATE remote desktop\
          \ on your existing instance,\nthen you can find some instructions below.\
          \ It assumes that you uses Ubuntu as the\noperating system in your existing\
          \ virtual machine and TPAC has only tested it on\nUbuntu 14.04.</p>\n<h3>Install\
          \ the Mate GUI</h3>\n<p>Use your terminal application (e.g. Putty) to ssh\
          \ to the remote host\n(i.e. your virtual machine).</p>\n<p>Run the following\
          \ commands:</p>\n<p>```</p>\n<p>sudo apt-add-repository ppa:ubuntu-mate-dev/ppa\n\
          sudo apt-add-repository ppa:ubuntu-mate-dev/trusty-mate\nsudo apt-get update\n\
          sudo apt-get upgrade\nsudo apt-get install --no-install-recommends ubuntu-mate-core\
          \ ubuntu-mate-desktop\nsudo reboot</p>\n<p>```</p>\n<h3>Install x2Go on\
          \ the remote host</h3>\n<p>Use your terminal application (e.g. Putty) to\
          \ ssh to the remote host\n(i.e. your virtual machine).</p>\n<p>Run the following\
          \ commands:</p>\n<p>```</p>\n<p>sudo apt-get update\nsudo apt-get install\
          \ software-properties-common\nsudo add-apt-repository ppa:x2go/stable\n\
          sudo apt-get update\nsudo apt-get install x2goserver x2goserver-xsession</p>\n\
          <p>```</p>\n<p>For more information, please visit X2Go official <a href=\"\
          http://wiki.x2go.org/doku.php/doc:newtox2go\">website</a></p>\n<h2>Contact\
          \ <a name=\"contact\"></a>\n</h2>\n<p>If you have problems with TPAC X2Go\
          \ image, please contact TPAC help desk via\nhelpdesk@tpac.org.au, or any\
          \ help desks from your local Eresearch service providers.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 11
        id: 6000090909
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-02T23:33:33-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000090909
        position: 9
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: TPAC Remote Desktop User Guide
        updated_at: '2015-12-02T23:33:33-05:00'
        user_id: 6002464727
  html: "<ul>\n<li><a href=\"#intro\">Introduction</a></li>\n<li><a href=\"#desktop\"\
    >X2Go Remote Desktop</a></li>\n<li><a href=\"#image\">TPAC Remote Desktop Image</a></li>\n\
    <li><a href=\"#guide\">TPAC Remote Desktop (X2Go) User Guide</a></li>\n<li><a\
    \ href=\"#security\">Security</a></li>\n<li><a href=\"#installation\">Remote Desktop\
    \ Server Installation</a></li>\n<li><a href=\"#contact\">Contact</a></li>\n</ul>\n\
    <h2>Introduction <a name=\"intro\"></a></h2>\n<p>A remote desktop is a service\
    \ that allows a user to access and view an operating\nsystem\u2019s desktop session\
    \ that is running on another computer in another\ngeographical location.  The\
    \ access occurs via the Internet or through local area\nnetwork and enables users\
    \ to  interact with at system as if they were physically\nat their own computer.\
    \ </p>\n<p>In a remote desktop setup, the local computer receives a copy of the\
    \ desktop\nimage from the remote computer updated regularly or when a change is\
    \ detected.\nThe local computer\u2019s keyboard and mouse inputs are transferred\
    \ to the remote\ncomputer, where the remote desktop software implements the instructions\n\
    accordingly. </p>\n<p>Protocols for remote desktop include Remote Desktop Protocol(RDP),\
    \ virtual\nnetwork computing (VNC) and NX technology.</p>\n<p>Virtual machines\
    \ running in the Nectar Cloud can be accessed via a remote\ndesktop service, which\
    \ allows users to access the virtual machines through a\ndesktop GUI rather than\
    \ a traditional command line console.</p>\n<p>Accessing virtual machine through\
    \ a remote desktop provides many benefits over\ntraditional local computer access:</p>\n\
    <ul>\n<li>\n<p>Allowing users to access a \u2018workplace\u2019 computer from\
    \ any location</p>\n</li>\n<li>\n<p>More computing power than is available in\
    \ user\u2019s local computer</p>\n</li>\n<li>\n<p>Easy to share data and to collaborate\
    \ among users</p>\n</li>\n<li>\n<p>More reliable computer system that offers 24\
    \ hours access</p>\n</li>\n<li>\n<p>More storage options and larger disk size</p>\n\
    </li>\n<li>\n<p>Better technical supports as the virtual machine can be easily\
    \ accessed by a\n system administrator</p>\n</li>\n<li>\n<p>Enables running GUI\
    \ applications (e.g.Matlab, R-Studio desktop edition) in the\n Cloud </p>\n</li>\n\
    <li>\n<p>Multiple users can access the remote computer at the same time</p>\n\
    </li>\n</ul>\n<h2>X2Go Remote Desktop <a name=\"desktop\"></a></h2>\n<p>x2go is\
    \ a free remote desktop tool using NX technology for low latency access to\ngraphical\
    \ applications running on remote computers (such as NeCTAR virtual\nmachines).\
    \  It's much more elegant and easier to use than VNC over ssh, or\nfreeNX or the\
    \ like.  Features include:</p>\n<ul>\n<li>\n<p>Simple installation</p>\n</li>\n\
    <li>\n<p>Client supports windows, mac and linux</p>\n</li>\n<li>\n<p>Traffic is\
    \ securely tunneled over SSH</p>\n</li>\n<li>\n<p>Very fast window redraw, low\
    \ latency feedback on user input.</p>\n</li>\n<li>\n<p>Dynamic window re-scaling\
    \ (you can drag the x2go window to resize it, and the\n remote windows resize\
    \ too)</p>\n</li>\n<li>\n<p>Supports multiple desktop environments (MAte, GNOME,\
    \ KDE, etc.)</p>\n</li>\n<li>\n<p>Copy and paste passthrough</p>\n</li>\n<li>\n\
    <p>Sound, printing and remote file sharing (all untested at this stage)</p>\n\
    </li>\n</ul>\n<p>For more information about X2Go, please refer to its offical\
    \ website<a href=\"http://wiki.x2go.org/doku.php/doc:newtox2go\">x2go</a></p>\n\
    <h3>X20Go Client</h3>\n<p>The X2Go Client is the client application that connects\
    \ to a remote server and a\ndisplay a graphical desktop on a local machine. The\
    \ client requires X11 Server\ninstalled on the local machine. On windows, the\
    \ X11 Server has included in the\ninstallation. On Linux, the client uses the\
    \ local Xorg Server. On Mac, XQuartz\nX11 server is required in order for the\
    \ client to function.</p>\n<h3>X2Go Server</h3>\n<p>The X2Go server is the server\
    \ application that runs on the remote machine. It\nstarts the application desktop\
    \ sessions and transfers the desktop to the client,\nwhich is the X20Go client.\
    \ </p>\n<p>For more information about X2G0, please visit X2Go official <a href=\"\
    http://wiki.x2go.org/doku.php/doc:newtox2go\">website</a></p>\n<h2>TPAC Remote\
    \ Desktop Image <a name=\"image\"></a></h2>\n<p>You can install X2Go server on\
    \ any supported Linux distributions on the virtual\nmachines in NecTAR Cloud and\
    \ access that machines from anywhere over a network.\nCurrently, TPAC provides\
    \ a Image in NecTAR Cloud with X2Go Server pre-installed.\nUsers can utilize this\
    \ image to launch a Virtual Machine for their applications\nrequire remote desktop.\
    \ The image also contains a GUI desktop application (Mate),\nthat provides the\
    \ GUI environment for users to images applications in Ubuntu.\nThe below lists\
    \ what software packages have been pre-installed:</p>\n<ul>\n<li>\n<p>Ubuntu 14.04\
    \ (operating system)</p>\n</li>\n<li>\n<p>X2Go Server (remote desktop server)</p>\n\
    </li>\n<li>\n<p>Mate 1.8.1 (GUI desktop)</p>\n</li>\n<li>\n<p>Python 2.7.6 and\
    \ Python 3.4</p>\n</li>\n<li>\n<p>openjdk-7</p>\n</li>\n<li>\n<p>nano</p>\n</li>\n\
    <li>\n<p>gcc 4.8, g++ 4.8</p>\n</li>\n<li>\n<p>gimp</p>\n</li>\n</ul>\n<h2>TPAC\
    \ Remote Desktop (X2Go) User Guide <a name=\"guide\"></a></h2>\n<p>TPAC recommends\
    \ X2Go and MATE desktop environment for providing remote desktop\ncapability to\
    \ NeCTAR virtual machines. This guide is about how to install and\nuse three components\
    \ to make an X2Go remote desktop run in your virtual machine. \nThe GUI provider\
    \ (MATE) (on your virtual machine), the X2Go server (on your\nvirtual machine),\
    \ and the X2Go client (on your local machine). If you use one of\nthe TPAC provided\
    \ X2Go/MATE enabled images as the basis of your VM, then you\nonly need to ensure\
    \ the you have an X2Go Client installed; the X2Go Server and\nthe MATE GUI provider\
    \ are already installed for you. </p>\n<p>General requirements:</p>\n<ul>\n<li>\n\
    <p>A supported Linux operating system on the remote host</p>\n</li>\n<li>\n<p>Windows,\
    \ OSX or Linux on the client side.</p>\n</li>\n<li>\n<p>X2Go server installed\
    \ on the remote host, no further configuration is required.\n You can use TPAC\
    \ rebuild image to launch a virtual machine as it has pre-installed\n the X2Go\
    \ Server and MATE Desktop.</p>\n</li>\n<li>\n<p>An account with ssh access on\
    \ the remote host (either via certificates or password)</p>\n</li>\n<li>\n<p>X2Go\
    \ client installed and configured to talk to the remote host</p>\n</li>\n</ul>\n\
    <h3>What you need</h3>\n<p>Aside from computer and network access, you will need\
    \ to be an <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
    >Australian Access Federation</a>\neligible researcher to access the NeCTAR cloud.\
    \ You will also have to use key-pair\nsecurity for your <a href=\"https://support.nectar.org.au/support/solutions/articles/6000077794-getting-started\"\
    >virtual machine authentication</a>.\nUpon first NeCTAR cloud use, AAF eligible\
    \ researchers are issued with a limited\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000055380-resources-available-to-you\"\
    >trial allocation</a> that will do just fine for trying the\nTPAC RStudio in the\
    \ research cloud. If you need more resources, such as CPU, data\nstorage space,\
    \ or you need it for longer than your trial allocation, then you can\nrequest\
    \ a <a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
    >NeCTAR allocation</a>.</p>\n<h3>X2Go Client Installation</h3>\n<h4>X2Go Client\
    \ on Windows</h4>\n<p>Install X2Go Client on Windows is straightforward. You can\
    \ go to this <a href=\"http://code.x2go.org/releases/binary-win32/x2goclient/releases/4.0.5.0-2015.07.31/\"\
    >link</a>\nto download the windows executable file. After the download, double\
    \ click the\nexecutable file and follow the instructions on the screen. Once you\
    \ have finished\nthe installation, you can double click the X2Go icon to start\
    \ the client.</p>\n<h4>X2Go Client on OS X</h4>\n<p>You need to install OS X X11\
    \ server first before you can use the X2go Is Client.\nThe X2Go OS X client use\
    \ OS X X11 server and you can obtain it(.dmg) from <a href=\"http://www.xquartz.org/\"\
    >xquartz</a>.</p>\n<p>To install x2Go Client on OS X, please go to this <a href=\"\
    http://code.x2go.org/releases/binary-macosx/x2goclient/\">link</a> to download\
    \ the\ninstallation packages (.dmg) matching your IOS version.</p>\n<p>The below\
    \ instruction shows how to install a .dmf file:</p>\n<ul>\n<li>\n<p>double click\
    \ the .dmf file to make its content available</p>\n</li>\n<li>\n<p>drag the application\
    \ from the .dmf window into /Applications to install</p>\n</li>\n<li>\n<p>wait\
    \ for the copy process to finish</p>\n</li>\n<li>\n<p>eject the .dmf file</p>\n\
    </li>\n<li>\n<p>delete the .dmf file</p>\n</li>\n</ul>\n<h4>X2Go Client on Linux</h4>\n\
    <p>Ubuntu/Debian\napt-get install x2goclient</p>\n<p>Fedora\nyum install x2goclient</p>\n\
    <p>Redhat\nPlease go to this <a href=\"http://wiki.x2go.org/doku.php/wiki:repositories:redhat\"\
    >link</a> for detailed instruction.</p>\n<h3>Use X2Go Client</h3>\n<p>The below\
    \ instruction shows how to set up X2Go Client to connect to a remote\nvirtual\
    \ machine with X2Go client preinstalled in windows environment. For\ninstructions\
    \ in Linux and OS X, please refer to X2Go official <a href=\"http://wiki.x2go.org/doku.php/doc:newtox2go\"\
    >website</a>.</p>\n<ul>\n<li>Double click X2Go Client icon on the desktop, or\
    \ you can search it through windows search function.\n You should see the below\
    \ screenshot:</li>\n</ul>\n<p><img alt=\"snapshot1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-1.png?raw=true\"\
    ></p>\n<ul>\n<li>You need to create a session to connect to the remote virtual\
    \ machine desktop.\n Click \u2018session\u2019 menu and then click \u2018New session\u2019\
    \ menu time. You should see the\n below screenshot:</li>\n</ul>\n<p><img alt=\"\
    snapshot2\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-2.png?raw=true\"\
    ></p>\n<ul>\n<li>You can provide a Session name, the IP of the virtual machine\
    \ in Host field\n and the user account in Login field. In Use RSA/DSA key for\
    \ ssh connection\n field, put the private key matching the public key used when\
    \ launching the\n virtual machine in NecTAR Cloud. In the Session type list, select\
    \ MATE as your\n desktop. You can also select other desktop type if it is installed\
    \ on your\n virtual machine. Then, click OK and you should see something like\
    \ the below\n screenshot:</li>\n</ul>\n<p><img alt=\"snapshot3\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-3.png?raw=true\"\
    ></p>\n<ul>\n<li>Double click that new icon on the right hand side of X2Go window,\
    \ you should\n see the mate desktop</li>\n</ul>\n<p><img alt=\"snapshot4\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-4.png?raw=true\"\
    ></p>\n<h3>Launch a Virtual Machine With X2Go</h3>\n<p>You can follow the below\
    \ instruction to launch a virtual machine in NeCTAR cloud\nusing the TPAC pre-build\
    \ X2Go Image. For details how to launch a virtual machine\nin NeCTAR cloud, you\
    \ can refer to this <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055376-launching-virtual-machines\"\
    >link</a>.</p>\n<ul>\n<li>\n<p>Go to NeCTAR <a href=\"https://dashboard.rc.nectar.org.au\"\
    >Dashboard</a></p>\n</li>\n<li>\n<p>Select a project</p>\n</li>\n<li>\n<p>Click\
    \ \u2018Images\u2019 and in the image list find image \u2018TPAC core.003 1448253981\u2019\
    </p>\n</li>\n</ul>\n<p><img alt=\"snapshot15\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-15.png?raw=true\"\
    ></p>\n<ul>\n<li>Click associated \u2018Launch\u2019 button and follow the instructions\
    \ on the pop up\n window. Provide some information for the virtual machine, such\
    \ as name and flavour.\n The desktop application such as Mate requires larger\
    \ root disk size, so it is\n preferred to use flavour m2.small, m2.medium, m2.large\
    \ and m2.xlarge as these\n flavours have 30G root disk. </li>\n</ul>\n<p><img\
    \ alt=\"snapshot16\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-16.png?raw=true\"\
    ></p>\n<ul>\n<li>Click 'Access &amp; Security' tab, select the key pair for authentication\
    \ and the\n security group. For how to generate a key pair in NecTAR Dashboard,\
    \ please refer to\n this <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055376-launching-virtual-machines\"\
    >link</a>. You also need to open port 22, as X2Go uses it for communication\n\
    \ between X2Go Server and Client. So please ensure ticking the security group\
    \ with ssh\n 22 open.</li>\n</ul>\n<p><img alt=\"snapshot17\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-17.png?raw=true\"\
    ></p>\n<ul>\n<li>Click 'Availability Zone 'tab. Select the required location of\
    \ virtualm achine.\n Click \u2018Launch\u2019 button. It might take various minutes\
    \ to launch a virtual\n machine up to the chosen availability zone.</li>\n</ul>\n\
    <p><img alt=\"snapshot18\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-18.png?raw=true\"\
    ></p>\n<p>Now, you should have a working X2Go server and you can use X2Go client\
    \ (refer\nto above document) to connect to it. The X2Go has a default user account\n\
    available which is same as the image default account. For Ubuntu image, the\n\
    default user is ubuntu. You can find more default users for other operating\n\
    systems at this <a href=\"https://wiki.rc.nectar.org.au/wiki/Image_Catalog\">link</a>.</p>\n\
    <h3>Introduction to MATE Desktop</h3>\n<p>The TPAC pre-build X2Go image has Mate\
    \ Desktop installed as its default desktop\napplication. The MATE Desktop Environment\
    \ is derived from GNOME 2 and it provides\nan attractive and user-friendly interface\
    \ for Linux. The below note explains how\nto use the MATE interface and how to\
    \ start applications, and how to explore the\nfile system.</p>\n<p>For more information\
    \ about Mate Desktop, please refer to Mate Desktop official\n<a href=\"http://mate-desktop.org/\"\
    >website</a>.</p>\n<h4>Elements of the MATE Desktop</h4>\n<p>The MATE Desktop\
    \ contains a link to your home directory file browser and the Edge\nPanel on the\
    \ right top corner. The Edge Panel has a calendar, a power off button\nand a network\
    \ monitor. On the left top corner is the Applications menu, where you\ncan start\
    \ installed applications. See the below screenshot:</p>\n<p><img alt=\"snapshot4\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-4.png?raw=true\"\
    ></p>\n<h4>Launching Applications with the Application Menu</h4>\n<p>The Applications\
    \ menu is where you find and launch applications. Move your mouse\npointer over\
    \ the Application Menu and click to open the menu. All applications\nare grouped\
    \ by a name such as Accessories and System Tools. To start an application\nsuch\
    \ as \u2018MATE Terminal\u2019, move mouse pointer over the group name, in this\
    \ case it\nis \u2018System Tools\u2019 and this expands the menu to contain a\
    \ sub menu. From the sub\nmenu, move mouse pointer over the \u2018MATE Terminal\u2019\
    \ and click. It is possible to\nhave have more level of sub-menus and the launching\
    \ process is the same.</p>\n<p><img alt=\"snapshot5\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-5.png?raw=true\"\
    ></p>\n<h4>Managing File System</h4>\n<p>The MATE Desktop contains a link to your\
    \ home directory and you can simply double\nclick that to open the file browser.\
    \ You can also find the file browser from the\n\u2018Application menu\u2019 under\
    \ the \u2018System Tools\u2019 group. The menu item name is \u2018Caja\u2019.</p>\n\
    <p><img alt=\"snapshot6\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-6.png?raw=true\"\
    ></p>\n<p>The file browser shown above displays all files and folders under the\
    \ account\nubuntu\u2019s home directory. If you right click your mouse and this\
    \ should bring the\ncontext menu, see above screenshot. You can click the \u2018\
    Empty File\u2019 menu item\nunder the \u2018Create Document\u2019 to create a\
    \ new empty file or click \u2018Create Folder\u2019\nto create a new folder. On\
    \ the left hand side has a list of folders under your\nhome folder for your convenience.\
    \ You can also click the left arrow button on the\ntoolbar to navigate to parent\
    \ folder.</p>\n<h4>Change System settings</h4>\n<p>Besides the Applications menu,\
    \ there is a System menu, which you can use to\nperform system related functions\
    \ such as change the Fonts and Desktop appearances.\nAll these functions are under\
    \ Preferences menu.</p>\n<p><img alt=\"snapshot7\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-7.png?raw=true\"\
    ></p>\n<h3>Add Accounts on The X2Go Server</h3>\n<p>The MATE Desktop session is\
    \ associated with the system user account. By default\nin Ubuntu, this user account\
    \ is ubuntu. If you want to add more accounts to\naccess the X2Go Desktop, you\
    \ can add more system user accounts and X2Go will\nautomatically link the accounts\
    \ to the X2Go Desktop session. The below note shows\nhow to add a user account\
    \ to Ubuntu. For other operating systems, please refer to the relevant documents.</p>\n\
    <ul>\n<li>\n<p>Open a \u2018Mate Terminal\u2019 and type \u2018sudo adduser test\u2019\
    </p>\n</li>\n<li>\n<p>The console prompts a series of questions. The procedure\
    \ will be:</p>\n</li>\n<li>\n<p>Assign and confirm a password</p>\n</li>\n<li>\n\
    <p>Enter any additional information about the new user account</p>\n</li>\n<li>\n\
    <p>Type \u2018Y\u2019 to confirm and create the new user account</p>\n</li>\n\
    <li>\n<p>You can also add user to sudo group to give the user account sudo permission.\n\
    \ Type sudo usermod -aG sudo username</p>\n</li>\n</ul>\n<p>Note, by default,\
    \ user password authentication is disabled and you need to enable\nit first before\
    \ you can use password to login. Please edit the /etc/ssh/sshd_config\nfile and\
    \ set keyword PasswordAuthentication to yes to enable it.</p>\n<p>Now you should\
    \ have a new user created. To use this account to login to X2Go session,\nsimply\
    \ create a new session in the X2Go Client and add the new username in the Login\n\
    field. Once you have created the session, you can double click the session and\
    \ type\nin the password. You should see the MATE desktop after that.</p>\n<h3>Create\
    \ a Shared Data Folder on the Remote Server</h3>\n<p>X2Go provides a feature to\
    \ allow folder on a local computer such as a Laptop to\nbe shared with the X2Go\
    \ server. That means you can easily share your data and\nfiles between the X2Go\
    \ Client and Server. The below note demonstrates how to\nenable this feature using\
    \ X2Go Windows Client.</p>\n<ul>\n<li>\n<p>Double click the the X2Go icon on the\
    \ Windows Desktop</p>\n</li>\n<li>\n<p>This brings up the X2Go Client window.\
    \ Click the \u2018Session\u2019 menu and click the\n \u2018Session management\u2018\
    . This should bring you the screenshot like below:</p>\n</li>\n</ul>\n<p><img\
    \ alt=\"snapshot8\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-8.png?raw=true\"\
    ></p>\n<ul>\n<li>Find the session you want to share folder with the X2Go Server\
    \ and double click\n the session name. On the pop out window, click \u2018Shared\
    \ folders\u2019 tab and this\n should bring you the below screenshot. Please refer\
    \ to the above document to\n find out how to create a new session</li>\n</ul>\n\
    <p><img alt=\"snapshot9\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-9.png?raw=true\"\
    ></p>\n<ul>\n<li>\n<p>Click the \u2018file browser\u2019 button and in the pop\
    \ up window, select the local\n folder you want to share and click \u2018Select\
    \ Folder\u2019 button.</p>\n</li>\n<li>\n<p>Click the \u2018Add button\u2019 and\
    \ the folder name should be appeared in the list. Then\n tick Automount checkbox.\
    \ See below screenshot:</p>\n</li>\n</ul>\n<p><img alt=\"snapshot10\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-10.png?raw=true\"\
    ></p>\n<ul>\n<li>\n<p>Click \u2018Ok\u2019 button and client setup has been finished</p>\n\
    </li>\n<li>\n<p>You can double click the session and open a new connection to\
    \ X2Go Server. On\n the MATE Desktop, you should see a icon below the \u2018ubuntu\u2019\
    Home\u2019 icon. Double\n click the icon and it should open a file browser window.</p>\n\
    </li>\n</ul>\n<p><img alt=\"snapshot11\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-11.png?raw=true\"\
    ></p>\n<ul>\n<li>Now, if you copy files to your shared local folder, these files\
    \ will be appeared\n on your X2Go Server as well and vice verse.</li>\n</ul>\n\
    <p>Note, folder on your local computer should has read/write permission for X2Go\n\
    Client. Otherwise, the shared local fold cannot be accessed by X2Go Server.</p>\n\
    <h3>Upload and Download Files</h3>\n<p>Besides the shared local folder function,\
    \ you can also use a SFTP client to upload\nand download files from the X2Go Server.\
    \ The below note shows you how to use a\nSFTP client in Windows environment.</p>\n\
    <ul>\n<li>\n<p>Go to WinSCP official <a href=\"https://winscp.net/eng/download.php\"\
    >website</a>to download the installer</p>\n</li>\n<li>\n<p>Double click the downloaded\
    \ executable file and follow the instructions to\n install the software</p>\n\
    </li>\n<li>\n<p>After launching the software, you should see the below login window</p>\n\
    </li>\n</ul>\n<p><img alt=\"snapshot12\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-12.png?raw=true\"\
    ></p>\n<ul>\n<li>On the login window, you can type in the IP address of the Virtual\
    \ Machine\n (X2Go Server) in the \u2018Host name\u2019 field and account name\
    \ in the \u2018User name\u2019 field.\n You can type in the password if the user\
    \ account uses password authentication or\n click \u2018Advanced\u2019 button\
    \ to load a private key for authentication. See the below\n screenshot. After\
    \ you click the \u2018Authentication\u2019 under the SSH section, click the\n\
    \ file browser button located under \u2018Private key file\u2019 and then you\
    \ can select the\n private key and click \u2018Open\u2019 button. After that,\
    \ click \u2018Ok\u2019 button to go back to\n the login window.</li>\n</ul>\n\
    <p><img alt=\"snapshot13\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-13.png?raw=true\"\
    ></p>\n<ul>\n<li>\n<p>You can then click the Login button to connect to the virtual\
    \ machine (X2Go Server).\n You can also click the save button to save the login\
    \ session for reuse.</p>\n</li>\n<li>\n<p>After the connection is successfully\
    \ established. You should see the below window.\n On this window, you can drag\
    \ and drop files to be copied from the Client to the\n Server or vice versa. You\
    \ can also browse folder structure and select which\n folder to be the current\
    \ folder.</p>\n</li>\n</ul>\n<p><img alt=\"snapshot14\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/tpac-remote-desktop-14.png?raw=true\"\
    ></p>\n<h2>Security <a name=\"security\"></a></h2>\n<p>By default, there is only\
    \ one default user 'ubuntu' and it uses key based\nauthentication. If you want\
    \ to create more users to use the virtual machine, please\nuse key based authentication\
    \ rather than password based authentication. For a quick\nsecurity check list,\
    \ please refer to <a href=\"https://support.nectar.org.au/support/solutions/articles/6000091906-security-compromise-checklist\"\
    >here</a>.</p>\n<h2>Remote Desktop Server Installation  <a name=\"installation\"\
    ></a></h2>\n<p>If you would like to install an X2Go/MATE remote desktop on your\
    \ existing instance,\nthen you can find some instructions below. It assumes that\
    \ you uses Ubuntu as the\noperating system in your existing virtual machine and\
    \ TPAC has only tested it on\nUbuntu 14.04.</p>\n<h3>Install the Mate GUI</h3>\n\
    <p>Use your terminal application (e.g. Putty) to ssh to the remote host\n(i.e.\
    \ your virtual machine).</p>\n<p>Run the following commands:</p>\n<p>```</p>\n\
    <p>sudo apt-add-repository ppa:ubuntu-mate-dev/ppa\nsudo apt-add-repository ppa:ubuntu-mate-dev/trusty-mate\n\
    sudo apt-get update\nsudo apt-get upgrade\nsudo apt-get install --no-install-recommends\
    \ ubuntu-mate-core ubuntu-mate-desktop\nsudo reboot</p>\n<p>```</p>\n<h3>Install\
    \ x2Go on the remote host</h3>\n<p>Use your terminal application (e.g. Putty)\
    \ to ssh to the remote host\n(i.e. your virtual machine).</p>\n<p>Run the following\
    \ commands:</p>\n<p>```</p>\n<p>sudo apt-get update\nsudo apt-get install software-properties-common\n\
    sudo add-apt-repository ppa:x2go/stable\nsudo apt-get update\nsudo apt-get install\
    \ x2goserver x2goserver-xsession</p>\n<p>```</p>\n<p>For more information, please\
    \ visit X2Go official <a href=\"http://wiki.x2go.org/doku.php/doc:newtox2go\"\
    >website</a></p>\n<h2>Contact <a name=\"contact\"></a></h2>\n<p>If you have problems\
    \ with TPAC X2Go image, please contact TPAC help desk via\nhelpdesk@tpac.org.au,\
    \ or any help desks from your local Eresearch service providers.</p>"
  parent: 24
  sha1: fe20d93bd25169a4c7dc3426f4f3173b37471714
  title: TPAC Remote Desktop User Guide
93:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-24T22:38:14-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Intersect Launchpod User Guide \n Description \n Launchpod\
          \ is a tool to deploy virtual machines (VMs) on the NeCTAR Research Cloud\
          \ with one of a number of preconfigured research-based software applications.\
          \ Launchpod is designed to work like a wizard; it will take care of the\
          \ technical aspects of spawning a VM by asking the user for the relevnt\
          \ details. The software applications that can be built using Launchpod are:\
          \ \n \n \nTwitter Scraper \u2013 a tool to harvest Twitter for hashtags,\
          \ phrases, exact tweets and specific users \n \nDIVER \u2013 a general purpose\
          \ open source research data capture and sharing application \n \nOmeka \u2013\
          \ an open source Content Management System suitable for rich collections\
          \ of data and images \n \nLimeSurvey \u2013 a tool to quickly create intuitive,\
          \ powerful, online question-and-answer surveys \n \nMATLAB\xAE \u2013 a\
          \ powerful tool for numerical computation, visualization, and programming\
          \ \n \nAlveo \u2013 a virtual laboratory of tools for searching, analysing\
          \ and annotating natural language datasets \n \nCSIRO Workspace \u2013 a\
          \ powerful software platform for sharing scientific workflows in one coherent,\
          \ simple environment \n \nRStudio \u2013 a free, powerful tool for statistical\
          \ computing and graphics. \n \n Launchpod allows researchers to quickly\
          \ establish a working version of the software without the need for specialised\
          \ IT knowledge. Also, these applications are very resource-intensive, and\
          \ running them on a notebook/desktop computer can cause the machine to run\
          \ slowly, and often the machine will need to be left on for hours in order\
          \ to complete a process. Running them in the cloud means that they are less\
          \ susceptible to crashing, and will run much faster and more efficiently\
          \ on dedicated hardware, and can be left on constantly. \n Audience \n The\
          \ typical users of Launchpod are researchers who already use these tools\
          \ on existing machines and want to use them in the cloud to improve collaboration,\
          \ or upscale their use and take advantage of the NeCTAR computing environment;\
          \ or those who want to experiment with these tools and evaluate them for\
          \ their own projects without needing to configure their own machine to run\
          \ them. \n Please note: This is a guide to using Launchpod. It is not a\
          \ guide to using the applications that can be deployed with Launchpod. Some\
          \ of the applications may require additional expertise and extensive training\
          \ in order to utilise them in your research. \n Launchpod can be accessed\
          \ by any researcher from an organisation that participates in the Australian\
          \ Access Federation (AAF). All Australian universities are members of AAF.\
          \ \n How does Launchpod work \n Launchpod uses your OpenStack API password\
          \ to access your NeCTAR account and deploy instances on your behalf. It\
          \ then runs an Ansible playbook to install the necessary software packages\
          \ and dependencies in order for the user's chosen product to be installed.\
          \ Ansible is an open-source software platform used for the automation of\
          \ software deployment using a playbook, which works like a script of actions\
          \ to be completed in order. \n The way Launchpod interacts with the NeCTAR\
          \ Research Cloud and Ansible to build the user's virtual machine complete\
          \ with their chosen software product is illustrated below. \n \n Launchpod\
          \ works as follows: \n \n The user configures their OpenStack API key in\
          \ Launchpod \n Launchpod spawns a VM in the NeCTAR Research Cloud based\
          \ on the user's entered details \n The NeCTAR Research Cloud returns the\
          \ machine's IP address on completion \n Launchpod populates an Ansible playbook\
          \ using the IP address and the user's entered details \n This Ansible playbook\
          \ is then run on the NeCTAR VM and the software packages are installed and\
          \ configured according to the user's requirements. \n \n The following sections\
          \ will cover how to obtain an OpenStack API key, what sort of configuration\
          \ options are required for spawning a virtual machine, and what sort of\
          \ configuration options are required to deploy each of the available products.\
          \ \n Obtaining an OpenStack API password \n To allow Launchpod to deploy\
          \ a VM, you must first create an OpenStack API password in your NeCTAR Dashboard.\
          \ Log in to the NeCTAR Dashboard via AAF using your institutional credentials\
          \ and go to your account settings, which are accessed by hovering the mouse\
          \ over your email address in the top-right corner of the screen.  \n \n\
          \ In Settings, select Reset Password. This will display a new API password\
          \ on the screen. Copy this password and have it ready to enter into Launchpod.\
          \ \n \n Creating or resetting the API password will not affect the way you\
          \ log into NeCTAR or any other AAF service; it is only used to allow external\
          \ services to connect to your NeCTAR account. That said, if you have other\
          \ external services that use a password to log in to your NeCTAR account,\
          \ this step will reset that password and you will have to re-authenticate\
          \ those services, or otherwise use the same password from your existing\
          \ services to authenticate Launchpod. \n Once you have your Openstack API\
          \ password, go to the Launchpod website and login using AAF. You will be\
          \ prompted to enter your OpenStack API password, which you retrieved in\
          \ the last step. Enter it here and select Change Your Password.  \n \n Launchpod\
          \ is now authorised to deploy a VM on your behalf. \n Deploying a Virtual\
          \ Machine \n Clicking Deploy New Instance will open a page where Launchpod\
          \ will ask for various configuration settings. These settings correspond\
          \ to VM deployment options within the NeCTAR Research Cloud. You are encouraged\
          \ to NeCTAR support prior to using Launchpod, to understand what these settings\
          \ refer to. \n VM Settings \n The Virtual Machine settings page asks for\
          \ the following: \n \n Product \n Project \n Flavour \n SSH Key Pair \n\
          \ Availability Zone \n Instance Name \n \n Product to be deployed (Required)\
          \ \n The product is the software application (from the list above) that\
          \ this VM will run. Selecting an application will display information about\
          \ it on the right side of the screen. You can also find more information\
          \ and links to the software website on the View Products screen. \n \n NeCTAR\
          \ project (Required) \n Launchpod deploys VMs into your existing projects.\
          \ If you have never used NeCTAR before, only your personal trial project\
          \ (beginning with pt-) will be displayed. If you are registered as a user\
          \ on any allocations, each of these will be listed and you will need to\
          \ select the appropriate one. \n Please Note: Launchpod does not have the\
          \ ability to query your project resources prior to attempting to launch\
          \ a VM. If you instruct Launchpod to deploy a VM with more resources than\
          \ you have available in your project, the deployment will fail with the\
          \ error message show below. \n \n The flavour (size) of the VM (Required)\
          \ \n Selecting a VM flavour from the drop-down list will display the flavour\
          \ technical details in the pane on the right. \n The size of the VM is limited\
          \ to the resources that are available in the project. If you select a flavour\
          \ that requires more resources than your project has available, the deployment\
          \ will fail and you will be prompted to either change project or select\
          \ a smaller flavour. \n \n SSH key pair \n The keypair is used to authenticate\
          \ to the machine via SSH (protocol to securely obtain access to a remote\
          \ computer). This drop-down list will display the keypairs that you have\
          \ in your NeCTAR account. If you have not created or uploaded a keypair\
          \ in NeCTAR and you need SSH access to this server, you should use the NeCTAR\
          \ Dashboard to create a keypair before you launch a VM with Launchpod. \n\
          \ Availability zone \n If you need the server to be deployed to a particular\
          \ node of NeCTAR, then select that node in the Availability Zone drop-down\
          \ box. If this is not important to your project, leave this blank and NeCTAR\
          \ will automatically select a node with available resources. The vast majority\
          \ of users will not need to change the availability zone of their VM. \n\
          \ Instance name \n Launchpod will set a default name for your instance,\
          \ based on the name of the software product. You may change this if you\
          \ want to, but note that the purpose of the instance name is just for identification\
          \ purposes within NeCTAR and has no effect on the VM itself. \n When you\
          \ have entered all necessary settings, click Next. \n Product-specific configurations\
          \ \n Some applications require additional settings before they can be deployed.\
          \ The following sections describe each application. \n Omeka \n Omeka needs\
          \ no additional settings, and will be launched immediately after filling\
          \ in the required NeCTAR settings and clicking Deploy. Launchpod will email\
          \ you with instructions on how to access the Omeka application once it is\
          \ deployed. \n DIVER \n DIVER requires you to specify a username and password\
          \ that you will use to log into the DIVER application. You also need to\
          \ supply an email address. Launchpod will enter the email address associated\
          \ with your AAF identity by default, but you may change this. \n Please\
          \ note: DIVER is designed for use in an ongoing, production environment\
          \ and the NeCTAR Research Cloud is not designed for this purpose. As such,\
          \ deploying an instance of DIVER via Launchpod is intended for testing/review\
          \ purposes only. Intersect can assist to implement production environments\
          \ and managed services as required. Please contact your university\u2019\
          s eResearch Analyst for more information. \n LimeSurvey \n LimeSurvey requires\
          \ you to specify a username and password that you will use to log into the\
          \ LimeSurvey application. You also need to supply an email address. Launchpod\
          \ will enter the email address associated with your AAF identity by default,\
          \ but you may change this. \n MATLAB\xAE \n MATLAB\xAE is a desktop application\
          \ and not a web application, meaning that the virtual machine needs to be\
          \ configured to allow you to log into it as if it were a desktop computer.\
          \ To deploy a MATLAB\xAE instance, you will need to configure the operating\
          \ system (OS) username and password, which will be used to log into the\
          \ machine, as well as a Virtual Network Computing (VNC) password, which\
          \ is used specifically to view the machine\u2019s desktop over the web using\
          \ a remote desktop connection and VNC software. When a MATLAB\xAE VM is\
          \ deployed, Launchpod will email you instructions on how to get VNC software\
          \ to view the machine\u2019s desktop and run MATLAB\xAE. When accessing\
          \ the machine using the VNC software, you will need to enter the VNC password\
          \ that you specified in Launchpod first, and then the OS username and password,\
          \ which you will use to log into the user account, as if you were working\
          \ on a desktop computer. \n MATLAB\xAE also requires an installation key\
          \ and a licence. An installation key is a string that informs the server\
          \ which software packages it should install. If you do not have an installation\
          \ key, your university may assist you with this. MATLAB\xAE is commercial\
          \ software and requires a licence to run. If you are a researcher at a university,\
          \ there may be an institutional licence that you can use. Contact your university\u2019\
          s IT department for assistance. Launchpod does not need the licence to deploy\
          \ a MATLAB\xAE VM and it does not ask for it, but you will need to enter\
          \ a licence in order to run the MATLAB\xAE software after the VM is deployed.\
          \ \n Alveo \n Alveo requires you to specify a username and password that\
          \ you will use to log into the Alveo application. You also need to supply\
          \ an email address. Launchpod will enter the email address associated with\
          \ your AAF identity by default, but you may change this. \n Please note:\
          \ Alveo is designed for use in an ongoing, production environment and the\
          \ NeCTAR Research Cloud is not designed for this purpose. As such, deploying\
          \ an instance of Alveo via Launchpod is intended for testing/review purposes\
          \ only. Intersect can assist to implement production environments and managed\
          \ services as required. Please contact your university\u2019s eResearch\
          \ Analyst for more information. \n Twitter Scraper \n The Twitter Scraper\
          \ is a very different tool from the rest of the applications. It does not\
          \ offer a user interface, meaning you cannot log into it, and does not allow\
          \ the user to set the search parameters once it is launched. Instead, the\
          \ search parameters are set within Launchpod, and after it is deployed it\
          \ will run continuously, generating more data until it is shut off. For\
          \ this reason, Launchpod requires you to configure the parameters during\
          \ the deployment phase. Launchpod also requires access to use your Twitter\
          \ account, much like you allowed Launchpod to interact with your NeCTAR\
          \ account. \n Please see the Twitter Scraper user guide for information\
          \ on how to deploy this tool using Launchpod. \n CSIRO Workspace \n CSIRO\
          \ Workspace is a desktop application and not a web application, meaning\
          \ that the virtual machine needs to be configured to allow you to log into\
          \ it as if it were a desktop computer. To deploy a CSIRO Workspace instance,\
          \ you will need to configure the operating system (OS) username and password,\
          \ which will be used to log into the machine, as well as a Virtual Network\
          \ Computing (VNC) password, which is used specifically to view the machine\u2019\
          s desktop over the web using a remote desktop connection and VNC software.\
          \ When the VM is deployed, Launchpod will email you instructions on how\
          \ to get VNC software to view the machine\u2019s desktop and run the software.\
          \ When accessing the machine using the VNC software, you will need to enter\
          \ the VNC password that you specified in Launchpod first, and then the OS\
          \ username and password, which you will use to log into the user account,\
          \ as if you were working on a desktop computer. \n RStudio \n RStudio is\
          \ a desktop application and not a web application, meaning that the virtual\
          \ machine needs to be configured to allow you to log into it as if it were\
          \ a desktop computer. To deploy an RStudio instance, you will need to configure\
          \ the operating system (OS) username and password, which will be used to\
          \ log into the machine, as well as a Virtual Network Computing (VNC) password,\
          \ which is used specifically to view the machine\u2019s desktop over the\
          \ web using a remote desktop connection and VNC software. When the VM is\
          \ deployed, Launchpod will email you instructions on how to get VNC software\
          \ to view the machine\u2019s desktop and run the software. When accessing\
          \ the machine using the VNC software, you will need to enter the VNC password\
          \ that you specified in Launchpod first, and then the OS username and password,\
          \ which you will use to log into the user account, as if you were working\
          \ on a desktop computer. \n Deployment \n Once you have filled in all the\
          \ necessary information that Launchpod requires for your desired application,\
          \ click Deploy. The process can take as little as two minutes or up to 40\
          \ minutes depending on the number of software packages that the machine\
          \ will have to download and install for the selected product to run properly.\
          \ When the deployment process is complete, you will receive an email with\
          \ instructions on how to access your machine. This information is also available\
          \ anytime from the Launchpod homepage via the View Instance Details link.\
          \ \n To terminate a machine, you can do so either from within the NeCTAR\
          \ Dashboard, as with any NeCTAR instance, or through the Launchpod interface\
          \ by clicking the Delete link on the homepage. \n What else do I need to\
          \ know about Launchpod \n Launchpod is simply an interface used to interact\
          \ with your NeCTAR account and, as such, you are strongly encouraged to\
          \ seek advice on using the NeCTAR Research Cloud. It is important to understand\
          \ the risks associated with cloud computing and to take any appropriate\
          \ measures to mitigate those risks such as regular backups of your data\
          \ and snapshots of your systems. We recommend you consult NeCTAR User Support\
          \ for assistance with this, or contact your university's eResearch Analyst.\
          \ \n What costs are involved \n Both Launchpod and the NeCTAR Research Cloud\
          \ are free to use for all Australian researchers.  Note that this does not\
          \ include application licensing costs where applicable (e.g. MATLAB\xAE\
          ).   "
        description: "<h1>Intersect Launchpod User Guide</h1>\n<h2>Description</h2>\n\
          <p>Launchpod is a tool to deploy virtual machines (VMs) on the <a href=\"\
          http://cloud.nectar.org.au/\">NeCTAR Research Cloud</a> with one of a number\
          \ of preconfigured research-based software applications. Launchpod is designed\
          \ to work like a wizard; it will take care of the technical aspects of spawning\
          \ a VM by asking the user for the relevnt details. The software applications\
          \ that can be built using Launchpod are:</p>\n<ul>\n<li>\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000089738-intersect-twitter-scraper-user-guide\"\
          >Twitter Scraper</a> \u2013 a tool to harvest Twitter for hashtags, phrases,\
          \ exact tweets and specific users</li>\n<li>\n<a href=\"http://www.intersect.org.au/content/diver-0\"\
          >DIVER</a> \u2013 a general purpose open source research data capture and\
          \ sharing application</li>\n<li>\n<a href=\"https://omeka.org/\">Omeka</a>\
          \ \u2013 an open source Content Management System suitable for rich collections\
          \ of data and images</li>\n<li>\n<a href=\"https://www.limesurvey.org/en/\"\
          >LimeSurvey</a> \u2013 a tool to quickly create intuitive, powerful, online\
          \ question-and-answer surveys</li>\n<li>\n<a href=\"http://au.mathworks.com/products/matlab/\"\
          >MATLAB\xAE</a> \u2013 a powerful tool for numerical computation, visualization,\
          \ and programming</li>\n<li>\n<a href=\"http://alveo.edu.au/\">Alveo</a>\
          \ \u2013 a virtual laboratory of tools for searching, analysing and annotating\
          \ natural language datasets</li>\n<li>\n<a href=\"http://www.intersect.org.au/csiro\"\
          >CSIRO Workspace</a> \u2013 a powerful software platform for sharing scientific\
          \ workflows in one coherent, simple environment</li>\n<li>\n<a href=\"http://www.rstudio.com/\"\
          >RStudio</a> \u2013 a free, powerful tool for statistical computing and\
          \ graphics.</li>\n</ul>\n<p>Launchpod allows researchers to quickly establish\
          \ a working version of the software without the need for specialised IT\
          \ knowledge. Also, these applications are very resource-intensive, and running\
          \ them on a notebook/desktop computer can cause the machine to run slowly,\
          \ and often the machine will need to be left on for hours in order to complete\
          \ a process. Running them in the cloud means that they are less susceptible\
          \ to crashing, and will run much faster and more efficiently on dedicated\
          \ hardware, and can be left on constantly.</p>\n<h2>Audience</h2>\n<p>The\
          \ typical users of Launchpod are researchers who already use these tools\
          \ on existing machines and want to use them in the cloud to improve collaboration,\
          \ or upscale their use and take advantage of the NeCTAR computing environment;\
          \ or those who want to experiment with these tools and evaluate them for\
          \ their own projects without needing to configure their own machine to run\
          \ them.</p>\n<p><strong>Please note:</strong> <em>This is a guide to using\
          \ Launchpod. It is not a guide to using the applications that can be deployed\
          \ with Launchpod. Some of the applications may require additional expertise\
          \ and extensive training in order to utilise them in your research.</em></p>\n\
          <p>Launchpod can be accessed by any researcher from an organisation that\
          \ participates in the Australian Access Federation (AAF). All Australian\
          \ universities are members of AAF.</p>\n<h2>How does Launchpod work</h2>\n\
          <p>Launchpod uses your OpenStack API password to access your NeCTAR account\
          \ and deploy instances on your behalf. It then runs an Ansible playbook\
          \ to install the necessary software packages and dependencies in order for\
          \ the user's chosen product to be installed. <a href=\"http://www.ansible.com/\"\
          >Ansible</a> is an open-source software platform used for the automation\
          \ of software deployment using a <em>playbook</em>, which works like a script\
          \ of actions to be completed in order.</p>\n<p>The way Launchpod interacts\
          \ with the NeCTAR Research Cloud and Ansible to build the user's virtual\
          \ machine complete with their chosen software product is illustrated below.</p>\n\
          <p><img alt=\"launchpod_workflow\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/launchpod-launchpod-workflow.png?raw=true\"\
          \ title=\"Launchpod Workflow\"></p>\n<p>Launchpod works as follows:</p>\n\
          <ol>\n<li>The user configures their OpenStack API key in Launchpod</li>\n\
          <li>Launchpod spawns a VM in the NeCTAR Research Cloud based on the user's\
          \ entered details</li>\n<li>The NeCTAR Research Cloud returns the machine's\
          \ IP address on completion</li>\n<li>Launchpod populates an Ansible playbook\
          \ using the IP address and the user's entered details</li>\n<li>This Ansible\
          \ playbook is then run on the NeCTAR VM and the software packages are installed\
          \ and configured according to the user's requirements.</li>\n</ol>\n<p>The\
          \ following sections will cover how to obtain an OpenStack API key, what\
          \ sort of configuration options are required for spawning a virtual machine,\
          \ and what sort of configuration options are required to deploy each of\
          \ the available products.</p>\n<h3>Obtaining an OpenStack API password</h3>\n\
          <p>To allow Launchpod to deploy a VM, you must first create an OpenStack\
          \ API password in your NeCTAR Dashboard. Log in to the <a href=\"http://dashboard.rc.nectar.org.au/\"\
          >NeCTAR Dashboard</a> via AAF using your institutional credentials and go\
          \ to your account settings, which are accessed by hovering the mouse over\
          \ your email address in the top-right corner of the screen. </p>\n<p><img\
          \ alt=\"nectar-settings\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/launchpod-user-settings.png?raw=true\"\
          \ title=\"NeCTAR User Settings\"></p>\n<p>In Settings, select <em>Reset\
          \ Password</em>. This will display a new API password on the screen. Copy\
          \ this password and have it ready to enter into Launchpod.</p>\n<p><img\
          \ alt=\"reset-password\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/launchpod-reset-password.png?raw=true\"\
          \ title=\"Reset Password\"></p>\n<p>Creating or resetting the API password\
          \ will not affect the way you log into NeCTAR or any other AAF service;\
          \ it is only used to allow external services to connect to your NeCTAR account.\
          \ That said, if you have other external services that use a password to\
          \ log in to your NeCTAR account, this step will reset that password and\
          \ you will have to re-authenticate those services, or otherwise use the\
          \ same password from your existing services to authenticate Launchpod.</p>\n\
          <p>Once you have your Openstack API password, go to the Launchpod website\
          \ and login using AAF. You will be prompted to enter your OpenStack API\
          \ password, which you retrieved in the last step. Enter it here and select\
          \ <em>Change Your Password</em>. </p>\n<p><img alt=\"change-password\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/launchpod-change-password.png?raw=true\"\
          \ title=\"Change Password\"></p>\n<p>Launchpod is now authorised to deploy\
          \ a VM on your behalf.</p>\n<h3>Deploying a Virtual Machine</h3>\n<p>Clicking\
          \ <em>Deploy New Instance</em> will open a page where Launchpod will ask\
          \ for various configuration settings. These settings correspond to VM deployment\
          \ options within the NeCTAR Research Cloud. You are encouraged to NeCTAR\
          \ support prior to using Launchpod, to understand what these settings refer\
          \ to.</p>\n<h4>VM Settings</h4>\n<p>The Virtual Machine settings page asks\
          \ for the following:</p>\n<ul>\n<li>Product</li>\n<li>Project</li>\n<li>Flavour</li>\n\
          <li>SSH Key Pair</li>\n<li>Availability Zone</li>\n<li>Instance Name</li>\n\
          </ul>\n<h5>Product to be deployed (Required)</h5>\n<p>The <em>product</em>\
          \ is the software application (from the list above) that this VM will run.\
          \ Selecting an application will display information about it on the right\
          \ side of the screen. You can also find more information and links to the\
          \ software website on the <em>View Products</em> screen.</p>\n<p><img alt=\"\
          product-details\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/launchpod-product-details.png?raw=true\"\
          \ title=\"Product Details\"></p>\n<h5>NeCTAR project (Required)</h5>\n<p>Launchpod\
          \ deploys VMs into your existing projects. If you have never used NeCTAR\
          \ before, only your personal trial project (beginning with <em>pt-</em>)\
          \ will be displayed. If you are registered as a user on any allocations,\
          \ each of these will be listed and you will need to select the appropriate\
          \ one.</p>\n<p><strong>Please Note</strong>: <em>Launchpod does not have\
          \ the ability to query your project resources prior to attempting to launch\
          \ a VM. If you instruct Launchpod to deploy a VM with more resources than\
          \ you have available in your project, the deployment will fail with the\
          \ error message show below.</em></p>\n<p><img alt=\"insufficient-resources\"\
          \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/launchpod-insufficient-resources.png?raw=true\"\
          \ title=\"Insufficient Resources\"></p>\n<h5>The <em>flavour</em> (size)\
          \ of the VM (Required)</h5>\n<p>Selecting a VM flavour from the drop-down\
          \ list will display the flavour technical details in the pane on the right.</p>\n\
          <p>The size of the VM is limited to the resources that are available in\
          \ the project. If you select a flavour that requires more resources than\
          \ your project has available, the deployment will fail and you will be prompted\
          \ to either change project or select a smaller flavour.</p>\n<p><img alt=\"\
          flavour\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/launchpod-flavour.png?raw=true\"\
          \ title=\"Flavour\"></p>\n<h5>SSH key pair</h5>\n<p>The keypair is used\
          \ to authenticate to the machine via SSH (protocol to securely obtain access\
          \ to a remote computer). This drop-down list will display the keypairs that\
          \ you have in your NeCTAR account. If you have not created or uploaded a\
          \ keypair in NeCTAR and you need SSH access to this server, you should use\
          \ the NeCTAR Dashboard to create a keypair before you launch a VM with Launchpod.</p>\n\
          <h5>Availability zone</h5>\n<p>If you need the server to be deployed to\
          \ a particular node of NeCTAR, then select that node in the <em>Availability\
          \ Zone</em> drop-down box. If this is not important to your project, leave\
          \ this blank and NeCTAR will automatically select a node with available\
          \ resources. The vast majority of users will not need to change the availability\
          \ zone of their VM.</p>\n<h5>Instance name</h5>\n<p>Launchpod will set a\
          \ default name for your instance, based on the name of the software product.\
          \ You may change this if you want to, but note that the purpose of the instance\
          \ name is just for identification purposes within NeCTAR and has no effect\
          \ on the VM itself.</p>\n<p>When you have entered all necessary settings,\
          \ click <em>Next</em>.</p>\n<h4>Product-specific configurations</h4>\n<p>Some\
          \ applications require additional settings before they can be deployed.\
          \ The following sections describe each application.</p>\n<h5>Omeka</h5>\n\
          <p>Omeka needs no additional settings, and will be launched immediately\
          \ after filling in the required NeCTAR settings and clicking <em>Deploy</em>.\
          \ Launchpod will email you with instructions on how to access the Omeka\
          \ application once it is deployed.</p>\n<h5>DIVER</h5>\n<p>DIVER requires\
          \ you to specify a username and password that you will use to log into the\
          \ DIVER application. You also need to supply an email address. Launchpod\
          \ will enter the email address associated with your AAF identity by default,\
          \ but you may change this.</p>\n<p><strong>Please note:</strong> <em>DIVER\
          \ is designed for use in an ongoing, production environment and the NeCTAR\
          \ Research Cloud is not designed for this purpose. As such, deploying an\
          \ instance of DIVER via Launchpod is intended for testing/review purposes\
          \ only. Intersect can assist to implement production environments and managed\
          \ services as required. Please contact your university\u2019s <a href=\"\
          http://intersect.org.au/content/eresearch-analysts\">eResearch Analyst</a>\
          \ for more information.</em></p>\n<h5>LimeSurvey</h5>\n<p>LimeSurvey requires\
          \ you to specify a username and password that you will use to log into the\
          \ LimeSurvey application. You also need to supply an email address. Launchpod\
          \ will enter the email address associated with your AAF identity by default,\
          \ but you may change this.</p>\n<h5>MATLAB\xAE</h5>\n<p>MATLAB\xAE is a\
          \ desktop application and not a web application, meaning that the virtual\
          \ machine needs to be configured to allow you to log into it as if it were\
          \ a desktop computer. To deploy a MATLAB\xAE instance, you will need to\
          \ configure the operating system (OS) username and password, which will\
          \ be used to log into the machine, as well as a Virtual Network Computing\
          \ (VNC) password, which is used specifically to view the machine\u2019s\
          \ desktop over the web using a remote desktop connection and VNC software.\
          \ When a MATLAB\xAE VM is deployed, Launchpod will email you instructions\
          \ on how to get VNC software to view the machine\u2019s desktop and run\
          \ MATLAB\xAE. When accessing the machine using the VNC software, you will\
          \ need to enter the VNC password that you specified in Launchpod first,\
          \ and then the OS username and password, which you will use to log into\
          \ the user account, as if you were working on a desktop computer.</p>\n\
          <p>MATLAB\xAE also requires an installation key and a licence. An installation\
          \ key is a string that informs the server which software packages it should\
          \ install. If you do not have an installation key, your university may assist\
          \ you with this. MATLAB\xAE is commercial software and requires a licence\
          \ to run. If you are a researcher at a university, there may be an institutional\
          \ licence that you can use. Contact your university\u2019s IT department\
          \ for assistance. Launchpod does not need the licence to deploy a MATLAB\xAE\
          \ VM and it does not ask for it, but you will need to enter a licence in\
          \ order to run the MATLAB\xAE software after the VM is deployed.</p>\n<h5>Alveo</h5>\n\
          <p>Alveo requires you to specify a username and password that you will use\
          \ to log into the Alveo application. You also need to supply an email address.\
          \ Launchpod will enter the email address associated with your AAF identity\
          \ by default, but you may change this.</p>\n<p><strong>Please note:</strong>\
          \ <em>Alveo is designed for use in an ongoing, production environment and\
          \ the NeCTAR Research Cloud is not designed for this purpose. As such, deploying\
          \ an instance of Alveo via Launchpod is intended for testing/review purposes\
          \ only. Intersect can assist to implement production environments and managed\
          \ services as required. Please contact your university\u2019s <a href=\"\
          http://intersect.org.au/content/eresearch-analysts\">eResearch Analyst</a>\
          \ for more information.</em></p>\n<h5>Twitter Scraper</h5>\n<p>The Twitter\
          \ Scraper is a very different tool from the rest of the applications. It\
          \ does not offer a user interface, meaning you cannot log into it, and does\
          \ not allow the user to set the search parameters once it is launched. Instead,\
          \ the search parameters are set within Launchpod, and after it is deployed\
          \ it will run continuously, generating more data until it is shut off. For\
          \ this reason, Launchpod requires you to configure the parameters during\
          \ the deployment phase. Launchpod also requires access to use your Twitter\
          \ account, much like you allowed Launchpod to interact with your NeCTAR\
          \ account.</p>\n<p>Please see the <a href=\"https://support.nectar.org.au/support/solutions/articles/6000089738-intersect-twitter-scraper-user-guide\"\
          >Twitter Scraper user guide</a> for information on how to deploy this tool\
          \ using Launchpod.</p>\n<h5>CSIRO Workspace</h5>\n<p>CSIRO Workspace is\
          \ a desktop application and not a web application, meaning that the virtual\
          \ machine needs to be configured to allow you to log into it as if it were\
          \ a desktop computer. To deploy a CSIRO Workspace instance, you will need\
          \ to configure the operating system (OS) username and password, which will\
          \ be used to log into the machine, as well as a Virtual Network Computing\
          \ (VNC) password, which is used specifically to view the machine\u2019s\
          \ desktop over the web using a remote desktop connection and VNC software.\
          \ When the VM is deployed, Launchpod will email you instructions on how\
          \ to get VNC software to view the machine\u2019s desktop and run the software.\
          \ When accessing the machine using the VNC software, you will need to enter\
          \ the VNC password that you specified in Launchpod first, and then the OS\
          \ username and password, which you will use to log into the user account,\
          \ as if you were working on a desktop computer.</p>\n<h5>RStudio</h5>\n\
          <p>RStudio is a desktop application and not a web application, meaning that\
          \ the virtual machine needs to be configured to allow you to log into it\
          \ as if it were a desktop computer. To deploy an RStudio instance, you will\
          \ need to configure the operating system (OS) username and password, which\
          \ will be used to log into the machine, as well as a Virtual Network Computing\
          \ (VNC) password, which is used specifically to view the machine\u2019s\
          \ desktop over the web using a remote desktop connection and VNC software.\
          \ When the VM is deployed, Launchpod will email you instructions on how\
          \ to get VNC software to view the machine\u2019s desktop and run the software.\
          \ When accessing the machine using the VNC software, you will need to enter\
          \ the VNC password that you specified in Launchpod first, and then the OS\
          \ username and password, which you will use to log into the user account,\
          \ as if you were working on a desktop computer.</p>\n<h3>Deployment</h3>\n\
          <p>Once you have filled in all the necessary information that Launchpod\
          \ requires for your desired application, click <em>Deploy</em>. The process\
          \ can take as little as two minutes or up to 40 minutes depending on the\
          \ number of software packages that the machine will have to download and\
          \ install for the selected product to run properly. When the deployment\
          \ process is complete, you will receive an email with instructions on how\
          \ to access your machine. This information is also available anytime from\
          \ the Launchpod homepage via the <em>View Instance Details</em> link.</p>\n\
          <p>To terminate a machine, you can do so either from within the NeCTAR Dashboard,\
          \ as with any NeCTAR instance, or through the Launchpod interface by clicking\
          \ the <em>Delete</em> link on the homepage.</p>\n<h2>What else do I need\
          \ to know about Launchpod</h2>\n<p>Launchpod is simply an interface used\
          \ to interact with your NeCTAR account and, as such, you are strongly encouraged\
          \ to seek advice on using the NeCTAR Research Cloud. It is important to\
          \ understand the risks associated with cloud computing and to take any appropriate\
          \ measures to mitigate those risks such as regular backups of your data\
          \ and snapshots of your systems. We recommend you consult NeCTAR User Support\
          \ for assistance with this, or contact your university's <a href=\"http://intersect.org.au/content/eresearch-analysts\"\
          >eResearch Analyst</a>.</p>\n<h2>What costs are involved</h2>\n<p>Both Launchpod\
          \ and the NeCTAR Research Cloud are free to use for all Australian researchers.\
          \  Note that this does not include application licensing costs where applicable\
          \ (e.g. MATLAB\xAE).  </p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000091614
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-24T22:38:14-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000091614
        position: 7
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Intersect Launchpod User Guide
        updated_at: '2015-11-24T22:38:14-05:00'
        user_id: 6002464727
  html: "<h1>Intersect Launchpod User Guide</h1>\n<h2>Description</h2>\n<p>Launchpod\
    \ is a tool to deploy virtual machines (VMs) on the <a href=\"http://cloud.nectar.org.au/\"\
    >NeCTAR Research Cloud</a> with one of a number of preconfigured research-based\
    \ software applications. Launchpod is designed to work like a wizard; it will\
    \ take care of the technical aspects of spawning a VM by asking the user for the\
    \ relevnt details. The software applications that can be built using Launchpod\
    \ are:</p>\n<ul>\n<li><a href=\"https://support.nectar.org.au/support/solutions/articles/6000089738-intersect-twitter-scraper-user-guide\"\
    >Twitter Scraper</a> \u2013 a tool to harvest Twitter for hashtags, phrases, exact\
    \ tweets and specific users</li>\n<li><a href=\"http://www.intersect.org.au/content/diver-0\"\
    >DIVER</a> \u2013 a general purpose open source research data capture and sharing\
    \ application</li>\n<li><a href=\"https://omeka.org/\">Omeka</a> \u2013 an open\
    \ source Content Management System suitable for rich collections of data and images</li>\n\
    <li><a href=\"https://www.limesurvey.org/en/\">LimeSurvey</a> \u2013 a tool to\
    \ quickly create intuitive, powerful, online question-and-answer surveys</li>\n\
    <li><a href=\"http://au.mathworks.com/products/matlab/\">MATLAB\xAE</a> \u2013\
    \ a powerful tool for numerical computation, visualization, and programming</li>\n\
    <li><a href=\"http://alveo.edu.au/\">Alveo</a> \u2013 a virtual laboratory of\
    \ tools for searching, analysing and annotating natural language datasets</li>\n\
    <li><a href=\"http://www.intersect.org.au/csiro\">CSIRO Workspace</a> \u2013 a\
    \ powerful software platform for sharing scientific workflows in one coherent,\
    \ simple environment</li>\n<li><a href=\"http://www.rstudio.com/\">RStudio</a>\
    \ \u2013 a free, powerful tool for statistical computing and graphics.</li>\n\
    </ul>\n<p>Launchpod allows researchers to quickly establish a working version\
    \ of the software without the need for specialised IT knowledge. Also, these applications\
    \ are very resource-intensive, and running them on a notebook/desktop computer\
    \ can cause the machine to run slowly, and often the machine will need to be left\
    \ on for hours in order to complete a process. Running them in the cloud means\
    \ that they are less susceptible to crashing, and will run much faster and more\
    \ efficiently on dedicated hardware, and can be left on constantly.</p>\n<h2>Audience</h2>\n\
    <p>The typical users of Launchpod are researchers who already use these tools\
    \ on existing machines and want to use them in the cloud to improve collaboration,\
    \ or upscale their use and take advantage of the NeCTAR computing environment;\
    \ or those who want to experiment with these tools and evaluate them for their\
    \ own projects without needing to configure their own machine to run them.</p>\n\
    <p><strong>Please note:</strong> <em>This is a guide to using Launchpod. It is\
    \ not a guide to using the applications that can be deployed with Launchpod. Some\
    \ of the applications may require additional expertise and extensive training\
    \ in order to utilise them in your research.</em></p>\n<p>Launchpod can be accessed\
    \ by any researcher from an organisation that participates in the Australian Access\
    \ Federation (AAF). All Australian universities are members of AAF.</p>\n<h2>How\
    \ does Launchpod work</h2>\n<p>Launchpod uses your OpenStack API password to access\
    \ your NeCTAR account and deploy instances on your behalf. It then runs an Ansible\
    \ playbook to install the necessary software packages and dependencies in order\
    \ for the user's chosen product to be installed. <a href=\"http://www.ansible.com/\"\
    >Ansible</a> is an open-source software platform used for the automation of software\
    \ deployment using a <em>playbook</em>, which works like a script of actions to\
    \ be completed in order.</p>\n<p>The way Launchpod interacts with the NeCTAR Research\
    \ Cloud and Ansible to build the user's virtual machine complete with their chosen\
    \ software product is illustrated below.</p>\n<p><img alt=\"launchpod_workflow\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/launchpod-launchpod-workflow.png?raw=true\"\
    \ title=\"Launchpod Workflow\"></p>\n<p>Launchpod works as follows:</p>\n<ol>\n\
    <li>The user configures their OpenStack API key in Launchpod</li>\n<li>Launchpod\
    \ spawns a VM in the NeCTAR Research Cloud based on the user's entered details</li>\n\
    <li>The NeCTAR Research Cloud returns the machine's IP address on completion</li>\n\
    <li>Launchpod populates an Ansible playbook using the IP address and the user's\
    \ entered details</li>\n<li>This Ansible playbook is then run on the NeCTAR VM\
    \ and the software packages are installed and configured according to the user's\
    \ requirements.</li>\n</ol>\n<p>The following sections will cover how to obtain\
    \ an OpenStack API key, what sort of configuration options are required for spawning\
    \ a virtual machine, and what sort of configuration options are required to deploy\
    \ each of the available products.</p>\n<h3>Obtaining an OpenStack API password</h3>\n\
    <p>To allow Launchpod to deploy a VM, you must first create an OpenStack API password\
    \ in your NeCTAR Dashboard. Log in to the <a href=\"http://dashboard.rc.nectar.org.au/\"\
    >NeCTAR Dashboard</a> via AAF using your institutional credentials and go to your\
    \ account settings, which are accessed by hovering the mouse over your email address\
    \ in the top-right corner of the screen. </p>\n<p><img alt=\"nectar-settings\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/launchpod-user-settings.png?raw=true\"\
    \ title=\"NeCTAR User Settings\"></p>\n<p>In Settings, select <em>Reset Password</em>.\
    \ This will display a new API password on the screen. Copy this password and have\
    \ it ready to enter into Launchpod.</p>\n<p><img alt=\"reset-password\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/launchpod-reset-password.png?raw=true\"\
    \ title=\"Reset Password\"></p>\n<p>Creating or resetting the API password will\
    \ not affect the way you log into NeCTAR or any other AAF service; it is only\
    \ used to allow external services to connect to your NeCTAR account. That said,\
    \ if you have other external services that use a password to log in to your NeCTAR\
    \ account, this step will reset that password and you will have to re-authenticate\
    \ those services, or otherwise use the same password from your existing services\
    \ to authenticate Launchpod.</p>\n<p>Once you have your Openstack API password,\
    \ go to the Launchpod website and login using AAF. You will be prompted to enter\
    \ your OpenStack API password, which you retrieved in the last step. Enter it\
    \ here and select <em>Change Your Password</em>. </p>\n<p><img alt=\"change-password\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/launchpod-change-password.png?raw=true\"\
    \ title=\"Change Password\"></p>\n<p>Launchpod is now authorised to deploy a VM\
    \ on your behalf.</p>\n<h3>Deploying a Virtual Machine</h3>\n<p>Clicking <em>Deploy\
    \ New Instance</em> will open a page where Launchpod will ask for various configuration\
    \ settings. These settings correspond to VM deployment options within the NeCTAR\
    \ Research Cloud. You are encouraged to NeCTAR support prior to using Launchpod,\
    \ to understand what these settings refer to.</p>\n<h4>VM Settings</h4>\n<p>The\
    \ Virtual Machine settings page asks for the following:</p>\n<ul>\n<li>Product</li>\n\
    <li>Project</li>\n<li>Flavour</li>\n<li>SSH Key Pair</li>\n<li>Availability Zone</li>\n\
    <li>Instance Name</li>\n</ul>\n<h5>Product to be deployed (Required)</h5>\n<p>The\
    \ <em>product</em> is the software application (from the list above) that this\
    \ VM will run. Selecting an application will display information about it on the\
    \ right side of the screen. You can also find more information and links to the\
    \ software website on the <em>View Products</em> screen.</p>\n<p><img alt=\"product-details\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/launchpod-product-details.png?raw=true\"\
    \ title=\"Product Details\"></p>\n<h5>NeCTAR project (Required)</h5>\n<p>Launchpod\
    \ deploys VMs into your existing projects. If you have never used NeCTAR before,\
    \ only your personal trial project (beginning with <em>pt-</em>) will be displayed.\
    \ If you are registered as a user on any allocations, each of these will be listed\
    \ and you will need to select the appropriate one.</p>\n<p><strong>Please Note</strong>:\
    \ <em>Launchpod does not have the ability to query your project resources prior\
    \ to attempting to launch a VM. If you instruct Launchpod to deploy a VM with\
    \ more resources than you have available in your project, the deployment will\
    \ fail with the error message show below.</em></p>\n<p><img alt=\"insufficient-resources\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/launchpod-insufficient-resources.png?raw=true\"\
    \ title=\"Insufficient Resources\"></p>\n<h5>The <em>flavour</em> (size) of the\
    \ VM (Required)</h5>\n<p>Selecting a VM flavour from the drop-down list will display\
    \ the flavour technical details in the pane on the right.</p>\n<p>The size of\
    \ the VM is limited to the resources that are available in the project. If you\
    \ select a flavour that requires more resources than your project has available,\
    \ the deployment will fail and you will be prompted to either change project or\
    \ select a smaller flavour.</p>\n<p><img alt=\"flavour\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/launchpod-flavour.png?raw=true\"\
    \ title=\"Flavour\"></p>\n<h5>SSH key pair</h5>\n<p>The keypair is used to authenticate\
    \ to the machine via SSH (protocol to securely obtain access to a remote computer).\
    \ This drop-down list will display the keypairs that you have in your NeCTAR account.\
    \ If you have not created or uploaded a keypair in NeCTAR and you need SSH access\
    \ to this server, you should use the NeCTAR Dashboard to create a keypair before\
    \ you launch a VM with Launchpod.</p>\n<h5>Availability zone</h5>\n<p>If you need\
    \ the server to be deployed to a particular node of NeCTAR, then select that node\
    \ in the <em>Availability Zone</em> drop-down box. If this is not important to\
    \ your project, leave this blank and NeCTAR will automatically select a node with\
    \ available resources. The vast majority of users will not need to change the\
    \ availability zone of their VM.</p>\n<h5>Instance name</h5>\n<p>Launchpod will\
    \ set a default name for your instance, based on the name of the software product.\
    \ You may change this if you want to, but note that the purpose of the instance\
    \ name is just for identification purposes within NeCTAR and has no effect on\
    \ the VM itself.</p>\n<p>When you have entered all necessary settings, click <em>Next</em>.</p>\n\
    <h4>Product-specific configurations</h4>\n<p>Some applications require additional\
    \ settings before they can be deployed. The following sections describe each application.</p>\n\
    <h5>Omeka</h5>\n<p>Omeka needs no additional settings, and will be launched immediately\
    \ after filling in the required NeCTAR settings and clicking <em>Deploy</em>.\
    \ Launchpod will email you with instructions on how to access the Omeka application\
    \ once it is deployed.</p>\n<h5>DIVER</h5>\n<p>DIVER requires you to specify a\
    \ username and password that you will use to log into the DIVER application. You\
    \ also need to supply an email address. Launchpod will enter the email address\
    \ associated with your AAF identity by default, but you may change this.</p>\n\
    <p><strong>Please note:</strong> <em>DIVER is designed for use in an ongoing,\
    \ production environment and the NeCTAR Research Cloud is not designed for this\
    \ purpose. As such, deploying an instance of DIVER via Launchpod is intended for\
    \ testing/review purposes only. Intersect can assist to implement production environments\
    \ and managed services as required. Please contact your university\u2019s <a href=\"\
    http://intersect.org.au/content/eresearch-analysts\">eResearch Analyst</a> for\
    \ more information.</em></p>\n<h5>LimeSurvey</h5>\n<p>LimeSurvey requires you\
    \ to specify a username and password that you will use to log into the LimeSurvey\
    \ application. You also need to supply an email address. Launchpod will enter\
    \ the email address associated with your AAF identity by default, but you may\
    \ change this.</p>\n<h5>MATLAB\xAE</h5>\n<p>MATLAB\xAE is a desktop application\
    \ and not a web application, meaning that the virtual machine needs to be configured\
    \ to allow you to log into it as if it were a desktop computer. To deploy a MATLAB\xAE\
    \ instance, you will need to configure the operating system (OS) username and\
    \ password, which will be used to log into the machine, as well as a Virtual Network\
    \ Computing (VNC) password, which is used specifically to view the machine\u2019\
    s desktop over the web using a remote desktop connection and VNC software. When\
    \ a MATLAB\xAE VM is deployed, Launchpod will email you instructions on how to\
    \ get VNC software to view the machine\u2019s desktop and run MATLAB\xAE. When\
    \ accessing the machine using the VNC software, you will need to enter the VNC\
    \ password that you specified in Launchpod first, and then the OS username and\
    \ password, which you will use to log into the user account, as if you were working\
    \ on a desktop computer.</p>\n<p>MATLAB\xAE also requires an installation key\
    \ and a licence. An installation key is a string that informs the server which\
    \ software packages it should install. If you do not have an installation key,\
    \ your university may assist you with this. MATLAB\xAE is commercial software\
    \ and requires a licence to run. If you are a researcher at a university, there\
    \ may be an institutional licence that you can use. Contact your university\u2019\
    s IT department for assistance. Launchpod does not need the licence to deploy\
    \ a MATLAB\xAE VM and it does not ask for it, but you will need to enter a licence\
    \ in order to run the MATLAB\xAE software after the VM is deployed.</p>\n<h5>Alveo</h5>\n\
    <p>Alveo requires you to specify a username and password that you will use to\
    \ log into the Alveo application. You also need to supply an email address. Launchpod\
    \ will enter the email address associated with your AAF identity by default, but\
    \ you may change this.</p>\n<p><strong>Please note:</strong> <em>Alveo is designed\
    \ for use in an ongoing, production environment and the NeCTAR Research Cloud\
    \ is not designed for this purpose. As such, deploying an instance of Alveo via\
    \ Launchpod is intended for testing/review purposes only. Intersect can assist\
    \ to implement production environments and managed services as required. Please\
    \ contact your university\u2019s <a href=\"http://intersect.org.au/content/eresearch-analysts\"\
    >eResearch Analyst</a> for more information.</em></p>\n<h5>Twitter Scraper</h5>\n\
    <p>The Twitter Scraper is a very different tool from the rest of the applications.\
    \ It does not offer a user interface, meaning you cannot log into it, and does\
    \ not allow the user to set the search parameters once it is launched. Instead,\
    \ the search parameters are set within Launchpod, and after it is deployed it\
    \ will run continuously, generating more data until it is shut off. For this reason,\
    \ Launchpod requires you to configure the parameters during the deployment phase.\
    \ Launchpod also requires access to use your Twitter account, much like you allowed\
    \ Launchpod to interact with your NeCTAR account.</p>\n<p>Please see the <a href=\"\
    https://support.nectar.org.au/support/solutions/articles/6000089738-intersect-twitter-scraper-user-guide\"\
    >Twitter Scraper user guide</a> for information on how to deploy this tool using\
    \ Launchpod.</p>\n<h5>CSIRO Workspace</h5>\n<p>CSIRO Workspace is a desktop application\
    \ and not a web application, meaning that the virtual machine needs to be configured\
    \ to allow you to log into it as if it were a desktop computer. To deploy a CSIRO\
    \ Workspace instance, you will need to configure the operating system (OS) username\
    \ and password, which will be used to log into the machine, as well as a Virtual\
    \ Network Computing (VNC) password, which is used specifically to view the machine\u2019\
    s desktop over the web using a remote desktop connection and VNC software. When\
    \ the VM is deployed, Launchpod will email you instructions on how to get VNC\
    \ software to view the machine\u2019s desktop and run the software. When accessing\
    \ the machine using the VNC software, you will need to enter the VNC password\
    \ that you specified in Launchpod first, and then the OS username and password,\
    \ which you will use to log into the user account, as if you were working on a\
    \ desktop computer.</p>\n<h5>RStudio</h5>\n<p>RStudio is a desktop application\
    \ and not a web application, meaning that the virtual machine needs to be configured\
    \ to allow you to log into it as if it were a desktop computer. To deploy an RStudio\
    \ instance, you will need to configure the operating system (OS) username and\
    \ password, which will be used to log into the machine, as well as a Virtual Network\
    \ Computing (VNC) password, which is used specifically to view the machine\u2019\
    s desktop over the web using a remote desktop connection and VNC software. When\
    \ the VM is deployed, Launchpod will email you instructions on how to get VNC\
    \ software to view the machine\u2019s desktop and run the software. When accessing\
    \ the machine using the VNC software, you will need to enter the VNC password\
    \ that you specified in Launchpod first, and then the OS username and password,\
    \ which you will use to log into the user account, as if you were working on a\
    \ desktop computer.</p>\n<h3>Deployment</h3>\n<p>Once you have filled in all the\
    \ necessary information that Launchpod requires for your desired application,\
    \ click <em>Deploy</em>. The process can take as little as two minutes or up to\
    \ 40 minutes depending on the number of software packages that the machine will\
    \ have to download and install for the selected product to run properly. When\
    \ the deployment process is complete, you will receive an email with instructions\
    \ on how to access your machine. This information is also available anytime from\
    \ the Launchpod homepage via the <em>View Instance Details</em> link.</p>\n<p>To\
    \ terminate a machine, you can do so either from within the NeCTAR Dashboard,\
    \ as with any NeCTAR instance, or through the Launchpod interface by clicking\
    \ the <em>Delete</em> link on the homepage.</p>\n<h2>What else do I need to know\
    \ about Launchpod</h2>\n<p>Launchpod is simply an interface used to interact with\
    \ your NeCTAR account and, as such, you are strongly encouraged to seek advice\
    \ on using the NeCTAR Research Cloud. It is important to understand the risks\
    \ associated with cloud computing and to take any appropriate measures to mitigate\
    \ those risks such as regular backups of your data and snapshots of your systems.\
    \ We recommend you consult NeCTAR User Support for assistance with this, or contact\
    \ your university's <a href=\"http://intersect.org.au/content/eresearch-analysts\"\
    >eResearch Analyst</a>.</p>\n<h2>What costs are involved</h2>\n<p>Both Launchpod\
    \ and the NeCTAR Research Cloud are free to use for all Australian researchers.\
    \  Note that this does not include application licensing costs where applicable\
    \ (e.g. MATLAB\xAE).  </p>"
  parent: 24
  sha1: 59474bdce392a8260dfba83a519239a93d27c3b5
  title: Intersect Launchpod User Guide
94:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-24T22:39:12-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Intersect DIVER User Guide \n Description \n DIVER (Data Is\
          \ Vital for Empirical Research) is a general purpose, user-friendly research\
          \ data capture and sharing application. \n DIVER is a full lifecycle research\
          \ data management solution, developed by Intersect for the University of\
          \ Western Sydney Hawkesbury Institute for the Environment (HIE).  \n DIVER\
          \ is particularly beneficial where the researcher needs to quickly organize\
          \ and share their file-based data locally or with an international community.\
          \ DIVER provides functionality beyond traditional organisational file shares\
          \ addressing contemporary research needs such as data provenance and lifecycle\
          \ management, data access management, management of metadata, data citation\
          \ and reproducibility of research. \n Audience \n DIVER is Open Source software\
          \ and as such is available to all researchers at no cost. \n Intersect Australia\
          \ has experience in assisting researchers/research groups to establish a\
          \ DIVER instance through its Software Engineering capability. Hosted solutions\
          \ may also be managed by Intersect where required.  \n How to deploy DIVER\
          \ \n The latest version of DIVER is available through Launchpod, a tool\
          \ to deploy preconfigured virtual machines (VMs) on the NeCTAR Research\
          \ Cloud. Please read the Launchpod user guide for more information about\
          \ how to use it to deploy an instance of DIVER. \n For more detailed discussion\
          \ on the potential to deploy DIVER within an Intersect member institution,\
          \ contact your university's eResearch Analyst. \n Alternatively, you can\
          \ contact Intersect to enquire about a managed DIVER instance for your university\
          \ or project.  \n How to use DIVER \n Intersect maintains a comprehensive\
          \ User Manual for DIVER, which covers everything you need to know about\
          \ installing, managing and using this tool. \n For queries in using DIVER\
          \ in an institutional environment, please contact Intersect. \n What else\
          \ do I need to know about DIVER \n DIVER is Australian Access Federation\
          \ (AAF) enabled, meaning that users can connect to the system using their\
          \ institutional username and password.  \n DIVER has been under continuous\
          \ development by Intersect for a variety of different research disciplines.\
          \ \n There is a community of DIVER users that communicates via Google Groups\
          \ to discuss suggestions for new features as well as ways in which DIVER\
          \ is being used. "
        description: '<h1>Intersect DIVER User Guide</h1>

          <h2>Description</h2>

          <p>DIVER (Data Is Vital for Empirical Research) is a general purpose, user-friendly
          research data capture and sharing application.</p>

          <p>DIVER is a full lifecycle research data management solution, developed
          by Intersect for the University of Western Sydney Hawkesbury Institute for
          the Environment (HIE). </p>

          <p>DIVER is particularly beneficial where the researcher needs to quickly
          organize and share their file-based data locally or with an international
          community. DIVER provides functionality beyond traditional organisational
          file shares addressing contemporary research needs such as data provenance
          and lifecycle management, data access management, management of metadata,
          data citation and reproducibility of research.</p>

          <h2>Audience</h2>

          <p>DIVER is Open Source software and as such is available to all researchers
          at no cost.</p>

          <p>Intersect Australia has experience in assisting researchers/research
          groups to establish a DIVER instance through its Software Engineering capability.
          Hosted solutions may also be managed by Intersect where required. </p>

          <h2>How to deploy DIVER</h2>

          <p>The latest version of DIVER is available through <a href="http://launchpod.intersect.org.au"
          title="Launchpod">Launchpod</a>, a tool to deploy preconfigured virtual
          machines (VMs) on the <a href="http://cloud.nectar.org.au/" title="NeCTAR
          Research Cloud">NeCTAR Research Cloud</a>. Please read the <a href="http://intersect.org.au/content/launchpod"
          title="Launchpod user guide">Launchpod user guide</a> for more information
          about how to use it to deploy an instance of DIVER.</p>

          <p>For more detailed discussion on the potential to deploy DIVER within
          an Intersect member institution, contact your university''s <a href="http://intersect.org.au/content/eresearch-analysts"
          title="eResearch Analysts">eResearch Analyst</a>.</p>

          <p>Alternatively, you can <a href="mailto:enquiries@intersect.org.au">contact
          Intersect</a> to enquire about a managed DIVER instance for your university
          or project. </p>

          <h2>How to use DIVER</h2>

          <p>Intersect maintains a comprehensive <a href="https://github.com/IntersectAustralia/dc21-doc/blob/master/files/DIVER%20UserManual.pdf"
          title="Diver User Manual">User Manual</a> for DIVER, which covers everything
          you need to know about installing, managing and using this tool.</p>

          <p>For queries in using DIVER in an institutional environment, please <a
          href="mailto:enquiries@intersect.org.au">contact Intersect</a>.</p>

          <h2>What else do I need to know about DIVER</h2>

          <p>DIVER is Australian Access Federation (AAF) enabled, meaning that users
          can connect to the system using their institutional username and password.
          </p>

          <p>DIVER has been under continuous development by Intersect for a variety
          of different research disciplines.</p>

          <p>There is a <a href="https://groups.google.com/forum/#!forum/diver-community">community</a>
          of DIVER users that communicates via Google Groups to discuss suggestions
          for new features as well as ways in which DIVER is being used.</p>'
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000091615
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-24T22:39:12-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000091615
        position: 8
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Intersect DIVER User Guide
        updated_at: '2015-11-24T22:39:12-05:00'
        user_id: 6002464727
  html: '<h1>Intersect DIVER User Guide</h1>

    <h2>Description</h2>

    <p>DIVER (Data Is Vital for Empirical Research) is a general purpose, user-friendly
    research data capture and sharing application.</p>

    <p>DIVER is a full lifecycle research data management solution, developed by Intersect
    for the University of Western Sydney Hawkesbury Institute for the Environment
    (HIE). </p>

    <p>DIVER is particularly beneficial where the researcher needs to quickly organize
    and share their file-based data locally or with an international community. DIVER
    provides functionality beyond traditional organisational file shares addressing
    contemporary research needs such as data provenance and lifecycle management,
    data access management, management of metadata, data citation and reproducibility
    of research.</p>

    <h2>Audience</h2>

    <p>DIVER is Open Source software and as such is available to all researchers at
    no cost.</p>

    <p>Intersect Australia has experience in assisting researchers/research groups
    to establish a DIVER instance through its Software Engineering capability. Hosted
    solutions may also be managed by Intersect where required. </p>

    <h2>How to deploy DIVER</h2>

    <p>The latest version of DIVER is available through <a href="http://launchpod.intersect.org.au"
    title="Launchpod">Launchpod</a>, a tool to deploy preconfigured virtual machines
    (VMs) on the <a href="http://cloud.nectar.org.au/" title="NeCTAR Research Cloud">NeCTAR
    Research Cloud</a>. Please read the <a href="http://intersect.org.au/content/launchpod"
    title="Launchpod user guide">Launchpod user guide</a> for more information about
    how to use it to deploy an instance of DIVER.</p>

    <p>For more detailed discussion on the potential to deploy DIVER within an Intersect
    member institution, contact your university''s <a href="http://intersect.org.au/content/eresearch-analysts"
    title="eResearch Analysts">eResearch Analyst</a>.</p>

    <p>Alternatively, you can <a href="mailto:enquiries@intersect.org.au">contact
    Intersect</a> to enquire about a managed DIVER instance for your university or
    project. </p>

    <h2>How to use DIVER</h2>

    <p>Intersect maintains a comprehensive <a href="https://github.com/IntersectAustralia/dc21-doc/blob/master/files/DIVER%20UserManual.pdf"
    title="Diver User Manual">User Manual</a> for DIVER, which covers everything you
    need to know about installing, managing and using this tool.</p>

    <p>For queries in using DIVER in an institutional environment, please <a href="mailto:enquiries@intersect.org.au">contact
    Intersect</a>.</p>

    <h2>What else do I need to know about DIVER</h2>

    <p>DIVER is Australian Access Federation (AAF) enabled, meaning that users can
    connect to the system using their institutional username and password. </p>

    <p>DIVER has been under continuous development by Intersect for a variety of different
    research disciplines.</p>

    <p>There is a <a href="https://groups.google.com/forum/#!forum/diver-community">community</a>
    of DIVER users that communicates via Google Groups to discuss suggestions for
    new features as well as ways in which DIVER is being used.</p>'
  parent: 24
  sha1: ec2713fd8a6436c2d4f4dacb21e5724ed84995cf
  title: Intersect DIVER User Guide
95:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-25T23:16:29-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Check-Security-01: Are you running a mail server \n If you\
          \ want to run a mail server in NecTAR Virtual Machine, make sure it only\n\
          listens on Localhost (127.0.0.1). \n Check-Security-02: Is automatic updates\
          \ enabled \n Check whether automatic updates is enabled in operating system.\
          \ \n Check-Security-03: Have you Upgrade operating system kernel \n Check\
          \ whether your operating system kernel is the latest. Kernel upgrade requires\n\
          reboot and you need to schedule this into regular maintenance. \n Check-Security-04:\
          \ Are you running DNS service \n If you are running a DNS server, ensure\
          \ you only allow recursion from trusted\nhosts. \n Check-Security-05: Are\
          \ you running NTP service \n If you run a NTP server, limit which systems\
          \ can access it. Disable the 'monlist'\ncommand as this can be used as a\
          \ denial of service vector on your system. \n Check-Security-06: Have you\
          \ subscribed to security announcements \n If there is a security problem\
          \ with your operating system, you need to find out\nas soon as possible.\
          \ Find the appropriate mailing list and keep an eye\nout for anything that\
          \ requires urgent action. As soon as new security bugs are\ndetected, you\
          \ need to execute security upgrade immediately. \n Check-Security-07: Is\
          \ FireWall running \n Virtual machine should be configured so they allow\
          \ the minimum access required\nto run their service. Please use a host-based\
          \ firewall, in conjunction with\nthe cloud-provided firewall to manage access.\
          \ \n Check-Security-08: Are unneeded accounts in the system \n Keep an eye\
          \ on the user accounts enabled on your system. Some applications\ncreate\
          \ default accounts which are insecure. You may also open a temporary user\n\
          account to allow quick login for a task and leave it forever. This may lead\
          \ to\nsecurity issue later, and you need to regular check and delete these\
          \ user\naccounts. \n Check-Security-09: Is SSH password login disabled \n\
          \ With enough time and compute power it is possible for passwords to be\
          \ brute\nforce attacked. The average SSH server deals with thousands of\
          \ such attacks\nevery week, so use ssh keys. \n Check-Security-10: Are keys\
          \ stored in image \n The cloud provides a metadata service so you can download\
          \ keys on boot, so\nyou don't need to copy keys manually. This ensures that\
          \ if your key is\ncompromised, not all running instances of that image are\
          \ compromised. \n Check-Security-11: Is SSH attack banning tools installed\
          \ \n Install a tools like fail2ban or denyhosts, which checks log files\
          \ for\nattempted breaches and then blocks malicious IP addresses. \n Check-Security-12:\
          \ Are unneeded services disable \n Know what services run on your virtual\
          \ machine, and disable the unneeded ones. \n Check-Security-13: Are Encrypted\
          \ Communications Used \n Wherever possible, use encrypted communications\
          \ to avoid attacks which\nintercept data. \n Check-Security-14: Are logging\
          \ stored in a secure place \n Make sure that services are logging to a secure\
          \ location, that is as\ntamperproof as possible. If logging remotely, ensure\
          \ that it is done over\na secure channel so that eavesdroppers cannot monitor\
          \ what is happening on\nyour instance. \n Check-Security-15: Are ports opened\
          \ for not required services \n By default, virtual machines in NeCTAR has\
          \ closed all ports, so in order to make\nservices available to public, you\
          \ need to open certain ports for it. Before you\nopen a open, you need to\
          \ think carefully about what service associated with it\nand what is the\
          \ intention. Never open ports for non-service binded to it. \n Check-Security-16:\
          \ What permission granted to user account \n When creating user account,\
          \ make sure only permission sufficient for its use \nis granted. Never grant\
          \ extra permission if it is not needed. \n Check-Security-17: Is root access\
          \ disabled from SSH \n Disable root user SSH login and setup user account\
          \ with sudo permission to\nperform administrator tasks. \n Check-Security-18:\
          \ Is other ports used for SSH \n The SSH service on the virtual machine\
          \ uses port 22 by default. This port is \nwell-known and can attract many\
          \ attackers. Use a custom ssh port other than 22\nwill improve security.\
          \ Be noted, the port number below 1024 is well reserved and\nshouldn't be\
          \ used for SSH. "
        description: "<h2>Check-Security-01: Are you running a mail server</h2>\n\
          <p>If you want to run a mail server in NecTAR Virtual Machine, make sure\
          \ it only\nlistens on Localhost (127.0.0.1).</p>\n<h2>Check-Security-02:\
          \ Is automatic updates enabled</h2>\n<p>Check whether automatic updates\
          \ is enabled in operating system.</p>\n<h2>Check-Security-03: Have you Upgrade\
          \ operating system kernel</h2>\n<p>Check whether your operating system kernel\
          \ is the latest. Kernel upgrade requires\nreboot and you need to schedule\
          \ this into regular maintenance.</p>\n<h2>Check-Security-04: Are you running\
          \ DNS service</h2>\n<p>If you are running a DNS server, ensure you only\
          \ allow recursion from trusted\nhosts.</p>\n<h2>Check-Security-05: Are you\
          \ running NTP service</h2>\n<p>If you run a NTP server, limit which systems\
          \ can access it. Disable the 'monlist'\ncommand as this can be used as a\
          \ denial of service vector on your system.</p>\n<h2>Check-Security-06: Have\
          \ you subscribed to security announcements</h2>\n<p>If there is a security\
          \ problem with your operating system, you need to find out\nas soon as possible.\
          \ Find the appropriate mailing list and keep an eye\nout for anything that\
          \ requires urgent action. As soon as new security bugs are\ndetected, you\
          \ need to execute security upgrade immediately.</p>\n<h2>Check-Security-07:\
          \ Is FireWall running</h2>\n<p>Virtual machine should be configured so they\
          \ allow the minimum access required\nto run their service. Please use a\
          \ host-based firewall, in conjunction with\nthe cloud-provided firewall\
          \ to manage access.</p>\n<h2>Check-Security-08: Are unneeded accounts in\
          \ the system</h2>\n<p>Keep an eye on the user accounts enabled on your system.\
          \ Some applications\ncreate default accounts which are insecure. You may\
          \ also open a temporary user\naccount to allow quick login for a task and\
          \ leave it forever. This may lead to\nsecurity issue later, and you need\
          \ to regular check and delete these user\naccounts.</p>\n<h2>Check-Security-09:\
          \ Is SSH password login disabled</h2>\n<p>With enough time and compute power\
          \ it is possible for passwords to be brute\nforce attacked. The average\
          \ SSH server deals with thousands of such attacks\nevery week, so use ssh\
          \ keys.</p>\n<h2>Check-Security-10: Are keys stored in image</h2>\n<p>The\
          \ cloud provides a metadata service so you can download keys on boot, so\n\
          you don't need to copy keys manually. This ensures that if your key is\n\
          compromised, not all running instances of that image are compromised.</p>\n\
          <h2>Check-Security-11: Is SSH attack banning tools installed</h2>\n<p>Install\
          \ a tools like fail2ban or denyhosts, which checks log files for\nattempted\
          \ breaches and then blocks malicious IP addresses.</p>\n<h2>Check-Security-12:\
          \ Are unneeded services disable</h2>\n<p>Know what services run on your\
          \ virtual machine, and disable the unneeded ones.</p>\n<h2>Check-Security-13:\
          \ Are Encrypted Communications Used</h2>\n<p>Wherever possible, use encrypted\
          \ communications to avoid attacks which\nintercept data.</p>\n<h2>Check-Security-14:\
          \ Are logging stored in a secure place</h2>\n<p>Make sure that services\
          \ are logging to a secure location, that is as\ntamperproof as possible.\
          \ If logging remotely, ensure that it is done over\na secure channel so\
          \ that eavesdroppers cannot monitor what is happening on\nyour instance.</p>\n\
          <h2>Check-Security-15: Are ports opened for not required services</h2>\n\
          <p>By default, virtual machines in NeCTAR has closed all ports, so in order\
          \ to make\nservices available to public, you need to open certain ports\
          \ for it. Before you\nopen a open, you need to think carefully about what\
          \ service associated with it\nand what is the intention. Never open ports\
          \ for non-service binded to it.</p>\n<h2>Check-Security-16: What permission\
          \ granted to user account</h2>\n<p>When creating user account, make sure\
          \ only permission sufficient for its use \nis granted. Never grant extra\
          \ permission if it is not needed.</p>\n<h2>Check-Security-17: Is root access\
          \ disabled from SSH</h2>\n<p>Disable root user SSH login and setup user\
          \ account with sudo permission to\nperform administrator tasks.</p>\n<h2>Check-Security-18:\
          \ Is other ports used for SSH</h2>\n<p>The SSH service on the virtual machine\
          \ uses port 22 by default. This port is \nwell-known and can attract many\
          \ attackers. Use a custom ssh port other than 22\nwill improve security.\
          \ Be noted, the port number below 1024 is well reserved and\nshouldn't be\
          \ used for SSH.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:04-04:00'
          customer_folders: []
          description: Cloud Basics
          id: 6000190150
          is_default: false
          language_id: 6
          name: Cloud Basics
          parent_id: 6000190150
          position: 1
          updated_at: '2015-10-08T21:02:17-04:00'
          visibility: 1
        folder_id: 6000190150
        hits: 0
        id: 6000091906
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-11-25T23:16:29-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000091906
        position: 14
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Security Compromise Checklist
        updated_at: '2015-11-25T23:16:29-05:00'
        user_id: 6002464727
  html: "<h2>Check-Security-01: Are you running a mail server</h2>\n<p>If you want\
    \ to run a mail server in NecTAR Virtual Machine, make sure it only\nlistens on\
    \ Localhost (127.0.0.1).</p>\n<h2>Check-Security-02: Is automatic updates enabled</h2>\n\
    <p>Check whether automatic updates is enabled in operating system.</p>\n<h2>Check-Security-03:\
    \ Have you Upgrade operating system kernel</h2>\n<p>Check whether your operating\
    \ system kernel is the latest. Kernel upgrade requires\nreboot and you need to\
    \ schedule this into regular maintenance.</p>\n<h2>Check-Security-04: Are you\
    \ running DNS service</h2>\n<p>If you are running a DNS server, ensure you only\
    \ allow recursion from trusted\nhosts.</p>\n<h2>Check-Security-05: Are you running\
    \ NTP service</h2>\n<p>If you run a NTP server, limit which systems can access\
    \ it. Disable the 'monlist'\ncommand as this can be used as a denial of service\
    \ vector on your system.</p>\n<h2>Check-Security-06: Have you subscribed to security\
    \ announcements</h2>\n<p>If there is a security problem with your operating system,\
    \ you need to find out\nas soon as possible. Find the appropriate mailing list\
    \ and keep an eye\nout for anything that requires urgent action. As soon as new\
    \ security bugs are\ndetected, you need to execute security upgrade immediately.</p>\n\
    <h2>Check-Security-07: Is FireWall running</h2>\n<p>Virtual machine should be\
    \ configured so they allow the minimum access required\nto run their service.\
    \ Please use a host-based firewall, in conjunction with\nthe cloud-provided firewall\
    \ to manage access.</p>\n<h2>Check-Security-08: Are unneeded accounts in the system</h2>\n\
    <p>Keep an eye on the user accounts enabled on your system. Some applications\n\
    create default accounts which are insecure. You may also open a temporary user\n\
    account to allow quick login for a task and leave it forever. This may lead to\n\
    security issue later, and you need to regular check and delete these user\naccounts.</p>\n\
    <h2>Check-Security-09: Is SSH password login disabled</h2>\n<p>With enough time\
    \ and compute power it is possible for passwords to be brute\nforce attacked.\
    \ The average SSH server deals with thousands of such attacks\nevery week, so\
    \ use ssh keys.</p>\n<h2>Check-Security-10: Are keys stored in image</h2>\n<p>The\
    \ cloud provides a metadata service so you can download keys on boot, so\nyou\
    \ don't need to copy keys manually. This ensures that if your key is\ncompromised,\
    \ not all running instances of that image are compromised.</p>\n<h2>Check-Security-11:\
    \ Is SSH attack banning tools installed</h2>\n<p>Install a tools like fail2ban\
    \ or denyhosts, which checks log files for\nattempted breaches and then blocks\
    \ malicious IP addresses.</p>\n<h2>Check-Security-12: Are unneeded services disable</h2>\n\
    <p>Know what services run on your virtual machine, and disable the unneeded ones.</p>\n\
    <h2>Check-Security-13: Are Encrypted Communications Used</h2>\n<p>Wherever possible,\
    \ use encrypted communications to avoid attacks which\nintercept data.</p>\n<h2>Check-Security-14:\
    \ Are logging stored in a secure place</h2>\n<p>Make sure that services are logging\
    \ to a secure location, that is as\ntamperproof as possible. If logging remotely,\
    \ ensure that it is done over\na secure channel so that eavesdroppers cannot monitor\
    \ what is happening on\nyour instance.</p>\n<h2>Check-Security-15: Are ports opened\
    \ for not required services</h2>\n<p>By default, virtual machines in NeCTAR has\
    \ closed all ports, so in order to make\nservices available to public, you need\
    \ to open certain ports for it. Before you\nopen a open, you need to think carefully\
    \ about what service associated with it\nand what is the intention. Never open\
    \ ports for non-service binded to it.</p>\n<h2>Check-Security-16: What permission\
    \ granted to user account</h2>\n<p>When creating user account, make sure only\
    \ permission sufficient for its use \nis granted. Never grant extra permission\
    \ if it is not needed.</p>\n<h2>Check-Security-17: Is root access disabled from\
    \ SSH</h2>\n<p>Disable root user SSH login and setup user account with sudo permission\
    \ to\nperform administrator tasks.</p>\n<h2>Check-Security-18: Is other ports\
    \ used for SSH</h2>\n<p>The SSH service on the virtual machine uses port 22 by\
    \ default. This port is \nwell-known and can attract many attackers. Use a custom\
    \ ssh port other than 22\nwill improve security. Be noted, the port number below\
    \ 1024 is well reserved and\nshouldn't be used for SSH.</p>"
  parent: 21
  sha1: 1f41c7ec9ff193240456cfe0886ee4667d8b2667
  title: Security Compromise Checklist
96:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2015-11-30T19:44:05-05:00'
        desc_un_html: " \n SA node service for users in South Australia \n \n About\
          \ \n Differences in the cloud \n Cloud vs HPC - which is better for my job?\
          \ \n Register for an eRSA account \n Emu submit node \n Connecting to Emu\
          \ \n Windows Users \n Mac and Linux Users \n Storage \n General information\
          \ on using eRSA Supercomputers \n Exploring the available software \n Submitting\
          \ your job \n Transfer files with SCP and SFTP \n Using your own cloud allocation\
          \ \n The Name \n Appendices \n An example Torque submission script \n Converting\
          \ a tizard submission script for Emu \n A quick guide to copying files from\
          \ eRSA '/data' storage \n Glossary \n \n \n About \n Emu is a cluster that\
          \ is designed to be similar to eRSA's Tizard supercomputer, but makes use\
          \ of the Australian Research Cloud. \nThe Emu cluster-in-the-cloud is managed\
          \ by eRSA and provides a shared service for eRSA users who don't have a\
          \ resource allocation on the national cloud or don't have the expertise\
          \ to set up and manage a private cluster-in-the-cloud using StarCluster.\
          \ \n Emu currently consists of 136 processing cores, with an eight-core\
          \ machine for the head node and 16 worker nodes to run jobs. Each node has\
          \ eight cores, 32GB RAM and 240GB of local disk. The cluster uses the same\
          \ job management system (Torque) and eRSA user accounts that are used on\
          \ Tizard (and previously on Corvus). The cluster has access to the same\
          \ repository of software packages as Tizard. \n This service is designed\
          \ for: \n \n South Australian researchers who want to run compute-intensive\
          \ software applications in the cloud without the set-up involved in managing\
          \ a virtual machine. \n Registered eRSA users familiar with Tizard HPC services,\
          \ who would like to use their NeCTAR allocation to have their own node rather\
          \ than share nodes with other users. \n \n \n Differences in the cloud \n\
          \ Due to technical constraints and security policies, we are unable to replicate\
          \ everything in a traditional HPC cluster (such as Tizard) on the cloud.\
          \ However, we aim to provide, as much as possible, a seamless experience\
          \ for users in switching from a traditional HPC cluster to the cluster-in-the-cloud\
          \ approach. \n \n Users employ the same eRSA account to log into Emu and\
          \ the home directory on Emu will be the same as on Tizard. However, the\
          \ '/data' storage is not automatically available. Email the eRSA service\
          \ desk and it may be arranged for the '/data' disk to be made available\
          \ through Emu. Otherwise, data can be transferred using sftp between '/data'\
          \ and the cloud. \n The worker nodes in Emu are dynamic, which means they\
          \ will be launched when there are pending jobs, and shut down when nodes\
          \ are idle. Users may see a different number of worker nodes at different\
          \ times when they check the status of the cluster. \n There is no wall-time\
          \ restriction when running jobs with Emu when using your private project\
          \ allocation. \n In the cloud, there is 4G memory allocated per core. So,\
          \ if someone requests one core and 8GB memory for a job, it will be a waste.\
          \ For such jobs it is recommended to run on the Tizard CPU cluster or big\
          \ memory nodes. On Emu, users don't need to put the memory requirement in\
          \ the job description file as the core/memory ratio is set by default. \n\
          \ The same set of applications are available as for Tizard, however licensed\
          \ software may not be functional in the cloud. Please contact our Service\
          \ Desk if you need to run licensed software. \n \n Glossary of Terms  \n\
          Top of page \n \n \n Cloud vs HPC \n There are some differences between\
          \ a cluster in the cloud and an HPC cluster, such as Tizard, which has more\
          \ processors and memory on each node, and a faster communication network\
          \ between the nodes. Some types of computation that run on HPC clusters\
          \ are suitable for running in the cloud, and the cluster-in-the-cloud approach\
          \ should work well for those. \n \n Run compute jobs in the same way as\
          \ for eRSA HPC clusters (e.g Tizard) \n Any eRSA user can use Emu, you don't\
          \ need to have a cloud resource allocation  \n If your research group has\
          \ a cloud allocation, you can use it on Emu, so it's like having a private\
          \ sub-cluster  \n There is no wall-time restriction on Emu if you use a\
          \ cloud allocation (usually limited to 100 hours) \n \n However, some types\
          \ of applications are not well-suited to the cloud and would run better\
          \ on HPC cluster. Examples of such applications include: \n \n Parallel\
          \ programs that can run only on a single compute node and need more than\
          \ eight processing cores or 32GB memory \n Parallel (multi-processor) programs\
          \ that need to run on more than eight cores and can use multiple compute\
          \ nodes (e.g. MPI programs) but require a lot of interprocessor communication,\
          \ particularly low-latency communication \n Programs that need more than\
          \ 4GB of memory per processing core \n Programs that have more than about\
          \ 500GB total of input and output files \n Applications that run on GPUs\
          \ \n \n If you are unsure of whether or not your application is suitable\
          \ for the cloud, contact our Service Desk. \n \n \n Register for an eRSA\
          \ account \n To access the Emu cluster in the cloud, you will need to be\
          \ registered with eResearchSA. You will be provided with an eRSA username\
          \ and password which you will use to access the Emu cluster. Email the eRSA\
          \ Helpdesk with any queries. \n \n Emu submit node \n \n Emu's submit node\
          \ is 'emu.ersa.edu.au' \n To run jobs in the Emu cluster, you must login\
          \ to the Emu submit node via SSH with your eRSA username and password. \n\
          \ You can run short (a few minutes) test jobs on the commandline of the\
          \ submit node without using the queueing system. \n Longer jobs are submitted\
          \ to the Torque queueing system with a submission script. \n \n Glossary\
          \ of Terms  \nTop of page \n \n \n Connecting to Emu \n \n Emu is accessible\
          \ via SSH. \n \n \n Windows users \n \n Windows users can make use of free\
          \ ssh clients such as putty.  \n \nPutty Download   \n \n Instructions for\
          \ downloading Putty \n \n \n In the Putty configuration window, enter emu.ersa.edu.au\
          \ as the \"Host Name (or IP Address)\", then click 'Open'. \n \n You will\
          \ be prompted for your username and password. \n \n \n Mac and Linux users\
          \ \n \n Open the Terminal application (for Mac, look under Applications\
          \ -> Utilities). \n Then run: \nssh username@emu.ersa.edu.au\n \n You will\
          \ be prompted for your password. \n \n Glossary of Terms  \nTop of page\
          \ \n \n \n Storage \n \n As with other clusters managed by eRSA, there are\
          \ three storage areas that jobs have access to: \n \n/home/users, which\
          \ contains user home directories, and is accessible on all worker nodes\
          \ via NFS but has limited space (50GB).  \n \n/scratch, which provides a\
          \ larger temporary storage area, and is accessible from all nodes of the\
          \ cluster, but uses NFS and will therefore be slower than /tmp. This is\
          \ the disk location from which the user must run jobs. \n \n/tmp, which\
          \ is fast, temporary storage that is local to a particular worker node in\
          \ the cluster. It should be used only for the duration of a single job and\
          \ cleaned up after the job has finished. On Emu it is 240GB per worker node,\
          \ which is smaller than the local /tmp storageTizard nodes. \n \n Glossary\
          \ of Terms  \nTop of page \n \n \n General information on using eRSA supercomputers\
          \ \n \n Please read the general information about Using Supercomputers,\
          \ which is relevant to all eRSA supercomputers. \n \n An overview of the\
          \ steps for running a job on Emu (details in the following sections): \n\
          \ \n Create a folder in the '/scratch' directory to use as a working directory\
          \ for running jobs \n Copy the Emu submission script and your input files\
          \ to this directory \n Check which modules you need to load to run the job\
          \ \n Edit the emu submission script - with a comand-line editor or with\
          \ FileZilla\n \n Submit the script, and await an email informing you the\
          \ job is complete \n \n \n Exploring the available software packages \n\
          \ The 'module' commands allow users to: \n \n List the available packages\
          \ (modules) on Emu \nmodule avail \nmodule avail <search term>  - search\
          \ for a particular package   \n Find out what dependencies are required\
          \ to be loaded before the package of interest can be loaded \nmodule whatis\
          \ <package name>  -  make note of any required modules\n \n Load the packages,\
          \ by entering the module load ... command in the PBS submission script.\
          \ \n \n NOTE: If there is software that you would like to access that is\
          \ not already in the software repository, email the eRSA Helpdesk and request\
          \ that it be added. Ensure you mention that you would like to access it\
          \ through Emu cluster in the cloud. \n \n Submit your job using Torque/PBS\
          \ queuing system \n \n As with all eRSA supercomputers, you submit jobs\
          \ to Emu using the Torque job management (or queueing) system. \n Introduction\
          \ and Tutorial on using the Torque/PBS Queuing System \n Running jobs with\
          \ a Torque submission script \n \n There is a template of the Emu submission\
          \ script in the home folder. After you have logged on to emu.ersa.edu.au,\
          \ the script is in the '~/.templates' directory. \n \n look at the file:\
          \ \nless ~/.templates/emu.sub\n \n create a directory to work from in '/scratch',\
          \  \n  e.g. mkdir -p /scratch/MyDirectory/MyExperiment1\n \n copy the emu\
          \ submission script to your directory \n  e.g. cp ~/.templates/emu.sub /scratch/MyDirectory/MyExperiment1/experiment1.sub\n\
          \ \n Navigate to the directory  \n  e.g. cd /scratch/MyDirectory/MyExperiment1\n\
          \ \n Edit the submission script with nano experiment1.sub (or use the file\
          \ edit option in FileZilla)   \n \nReplace the following terms in bold in\
          \ the submission script\n \n MyJobName  \n Your-email-Address  \n \n#PBS\
          \ -l nodes=1:ppn=X - enter the number of processors required (up to 8, unless\
          \ you have a private allocation with 16 CPUs. NB  ensure \"nodes=1\") \n\
          \ \n#PBS -l walltime=HH:MM:SS - Enter the maximum time the process will\
          \ take to complete. If you are using a project cloud allocation, put \"\
          ###\" at the start of this line so it is ignored. \n \nmodule load application_module\
          \ - load any required modules first (see the output from the  module whatis\
          \ command above). Then on a new line, load the program you will use. \n\
          \ \n MyProgram+Arguments - Enter the command to start the program, as you\
          \ would enter it on the command line on your own computer. \n \n \n Copy\
          \ your input files to the directory. \n \n To submit the job, enter: \n\
          \  e.g. qsub experiment1.sub \nqstat - check that the job is running. You\
          \ will receive an email when the job ends. \n \n Glossary of Terms  \nTop\
          \ of page \n \n \n Sharing files with the virtual machine \n There is a\
          \ NeCTAR training module and support guide with comprehensive details on\
          \ transferring data between a cloud VM and your local computer or remote\
          \ storage servers.  \n Using programs like FileZilla or WinSCP is an easy\
          \ method of transferring data from your local computer.  \n See the Appendix\
          \ for a quick guide to copying data between Emu and your eRSA /data storage.\
          \ There is an eRSA support page with more detail on transferring data from\
          \ eRSA storage. \n Glossary of Terms  \nTop of page \n \n \n Using your\
          \ own cloud allocation \n Emu allows you the option to use your own NeCTAR\
          \ cloud resource allocation to start-up worker nodes. These worker nodes\
          \ will be exclusive to your group only and are not shared with other groups.\
          \ A useful feature is that if all your worker nodes are busy, your job will\
          \ be able to be scheduled to the shared worker nodes (contributed by eRSA)\
          \ if any of them is free. If this is still not enough, you can request more\
          \ cores from NeCTAR and we can bump up your own share in Emu so it can start\
          \ up more exclusive worker nodes for you. \n To set this up, you need to\
          \ follow these steps: \n \n Follow this guide to get a NeCTAR account\n\
          \ \n Apply for a NeCTAR cloud resource allocation by logging in to the NeCTAR\
          \ web dashboard and going to the New Request page under Allocations in the\
          \ menu. Contact our Service Desk if you need help in filling in the allocation\
          \ request. \n If you request persistent cloud storage (volume storage),\
          \ this can be set up to be used by your worker nodes. Note that this needs\
          \ one extra core to run a file server. For example, if you need eight cores\
          \ for your job, and you also request some volume storage, you will need\
          \ to request a total of nine cores. \n Send an email to our Service Desk\
          \ with the following information: \n Your NeCTAR project name \n A short,\
          \ one-word name to identify your project in your Torque/PBS job submission\
          \ script \n How many worker nodes you want to be used by Emu and how many\
          \ cores each one should have (note that the total number of cores must be\
          \ less than or equal to your NeCTAR project allocation) \n Do you have volume\
          \ storage to use? If so, how much do you want to be accessible from Emu?\
          \ \n A list of users who are allowed to use these worker nodes (please provide\
          \ their eRSA usernames). \n In order for eRSA to set up Emu in your project\
          \ allocation, the project manager (the user who requested the allocation)\
          \ must add the eRSA cloud support staff member as a user. This is done by\
          \ selecting the \"Users\" option in the project menu on the NeCTAR dashboard\
          \ and entering the email address of the eRSA team member that is assisting\
          \ you. \n \n Once we receive your email request, we will set up Emu to use\
          \ your allocation. On completion of setup, you can add a flag -A when running\
          \ your job script to specify the project name in order to make use of your\
          \ dedicated worker nodes. In your Torque/PBS job script, add the following\
          \ line (using your actual project name rather than myprojectname): \n  \
          \   #PBS -A myprojectname\n \n Alternatively, you can specify the project\
          \ name as a command line option to the qsub job submission command, as follows:\
          \ \n     $ qsub -A myprojectname myjobscript.sub\n \n If you don't know\
          \ or can't remember the project name, you can just type anything after the\
          \ -A flag and you will get an error message telling you what project names\
          \ you are eligible to use. \n If you do not specify a project name, the\
          \ job will be run on the shared worker nodes of the cluster. \n If you want\
          \ to run jobs ONLY on your own worker nodes, add myprojectname to the nodes'\
          \ properties. For example, in the job scripts, it can be \n     #PBS -l\
          \ nodes=1:myprojectname\n \n Glossary of Terms  \nTop of page \n \n \n The\
          \ name \n \n Clusters managed by eRSA have traditionally been given names\
          \ of constellations. In this case, we also wanted to somehow incorporate\
          \ the concept of \"cloud\". We chose the name based on a constellation from\
          \ Aboriginal culture, the Emu in the sky, which is not based on stars, but\
          \ rather on dust clouds in our galaxy creating dark areas in the Milky Way\
          \ between the Southern Cross and Scorpius, which resemble the outline of\
          \ an emu. \n \n Top of page \n \n \n Appendices \n \n An example Torque\
          \ submission script \n This is an example of modifying a copy of the 'emu.sub'\
          \ submission script template to run an executable 'process_radtags' from\
          \ a package called 'Stacks'. The first step is to check the availability\
          \ of the package, and what modules need to be loaded first as a prerequisite\
          \ for loading Stacks. Then the script is modified as highlighted for submission\
          \ of the job. \n \n \n Top of page \n \n \n Modify a Tizard submision script\
          \ for Emu \n If you have an existing submission script based on the 'tizard.sub',\
          \ you can convert it to an Emu submission script with the simple changes\
          \ highlighted below. \n \n Top of page \n \n \n A quick guide to copying\
          \ files from eRSA '/data' storage \n The following information outlines\
          \ commands that can be entered on your VM in order to transfer data to and\
          \ from remote data storage, such as the eRSA '/data' storage block. There\
          \ is an eRSA support page with more detail on transferring data from eRSA\
          \ storage. \n SFTP via the Command Line \n Secure file transfer is available\
          \ between the VM and remote data storage using command line controls \n\
          \ Enter the 'sftp' command while logged on to 'emu.ersa.edu.au', and you\
          \ will have access to the remote storage server. \n sftp username@sftp.ersa.edu.au\
          \   - you will be prompted for a password. \n You are now accessing the\
          \ remote data storage server, and you can navigate the files on the server\
          \ as per usual with commands like cd and ls. \nThe commands get and put\
          \ will transfer data between the machines: \n \n get <remote_server_file.txt>\
          \ <localEMU_destination/> \n \ncd /data/<My directory> , ls - navigate to\
          \ your files on the remote server \n \n get file.data ./ - fetch the file\
          \ from the server to the Emu working directory \n \n \n put <localEMU_destination/file.txt>\
          \ <remote_directory/> \n \n put results.zip /data/<My directory> \n \n to\
          \ close the sftp connection, type exit. \n \n \n Glossary \n Dashboard \n\
          \ \n The NeCTAR Dashboard is the main web-based interface for managing NeCTAR\
          \ virtuals. \n \n ERSA \n \n eResearch SA runs the South Australian node\
          \ of the NeCTAR research cloud. \n \n HPC \n \n High Performance Computing\
          \ systems - typically refers to \"high end\" computing hardware designed\
          \ for doing \"large\" computational tasks. \n \n Modules \n \n Environment\
          \ modules are used to configure a users environment to allow use of the\
          \ software packages available on the server. The module commands are used\
          \ to find information on the available packages, and to load the packages\
          \ for use.  \n \n Node (compute node)  \n \n OpenStack terminology for a\
          \ physical computer used to run virtual machines. It will typically have\
          \ multiple CPUs and shared memory, and one or more network interfaces. It\
          \ may also have on-node disk storage. \n \n Project \n \n The NeCTAR term\
          \ for a \"resource container\"; i.e. what you get when you are granted a\
          \ NeCTAR allocation. A project \"owns\" virtual machine instances, snapshots\
          \ and various kinds of storage, and may be shared by multiple users. \n\
          \ \n SSH \n \n A protocol and tools for establishing secure \"shell\" sessions\
          \ over the network. SSH encrypts the data transferred, and supports user\
          \ authentication using public/private keys. \n \n Submission script \n \n\
          \ A text file that is submitted to the Torque queueing system to run a job.\
          \ It consists of lines that are not read by torque (beginning with ###),\
          \ lines with Torque commands (beginning with #), and lines with shell script\
          \ commands. \n \n Tizard \n \n Tizard is eRSA's high performance computing\
          \ server that can be used for complex data processing and analysis jobs\
          \ that standard desktop computers would find it difficult or impossible\
          \ to perform. It enables users to run many processing jobs with different\
          \ parameters or input files more quickly. \n \n Volume Storage \n \n Data\
          \ Storage in your Virtual Machine that works like a hard-drive on your PC\
          \ or laptop does. Volume storage is automatically available in your VM as\
          \ the storage space for you system drive. Some flavors of VMs include an\
          \ amount of ephemeral volume storage. Depending on your allocation you can\
          \ have persistent volume storage attached to your VM. \n \n Full NeCTAR\
          \ Glossary Page \nNeCTAR FAQ - general inormation \nFor more help, contact\
          \ the eRSA Helpdesk \n Top of page "
        description: "<p><a name=\"top\"></a></p>\n<h2>SA node service for users in\
          \ South Australia</h2>\n<ul>\n<li><a href=\"#about\">About</a></li>\n<li><a\
          \ href=\"#differences-in-the-cloud\">Differences in the cloud</a></li>\n\
          <li><a href=\"#cloud-vs-hpc---which-is-better-for-my-job\">Cloud vs HPC\
          \ - which is better for my job?</a></li>\n<li><a href=\"#register\">Register\
          \ for an eRSA account</a></li>\n<li><a href=\"#emu-head-node\">Emu submit\
          \ node</a></li>\n<li><a href=\"#connecting-to-emu\">Connecting to Emu</a></li>\n\
          <li><a href=\"#windows-users\">Windows Users</a></li>\n<li><a href=\"#mac-users\"\
          >Mac and Linux Users</a></li>\n<li><a href=\"#storage\">Storage</a></li>\n\
          <li><a href=\"#general-information-on-using-ersa-supercomputers\">General\
          \ information on using eRSA Supercomputers</a></li>\n<li><a href=\"#modules\"\
          >Exploring the available software</a></li>\n<li><a href=\"#torquepbs\">Submitting\
          \ your job</a></li>\n<li><a href=\"#transfer\">Transfer files with SCP and\
          \ SFTP</a></li>\n<li><a href=\"#cloud-allocation\">Using your own cloud\
          \ allocation</a></li>\n<li><a href=\"#the-name\">The Name</a></li>\n<li><a\
          \ href=\"#appendix\">Appendices</a></li>\n<li><a href=\"#example\">An example\
          \ Torque submission script</a></li>\n<li><a href=\"#convert\">Converting\
          \ a tizard submission script for Emu</a></li>\n<li><a href=\"#app1\">A quick\
          \ guide to copying files from eRSA '/data' storage</a></li>\n<li><a href=\"\
          #glossary\">Glossary</a></li>\n</ul>\n<p><a name=\"about\"></a></p>\n<h2>About</h2>\n\
          <p>Emu is a cluster that is designed to be similar to eRSA's Tizard supercomputer,\
          \ but makes use of the <a href=\"http://www.nectar.org.au/research-cloud/\"\
          >Australian Research Cloud</a>. \nThe Emu cluster-in-the-cloud is managed\
          \ by eRSA and provides a shared service for eRSA users who don't have a\
          \ resource allocation on the national cloud or don't have the expertise\
          \ to set up and manage a private cluster-in-the-cloud using <a href=\"star-cluster.html\"\
          >StarCluster</a>.</p>\n<p>Emu currently consists of 136 processing cores,\
          \ with an eight-core machine for the head node and 16 worker nodes to run\
          \ jobs. Each node has eight cores, 32GB RAM and 240GB of local disk. The\
          \ cluster uses the same job management system (Torque) and eRSA user accounts\
          \ that are used on Tizard (and previously on Corvus). The cluster has access\
          \ to the same repository of software packages as Tizard.</p>\n<p>This service\
          \ is designed for:</p>\n<ul>\n<li>South Australian researchers who want\
          \ to run compute-intensive software applications in the cloud without the\
          \ set-up involved in managing a virtual machine.</li>\n<li>Registered eRSA\
          \ users familiar with Tizard HPC services, who would like to use their NeCTAR\
          \ allocation to have their own node rather than share nodes with other users.</li>\n\
          </ul>\n<p><a name=\"differences-in-the-cloud\"></a></p>\n<h2>Differences\
          \ in the cloud</h2>\n<p>Due to technical constraints and security policies,\
          \ we are unable to replicate everything in a traditional HPC cluster (such\
          \ as Tizard) on the cloud. However, we aim to provide, as much as possible,\
          \ a seamless experience for users in switching from a traditional HPC cluster\
          \ to the cluster-in-the-cloud approach.</p>\n<ul>\n<li>Users employ the\
          \ same eRSA account to log into Emu and the home directory on Emu will be\
          \ the same as on Tizard. However, the '/data' storage is not automatically\
          \ available. Email the <a href=\"mailto:servicedesk@ersa.edu.au\">eRSA service\
          \ desk</a> and it may be arranged for the '/data' disk to be made available\
          \ through Emu. Otherwise, data can be <a href=\"#app1\">transferred using\
          \ <strong>sftp</strong></a> between '/data' and the cloud.</li>\n<li>The\
          \ worker nodes in Emu are dynamic, which means they will be launched when\
          \ there are pending jobs, and shut down when nodes are idle. Users may see\
          \ a different number of worker nodes at different times when they check\
          \ the status of the cluster.</li>\n<li>There is no wall-time restriction\
          \ when running jobs with Emu when using your private project allocation.</li>\n\
          <li>In the cloud, there is 4G memory allocated per core. So, if someone\
          \ requests one core and 8GB memory for a job, it will be a waste. For such\
          \ jobs it is recommended to run on the Tizard CPU cluster or big memory\
          \ nodes. On Emu, users don't need to put the memory requirement in the job\
          \ description file as the core/memory ratio is set by default.</li>\n<li>The\
          \ same set of applications are available as for Tizard, however licensed\
          \ software may not be functional in the cloud. Please contact our <a href=\"\
          mailto:servicedesk@ersa.edu.au\">Service Desk</a> if you need to run licensed\
          \ software.</li>\n</ul>\n<p><a href=\"#glossary\">Glossary of Terms</a>\
          \ <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"cloud-vs-hpc---which-is-better-for-my-job\"\
          ></a></p>\n<h2>Cloud vs HPC</h2>\n<p>There are some differences between\
          \ a cluster in the cloud and an HPC cluster, such as Tizard, which has more\
          \ processors and memory on each node, and a faster communication network\
          \ between the nodes. Some types of computation that run on HPC clusters\
          \ are suitable for running in the cloud, and the cluster-in-the-cloud approach\
          \ should work well for those.</p>\n<ul>\n<li>Run compute jobs in the same\
          \ way as for eRSA HPC clusters (e.g Tizard)</li>\n<li>Any eRSA user can\
          \ use Emu, you don't need to have a cloud resource allocation </li>\n<li>If\
          \ your research group has a cloud allocation, you can use it on Emu, so\
          \ it's like having a private sub-cluster </li>\n<li>There is no wall-time\
          \ restriction on Emu if you use a cloud allocation (usually limited to 100\
          \ hours)</li>\n</ul>\n<p>However, some types of applications are not well-suited\
          \ to the cloud and would run better on HPC cluster. Examples of such applications\
          \ include:</p>\n<ul>\n<li>Parallel programs that can run only on a single\
          \ compute node and need more than eight processing cores or 32GB memory</li>\n\
          <li>Parallel (multi-processor) programs that need to run on more than eight\
          \ cores and can use multiple compute nodes (e.g. MPI programs) but require\
          \ a lot of interprocessor communication, particularly low-latency communication</li>\n\
          <li>Programs that need more than 4GB of memory per processing core</li>\n\
          <li>Programs that have more than about 500GB total of input and output files</li>\n\
          <li>Applications that run on GPUs</li>\n</ul>\n<p>If you are unsure of whether\
          \ or not your application is suitable for the cloud, contact our <a href=\"\
          mailto:servicedesk@ersa.edu.au\">Service Desk</a>.</p>\n<hr>\n<p><a name=\"\
          register\"></a></p>\n<h2>Register for an eRSA account</h2>\n<p>To access\
          \ the Emu cluster in the cloud, you will need to be <a href=\"https://register.ersa.edu.au/\"\
          >registered with eResearchSA</a>. You will be provided with an eRSA username\
          \ and password which you will use to access the Emu cluster. Email the <a\
          \ href=\"mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a> with any queries.</p>\n\
          <p><a name=\"emu-head-node\"></a></p>\n<h2>Emu submit node</h2>\n<ul>\n\
          <li>Emu's submit node is '<strong>emu.ersa.edu.au</strong>'</li>\n<li>To\
          \ run jobs in the Emu cluster, you must login to the Emu submit node via\
          \ SSH with your eRSA username and password.</li>\n<li>You can run short\
          \ (a few minutes) test jobs on the commandline of the submit node without\
          \ using the queueing system.</li>\n<li>Longer jobs are submitted to the\
          \ Torque queueing system with a submission script.</li>\n</ul>\n<p><a href=\"\
          #glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n\
          <hr>\n<p><a name=\"connecting-to-emu\"></a></p>\n<h2>Connecting to Emu</h2>\n\
          <ul>\n<li>Emu is accessible via SSH.</li>\n</ul>\n<p><a name=\"windows-users\"\
          ></a></p>\n<h3>Windows users</h3>\n<ul>\n<li>Windows users can make use\
          \ of free ssh clients such as putty. </li>\n<li>\n<a href=\"http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\"\
          >Putty Download</a>  </li>\n<li>\n<p><a href=\"http://support.ersa.edu.au/hpc/putty-download.html\"\
          >Instructions for downloading Putty</a></p>\n</li>\n<li>\n<p>In the Putty\
          \ configuration window, enter <strong>emu.ersa.edu.au</strong> as the \"\
          Host Name (or IP Address)\", then click 'Open'.</p>\n</li>\n<li>You will\
          \ be prompted for your username and password.</li>\n</ul>\n<p><a name=\"\
          mac-users\"></a></p>\n<h3>Mac and Linux users</h3>\n<ul>\n<li>Open the Terminal\
          \ application (for Mac, look under Applications -&gt; Utilities).</li>\n\
          <li>Then run:<br>\n<code>ssh username@emu.ersa.edu.au</code>\n</li>\n<li>You\
          \ will be prompted for your password.</li>\n</ul>\n<p><a href=\"#glossary\"\
          >Glossary of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n\
          <p><a name=\"storage\"></a></p>\n<h2>Storage</h2>\n<ul>\n<li>As with other\
          \ clusters managed by eRSA, there are three storage areas that jobs have\
          \ access to:</li>\n<li>\n<strong>/home/users</strong>, which contains user\
          \ home directories, and is accessible on all worker nodes via NFS but has\
          \ limited space (50GB). </li>\n<li>\n<strong>/scratch</strong>, which provides\
          \ a larger temporary storage area, and is accessible from all nodes of the\
          \ cluster, but uses NFS and will therefore be slower than /tmp. This is\
          \ the disk location from which the user must run jobs.</li>\n<li>\n<strong>/tmp</strong>,\
          \ which is fast, temporary storage that is local to a particular worker\
          \ node in the cluster. It should be used only for the duration of a single\
          \ job and cleaned up after the job has finished. On Emu it is 240GB per\
          \ worker node, which is smaller than the local /tmp storageTizard nodes.</li>\n\
          </ul>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\"\
          >Top of page</a></p>\n<hr>\n<p><a name=\"general-information-on-using-ersa-supercomputers\"\
          ></a></p>\n<h2>General information on using eRSA supercomputers</h2>\n<ul>\n\
          <li>Please read the general information about <a href=\"http://support.ersa.edu.au/hpc/using-supercomputers.html\"\
          >Using Supercomputers</a>, which is relevant to all eRSA supercomputers.</li>\n\
          </ul>\n<p>An overview of the steps for running a job on Emu (details in\
          \ the following sections):</p>\n<ol>\n<li>Create a folder in the '<strong>/scratch</strong>'\
          \ directory to use as a working directory for running jobs</li>\n<li>Copy\
          \ the Emu submission script and your input files to this directory</li>\n\
          <li>Check which modules you need to load to run the job</li>\n<li>Edit the\
          \ emu submission script - with a comand-line editor or with <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm#edit\"\
          >FileZilla</a>\n</li>\n<li>Submit the script, and await an email informing\
          \ you the job is complete</li>\n</ol>\n<p><a name=\"modules\"></a></p>\n\
          <h2>Exploring the available software packages</h2>\n<p>The <a href=\"http://support.ersa.edu.au/hpc/module-commands.html\"\
          >'module' commands</a> allow users to:</p>\n<ul>\n<li>List the available\
          \ packages (modules) on Emu<br>\n<code>module avail</code><br>\n<code>module\
          \ avail &lt;search term&gt;</code>  - search for a particular package  </li>\n\
          <li>Find out what dependencies are required to be loaded before the package\
          \ of interest can be loaded<br>\n<code>module whatis &lt;package name&gt;</code>\
          \  -  <em>make note of any required modules</em>\n</li>\n<li>Load the packages,\
          \ by entering the <code>module load ...</code> command in the PBS submission\
          \ script.</li>\n</ul>\n<p>NOTE: If there is software that you would like\
          \ to access that is not already in the software repository, email the <a\
          \ href=\"mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a> and request\
          \ that it be added. Ensure you mention that you would like to access it\
          \ through Emu cluster in the cloud.</p>\n<p><a name=\"torquepbs\"></a></p>\n\
          <h2>Submit your job using Torque/PBS queuing system</h2>\n<ul>\n<li>As with\
          \ all eRSA supercomputers, you submit jobs to Emu using the Torque job management\
          \ (or queueing) system.</li>\n<li><a href=\"http://support.ersa.edu.au/hpc/torque-pbs-queuing-system-commands.html\"\
          >Introduction and Tutorial on using the Torque/PBS Queuing System</a></li>\n\
          <li><a href=\"http://support.ersa.edu.au/hpc/user-guide.html#running-jobs\"\
          >Running jobs with a Torque submission script</a></li>\n</ul>\n<p>There\
          \ is a template of the Emu submission script in the home folder. After you\
          \ have logged on to emu.ersa.edu.au, the script is in the '~/.templates'\
          \ directory.</p>\n<ul>\n<li>look at the file:<br>\n<code>less ~/.templates/emu.sub</code>\n\
          </li>\n<li>create a directory to work from in '/scratch', <br>\n  e.g. <code>mkdir\
          \ -p /scratch/MyDirectory/MyExperiment1</code>\n</li>\n<li>copy the emu\
          \ submission script to your directory<br>\n  e.g. <code>cp ~/.templates/emu.sub\
          \ /scratch/MyDirectory/MyExperiment1/experiment1.sub</code>\n</li>\n<li>Navigate\
          \ to the directory <br>\n  e.g. <code>cd /scratch/MyDirectory/MyExperiment1</code>\n\
          </li>\n<li>Edit the submission script with <code>nano experiment1.sub</code>\
          \ (or use the file edit option in <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm#edit\"\
          >FileZilla</a>)  </li>\n<li>\n<em>Replace the following terms in</em> <strong>bold</strong>\
          \ <em>in the submission script</em>\n</li>\n<li><tt><strong>MyJobName</strong>\
          \ </tt></li>\n<li><tt><strong>Your-email-Address</strong> </tt></li>\n<li>\n\
          <tt>#PBS -l nodes=1:ppn=<strong>X</strong></tt> - enter the number of processors\
          \ required (up to 8, unless you have a private allocation with 16 CPUs.\
          \ NB  ensure \"nodes=1\")</li>\n<li>\n<tt>#PBS -l walltime=<strong>HH:MM:SS</strong></tt>\
          \ - Enter the maximum time the process will take to complete. If you are\
          \ using a project cloud allocation, put \"<tt><strong>###</strong></tt>\"\
          \ at the start of this line so it is ignored.</li>\n<li>\n<tt>module load\
          \ <strong>application_module</strong></tt> - load any required modules first\
          \ (see the output from the  <code>module whatis</code> command above). Then\
          \ on a new line, load the program you will use.</li>\n<li>\n<p><tt><strong>MyProgram+Arguments</strong></tt>\
          \ - Enter the command to start the program, as you would enter it on the\
          \ command line on your own computer.</p>\n</li>\n<li>\n<p><a href=\"#transfer\"\
          >Copy your input files</a> to the directory.</p>\n</li>\n<li>To submit the\
          \ job, enter:<br>\n  e.g. <code>qsub experiment1.sub</code><br>\n<code>qstat</code>\
          \ - check that the job is running. You will receive an email when the job\
          \ ends.</li>\n</ul>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n\
          <a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"transfer\"></a></p>\n\
          <h2>Sharing files with the virtual machine</h2>\n<p>There is a <a href=\"\
          http://training.nectar.org.au/package07/sections/copyFiles.html\">NeCTAR\
          \ training module</a> and <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
          >support guide</a> with comprehensive details on transferring data between\
          \ a cloud VM and your local computer or remote storage servers. </p>\n<p>Using\
          \ programs like FileZilla or WinSCP is an easy method of transferring data\
          \ from your local computer. </p>\n<p>See the <a href=\"#app1\">Appendix</a>\
          \ for a quick guide to copying data between Emu and your eRSA /data storage.\
          \ There is an <a href=\"http://support.ersa.edu.au/storage/quick-start.html\"\
          >eRSA support page</a> with more detail on transferring data from eRSA storage.</p>\n\
          <p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top\
          \ of page</a></p>\n<hr>\n<p><a name=\"cloud-allocation\"></a></p>\n<h2>Using\
          \ your own cloud allocation</h2>\n<p>Emu allows you the option to use your\
          \ own NeCTAR cloud resource allocation to start-up worker nodes. These worker\
          \ nodes will be exclusive to your group only and are not shared with other\
          \ groups. A useful feature is that if all your worker nodes are busy, your\
          \ job will be able to be scheduled to the shared worker nodes (contributed\
          \ by eRSA) if any of them is free. If this is still not enough, you can\
          \ request more cores from NeCTAR and we can bump up your own share in Emu\
          \ so it can start up more exclusive worker nodes for you.</p>\n<p>To set\
          \ this up, you need to follow these steps:</p>\n<ul>\n<li>Follow this <a\
          \ href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
          >guide to get a NeCTAR account</a>\n</li>\n<li>Apply for a <a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
          >NeCTAR cloud resource allocation</a> by logging in to the <a href=\"https://dashboard.rc.nectar.org.au/\"\
          >NeCTAR web dashboard</a> and going to the New Request page under Allocations\
          \ in the menu. Contact our <a href=\"mailto:servicedesk@ersa.edu.au\">Service\
          \ Desk</a> if you need help in filling in the allocation request.</li>\n\
          <li>If you request persistent cloud storage (<a href=\"https://support.nectar.org.au/support/solutions/articles/6000055382-introduction-to-cloud-storage\"\
          >volume storage</a>), this can be set up to be used by your worker nodes.\
          \ Note that this needs one extra core to run a file server. For example,\
          \ if you need eight cores for your job, and you also request some volume\
          \ storage, you will need to request a total of nine cores.</li>\n<li>Send\
          \ an email to our <a href=\"mailto:servicedesk@ersa.edu.au\">Service Desk</a>\
          \ with the following information:</li>\n<li>Your NeCTAR project name</li>\n\
          <li>A short, one-word name to identify your project in your Torque/PBS job\
          \ submission script</li>\n<li>How many worker nodes you want to be used\
          \ by Emu and how many cores each one should have (note that the total number\
          \ of cores must be less than or equal to your NeCTAR project allocation)</li>\n\
          <li>Do you have volume storage to use? If so, how much do you want to be\
          \ accessible from Emu?</li>\n<li>A list of users who are allowed to use\
          \ these worker nodes (please provide their eRSA usernames).</li>\n<li>In\
          \ order for eRSA to set up Emu in your project allocation, the project manager\
          \ (the user who requested the allocation) must add the eRSA cloud support\
          \ staff member as a user. This is done by selecting the \"Users\" option\
          \ in the project menu on the NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/project/members/\"\
          >dashboard</a> and entering the email address of the eRSA team member that\
          \ is assisting you.</li>\n</ul>\n<p>Once we receive your email request,\
          \ we will set up Emu to use your allocation. On completion of setup, you\
          \ can add a flag <code>-A</code> when running your job script to specify\
          \ the project name in order to make use of your dedicated worker nodes.\
          \ In your Torque/PBS job script, add the following line (using your actual\
          \ project name rather than <code>myprojectname</code>):</p>\n<pre><code>\
          \    #PBS -A myprojectname\n</code></pre>\n<p>Alternatively, you can specify\
          \ the project name as a command line option to the qsub job submission command,\
          \ as follows:</p>\n<pre><code>    $ qsub -A myprojectname myjobscript.sub\n\
          </code></pre>\n<p>If you don't know or can't remember the project name,\
          \ you can just type anything after the <code>-A</code> flag and you will\
          \ get an error message telling you what project names you are eligible to\
          \ use.</p>\n<p>If you do not specify a project name, the job will be run\
          \ on the shared worker nodes of the cluster.</p>\n<p>If you want to run\
          \ jobs ONLY on your own worker nodes, add <code>myprojectname</code> to\
          \ the nodes' properties. For example, in the job scripts, it can be</p>\n\
          <pre><code>    #PBS -l nodes=1:myprojectname\n</code></pre>\n<p><a href=\"\
          #glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n\
          <hr>\n<p><a name=\"the-name\"></a></p>\n<h2>The name</h2>\n<ul>\n<li>Clusters\
          \ managed by eRSA have traditionally been given names of constellations.\
          \ In this case, we also wanted to somehow incorporate the concept of \"\
          cloud\". We chose the name based on a constellation from Aboriginal culture,\
          \ the <a href=\"http://en.wikipedia.org/wiki/Australian_Aboriginal_astronomy#Emu_in_the_sky\"\
          >Emu in the sky</a>, which is not based on stars, but rather on dust clouds\
          \ in our galaxy creating dark areas in the Milky Way between the Southern\
          \ Cross and Scorpius, which resemble the outline of an emu.</li>\n</ul>\n\
          <p><a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"appendix\"></a></p>\n\
          <h2>Appendices</h2>\n<p><a name=\"example\"></a></p>\n<h3>An example Torque\
          \ submission script</h3>\n<p>This is an example of modifying a copy of the\
          \ 'emu.sub' submission script template to run an executable 'process_radtags'\
          \ from a package called 'Stacks'. The first step is to check the availability\
          \ of the package, and what modules need to be loaded first as a prerequisite\
          \ for loading Stacks. Then the script is modified as highlighted for submission\
          \ of the job.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/emu_module_availwhatis.png?raw=true\"\
          ></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/emu_modify_emu_sub.png?raw=true\"\
          ></p>\n<p><a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"convert\"\
          ></a></p>\n<h3>Modify a Tizard submision script for Emu</h3>\n<p>If you\
          \ have an existing submission script based on the 'tizard.sub', you can\
          \ convert it to an Emu submission script with the simple changes highlighted\
          \ below.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/emu_tizard_emu_sub.png?raw=true\"\
          ></p>\n<p><a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"app1\"\
          ></a></p>\n<h3>A quick guide to copying files from eRSA '/data' storage</h3>\n\
          <p>The following information outlines commands that can be entered on your\
          \ VM in order to transfer data to and from remote data storage, such as\
          \ the eRSA '/data' storage block. There is an <a href=\"http://support.ersa.edu.au/storage/quick-start.html\"\
          >eRSA support page</a> with more detail on transferring data from eRSA storage.</p>\n\
          <h4>SFTP via the Command Line</h4>\n<p>Secure file transfer is available\
          \ between the VM and remote data storage using command line controls</p>\n\
          <p>Enter the 'sftp' command while logged on to 'emu.ersa.edu.au', and you\
          \ will have access to the remote storage server.</p>\n<p><code>sftp username@sftp.ersa.edu.au</code>\
          \   - you will be prompted for a password.</p>\n<p>You are now accessing\
          \ the remote data storage server, and you can navigate the files on the\
          \ server as per usual with commands like <code>cd</code> and <code>ls</code>.<br>\n\
          The commands <code>get</code> and <code>put</code> will transfer data between\
          \ the machines:</p>\n<ul>\n<li><code>get &lt;remote_server_file.txt&gt;\
          \ &lt;localEMU_destination/&gt;</code></li>\n<li>\n<code>cd /data/&lt;My\
          \ directory&gt;</code> , <code>ls</code> - navigate to your files on the\
          \ remote server</li>\n<li>\n<p><code>get file.data ./</code> - fetch the\
          \ file from the server to the Emu working directory</p>\n</li>\n<li>\n<p><code>put\
          \ &lt;localEMU_destination/file.txt&gt; &lt;remote_directory/&gt;</code></p>\n\
          </li>\n<li><code>put results.zip /data/&lt;My directory&gt;</code></li>\n\
          </ul>\n<p>to close the sftp connection, type <code>exit</code>.</p>\n<hr>\n\
          <p><a name=\"glossary\"></a></p>\n<h2>Glossary</h2>\n<p><strong>Dashboard</strong></p>\n\
          <blockquote>\n<p>The NeCTAR Dashboard is the main web-based interface for\
          \ managing NeCTAR virtuals.</p>\n</blockquote>\n<p><strong>ERSA</strong></p>\n\
          <blockquote>\n<p>eResearch SA runs the South Australian node of the NeCTAR\
          \ research cloud.</p>\n</blockquote>\n<p><strong>HPC</strong></p>\n<blockquote>\n\
          <p>High Performance Computing systems - typically refers to \"high end\"\
          \ computing hardware designed for doing \"large\" computational tasks.</p>\n\
          </blockquote>\n<p><strong>Modules</strong></p>\n<blockquote>\n<p><a href=\"\
          http://modules.sourceforge.net/\">Environment modules</a> are used to configure\
          \ a users environment to allow use of the software packages available on\
          \ the server. The module commands are used to find information on the available\
          \ packages, and to load the packages for use. </p>\n</blockquote>\n<p><strong>Node</strong>\
          \ (compute node) </p>\n<blockquote>\n<p>OpenStack terminology for a physical\
          \ computer used to run virtual machines. It will typically have multiple\
          \ CPUs and shared memory, and one or more network interfaces. It may also\
          \ have on-node disk storage.</p>\n</blockquote>\n<p><strong>Project</strong></p>\n\
          <blockquote>\n<p>The NeCTAR term for a \"resource container\"; i.e. what\
          \ you get when you are granted a NeCTAR allocation. A project \"owns\" virtual\
          \ machine instances, snapshots and various kinds of storage, and may be\
          \ shared by multiple users.</p>\n</blockquote>\n<p><strong>SSH</strong></p>\n\
          <blockquote>\n<p>A protocol and tools for establishing secure \"shell\"\
          \ sessions over the network. SSH encrypts the data transferred, and supports\
          \ user authentication using public/private keys.</p>\n</blockquote>\n<p><strong>Submission\
          \ script</strong></p>\n<blockquote>\n<p>A text file that is submitted to\
          \ the <a href=\"http://support.ersa.edu.au/hpc/user-guide.html#running-jobs\"\
          >Torque queueing system</a> to run a job. It consists of lines that are\
          \ not read by torque (beginning with ###), lines with Torque commands (beginning\
          \ with #), and lines with shell script commands.</p>\n</blockquote>\n<p><strong>Tizard</strong></p>\n\
          <blockquote>\n<p><a href=\"http://www.ersa.edu.au/service/hpc/tizard/\"\
          >Tizard</a> is eRSA's high performance computing server that can be used\
          \ for complex data processing and analysis jobs that standard desktop computers\
          \ would find it difficult or impossible to perform. It enables users to\
          \ run many processing jobs with different parameters or input files more\
          \ quickly.</p>\n</blockquote>\n<p><strong>Volume Storage</strong></p>\n\
          <blockquote>\n<p>Data Storage in your Virtual Machine that works like a\
          \ hard-drive on your PC or laptop does. Volume storage is automatically\
          \ available in your VM as the storage space for you system drive. Some flavors\
          \ of VMs include an amount of ephemeral volume storage. Depending on your\
          \ allocation you can have persistent volume storage attached to your VM.</p>\n\
          </blockquote>\n<p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000055445-glossary\"\
          >Full NeCTAR Glossary Page</a><br>\n<a href=\"http://cloud.nectar.org.au/faq/\"\
          >NeCTAR FAQ - general inormation</a><br>\nFor more help, contact the <a\
          \ href=\"mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a></p>\n<p><a href=\"\
          #top\">Top of page</a></p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 62
        id: 6000092805
        modified_at: '2016-03-07T19:56:46-05:00'
        modified_by: null
        position: 1
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: eRSA Emu Cluster in the Cloud - user guide
        updated_at: '2016-03-07T19:56:46-05:00'
        user_id: 6002464727
  html: "<p><a name=\"top\"></a></p>\n<h2>SA node service for users in South Australia</h2>\n\
    <ul>\n<li><a href=\"#about\">About</a></li>\n<li><a href=\"#differences-in-the-cloud\"\
    >Differences in the cloud</a></li>\n<li><a href=\"#cloud-vs-hpc---which-is-better-for-my-job\"\
    >Cloud vs HPC - which is better for my job?</a></li>\n<li><a href=\"#register\"\
    >Register for an eRSA account</a></li>\n<li><a href=\"#emu-head-node\">Emu submit\
    \ node</a></li>\n<li><a href=\"#connecting-to-emu\">Connecting to Emu</a></li>\n\
    <li><a href=\"#windows-users\">Windows Users</a></li>\n<li><a href=\"#mac-users\"\
    >Mac and Linux Users</a></li>\n<li><a href=\"#storage\">Storage</a></li>\n<li><a\
    \ href=\"#general-information-on-using-ersa-supercomputers\">General information\
    \ on using eRSA Supercomputers</a></li>\n<li><a href=\"#modules\">Exploring the\
    \ available software</a></li>\n<li><a href=\"#torquepbs\">Submitting your job</a></li>\n\
    <li><a href=\"#transfer\">Transfer files with SCP and SFTP</a></li>\n<li><a href=\"\
    #cloud-allocation\">Using your own cloud allocation</a></li>\n<li><a href=\"#the-name\"\
    >The Name</a></li>\n<li><a href=\"#appendix\">Appendices</a></li>\n<li><a href=\"\
    #example\">An example Torque submission script</a></li>\n<li><a href=\"#convert\"\
    >Converting a tizard submission script for Emu</a></li>\n<li><a href=\"#app1\"\
    >A quick guide to copying files from eRSA '/data' storage</a></li>\n<li><a href=\"\
    #glossary\">Glossary</a></li>\n</ul>\n<p><a name=\"about\"></a></p>\n<h2>About</h2>\n\
    <p>Emu is a cluster that is designed to be similar to eRSA's Tizard supercomputer,\
    \ but makes use of the <a href=\"http://www.nectar.org.au/research-cloud/\">Australian\
    \ Research Cloud</a>. \nThe Emu cluster-in-the-cloud is managed by eRSA and provides\
    \ a shared service for eRSA users who don't have a resource allocation on the\
    \ national cloud or don't have the expertise to set up and manage a private cluster-in-the-cloud\
    \ using <a href=\"star-cluster.html\">StarCluster</a>.</p>\n<p>Emu currently consists\
    \ of 136 processing cores, with an eight-core machine for the head node and 16\
    \ worker nodes to run jobs. Each node has eight cores, 32GB RAM and 240GB of local\
    \ disk. The cluster uses the same job management system (Torque) and eRSA user\
    \ accounts that are used on Tizard (and previously on Corvus). The cluster has\
    \ access to the same repository of software packages as Tizard.</p>\n<p>This service\
    \ is designed for:</p>\n<ul>\n<li>South Australian researchers who want to run\
    \ compute-intensive software applications in the cloud without the set-up involved\
    \ in managing a virtual machine.</li>\n<li>Registered eRSA users familiar with\
    \ Tizard HPC services, who would like to use their NeCTAR allocation to have their\
    \ own node rather than share nodes with other users.</li>\n</ul>\n<p><a name=\"\
    differences-in-the-cloud\"></a></p>\n<h2>Differences in the cloud</h2>\n<p>Due\
    \ to technical constraints and security policies, we are unable to replicate everything\
    \ in a traditional HPC cluster (such as Tizard) on the cloud. However, we aim\
    \ to provide, as much as possible, a seamless experience for users in switching\
    \ from a traditional HPC cluster to the cluster-in-the-cloud approach.</p>\n<ul>\n\
    <li>Users employ the same eRSA account to log into Emu and the home directory\
    \ on Emu will be the same as on Tizard. However, the '/data' storage is not automatically\
    \ available. Email the <a href=\"mailto:servicedesk@ersa.edu.au\">eRSA service\
    \ desk</a> and it may be arranged for the '/data' disk to be made available through\
    \ Emu. Otherwise, data can be <a href=\"#app1\">transferred using <strong>sftp</strong></a>\
    \ between '/data' and the cloud.</li>\n<li>The worker nodes in Emu are dynamic,\
    \ which means they will be launched when there are pending jobs, and shut down\
    \ when nodes are idle. Users may see a different number of worker nodes at different\
    \ times when they check the status of the cluster.</li>\n<li>There is no wall-time\
    \ restriction when running jobs with Emu when using your private project allocation.</li>\n\
    <li>In the cloud, there is 4G memory allocated per core. So, if someone requests\
    \ one core and 8GB memory for a job, it will be a waste. For such jobs it is recommended\
    \ to run on the Tizard CPU cluster or big memory nodes. On Emu, users don't need\
    \ to put the memory requirement in the job description file as the core/memory\
    \ ratio is set by default.</li>\n<li>The same set of applications are available\
    \ as for Tizard, however licensed software may not be functional in the cloud.\
    \ Please contact our <a href=\"mailto:servicedesk@ersa.edu.au\">Service Desk</a>\
    \ if you need to run licensed software.</li>\n</ul>\n<p><a href=\"#glossary\"\
    >Glossary of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a\
    \ name=\"cloud-vs-hpc---which-is-better-for-my-job\"></a></p>\n<h2>Cloud vs HPC</h2>\n\
    <p>There are some differences between a cluster in the cloud and an HPC cluster,\
    \ such as Tizard, which has more processors and memory on each node, and a faster\
    \ communication network between the nodes. Some types of computation that run\
    \ on HPC clusters are suitable for running in the cloud, and the cluster-in-the-cloud\
    \ approach should work well for those.</p>\n<ul>\n<li>Run compute jobs in the\
    \ same way as for eRSA HPC clusters (e.g Tizard)</li>\n<li>Any eRSA user can use\
    \ Emu, you don't need to have a cloud resource allocation </li>\n<li>If your research\
    \ group has a cloud allocation, you can use it on Emu, so it's like having a private\
    \ sub-cluster </li>\n<li>There is no wall-time restriction on Emu if you use a\
    \ cloud allocation (usually limited to 100 hours)</li>\n</ul>\n<p>However, some\
    \ types of applications are not well-suited to the cloud and would run better\
    \ on HPC cluster. Examples of such applications include:</p>\n<ul>\n<li>Parallel\
    \ programs that can run only on a single compute node and need more than eight\
    \ processing cores or 32GB memory</li>\n<li>Parallel (multi-processor) programs\
    \ that need to run on more than eight cores and can use multiple compute nodes\
    \ (e.g. MPI programs) but require a lot of interprocessor communication, particularly\
    \ low-latency communication</li>\n<li>Programs that need more than 4GB of memory\
    \ per processing core</li>\n<li>Programs that have more than about 500GB total\
    \ of input and output files</li>\n<li>Applications that run on GPUs</li>\n</ul>\n\
    <p>If you are unsure of whether or not your application is suitable for the cloud,\
    \ contact our <a href=\"mailto:servicedesk@ersa.edu.au\">Service Desk</a>.</p>\n\
    <hr>\n<p><a name=\"register\"></a></p>\n<h2>Register for an eRSA account</h2>\n\
    <p>To access the Emu cluster in the cloud, you will need to be <a href=\"https://register.ersa.edu.au/\"\
    >registered with eResearchSA</a>. You will be provided with an eRSA username and\
    \ password which you will use to access the Emu cluster. Email the <a href=\"\
    mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a> with any queries.</p>\n<p><a\
    \ name=\"emu-head-node\"></a></p>\n<h2>Emu submit node</h2>\n<ul>\n<li>Emu's submit\
    \ node is '<strong>emu.ersa.edu.au</strong>'</li>\n<li>To run jobs in the Emu\
    \ cluster, you must login to the Emu submit node via SSH with your eRSA username\
    \ and password.</li>\n<li>You can run short (a few minutes) test jobs on the commandline\
    \ of the submit node without using the queueing system.</li>\n<li>Longer jobs\
    \ are submitted to the Torque queueing system with a submission script.</li>\n\
    </ul>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top\
    \ of page</a></p>\n<hr>\n<p><a name=\"connecting-to-emu\"></a></p>\n<h2>Connecting\
    \ to Emu</h2>\n<ul>\n<li>Emu is accessible via SSH.</li>\n</ul>\n<p><a name=\"\
    windows-users\"></a></p>\n<h3>Windows users</h3>\n<ul>\n<li>Windows users can\
    \ make use of free ssh clients such as putty. </li>\n<li><a href=\"http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\"\
    >Putty Download</a>  </li>\n<li>\n<p><a href=\"http://support.ersa.edu.au/hpc/putty-download.html\"\
    >Instructions for downloading Putty</a></p>\n</li>\n<li>\n<p>In the Putty configuration\
    \ window, enter <strong>emu.ersa.edu.au</strong> as the \"Host Name (or IP Address)\"\
    , then click 'Open'.</p>\n</li>\n<li>You will be prompted for your username and\
    \ password.</li>\n</ul>\n<p><a name=\"mac-users\"></a></p>\n<h3>Mac and Linux\
    \ users</h3>\n<ul>\n<li>Open the Terminal application (for Mac, look under Applications\
    \ -&gt; Utilities).</li>\n<li>Then run:<br>\n<code>ssh username@emu.ersa.edu.au</code></li>\n\
    <li>You will be prompted for your password.</li>\n</ul>\n<p><a href=\"#glossary\"\
    >Glossary of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a\
    \ name=\"storage\"></a></p>\n<h2>Storage</h2>\n<ul>\n<li>As with other clusters\
    \ managed by eRSA, there are three storage areas that jobs have access to:</li>\n\
    <li><strong>/home/users</strong>, which contains user home directories, and is\
    \ accessible on all worker nodes via NFS but has limited space (50GB). </li>\n\
    <li><strong>/scratch</strong>, which provides a larger temporary storage area,\
    \ and is accessible from all nodes of the cluster, but uses NFS and will therefore\
    \ be slower than /tmp. This is the disk location from which the user must run\
    \ jobs.</li>\n<li><strong>/tmp</strong>, which is fast, temporary storage that\
    \ is local to a particular worker node in the cluster. It should be used only\
    \ for the duration of a single job and cleaned up after the job has finished.\
    \ On Emu it is 240GB per worker node, which is smaller than the local /tmp storageTizard\
    \ nodes.</li>\n</ul>\n<p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a\
    \ href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"general-information-on-using-ersa-supercomputers\"\
    ></a></p>\n<h2>General information on using eRSA supercomputers</h2>\n<ul>\n<li>Please\
    \ read the general information about <a href=\"http://support.ersa.edu.au/hpc/using-supercomputers.html\"\
    >Using Supercomputers</a>, which is relevant to all eRSA supercomputers.</li>\n\
    </ul>\n<p>An overview of the steps for running a job on Emu (details in the following\
    \ sections):</p>\n<ol>\n<li>Create a folder in the '<strong>/scratch</strong>'\
    \ directory to use as a working directory for running jobs</li>\n<li>Copy the\
    \ Emu submission script and your input files to this directory</li>\n<li>Check\
    \ which modules you need to load to run the job</li>\n<li>Edit the emu submission\
    \ script - with a comand-line editor or with <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm#edit\"\
    >FileZilla</a></li>\n<li>Submit the script, and await an email informing you the\
    \ job is complete</li>\n</ol>\n<p><a name=\"modules\"></a></p>\n<h2>Exploring\
    \ the available software packages</h2>\n<p>The <a href=\"http://support.ersa.edu.au/hpc/module-commands.html\"\
    >'module' commands</a> allow users to:</p>\n<ul>\n<li>List the available packages\
    \ (modules) on Emu<br>\n<code>module avail</code><br>\n<code>module avail &lt;search\
    \ term&gt;</code>  - search for a particular package  </li>\n<li>Find out what\
    \ dependencies are required to be loaded before the package of interest can be\
    \ loaded<br>\n<code>module whatis &lt;package name&gt;</code>  -  <em>make note\
    \ of any required modules</em></li>\n<li>Load the packages, by entering the <code>module\
    \ load ...</code> command in the PBS submission script.</li>\n</ul>\n<p>NOTE:\
    \ If there is software that you would like to access that is not already in the\
    \ software repository, email the <a href=\"mailto:servicedesk@ersa.edu.au\">eRSA\
    \ Helpdesk</a> and request that it be added. Ensure you mention that you would\
    \ like to access it through Emu cluster in the cloud.</p>\n<p><a name=\"torquepbs\"\
    ></a></p>\n<h2>Submit your job using Torque/PBS queuing system</h2>\n<ul>\n<li>As\
    \ with all eRSA supercomputers, you submit jobs to Emu using the Torque job management\
    \ (or queueing) system.</li>\n<li><a href=\"http://support.ersa.edu.au/hpc/torque-pbs-queuing-system-commands.html\"\
    >Introduction and Tutorial on using the Torque/PBS Queuing System</a></li>\n<li><a\
    \ href=\"http://support.ersa.edu.au/hpc/user-guide.html#running-jobs\">Running\
    \ jobs with a Torque submission script</a></li>\n</ul>\n<p>There is a template\
    \ of the Emu submission script in the home folder. After you have logged on to\
    \ emu.ersa.edu.au, the script is in the '~/.templates' directory.</p>\n<ul>\n\
    <li>look at the file:<br>\n<code>less ~/.templates/emu.sub</code></li>\n<li>create\
    \ a directory to work from in '/scratch', <br>\n  e.g. <code>mkdir -p /scratch/MyDirectory/MyExperiment1</code></li>\n\
    <li>copy the emu submission script to your directory<br>\n  e.g. <code>cp ~/.templates/emu.sub\
    \ /scratch/MyDirectory/MyExperiment1/experiment1.sub</code></li>\n<li>Navigate\
    \ to the directory <br>\n  e.g. <code>cd /scratch/MyDirectory/MyExperiment1</code></li>\n\
    <li>Edit the submission script with <code>nano experiment1.sub</code> (or use\
    \ the file edit option in <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm#edit\"\
    >FileZilla</a>)  </li>\n<li><em>Replace the following terms in</em> <strong>bold</strong>\
    \ <em>in the submission script</em></li>\n<li><tt><strong>MyJobName</strong> </tt></li>\n\
    <li><tt><strong>Your-email-Address</strong> </tt></li>\n<li><tt>&#35;PBS -l nodes=1:ppn=<strong>X</strong></tt>\
    \ - enter the number of processors required (up to 8, unless you have a private\
    \ allocation with 16 CPUs. NB  ensure \"nodes=1\")</li>\n<li><tt>&#35;PBS -l walltime=<strong>HH:MM:SS</strong></tt>\
    \ - Enter the maximum time the process will take to complete. If you are using\
    \ a project cloud allocation, put \"<tt><strong>###</strong></tt>\" at the start\
    \ of this line so it is ignored.</li>\n<li><tt>module load <strong>application_module</strong></tt>\
    \ - load any required modules first (see the output from the  <code>module whatis</code>\
    \ command above). Then on a new line, load the program you will use.</li>\n<li>\n\
    <p><tt><strong>MyProgram+Arguments</strong></tt> - Enter the command to start\
    \ the program, as you would enter it on the command line on your own computer.</p>\n\
    </li>\n<li>\n<p><a href=\"#transfer\">Copy your input files</a> to the directory.</p>\n\
    </li>\n<li>To submit the job, enter:<br>\n  e.g. <code>qsub experiment1.sub</code><br>\n\
    <code>qstat</code> - check that the job is running. You will receive an email\
    \ when the job ends.</li>\n</ul>\n<p><a href=\"#glossary\">Glossary of Terms</a>\
    \ <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"transfer\"></a></p>\n\
    <h2>Sharing files with the virtual machine</h2>\n<p>There is a <a href=\"http://training.nectar.org.au/package07/sections/copyFiles.html\"\
    >NeCTAR training module</a> and <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
    >support guide</a> with comprehensive details on transferring data between a cloud\
    \ VM and your local computer or remote storage servers. </p>\n<p>Using programs\
    \ like FileZilla or WinSCP is an easy method of transferring data from your local\
    \ computer. </p>\n<p>See the <a href=\"#app1\">Appendix</a> for a quick guide\
    \ to copying data between Emu and your eRSA /data storage. There is an <a href=\"\
    http://support.ersa.edu.au/storage/quick-start.html\">eRSA support page</a> with\
    \ more detail on transferring data from eRSA storage.</p>\n<p><a href=\"#glossary\"\
    >Glossary of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a\
    \ name=\"cloud-allocation\"></a></p>\n<h2>Using your own cloud allocation</h2>\n\
    <p>Emu allows you the option to use your own NeCTAR cloud resource allocation\
    \ to start-up worker nodes. These worker nodes will be exclusive to your group\
    \ only and are not shared with other groups. A useful feature is that if all your\
    \ worker nodes are busy, your job will be able to be scheduled to the shared worker\
    \ nodes (contributed by eRSA) if any of them is free. If this is still not enough,\
    \ you can request more cores from NeCTAR and we can bump up your own share in\
    \ Emu so it can start up more exclusive worker nodes for you.</p>\n<p>To set this\
    \ up, you need to follow these steps:</p>\n<ul>\n<li>Follow this <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
    >guide to get a NeCTAR account</a></li>\n<li>Apply for a <a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
    >NeCTAR cloud resource allocation</a> by logging in to the <a href=\"https://dashboard.rc.nectar.org.au/\"\
    >NeCTAR web dashboard</a> and going to the New Request page under Allocations\
    \ in the menu. Contact our <a href=\"mailto:servicedesk@ersa.edu.au\">Service\
    \ Desk</a> if you need help in filling in the allocation request.</li>\n<li>If\
    \ you request persistent cloud storage (<a href=\"https://support.nectar.org.au/support/solutions/articles/6000055382-introduction-to-cloud-storage\"\
    >volume storage</a>), this can be set up to be used by your worker nodes. Note\
    \ that this needs one extra core to run a file server. For example, if you need\
    \ eight cores for your job, and you also request some volume storage, you will\
    \ need to request a total of nine cores.</li>\n<li>Send an email to our <a href=\"\
    mailto:servicedesk@ersa.edu.au\">Service Desk</a> with the following information:</li>\n\
    <li>Your NeCTAR project name</li>\n<li>A short, one-word name to identify your\
    \ project in your Torque/PBS job submission script</li>\n<li>How many worker nodes\
    \ you want to be used by Emu and how many cores each one should have (note that\
    \ the total number of cores must be less than or equal to your NeCTAR project\
    \ allocation)</li>\n<li>Do you have volume storage to use? If so, how much do\
    \ you want to be accessible from Emu?</li>\n<li>A list of users who are allowed\
    \ to use these worker nodes (please provide their eRSA usernames).</li>\n<li>In\
    \ order for eRSA to set up Emu in your project allocation, the project manager\
    \ (the user who requested the allocation) must add the eRSA cloud support staff\
    \ member as a user. This is done by selecting the \"Users\" option in the project\
    \ menu on the NeCTAR <a href=\"https://dashboard.rc.nectar.org.au/project/members/\"\
    >dashboard</a> and entering the email address of the eRSA team member that is\
    \ assisting you.</li>\n</ul>\n<p>Once we receive your email request, we will set\
    \ up Emu to use your allocation. On completion of setup, you can add a flag <code>-A</code>\
    \ when running your job script to specify the project name in order to make use\
    \ of your dedicated worker nodes. In your Torque/PBS job script, add the following\
    \ line (using your actual project name rather than <code>myprojectname</code>):</p>\n\
    <pre><code>    #PBS -A myprojectname\n</code></pre>\n<p>Alternatively, you can\
    \ specify the project name as a command line option to the qsub job submission\
    \ command, as follows:</p>\n<pre><code>    $ qsub -A myprojectname myjobscript.sub\n\
    </code></pre>\n<p>If you don't know or can't remember the project name, you can\
    \ just type anything after the <code>-A</code> flag and you will get an error\
    \ message telling you what project names you are eligible to use.</p>\n<p>If you\
    \ do not specify a project name, the job will be run on the shared worker nodes\
    \ of the cluster.</p>\n<p>If you want to run jobs ONLY on your own worker nodes,\
    \ add <code>myprojectname</code> to the nodes' properties. For example, in the\
    \ job scripts, it can be</p>\n<pre><code>    #PBS -l nodes=1:myprojectname\n</code></pre>\n\
    <p><a href=\"#glossary\">Glossary of Terms</a> <br>\n<a href=\"#top\">Top of page</a></p>\n\
    <hr>\n<p><a name=\"the-name\"></a></p>\n<h2>The name</h2>\n<ul>\n<li>Clusters\
    \ managed by eRSA have traditionally been given names of constellations. In this\
    \ case, we also wanted to somehow incorporate the concept of \"cloud\". We chose\
    \ the name based on a constellation from Aboriginal culture, the <a href=\"http://en.wikipedia.org/wiki/Australian_Aboriginal_astronomy#Emu_in_the_sky\"\
    >Emu in the sky</a>, which is not based on stars, but rather on dust clouds in\
    \ our galaxy creating dark areas in the Milky Way between the Southern Cross and\
    \ Scorpius, which resemble the outline of an emu.</li>\n</ul>\n<p><a href=\"#top\"\
    >Top of page</a></p>\n<hr>\n<p><a name=\"appendix\"></a></p>\n<h2>Appendices</h2>\n\
    <p><a name=\"example\"></a></p>\n<h3>An example Torque submission script</h3>\n\
    <p>This is an example of modifying a copy of the 'emu.sub' submission script template\
    \ to run an executable 'process_radtags' from a package called 'Stacks'. The first\
    \ step is to check the availability of the package, and what modules need to be\
    \ loaded first as a prerequisite for loading Stacks. Then the script is modified\
    \ as highlighted for submission of the job.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/emu_module_availwhatis.png?raw=true\"\
    ></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/emu_modify_emu_sub.png?raw=true\"\
    ></p>\n<p><a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"convert\"></a></p>\n\
    <h3>Modify a Tizard submision script for Emu</h3>\n<p>If you have an existing\
    \ submission script based on the 'tizard.sub', you can convert it to an Emu submission\
    \ script with the simple changes highlighted below.</p>\n<p><img alt=\"\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/emu_tizard_emu_sub.png?raw=true\"\
    ></p>\n<p><a href=\"#top\">Top of page</a></p>\n<hr>\n<p><a name=\"app1\"></a></p>\n\
    <h3>A quick guide to copying files from eRSA '/data' storage</h3>\n<p>The following\
    \ information outlines commands that can be entered on your VM in order to transfer\
    \ data to and from remote data storage, such as the eRSA '/data' storage block.\
    \ There is an <a href=\"http://support.ersa.edu.au/storage/quick-start.html\"\
    >eRSA support page</a> with more detail on transferring data from eRSA storage.</p>\n\
    <h4>SFTP via the Command Line</h4>\n<p>Secure file transfer is available between\
    \ the VM and remote data storage using command line controls</p>\n<p>Enter the\
    \ 'sftp' command while logged on to 'emu.ersa.edu.au', and you will have access\
    \ to the remote storage server.</p>\n<p><code>sftp username@sftp.ersa.edu.au</code>\
    \   - you will be prompted for a password.</p>\n<p>You are now accessing the remote\
    \ data storage server, and you can navigate the files on the server as per usual\
    \ with commands like <code>cd</code> and <code>ls</code>.<br>\nThe commands <code>get</code>\
    \ and <code>put</code> will transfer data between the machines:</p>\n<ul>\n<li><code>get\
    \ &lt;remote_server_file.txt&gt; &lt;localEMU_destination/&gt;</code></li>\n<li><code>cd\
    \ /data/&lt;My directory&gt;</code> , <code>ls</code> - navigate to your files\
    \ on the remote server</li>\n<li>\n<p><code>get file.data ./</code> - fetch the\
    \ file from the server to the Emu working directory</p>\n</li>\n<li>\n<p><code>put\
    \ &lt;localEMU_destination/file.txt&gt; &lt;remote_directory/&gt;</code></p>\n\
    </li>\n<li><code>put results.zip /data/&lt;My directory&gt;</code></li>\n</ul>\n\
    <p>to close the sftp connection, type <code>exit</code>.</p>\n<hr>\n<p><a name=\"\
    glossary\"></a></p>\n<h2>Glossary</h2>\n<p><strong>Dashboard</strong></p>\n<blockquote>\n\
    <p>The NeCTAR Dashboard is the main web-based interface for managing NeCTAR virtuals.</p>\n\
    </blockquote>\n<p><strong>ERSA</strong></p>\n<blockquote>\n<p>eResearch SA runs\
    \ the South Australian node of the NeCTAR research cloud.</p>\n</blockquote>\n\
    <p><strong>HPC</strong></p>\n<blockquote>\n<p>High Performance Computing systems\
    \ - typically refers to \"high end\" computing hardware designed for doing \"\
    large\" computational tasks.</p>\n</blockquote>\n<p><strong>Modules</strong></p>\n\
    <blockquote>\n<p><a href=\"http://modules.sourceforge.net/\">Environment modules</a>\
    \ are used to configure a users environment to allow use of the software packages\
    \ available on the server. The module commands are used to find information on\
    \ the available packages, and to load the packages for use. </p>\n</blockquote>\n\
    <p><strong>Node</strong> (compute node) </p>\n<blockquote>\n<p>OpenStack terminology\
    \ for a physical computer used to run virtual machines. It will typically have\
    \ multiple CPUs and shared memory, and one or more network interfaces. It may\
    \ also have on-node disk storage.</p>\n</blockquote>\n<p><strong>Project</strong></p>\n\
    <blockquote>\n<p>The NeCTAR term for a \"resource container\"; i.e. what you get\
    \ when you are granted a NeCTAR allocation. A project \"owns\" virtual machine\
    \ instances, snapshots and various kinds of storage, and may be shared by multiple\
    \ users.</p>\n</blockquote>\n<p><strong>SSH</strong></p>\n<blockquote>\n<p>A protocol\
    \ and tools for establishing secure \"shell\" sessions over the network. SSH encrypts\
    \ the data transferred, and supports user authentication using public/private\
    \ keys.</p>\n</blockquote>\n<p><strong>Submission script</strong></p>\n<blockquote>\n\
    <p>A text file that is submitted to the <a href=\"http://support.ersa.edu.au/hpc/user-guide.html#running-jobs\"\
    >Torque queueing system</a> to run a job. It consists of lines that are not read\
    \ by torque (beginning with ###), lines with Torque commands (beginning with #),\
    \ and lines with shell script commands.</p>\n</blockquote>\n<p><strong>Tizard</strong></p>\n\
    <blockquote>\n<p><a href=\"http://www.ersa.edu.au/service/hpc/tizard/\">Tizard</a>\
    \ is eRSA's high performance computing server that can be used for complex data\
    \ processing and analysis jobs that standard desktop computers would find it difficult\
    \ or impossible to perform. It enables users to run many processing jobs with\
    \ different parameters or input files more quickly.</p>\n</blockquote>\n<p><strong>Volume\
    \ Storage</strong></p>\n<blockquote>\n<p>Data Storage in your Virtual Machine\
    \ that works like a hard-drive on your PC or laptop does. Volume storage is automatically\
    \ available in your VM as the storage space for you system drive. Some flavors\
    \ of VMs include an amount of ephemeral volume storage. Depending on your allocation\
    \ you can have persistent volume storage attached to your VM.</p>\n</blockquote>\n\
    <p><a href=\"https://support.nectar.org.au/support/solutions/articles/6000055445-glossary\"\
    >Full NeCTAR Glossary Page</a><br>\n<a href=\"http://cloud.nectar.org.au/faq/\"\
    >NeCTAR FAQ - general inormation</a><br>\nFor more help, contact the <a href=\"\
    mailto:servicedesk@ersa.edu.au\">eRSA Helpdesk</a></p>\n<p><a href=\"#top\">Top\
    \ of page</a></p>"
  parent: 24
  sha1: 6f149ecf9224f64a5f1d404d151114f58165cb5c
  title: eRSA Emu Cluster in the Cloud - user guide
97:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-11-30T22:01:49-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Mounting NFS file systems on NeCTAR instances \n Introduction\
          \ \n This document is intended to be a starting point for a NeCTAR VM user\
          \ who\nwishes to gain access to files stored in an NFS file server.  It\
          \ does not\ndeal with how to set up and secure an NFS file server, or how\
          \ to set up\nidentity management to support per-user access control. \n\
          \ Note that these instructions are intended to be generic.  If you need\
          \ to\nacccess NFS servers implemented by a specific NeCTAR Node operator\
          \ (for\nexample the QRIScloud RDSI collection servers), or virtual laboratory,\n\
          contact them for any service specific instructions. \n Background \n NFS\
          \ (Network File System) is a protocol that allows one Linux or Unix system\n\
          to \"mount\" a file system that consists of collection of files and directories\n\
          that are stored on a different system. \n The NFS protocol is designed to\
          \ allow fast access to files over a local area\nnetwork.  It supports the\
          \ full range of Linux / Unix file system functionality,\nand allows different\
          \ systems to simultaneously access and update shared files\nand directories.\
          \ \n An NFS file system is \"exported\" by a server to one or more client\
          \ machines.\nThe clients gain access by \"mounting\" the NFS file system\
          \ within the namespace\nof the client's local file system. \n Prerequisites\
          \ \n The following skills and privileges are required for the client-side\
          \ setup. \n \n \n Basic Linux system admin skills. \n \n \n Root privilege\
          \ / sudo access on the client NeCTAR VM. \n \n \n In addition: \n \n \n\
          \ You need to know the IP address of the NFS server, and the \"mount\n \
          \   path\" that identifies the directory tree that you have been granted\n\
          \    access to.  (The NFS server administrators will typically need to\n\
          \    enable access to your instance's IP address in the server's \"exports\"\
          \n    file.) \n \n \n The NFS server needs to be addressible by your client\
          \ VM at the\n    IP protocol level.  If the NFS server has a private IP\
          \ address, then\n    your client typically needs a viable route to that\
          \ network.  (For\n    QRIScloud, this is achieved using the instance's second\
          \ virtual NIC.) \n \n \n Any firewalls need to have been configured to allow\
          \ NFS traffic on\n    port 111 (TCP and UDP) and 2049 (TCP and UDP).  Cluster\
          \ status\n    requires port 1110 (TCP), and client status requires port\
          \ 1110 (UDP), and\n    the NFS lock manager requires port 4045 (TCP and\
          \ UDP). \n \n \n Installing NFS client software \n Before you attempt to\
          \ use client-side NFS, you need to install some packages\nusing your system's\
          \ package manager. \n On a Debian, Ubuntu or similar system by running the\
          \ following commands: \n sudo apt-get update`\nsudo apt-get install nfs-common\
          \ autofs \n On RedHat, CentOS or Scientific Linux, run the following: \n\
          \ sudo yum install nfs-utils autofs` \n On (recent) Fedora, run the following:\
          \ \n sudo dnf install nfs-utils autofs \n (The \"autofs\" package is needed\
          \ if you want to configure the NFS client\nto automount the remote file\
          \ systems.) \n Configuring the NFS mount \n There are (at least) 3 ways\
          \ to mount a file system on a remote NFS server \n \n With a temporary mount,\
          \ the mount does not survive an instance reboot. \n With a permanent mount,\
          \ the file system is mounted automatically on\n    instance startup. \n\
          \ With an automount, the file system is mounted when some program tries\n\
          \    to access files, and then unmounted after a period of inactivity. \n\
          \ \n The NFS mount string and options \n The NFS mount string and mount\
          \ options are the key pieces of information\nthat are needed when an NFS\
          \ file system is mounted. \n The <mount-string> specifies the remote NFS\
          \ file system to be mounted\non your client VM.  It consists of the NFS\
          \ server's IP address, and\nan exported NFS path, with a colon between them.\
          \  For example: \n 10.255.120.220:/users/fred \n The <mount-options> determine\
          \ how the client-side kernel manages\nNFS access.  We recommend the following\
          \ NFS mount options as a\nstarting point: \n rw,hard,intr,nosuid,nodev,timeo=100,retrans=5,nolock\
          \ \n or the following if you need to use NFS version 3: \n rw,nfsvers=3,hard,intr,nosuid,nodev,timeo=100,retrans=5,nolock\
          \ \n The above parameters have the following meanings: \n \n \n \"rw\" means\
          \ mount the file system with read-write access.  An alternative\n    is\
          \ \"ro\" for read-only access. \n \n \n \"hard\" instructs the system to\
          \ attempt to retry \"for ever\" to reconnect\n    if the client looses its\
          \ NFS connection.  This is strongly recommended. \n \n \n \"intr\" is a\
          \ backwards compatibility flag. \n \n \n \"nosuid\" tells the kernel to\
          \ ignore the \"set user id\" flag on executables. \n \n \n \"nodev\" treats\
          \ \"device files\" as uninterpretted. \n \n \n the \"timeo\" value is the\
          \ timeout (in 10ths of a second) for NFS\n    request retransmission if\
          \ the client gets no response. \n \n \n the \"retrans\" value is the number\
          \ of simple retries before the client\n    attempts further recovery actions.\
          \ \n \n \n \"nolock\" disables file locking on the server.  (If a client-side\
          \ program\n    locks a file, the lock's coverage is limited to just this\
          \ client.) \n \n \n For more details on these and other NFS mount parameters,\
          \ please refer to\n\"man 5 nfs\" and other NFS documentation. \n The mount\
          \ point \n When a Linux (or UNIX) system mounts a file system, it mounts\
          \ it on top\nof an existing directory.  That directory is known as the mount\
          \ point.\nIf you are doing a temporary NFS mount, or setting up a permanent\
          \ mount,\nthe mount point directory needs to be created manually.  (If you\
          \ are\nusing the automount approach, the mount point directory can be created\n\
          automatically.) \n The normal Linux convention is to either use \"/mnt\"\
          \ or a subdirectory\nof \"/mnt\" as the mount point.  However NeCTAR VMs\
          \ use \"/mnt\" as the mount\npoint for the (so-called) ephemeral file system.\
          \ \n You can use the \"mkdir\" command to create the mountpoint directory.\
          \  It is\nprobably advisable to create it in direcftory that cannot be written\
          \ by\nunprivileged users. \n Creating a temporary NFS mount \n Before you\
          \ get into the (relative) complexity of setting up a permanent\nmount or\
          \ an automount, it is a good idea to check that you can access\nthe NFS\
          \ server by setting up a temporary mount.  You can also use this\napproach\
          \ for once-off or ad-hoc access to NFS. \n The steps are as follows: \n\
          \ \n \n Create a temporary mount point: \n mkdir ~/tempMount \n \n \n Run\
          \ the mount command: \n sudo mount -t nfs -o <mount-options> <mount-string>\
          \ ~/tempMount \n where the  and  are as described above. \n \n \n Check\
          \ that you can access data on the mounted file system: \n $ ls -l ~/tempMount\n\
          <directory listing> \n \n \n When you are done, unmount the file system\
          \ and tidy up the mount point: \n sudo umount ~/tempMount\nrmdir ~/tempMount\
          \ \n Note that the \"umount\" will fail if any process (including as shell)\n\
          \ has files on the mounted file system open, or if it has a directory\n\
          \ in the file system as its current directory. \n \n \n Configuring a fixed\
          \ NFS mount \n Fixed mounts are typically configured by adding entries to\
          \ the \"/etc/fstab\"\nfile.  This file is consulted to work out which file\
          \ systems to mount on\nsystem startup.  It is also used when you run \"\
          mount -a\" or \"mount  \".\n A typical \"/etc/fstab\" file on a NeCTAR instance\
          \ looks something like this: \n /dev/vda1 /          ext4    defaults  \
          \                           1 1\ntmpfs     /dev/shm   tmpfs   defaults \
          \                            0 0\ndevpts    /dev/pts   devpts  gid=5,mode=620\
          \                       0 0\nsysfs     /sys       sysfs   defaults     \
          \                        0 0\nproc      /proc      proc    defaults    \
          \                         0 0\n/dev/vdb  /mnt       auto    defaults,nofail,comment=cloudconfig\
          \  0 2 \n Each line describes a file system, and has 6 fields separated\
          \ by spaces\nand tab characters. \n \n Field 1 gives the device or other\
          \ specification for the file\n    system to be mounted. \n Field 2 gives\
          \ the mount point on which the file system should be mounted. \n Field 3\
          \ gives the file system type.  In the example above, \"ext4\" is\n    a\
          \ regular file system format, and the remainder have special meanings. \n\
          \ Field 4 gives any mount options relevant to the mount. \n Field 5 is only\
          \ relevant to the \"dump(8)\" program. \n Field 6 determines the order in\
          \ which (local) file systems are checked\n    by the \"fsck(8)\" program\
          \ at boot time. \n \n To configure a fixed NFS mount, you need to use a\
          \ text editor to edit the\n\"/etc/fstab\" file to add a line that looks\
          \ like this: \n <mount-string> <mount-point> nfs <mount-options> 0 0 \n\
          \ where the <mount-string> and <mount-options> are as above, and the\n<mount-point>\
          \ is a directory that you have created using \"mkdir\"\nas mentioned above.\
          \ \n Once you have added the entry, you should run \"sudo mount \"\nor \"\
          sudo mount -a\" to mount the NFS file system, and then check that you\n\
          can read files. \n (Note: depending on how the NFS file system was exported,\
          \ you\nmay find that local \"root\" account does not have special privileges\
          \ on\nthe NFS file system; see the section below on \"root squashing\".)\
          \ \n Configuring an NFS automount \n On a modern Linux distro, automounting\
          \ is handled by a service called\n\"autofs\".  This service consults the\
          \ \"/etc/autofs.master\" configuration\nfile to determine where the mount-points\
          \ should be, and then launches\n\"automount\" daemons to control the automatic\
          \ mounting and unmounting. \n The \"autofs\" / \"automount\" mechanisms\
          \ are highly configurable, but we\nrecommend a simple configuration as a\
          \ starting point.  Here is a simple\nrecipe: \n \n \n Install the \"autofs\"\
          \ package (as above). \n \n \n Edit the \"/etc/autofs.master\" file, and\
          \ add the following line at\n     the end of the file: \n /- file:/etc/auto.mynfsmounts\
          \ \n \n \n Create the \"/etc/auto.mynfsmount\" file, containing the following\n\
          \     line: \n <mount-point> <mount-options> <mount-path> \n where the <mount-point>,\
          \ <mount-options> and <mount-path> are as\n described above. \n \n \n Make\
          \ sure that the file is only writeable by root. \n sudo chown root:root\
          \ /etc/auto.mynfsmount\nsudo chmod 644 /etc/auto.mynfsmount \n \n \n Start\
          \ the \"autofs\" service, using your Linux distro's idiom for\n     starting\
          \ a service; e.g. \n sudo service autofs start \n or \n sudo systemctl start\
          \ autofs \n \n \n Check that the collection mounts: \n $ cd <mount-point>\n\
          $ ls -l\n<directory listing> \n \n \n Configure the \"autofs\" service to\
          \ start automatically on system\n     reboot. \n sudo chkconfig --add autofs\
          \ \n or \n sudo systemctl enable autofs \n \n \n Client-side Security and\
          \ Access Control \n Possibly the most difficult aspect of using NFS in the\
          \ NeCTAR context is\nestablishing who is allowed to access the files on\
          \ the NFS server.  The\nfirst problem is ensuring that the client and server\
          \ sides agree on user\nidentities. \n On UNIX / Linux systems, the operating\
          \ system and the file systems use\n\"uids\" (user identifiers) to denote\
          \ users.  These uids are fundamentally\njust numbers.  The problem is ensuring\
          \ that the uids are used consistently;\ne.g. that 1001 means the same person,\
          \ wherever it is used as a uid. \n \n \n This is easy to do within a NeCTAR\
          \ instance. The mapping between the\n    user accounts are created using\
          \ \"adduser\", and the uid <-> account mapping\n    is represented by the\
          \ \"/etc/passwd\" file. \n \n \n If you are managing a cluster of NeCTAR\
          \ instances, you create accounts on\n    one instance and push \"/etc/passwd\"\
          \ (and the associated \"/etc/shadow\"\n    files) to the other instences.\
          \  Alternatively, you can set up an LDAP\n    server (or similar) that your\
          \ instances consult to get definitive\n    information about user identities.\
          \ \n \n \n Problems arise when you are trying to manage a group of instances,\
          \ where\nthere isn't a shared source of user identities.  In such cases,\
          \ you need\nto arrange that uids exposed by the NFS server are meaningful\
          \ to the\nNFS client(s). \n Note: there is a similar mechanism for groups,\
          \ with uids replaced by gids,\nand \"/etc/passwd\" replaced by \"/etc/groups\"\
          . \n Using root access to circumvent the problem \n If a user has root access\
          \ (e.g. via the \"sudo\" command) they can circumvent\nnormal file access\
          \ control, and read or write other users' files.  (This is\nnot entirely\
          \ true if SELinux is used, but that is beyond the scope of this\ndocumentation.)\
          \  For example: \n \n \n Running \"sudo bash\" gives the user a root shell.\
          \ \n \n \n Running \"sudo -u #1234 -g #2345 bash\" gives the user a shell\
          \ running\n    with uid 1234 and gid 2345. \n \n \n This kind of thing will\
          \ allow you to access files on an NFS mounted file\nsystem, provided that\
          \ the file system has not been exported with\n\"root_squash\" or \"all_squash\"\
          .  (See below for an explanation.) \n Creating access accounts and groups\
          \ \n One possible strategy is to figure out what uids are used on the NFS\
          \ server,\nand create client-side accounts that match them.  This can work\
          \ as a short\nterm solution; e.g. if users can use \"sudo\" to switch identities.\
          \  However,\nit is clunky, and if the uids conflict it can be problematic.\
          \ \n If you want to go down this route, then you need to identify the appropriate\n\
          subset of the uids and gids used on the NFS server, and then create\nmirror\
          \ accounts and groups on the NFS client instance using the \"adduser\"\n\
          or \"useradd\" command and the \"groupadd\" command respectively. \n \n\
          \ \n Use the \"--uid\" and \"--gid\" options to set the same uid and gid\
          \ values\n    that are used on the NFS server. \n \n \n If the uid and gid\
          \ values are already in use on the client, you need\n    to consider whether\
          \ the collision is going to allow one user to access\n    another user's\
          \ files. \n \n \n Mapping identities \n The NFS version 4 allows uids to\
          \ \"name@domain\" strings and back for use in\nNFS requests.  This can be\
          \ used to deal with inconsistent uid <-> account\nname mmapings.  If you\
          \ want / need to do this, you will need to coordinate\nwith the manager\
          \ of the NFS server. \n This deals with the case where the same user (account\
          \ name) or group has\ndifferent uids and gids on the NFS server and client.\
          \  However, it doesn't\ndeal with the case where the same account or group\
          \ name is used for different\nidentities on the server and client.  And\
          \ it doesn't deal with the \"root\"\naccount \n NFS security \n NFS has\
          \ some inherent security issues that the people responsible for\nsetting\
          \ up the NFS server need to understand.  If you are merely using the\nNFS\
          \ server implemented by someone else, then you have to rely on the server\n\
          administrator to address these issues.  However, we mention them here\n\
          because the issues are relevant to you and the people whose data you may\n\
          be looking after. \n NFS client and server host identities \n By default,\
          \ an NFS server relies on IP addresses as the sole means of\ndetermining\
          \ the identify of NFS clients.  This is problematic if other machines\n\
          are able to spoof the IP address of a legitimate NFS client.  One way to\
          \ address\nthis (and other security concerns) is to use NFS with Kerberos.\
          \ \n There is also a concern that someone might spoof the IP address\nof\
          \ the NFS server, so that your NeCTAR instance mounts a \"fake\" file\n\
          system.  This might sound like a strange thing to do, but consider the\n\
          case where you have put user home directories on the NFS server, and\nthe\
          \ user's home directory holds a \".ssh/authorized_keys\" file.  If a\nhacker\
          \ can cause the client NFS to refer to a spoofed file, they can\nopen up\
          \ a way to login to the NFS client instance. \n Aside: unless there is a\
          \ misconfiguration, it should be impossible for\nNeCTAR OpenStack instances\
          \ to spoof IP addresses of other instances.\nHowever, it is not clear if\
          \ someone outside of your data centre might\nbe able to spoof the IP address\
          \ of an instance, and you probably would\nbe vulnerable to spoofing by a\
          \ non-Openstack host in your data centre,\nif such a host was ever compromised.\
          \ \n Root squashing \n The default behavior of an NFS server is to \"squash\"\
          \ the root account.\nWhat this does is to cause the NFS server to treate\
          \ any NFS requests\ncoming from the client using the root identity (user\
          \ 0) as if they\nwere coming from the nobody user.  This means that the\
          \ root user\n(or someone sudo'd to root) on the client does not have privileged\n\
          access to files on the mounted file system. \n Generally speaking, root\
          \ squashing is a sensible security measure,\nespecially if local root on\
          \ the clients cannot always be trusted (see\nbelow!).  However, it does\
          \ not prevent local root from assuming the\nidentity of some user, and accessing\
          \ his / her files that way.  In\nfact, the only things that root squashing\
          \ definitively stops are\noperations like \"chown\" that inherently require\
          \ root privilege. \n Note that root squashing is controlled by the NFS export\
          \ rules on the\nNFS server side. \n Deeper security issues \n By default,\
          \ NFS protocols send data, metadata and requests over the\nnetwork without\
          \ any encryption.  If it is possible for a 3rd party\nto run network snooping\
          \ (packet sniffing) software on any intervening\nnetworks, they will be\
          \ able see the files and metadata that is read or\nwritten by your client.\
          \  This is one reason why it is inadvisable to\nrun NFS over connections\
          \ that go outside of your NeCTAR node's networking\ninfrastructure. \n It\
          \ is possible to address the problem above by using a virtual private\n\
          network (VPN).  The problem is that the network traffic needs to be\nencrypted,\
          \ which impacts the performance of NFS running over the VPN. \n A second\
          \ issue is that the NFS file access control model assumes a level\nof trust\
          \ between people with root access to the client and server machines.  If\n\
          that trust does not exist (or is ill-founded) then the end user (the notional\n\
          owner of the files) cannot rely on access controls being properly enforced.\
          \ \n The problem is that the group of people with root access can be larger\n\
          than you might expect.  On the client side, it will include: \n \n The person\
          \ who launched the client-side instance, and who we can assume\n    has\
          \ the private key for logging in on the service account. \n Anyone who knows\
          \ the root password (if one has been set) and is a member\n    of the tenant.\
          \ \n Anyone who can legitimately login to the service account, or to any\
          \ other\n    account with sudo access. \n Anyone who has NeCTAR tenant member\
          \ access and can \"rebuild\" the instance. \n Anyone who is able to hack\
          \ into your instance and get root access, or\n    steal credentials for\
          \ the tenant. \n \n In short, if you are going to enable a NeCTAR instance\
          \ to mount an NFS\nfile system, then the security of the NeCTAR instance\
          \ (the NFS client) and\nthe trustworthiness of the administrators is paramount.\
          \ \n More information \n There is more information on NFS in general and\
          \ the topic of setting\nup NFS mounts in the following places. \n Linux\
          \ manual entries: \n \n man 5 nfs \n man 5 fstab \n man 5 autofs \n man\
          \ 5 auto.master \n man 8 mount \n man 8 umount \n man 8 autofs \n \n Ubuntu\
          \ guides: \n \n https://help.ubuntu.com/community/SettingUpNFSHowTo \n https://help.ubuntu.com/lts/serverguide/network-file-system.html\
          \ \n https://help.ubuntu.com/community/Autofs \n "
        description: "<h1>Mounting NFS file systems on NeCTAR instances</h1>\n<h2>Introduction</h2>\n\
          <p>This document is intended to be a starting point for a NeCTAR VM user\
          \ who\nwishes to gain access to files stored in an NFS file server.  It\
          \ does not\ndeal with how to set up and secure an NFS file server, or how\
          \ to set up\nidentity management to support per-user access control.</p>\n\
          <p>Note that these instructions are intended to be generic.  If you need\
          \ to\nacccess NFS servers implemented by a specific NeCTAR Node operator\
          \ (for\nexample the QRIScloud RDSI collection servers), or virtual laboratory,\n\
          contact them for any service specific instructions.</p>\n<h2>Background</h2>\n\
          <p>NFS (Network File System) is a protocol that allows one Linux or Unix\
          \ system\nto \"mount\" a file system that consists of collection of files\
          \ and directories\nthat are stored on a different system.</p>\n<p>The NFS\
          \ protocol is designed to allow fast access to files over a local area\n\
          network.  It supports the full range of Linux / Unix file system functionality,\n\
          and allows different systems to simultaneously access and update shared\
          \ files\nand directories.</p>\n<p>An NFS file system is \"exported\" by\
          \ a server to one or more client machines.\nThe clients gain access by \"\
          mounting\" the NFS file system within the namespace\nof the client's local\
          \ file system.</p>\n<h2>Prerequisites</h2>\n<p>The following skills and\
          \ privileges are required for the client-side setup.</p>\n<ul>\n<li>\n<p>Basic\
          \ Linux system admin skills.</p>\n</li>\n<li>\n<p>Root privilege / sudo\
          \ access on the client NeCTAR VM.</p>\n</li>\n</ul>\n<p>In addition:</p>\n\
          <ul>\n<li>\n<p>You need to know the IP address of the NFS server, and the\
          \ \"mount\n    path\" that identifies the directory tree that you have been\
          \ granted\n    access to.  (The NFS server administrators will typically\
          \ need to\n    enable access to your instance's IP address in the server's\
          \ \"exports\"\n    file.)</p>\n</li>\n<li>\n<p>The NFS server needs to be\
          \ addressible by your client VM at the\n    IP protocol level.  If the NFS\
          \ server has a private IP address, then\n    your client typically needs\
          \ a viable route to that network.  (For\n    QRIScloud, this is achieved\
          \ using the instance's second virtual NIC.)</p>\n</li>\n<li>\n<p>Any firewalls\
          \ need to have been configured to allow NFS traffic on\n    port 111 (TCP\
          \ and UDP) and 2049 (TCP and UDP).  Cluster status\n    requires port 1110\
          \ (TCP), and client status requires port 1110 (UDP), and\n    the NFS lock\
          \ manager requires port 4045 (TCP and UDP).</p>\n</li>\n</ul>\n<h2>Installing\
          \ NFS client software</h2>\n<p>Before you attempt to use client-side NFS,\
          \ you need to install some packages\nusing your system's package manager.</p>\n\
          <p>On a Debian, Ubuntu or similar system by running the following commands:</p>\n\
          <p><code>sudo apt-get update`\nsudo apt-get install nfs-common autofs</code></p>\n\
          <p>On RedHat, CentOS or Scientific Linux, run the following:</p>\n<p><code>sudo\
          \ yum install nfs-utils autofs`</code></p>\n<p>On (recent) Fedora, run the\
          \ following:</p>\n<p><code>sudo dnf install nfs-utils autofs</code></p>\n\
          <p>(The \"autofs\" package is needed if you want to configure the NFS client\n\
          to automount the remote file systems.)</p>\n<h2>Configuring the NFS mount</h2>\n\
          <p>There are (at least) 3 ways to mount a file system on a remote NFS server</p>\n\
          <ul>\n<li>With a temporary mount, the mount does not survive an instance\
          \ reboot.</li>\n<li>With a permanent mount, the file system is mounted automatically\
          \ on\n    instance startup.</li>\n<li>With an automount, the file system\
          \ is mounted when some program tries\n    to access files, and then unmounted\
          \ after a period of inactivity.</li>\n</ul>\n<h3>The NFS mount string and\
          \ options</h3>\n<p>The NFS mount string and mount options are the key pieces\
          \ of information\nthat are needed when an NFS file system is mounted.</p>\n\
          <p>The <code>&lt;mount-string&gt;</code> specifies the remote NFS file system\
          \ to be mounted\non your client VM.  It consists of the NFS server's IP\
          \ address, and\nan exported NFS path, with a colon between them.  For example:</p>\n\
          <p><code>10.255.120.220:/users/fred</code></p>\n<p>The <code>&lt;mount-options&gt;</code>\
          \ determine how the client-side kernel manages\nNFS access.  We recommend\
          \ the following NFS mount options as a\nstarting point:</p>\n<p><code>rw,hard,intr,nosuid,nodev,timeo=100,retrans=5,nolock</code></p>\n\
          <p>or the following if you need to use NFS version 3:</p>\n<p><code>rw,nfsvers=3,hard,intr,nosuid,nodev,timeo=100,retrans=5,nolock</code></p>\n\
          <p>The above parameters have the following meanings:</p>\n<ul>\n<li>\n<p>\"\
          rw\" means mount the file system with read-write access.  An alternative\n\
          \    is \"ro\" for read-only access.</p>\n</li>\n<li>\n<p>\"hard\" instructs\
          \ the system to attempt to retry \"for ever\" to reconnect\n    if the client\
          \ looses its NFS connection.  This is strongly recommended.</p>\n</li>\n\
          <li>\n<p>\"intr\" is a backwards compatibility flag.</p>\n</li>\n<li>\n\
          <p>\"nosuid\" tells the kernel to ignore the \"set user id\" flag on executables.</p>\n\
          </li>\n<li>\n<p>\"nodev\" treats \"device files\" as uninterpretted.</p>\n\
          </li>\n<li>\n<p>the \"timeo\" value is the timeout (in 10ths of a second)\
          \ for NFS\n    request retransmission if the client gets no response.</p>\n\
          </li>\n<li>\n<p>the \"retrans\" value is the number of simple retries before\
          \ the client\n    attempts further recovery actions.</p>\n</li>\n<li>\n\
          <p>\"nolock\" disables file locking on the server.  (If a client-side program\n\
          \    locks a file, the lock's coverage is limited to just this client.)</p>\n\
          </li>\n</ul>\n<p>For more details on these and other NFS mount parameters,\
          \ please refer to\n\"man 5 nfs\" and other NFS documentation.</p>\n<h3>The\
          \ mount point</h3>\n<p>When a Linux (or UNIX) system mounts a file system,\
          \ it mounts it on top\nof an existing directory.  That directory is known\
          \ as the mount point.\nIf you are doing a temporary NFS mount, or setting\
          \ up a permanent mount,\nthe mount point directory needs to be created manually.\
          \  (If you are\nusing the automount approach, the mount point directory\
          \ can be created\nautomatically.)</p>\n<p>The normal Linux convention is\
          \ to either use \"/mnt\" or a subdirectory\nof \"/mnt\" as the mount point.\
          \  However NeCTAR VMs use \"/mnt\" as the mount\npoint for the (so-called)\
          \ ephemeral file system.</p>\n<p>You can use the \"mkdir\" command to create\
          \ the mountpoint directory.  It is\nprobably advisable to create it in direcftory\
          \ that cannot be written by\nunprivileged users.</p>\n<h3>Creating a temporary\
          \ NFS mount</h3>\n<p>Before you get into the (relative) complexity of setting\
          \ up a permanent\nmount or an automount, it is a good idea to check that\
          \ you can access\nthe NFS server by setting up a temporary mount.  You can\
          \ also use this\napproach for once-off or ad-hoc access to NFS.</p>\n<p>The\
          \ steps are as follows:</p>\n<ol>\n<li>\n<p>Create a temporary mount point:</p>\n\
          <p><code>mkdir ~/tempMount</code></p>\n</li>\n<li>\n<p>Run the mount command:</p>\n\
          <p><code>sudo mount -t nfs -o &lt;mount-options&gt; &lt;mount-string&gt;\
          \ ~/tempMount</code></p>\n<p>where the  and  are as described above.</p>\n\
          </li>\n<li>\n<p>Check that you can access data on the mounted file system:</p>\n\
          <p><code>$ ls -l ~/tempMount\n&lt;directory listing&gt;</code></p>\n</li>\n\
          <li>\n<p>When you are done, unmount the file system and tidy up the mount\
          \ point:</p>\n<p><code>sudo umount ~/tempMount\nrmdir ~/tempMount</code></p>\n\
          <p>Note that the \"umount\" will fail if any process (including as shell)\n\
          \ has files on the mounted file system open, or if it has a directory\n\
          \ in the file system as its current directory.</p>\n</li>\n</ol>\n<h3>Configuring\
          \ a fixed NFS mount</h3>\n<p>Fixed mounts are typically configured by adding\
          \ entries to the \"/etc/fstab\"\nfile.  This file is consulted to work out\
          \ which file systems to mount on\nsystem startup.  It is also used when\
          \ you run \"mount -a\" or \"mount </p>\".\n<p>A typical \"/etc/fstab\" file\
          \ on a NeCTAR instance looks something like this:</p>\n<p><code>/dev/vda1\
          \ /          ext4    defaults                             1 1\ntmpfs   \
          \  /dev/shm   tmpfs   defaults                             0 0\ndevpts \
          \   /dev/pts   devpts  gid=5,mode=620                       0 0\nsysfs \
          \    /sys       sysfs   defaults                             0 0\nproc \
          \     /proc      proc    defaults                             0 0\n/dev/vdb\
          \  /mnt       auto    defaults,nofail,comment=cloudconfig  0 2</code></p>\n\
          <p>Each line describes a file system, and has 6 fields separated by spaces\n\
          and tab characters.</p>\n<ul>\n<li>Field 1 gives the device or other specification\
          \ for the file\n    system to be mounted.</li>\n<li>Field 2 gives the mount\
          \ point on which the file system should be mounted.</li>\n<li>Field 3 gives\
          \ the file system type.  In the example above, \"ext4\" is\n    a regular\
          \ file system format, and the remainder have special meanings.</li>\n<li>Field\
          \ 4 gives any mount options relevant to the mount.</li>\n<li>Field 5 is\
          \ only relevant to the \"dump(8)\" program.</li>\n<li>Field 6 determines\
          \ the order in which (local) file systems are checked\n    by the \"fsck(8)\"\
          \ program at boot time.</li>\n</ul>\n<p>To configure a fixed NFS mount,\
          \ you need to use a text editor to edit the\n\"/etc/fstab\" file to add\
          \ a line that looks like this:</p>\n<p><code>&lt;mount-string&gt; &lt;mount-point&gt;\
          \ nfs &lt;mount-options&gt; 0 0</code></p>\n<p>where the <code>&lt;mount-string&gt;</code>\
          \ and <code>&lt;mount-options&gt;</code> are as above, and the\n<code>&lt;mount-point&gt;</code>\
          \ is a directory that you have created using \"mkdir\"\nas mentioned above.</p>\n\
          <p>Once you have added the entry, you should run \"sudo mount \"\nor \"\
          sudo mount -a\" to mount the NFS file system, and then check that you\n\
          can read files.</p>\n<p>(Note: depending on how the NFS file system was\
          \ exported, you\nmay find that local \"root\" account does not have special\
          \ privileges on\nthe NFS file system; see the section below on \"root squashing\"\
          .)</p>\n<h3>Configuring an NFS automount</h3>\n<p>On a modern Linux distro,\
          \ automounting is handled by a service called\n\"autofs\".  This service\
          \ consults the \"/etc/autofs.master\" configuration\nfile to determine where\
          \ the mount-points should be, and then launches\n\"automount\" daemons to\
          \ control the automatic mounting and unmounting.</p>\n<p>The \"autofs\"\
          \ / \"automount\" mechanisms are highly configurable, but we\nrecommend\
          \ a simple configuration as a starting point.  Here is a simple\nrecipe:</p>\n\
          <ol>\n<li>\n<p>Install the \"autofs\" package (as above).</p>\n</li>\n<li>\n\
          <p>Edit the \"/etc/autofs.master\" file, and add the following line at\n\
          \     the end of the file:</p>\n<p><code>/- file:/etc/auto.mynfsmounts</code></p>\n\
          </li>\n<li>\n<p>Create the \"/etc/auto.mynfsmount\" file, containing the\
          \ following\n     line:</p>\n<p><code>&lt;mount-point&gt; &lt;mount-options&gt;\
          \ &lt;mount-path&gt;</code></p>\n<p>where the <code>&lt;mount-point&gt;</code>,\
          \ <code>&lt;mount-options&gt;</code> and <code>&lt;mount-path&gt;</code>\
          \ are as\n described above.</p>\n</li>\n<li>\n<p>Make sure that the file\
          \ is only writeable by root.</p>\n<p><code>sudo chown root:root /etc/auto.mynfsmount\n\
          sudo chmod 644 /etc/auto.mynfsmount</code></p>\n</li>\n<li>\n<p>Start the\
          \ \"autofs\" service, using your Linux distro's idiom for\n     starting\
          \ a service; e.g.</p>\n<p><code>sudo service autofs start</code></p>\n<p>or</p>\n\
          <p><code>sudo systemctl start autofs</code></p>\n</li>\n<li>\n<p>Check that\
          \ the collection mounts:</p>\n<p><code>$ cd &lt;mount-point&gt;\n$ ls -l\n\
          &lt;directory listing&gt;</code></p>\n</li>\n<li>\n<p>Configure the \"autofs\"\
          \ service to start automatically on system\n     reboot.</p>\n<p><code>sudo\
          \ chkconfig --add autofs</code></p>\n<p>or</p>\n<p><code>sudo systemctl\
          \ enable autofs</code></p>\n</li>\n</ol>\n<h2>Client-side Security and Access\
          \ Control</h2>\n<p>Possibly the most difficult aspect of using NFS in the\
          \ NeCTAR context is\nestablishing who is allowed to access the files on\
          \ the NFS server.  The\nfirst problem is ensuring that the client and server\
          \ sides agree on user\nidentities.</p>\n<p>On UNIX / Linux systems, the\
          \ operating system and the file systems use\n\"uids\" (user identifiers)\
          \ to denote users.  These uids are fundamentally\njust numbers.  The problem\
          \ is ensuring that the uids are used consistently;\ne.g. that <code>1001</code>\
          \ means the same person, wherever it is used as a uid.</p>\n<ul>\n<li>\n\
          <p>This is easy to do within a NeCTAR instance. The mapping between the\n\
          \    user accounts are created using \"adduser\", and the uid &lt;-&gt;\
          \ account mapping\n    is represented by the \"/etc/passwd\" file.</p>\n\
          </li>\n<li>\n<p>If you are managing a cluster of NeCTAR instances, you create\
          \ accounts on\n    one instance and push \"/etc/passwd\" (and the associated\
          \ \"/etc/shadow\"\n    files) to the other instences.  Alternatively, you\
          \ can set up an LDAP\n    server (or similar) that your instances consult\
          \ to get definitive\n    information about user identities.</p>\n</li>\n\
          </ul>\n<p>Problems arise when you are trying to manage a group of instances,\
          \ where\nthere isn't a shared source of user identities.  In such cases,\
          \ you need\nto arrange that uids exposed by the NFS server are meaningful\
          \ to the\nNFS client(s).</p>\n<p>Note: there is a similar mechanism for\
          \ groups, with uids replaced by gids,\nand \"/etc/passwd\" replaced by \"\
          /etc/groups\".</p>\n<h3>Using root access to circumvent the problem</h3>\n\
          <p>If a user has root access (e.g. via the \"sudo\" command) they can circumvent\n\
          normal file access control, and read or write other users' files.  (This\
          \ is\nnot entirely true if SELinux is used, but that is beyond the scope\
          \ of this\ndocumentation.)  For example:</p>\n<ul>\n<li>\n<p>Running \"\
          sudo bash\" gives the user a root shell.</p>\n</li>\n<li>\n<p>Running \"\
          sudo -u #1234 -g #2345 bash\" gives the user a shell running\n    with uid\
          \ 1234 and gid 2345.</p>\n</li>\n</ul>\n<p>This kind of thing will allow\
          \ you to access files on an NFS mounted file\nsystem, provided that the\
          \ file system has not been exported with\n\"root_squash\" or \"all_squash\"\
          .  (See below for an explanation.)</p>\n<h3>Creating access accounts and\
          \ groups</h3>\n<p>One possible strategy is to figure out what uids are used\
          \ on the NFS server,\nand create client-side accounts that match them. \
          \ This can work as a short\nterm solution; e.g. if users can use \"sudo\"\
          \ to switch identities.  However,\nit is clunky, and if the uids conflict\
          \ it can be problematic.</p>\n<p>If you want to go down this route, then\
          \ you need to identify the appropriate\nsubset of the uids and gids used\
          \ on the NFS server, and then create\nmirror accounts and groups on the\
          \ NFS client instance using the \"adduser\"\nor \"useradd\" command and\
          \ the \"groupadd\" command respectively.</p>\n<ul>\n<li>\n<p>Use the \"\
          --uid\" and \"--gid\" options to set the same uid and gid values\n    that\
          \ are used on the NFS server.</p>\n</li>\n<li>\n<p>If the uid and gid values\
          \ are already in use on the client, you need\n    to consider whether the\
          \ collision is going to allow one user to access\n    another user's files.</p>\n\
          </li>\n</ul>\n<h3>Mapping identities</h3>\n<p>The NFS version 4 allows uids\
          \ to \"name@domain\" strings and back for use in\nNFS requests.  This can\
          \ be used to deal with inconsistent uid &lt;-&gt; account\nname mmapings.\
          \  If you want / need to do this, you will need to coordinate\nwith the\
          \ manager of the NFS server.</p>\n<p>This deals with the case where the\
          \ same user (account name) or group has\ndifferent uids and gids on the\
          \ NFS server and client.  However, it doesn't\ndeal with the case where\
          \ the same account or group name is used for different\nidentities on the\
          \ server and client.  And it doesn't deal with the \"root\"\naccount</p>\n\
          <h2>NFS security</h2>\n<p>NFS has some inherent security issues that the\
          \ people responsible for\nsetting up the NFS server need to understand.\
          \  If you are merely using the\nNFS server implemented by someone else,\
          \ then you have to rely on the server\nadministrator to address these issues.\
          \  However, we mention them here\nbecause the issues are relevant to you\
          \ and the people whose data you may\nbe looking after.</p>\n<h3>NFS client\
          \ and server host identities</h3>\n<p>By default, an NFS server relies on\
          \ IP addresses as the sole means of\ndetermining the identify of NFS clients.\
          \  This is problematic if other machines\nare able to spoof the IP address\
          \ of a legitimate NFS client.  One way to address\nthis (and other security\
          \ concerns) is to use NFS with Kerberos.</p>\n<p>There is also a concern\
          \ that someone might spoof the IP address\nof the NFS server, so that your\
          \ NeCTAR instance mounts a \"fake\" file\nsystem.  This might sound like\
          \ a strange thing to do, but consider the\ncase where you have put user\
          \ home directories on the NFS server, and\nthe user's home directory holds\
          \ a \".ssh/authorized_keys\" file.  If a\nhacker can cause the client NFS\
          \ to refer to a spoofed file, they can\nopen up a way to login to the NFS\
          \ client instance.</p>\n<p>Aside: unless there is a misconfiguration, it\
          \ should be impossible for\nNeCTAR OpenStack instances to spoof IP addresses\
          \ of other instances.\nHowever, it is not clear if someone outside of your\
          \ data centre might\nbe able to spoof the IP address of an instance, and\
          \ you probably would\nbe vulnerable to spoofing by a non-Openstack host\
          \ in your data centre,\nif such a host was ever compromised.</p>\n<h3>Root\
          \ squashing</h3>\n<p>The default behavior of an NFS server is to \"squash\"\
          \ the root account.\nWhat this does is to cause the NFS server to treate\
          \ any NFS requests\ncoming from the client using the root identity (user\
          \ 0) <em>as if</em> they\nwere coming from the <em>nobody</em> user.  This\
          \ means that the root user\n(or someone sudo'd to root) on the client does\
          \ not have privileged\naccess to files on the mounted file system.</p>\n\
          <p>Generally speaking, root squashing is a sensible security measure,\n\
          especially if local root on the clients cannot always be trusted (see\n\
          below!).  However, it does not prevent local root from assuming the\nidentity\
          \ of some user, and accessing his / her files that way.  In\nfact, the only\
          \ things that root squashing definitively stops are\noperations like \"\
          chown\" that inherently require root privilege.</p>\n<p>Note that root squashing\
          \ is controlled by the NFS export rules on the\nNFS server side.</p>\n<h3>Deeper\
          \ security issues</h3>\n<p>By default, NFS protocols send data, metadata\
          \ and requests over the\nnetwork without any encryption.  If it is possible\
          \ for a 3rd party\nto run network snooping (packet sniffing) software on\
          \ any intervening\nnetworks, they will be able see the files and metadata\
          \ that is read or\nwritten by your client.  This is one reason why it is\
          \ inadvisable to\nrun NFS over connections that go outside of your NeCTAR\
          \ node's networking\ninfrastructure.</p>\n<p>It is possible to address the\
          \ problem above by using a virtual private\nnetwork (VPN).  The problem\
          \ is that the network traffic needs to be\nencrypted, which impacts the\
          \ performance of NFS running over the VPN.</p>\n<p>A second issue is that\
          \ the NFS file access control model assumes a level\nof trust between people\
          \ with root access to the client and server machines.  If\nthat trust does\
          \ not exist (or is ill-founded) then the end user (the notional\nowner of\
          \ the files) cannot rely on access controls being properly enforced.</p>\n\
          <p>The problem is that the group of people with root access can be larger\n\
          than you might expect.  On the client side, it will include:</p>\n<ul>\n\
          <li>The person who launched the client-side instance, and who we can assume\n\
          \    has the private key for logging in on the service account.</li>\n<li>Anyone\
          \ who knows the root password (if one has been set) and is a member\n  \
          \  of the tenant.</li>\n<li>Anyone who can legitimately login to the service\
          \ account, or to any other\n    account with sudo access.</li>\n<li>Anyone\
          \ who has NeCTAR tenant member access and can \"rebuild\" the instance.</li>\n\
          <li>Anyone who is able to hack into your instance and get root access, or\n\
          \    steal credentials for the tenant.</li>\n</ul>\n<p>In short, if you\
          \ are going to enable a NeCTAR instance to mount an NFS\nfile system, then\
          \ the security of the NeCTAR instance (the NFS client) and\nthe trustworthiness\
          \ of the administrators is paramount.</p>\n<h2>More information</h2>\n<p>There\
          \ is more information on NFS in general and the topic of setting\nup NFS\
          \ mounts in the following places.</p>\n<p>Linux manual entries:</p>\n<ul>\n\
          <li><a href=\"http://linux.die.net/man/5/nfs\"><code>man 5 nfs</code></a></li>\n\
          <li><a href=\"http://linux.die.net/man/5/nfs\"><code>man 5 fstab</code></a></li>\n\
          <li><a href=\"http://linux.die.net/man/5/autofs\"><code>man 5 autofs</code></a></li>\n\
          <li><a href=\"http://linux.die.net/man/5/auto.master\"><code>man 5 auto.master</code></a></li>\n\
          <li><a href=\"http://linux.die.net/man/8/mount\"><code>man 8 mount</code></a></li>\n\
          <li><a href=\"http://linux.die.net/man/8/umount\"><code>man 8 umount</code></a></li>\n\
          <li><a href=\"http://linux.die.net/man/8/autofs\"><code>man 8 autofs</code></a></li>\n\
          </ul>\n<p>Ubuntu guides:</p>\n<ul>\n<li>https://help.ubuntu.com/community/SettingUpNFSHowTo</li>\n\
          <li>https://help.ubuntu.com/lts/serverguide/network-file-system.html</li>\n\
          <li>https://help.ubuntu.com/community/Autofs</li>\n</ul>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 9
        id: 6000092818
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-07T16:41:03-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000092818
        position: 8
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: QCIF NFS Mounting
        updated_at: '2015-12-07T16:41:03-05:00'
        user_id: 6002464727
  html: "<h1>Mounting NFS file systems on NeCTAR instances</h1>\n<h2>Introduction</h2>\n\
    <p>This document is intended to be a starting point for a NeCTAR VM user who\n\
    wishes to gain access to files stored in an NFS file server.  It does not\ndeal\
    \ with how to set up and secure an NFS file server, or how to set up\nidentity\
    \ management to support per-user access control.</p>\n<p>Note that these instructions\
    \ are intended to be generic.  If you need to\nacccess NFS servers implemented\
    \ by a specific NeCTAR Node operator (for\nexample the QRIScloud RDSI collection\
    \ servers), or virtual laboratory,\ncontact them for any service specific instructions.</p>\n\
    <h2>Background</h2>\n<p>NFS (Network File System) is a protocol that allows one\
    \ Linux or Unix system\nto \"mount\" a file system that consists of collection\
    \ of files and directories\nthat are stored on a different system.</p>\n<p>The\
    \ NFS protocol is designed to allow fast access to files over a local area\nnetwork.\
    \  It supports the full range of Linux / Unix file system functionality,\nand\
    \ allows different systems to simultaneously access and update shared files\n\
    and directories.</p>\n<p>An NFS file system is \"exported\" by a server to one\
    \ or more client machines.\nThe clients gain access by \"mounting\" the NFS file\
    \ system within the namespace\nof the client's local file system.</p>\n<h2>Prerequisites</h2>\n\
    <p>The following skills and privileges are required for the client-side setup.</p>\n\
    <ul>\n<li>\n<p>Basic Linux system admin skills.</p>\n</li>\n<li>\n<p>Root privilege\
    \ / sudo access on the client NeCTAR VM.</p>\n</li>\n</ul>\n<p>In addition:</p>\n\
    <ul>\n<li>\n<p>You need to know the IP address of the NFS server, and the \"mount\n\
    \    path\" that identifies the directory tree that you have been granted\n  \
    \  access to.  (The NFS server administrators will typically need to\n    enable\
    \ access to your instance's IP address in the server's \"exports\"\n    file.)</p>\n\
    </li>\n<li>\n<p>The NFS server needs to be addressible by your client VM at the\n\
    \    IP protocol level.  If the NFS server has a private IP address, then\n  \
    \  your client typically needs a viable route to that network.  (For\n    QRIScloud,\
    \ this is achieved using the instance's second virtual NIC.)</p>\n</li>\n<li>\n\
    <p>Any firewalls need to have been configured to allow NFS traffic on\n    port\
    \ 111 (TCP and UDP) and 2049 (TCP and UDP).  Cluster status\n    requires port\
    \ 1110 (TCP), and client status requires port 1110 (UDP), and\n    the NFS lock\
    \ manager requires port 4045 (TCP and UDP).</p>\n</li>\n</ul>\n<h2>Installing\
    \ NFS client software</h2>\n<p>Before you attempt to use client-side NFS, you\
    \ need to install some packages\nusing your system's package manager.</p>\n<p>On\
    \ a Debian, Ubuntu or similar system by running the following commands:</p>\n\
    <p><code>sudo apt-get update`\nsudo apt-get install nfs-common autofs</code></p>\n\
    <p>On RedHat, CentOS or Scientific Linux, run the following:</p>\n<p><code>sudo\
    \ yum install nfs-utils autofs`</code></p>\n<p>On (recent) Fedora, run the following:</p>\n\
    <p><code>sudo dnf install nfs-utils autofs</code></p>\n<p>(The \"autofs\" package\
    \ is needed if you want to configure the NFS client\nto automount the remote file\
    \ systems.)</p>\n<h2>Configuring the NFS mount</h2>\n<p>There are (at least) 3\
    \ ways to mount a file system on a remote NFS server</p>\n<ul>\n<li>With a temporary\
    \ mount, the mount does not survive an instance reboot.</li>\n<li>With a permanent\
    \ mount, the file system is mounted automatically on\n    instance startup.</li>\n\
    <li>With an automount, the file system is mounted when some program tries\n  \
    \  to access files, and then unmounted after a period of inactivity.</li>\n</ul>\n\
    <h3>The NFS mount string and options</h3>\n<p>The NFS mount string and mount options\
    \ are the key pieces of information\nthat are needed when an NFS file system is\
    \ mounted.</p>\n<p>The <code>&lt;mount-string&gt;</code> specifies the remote\
    \ NFS file system to be mounted\non your client VM.  It consists of the NFS server's\
    \ IP address, and\nan exported NFS path, with a colon between them.  For example:</p>\n\
    <p><code>10.255.120.220:/users/fred</code></p>\n<p>The <code>&lt;mount-options&gt;</code>\
    \ determine how the client-side kernel manages\nNFS access.  We recommend the\
    \ following NFS mount options as a\nstarting point:</p>\n<p><code>rw,hard,intr,nosuid,nodev,timeo=100,retrans=5,nolock</code></p>\n\
    <p>or the following if you need to use NFS version 3:</p>\n<p><code>rw,nfsvers=3,hard,intr,nosuid,nodev,timeo=100,retrans=5,nolock</code></p>\n\
    <p>The above parameters have the following meanings:</p>\n<ul>\n<li>\n<p>\"rw\"\
    \ means mount the file system with read-write access.  An alternative\n    is\
    \ \"ro\" for read-only access.</p>\n</li>\n<li>\n<p>\"hard\" instructs the system\
    \ to attempt to retry \"for ever\" to reconnect\n    if the client looses its\
    \ NFS connection.  This is strongly recommended.</p>\n</li>\n<li>\n<p>\"intr\"\
    \ is a backwards compatibility flag.</p>\n</li>\n<li>\n<p>\"nosuid\" tells the\
    \ kernel to ignore the \"set user id\" flag on executables.</p>\n</li>\n<li>\n\
    <p>\"nodev\" treats \"device files\" as uninterpretted.</p>\n</li>\n<li>\n<p>the\
    \ \"timeo\" value is the timeout (in 10ths of a second) for NFS\n    request retransmission\
    \ if the client gets no response.</p>\n</li>\n<li>\n<p>the \"retrans\" value is\
    \ the number of simple retries before the client\n    attempts further recovery\
    \ actions.</p>\n</li>\n<li>\n<p>\"nolock\" disables file locking on the server.\
    \  (If a client-side program\n    locks a file, the lock's coverage is limited\
    \ to just this client.)</p>\n</li>\n</ul>\n<p>For more details on these and other\
    \ NFS mount parameters, please refer to\n\"man 5 nfs\" and other NFS documentation.</p>\n\
    <h3>The mount point</h3>\n<p>When a Linux (or UNIX) system mounts a file system,\
    \ it mounts it on top\nof an existing directory.  That directory is known as the\
    \ mount point.\nIf you are doing a temporary NFS mount, or setting up a permanent\
    \ mount,\nthe mount point directory needs to be created manually.  (If you are\n\
    using the automount approach, the mount point directory can be created\nautomatically.)</p>\n\
    <p>The normal Linux convention is to either use \"/mnt\" or a subdirectory\nof\
    \ \"/mnt\" as the mount point.  However NeCTAR VMs use \"/mnt\" as the mount\n\
    point for the (so-called) ephemeral file system.</p>\n<p>You can use the \"mkdir\"\
    \ command to create the mountpoint directory.  It is\nprobably advisable to create\
    \ it in direcftory that cannot be written by\nunprivileged users.</p>\n<h3>Creating\
    \ a temporary NFS mount</h3>\n<p>Before you get into the (relative) complexity\
    \ of setting up a permanent\nmount or an automount, it is a good idea to check\
    \ that you can access\nthe NFS server by setting up a temporary mount.  You can\
    \ also use this\napproach for once-off or ad-hoc access to NFS.</p>\n<p>The steps\
    \ are as follows:</p>\n<ol>\n<li>\n<p>Create a temporary mount point:</p>\n<p><code>mkdir\
    \ ~/tempMount</code></p>\n</li>\n<li>\n<p>Run the mount command:</p>\n<p><code>sudo\
    \ mount -t nfs -o &lt;mount-options&gt; &lt;mount-string&gt; ~/tempMount</code></p>\n\
    <p>where the <mount-options> and <mount-string> are as described above.</p>\n\
    </li>\n<li>\n<p>Check that you can access data on the mounted file system:</p>\n\
    <p><code>$ ls -l ~/tempMount\n&lt;directory listing&gt;</code></p>\n</li>\n<li>\n\
    <p>When you are done, unmount the file system and tidy up the mount point:</p>\n\
    <p><code>sudo umount ~/tempMount\nrmdir ~/tempMount</code></p>\n<p>Note that the\
    \ \"umount\" will fail if any process (including as shell)\n has files on the\
    \ mounted file system open, or if it has a directory\n in the file system as its\
    \ current directory.</p>\n</li>\n</ol>\n<h3>Configuring a fixed NFS mount</h3>\n\
    <p>Fixed mounts are typically configured by adding entries to the \"/etc/fstab\"\
    \nfile.  This file is consulted to work out which file systems to mount on\nsystem\
    \ startup.  It is also used when you run \"mount -a\" or \"mount <dir>\".</p>\n\
    <p>A typical \"/etc/fstab\" file on a NeCTAR instance looks something like this:</p>\n\
    <p><code>/dev/vda1 /          ext4    defaults                             1 1\n\
    tmpfs     /dev/shm   tmpfs   defaults                             0 0\ndevpts\
    \    /dev/pts   devpts  gid=5,mode=620                       0 0\nsysfs     /sys\
    \       sysfs   defaults                             0 0\nproc      /proc    \
    \  proc    defaults                             0 0\n/dev/vdb  /mnt       auto\
    \    defaults,nofail,comment=cloudconfig  0 2</code></p>\n<p>Each line describes\
    \ a file system, and has 6 fields separated by spaces\nand tab characters.</p>\n\
    <ul>\n<li>Field 1 gives the device or other specification for the file\n    system\
    \ to be mounted.</li>\n<li>Field 2 gives the mount point on which the file system\
    \ should be mounted.</li>\n<li>Field 3 gives the file system type.  In the example\
    \ above, \"ext4\" is\n    a regular file system format, and the remainder have\
    \ special meanings.</li>\n<li>Field 4 gives any mount options relevant to the\
    \ mount.</li>\n<li>Field 5 is only relevant to the \"dump(8)\" program.</li>\n\
    <li>Field 6 determines the order in which (local) file systems are checked\n \
    \   by the \"fsck(8)\" program at boot time.</li>\n</ul>\n<p>To configure a fixed\
    \ NFS mount, you need to use a text editor to edit the\n\"/etc/fstab\" file to\
    \ add a line that looks like this:</p>\n<p><code>&lt;mount-string&gt; &lt;mount-point&gt;\
    \ nfs &lt;mount-options&gt; 0 0</code></p>\n<p>where the <code>&lt;mount-string&gt;</code>\
    \ and <code>&lt;mount-options&gt;</code> are as above, and the\n<code>&lt;mount-point&gt;</code>\
    \ is a directory that you have created using \"mkdir\"\nas mentioned above.</p>\n\
    <p>Once you have added the entry, you should run \"sudo mount <mount-point>\"\n\
    or \"sudo mount -a\" to mount the NFS file system, and then check that you\ncan\
    \ read files.</p>\n<p>(Note: depending on how the NFS file system was exported,\
    \ you\nmay find that local \"root\" account does not have special privileges on\n\
    the NFS file system; see the section below on \"root squashing\".)</p>\n<h3>Configuring\
    \ an NFS automount</h3>\n<p>On a modern Linux distro, automounting is handled\
    \ by a service called\n\"autofs\".  This service consults the \"/etc/autofs.master\"\
    \ configuration\nfile to determine where the mount-points should be, and then\
    \ launches\n\"automount\" daemons to control the automatic mounting and unmounting.</p>\n\
    <p>The \"autofs\" / \"automount\" mechanisms are highly configurable, but we\n\
    recommend a simple configuration as a starting point.  Here is a simple\nrecipe:</p>\n\
    <ol>\n<li>\n<p>Install the \"autofs\" package (as above).</p>\n</li>\n<li>\n<p>Edit\
    \ the \"/etc/autofs.master\" file, and add the following line at\n     the end\
    \ of the file:</p>\n<p><code>/- file:/etc/auto.mynfsmounts</code></p>\n</li>\n\
    <li>\n<p>Create the \"/etc/auto.mynfsmount\" file, containing the following\n\
    \     line:</p>\n<p><code>&lt;mount-point&gt; &lt;mount-options&gt; &lt;mount-path&gt;</code></p>\n\
    <p>where the <code>&lt;mount-point&gt;</code>, <code>&lt;mount-options&gt;</code>\
    \ and <code>&lt;mount-path&gt;</code> are as\n described above.</p>\n</li>\n<li>\n\
    <p>Make sure that the file is only writeable by root.</p>\n<p><code>sudo chown\
    \ root:root /etc/auto.mynfsmount\nsudo chmod 644 /etc/auto.mynfsmount</code></p>\n\
    </li>\n<li>\n<p>Start the \"autofs\" service, using your Linux distro's idiom\
    \ for\n     starting a service; e.g.</p>\n<p><code>sudo service autofs start</code></p>\n\
    <p>or</p>\n<p><code>sudo systemctl start autofs</code></p>\n</li>\n<li>\n<p>Check\
    \ that the collection mounts:</p>\n<p><code>$ cd &lt;mount-point&gt;\n$ ls -l\n\
    &lt;directory listing&gt;</code></p>\n</li>\n<li>\n<p>Configure the \"autofs\"\
    \ service to start automatically on system\n     reboot.</p>\n<p><code>sudo chkconfig\
    \ --add autofs</code></p>\n<p>or</p>\n<p><code>sudo systemctl enable autofs</code></p>\n\
    </li>\n</ol>\n<h2>Client-side Security and Access Control</h2>\n<p>Possibly the\
    \ most difficult aspect of using NFS in the NeCTAR context is\nestablishing who\
    \ is allowed to access the files on the NFS server.  The\nfirst problem is ensuring\
    \ that the client and server sides agree on user\nidentities.</p>\n<p>On UNIX\
    \ / Linux systems, the operating system and the file systems use\n\"uids\" (user\
    \ identifiers) to denote users.  These uids are fundamentally\njust numbers. \
    \ The problem is ensuring that the uids are used consistently;\ne.g. that <code>1001</code>\
    \ means the same person, wherever it is used as a uid.</p>\n<ul>\n<li>\n<p>This\
    \ is easy to do within a NeCTAR instance. The mapping between the\n    user accounts\
    \ are created using \"adduser\", and the uid &lt;-&gt; account mapping\n    is\
    \ represented by the \"/etc/passwd\" file.</p>\n</li>\n<li>\n<p>If you are managing\
    \ a cluster of NeCTAR instances, you create accounts on\n    one instance and\
    \ push \"/etc/passwd\" (and the associated \"/etc/shadow\"\n    files) to the\
    \ other instences.  Alternatively, you can set up an LDAP\n    server (or similar)\
    \ that your instances consult to get definitive\n    information about user identities.</p>\n\
    </li>\n</ul>\n<p>Problems arise when you are trying to manage a group of instances,\
    \ where\nthere isn't a shared source of user identities.  In such cases, you need\n\
    to arrange that uids exposed by the NFS server are meaningful to the\nNFS client(s).</p>\n\
    <p>Note: there is a similar mechanism for groups, with uids replaced by gids,\n\
    and \"/etc/passwd\" replaced by \"/etc/groups\".</p>\n<h3>Using root access to\
    \ circumvent the problem</h3>\n<p>If a user has root access (e.g. via the \"sudo\"\
    \ command) they can circumvent\nnormal file access control, and read or write\
    \ other users' files.  (This is\nnot entirely true if SELinux is used, but that\
    \ is beyond the scope of this\ndocumentation.)  For example:</p>\n<ul>\n<li>\n\
    <p>Running \"sudo bash\" gives the user a root shell.</p>\n</li>\n<li>\n<p>Running\
    \ \"sudo -u #1234 -g #2345 bash\" gives the user a shell running\n    with uid\
    \ 1234 and gid 2345.</p>\n</li>\n</ul>\n<p>This kind of thing will allow you to\
    \ access files on an NFS mounted file\nsystem, provided that the file system has\
    \ not been exported with\n\"root_squash\" or \"all_squash\".  (See below for an\
    \ explanation.)</p>\n<h3>Creating access accounts and groups</h3>\n<p>One possible\
    \ strategy is to figure out what uids are used on the NFS server,\nand create\
    \ client-side accounts that match them.  This can work as a short\nterm solution;\
    \ e.g. if users can use \"sudo\" to switch identities.  However,\nit is clunky,\
    \ and if the uids conflict it can be problematic.</p>\n<p>If you want to go down\
    \ this route, then you need to identify the appropriate\nsubset of the uids and\
    \ gids used on the NFS server, and then create\nmirror accounts and groups on\
    \ the NFS client instance using the \"adduser\"\nor \"useradd\" command and the\
    \ \"groupadd\" command respectively.</p>\n<ul>\n<li>\n<p>Use the \"--uid\" and\
    \ \"--gid\" options to set the same uid and gid values\n    that are used on the\
    \ NFS server.</p>\n</li>\n<li>\n<p>If the uid and gid values are already in use\
    \ on the client, you need\n    to consider whether the collision is going to allow\
    \ one user to access\n    another user's files.</p>\n</li>\n</ul>\n<h3>Mapping\
    \ identities</h3>\n<p>The NFS version 4 allows uids to \"name@domain\" strings\
    \ and back for use in\nNFS requests.  This can be used to deal with inconsistent\
    \ uid &lt;-&gt; account\nname mmapings.  If you want / need to do this, you will\
    \ need to coordinate\nwith the manager of the NFS server.</p>\n<p>This deals with\
    \ the case where the same user (account name) or group has\ndifferent uids and\
    \ gids on the NFS server and client.  However, it doesn't\ndeal with the case\
    \ where the same account or group name is used for different\nidentities on the\
    \ server and client.  And it doesn't deal with the \"root\"\naccount</p>\n<h2>NFS\
    \ security</h2>\n<p>NFS has some inherent security issues that the people responsible\
    \ for\nsetting up the NFS server need to understand.  If you are merely using\
    \ the\nNFS server implemented by someone else, then you have to rely on the server\n\
    administrator to address these issues.  However, we mention them here\nbecause\
    \ the issues are relevant to you and the people whose data you may\nbe looking\
    \ after.</p>\n<h3>NFS client and server host identities</h3>\n<p>By default, an\
    \ NFS server relies on IP addresses as the sole means of\ndetermining the identify\
    \ of NFS clients.  This is problematic if other machines\nare able to spoof the\
    \ IP address of a legitimate NFS client.  One way to address\nthis (and other\
    \ security concerns) is to use NFS with Kerberos.</p>\n<p>There is also a concern\
    \ that someone might spoof the IP address\nof the NFS server, so that your NeCTAR\
    \ instance mounts a \"fake\" file\nsystem.  This might sound like a strange thing\
    \ to do, but consider the\ncase where you have put user home directories on the\
    \ NFS server, and\nthe user's home directory holds a \".ssh/authorized_keys\"\
    \ file.  If a\nhacker can cause the client NFS to refer to a spoofed file, they\
    \ can\nopen up a way to login to the NFS client instance.</p>\n<p>Aside: unless\
    \ there is a misconfiguration, it should be impossible for\nNeCTAR OpenStack instances\
    \ to spoof IP addresses of other instances.\nHowever, it is not clear if someone\
    \ outside of your data centre might\nbe able to spoof the IP address of an instance,\
    \ and you probably would\nbe vulnerable to spoofing by a non-Openstack host in\
    \ your data centre,\nif such a host was ever compromised.</p>\n<h3>Root squashing</h3>\n\
    <p>The default behavior of an NFS server is to \"squash\" the root account.\n\
    What this does is to cause the NFS server to treate any NFS requests\ncoming from\
    \ the client using the root identity (user 0) <em>as if</em> they\nwere coming\
    \ from the <em>nobody</em> user.  This means that the root user\n(or someone sudo'd\
    \ to root) on the client does not have privileged\naccess to files on the mounted\
    \ file system.</p>\n<p>Generally speaking, root squashing is a sensible security\
    \ measure,\nespecially if local root on the clients cannot always be trusted (see\n\
    below!).  However, it does not prevent local root from assuming the\nidentity\
    \ of some user, and accessing his / her files that way.  In\nfact, the only things\
    \ that root squashing definitively stops are\noperations like \"chown\" that inherently\
    \ require root privilege.</p>\n<p>Note that root squashing is controlled by the\
    \ NFS export rules on the\nNFS server side.</p>\n<h3>Deeper security issues</h3>\n\
    <p>By default, NFS protocols send data, metadata and requests over the\nnetwork\
    \ without any encryption.  If it is possible for a 3rd party\nto run network snooping\
    \ (packet sniffing) software on any intervening\nnetworks, they will be able see\
    \ the files and metadata that is read or\nwritten by your client.  This is one\
    \ reason why it is inadvisable to\nrun NFS over connections that go outside of\
    \ your NeCTAR node's networking\ninfrastructure.</p>\n<p>It is possible to address\
    \ the problem above by using a virtual private\nnetwork (VPN).  The problem is\
    \ that the network traffic needs to be\nencrypted, which impacts the performance\
    \ of NFS running over the VPN.</p>\n<p>A second issue is that the NFS file access\
    \ control model assumes a level\nof trust between people with root access to the\
    \ client and server machines.  If\nthat trust does not exist (or is ill-founded)\
    \ then the end user (the notional\nowner of the files) cannot rely on access controls\
    \ being properly enforced.</p>\n<p>The problem is that the group of people with\
    \ root access can be larger\nthan you might expect.  On the client side, it will\
    \ include:</p>\n<ul>\n<li>The person who launched the client-side instance, and\
    \ who we can assume\n    has the private key for logging in on the service account.</li>\n\
    <li>Anyone who knows the root password (if one has been set) and is a member\n\
    \    of the tenant.</li>\n<li>Anyone who can legitimately login to the service\
    \ account, or to any other\n    account with sudo access.</li>\n<li>Anyone who\
    \ has NeCTAR tenant member access and can \"rebuild\" the instance.</li>\n<li>Anyone\
    \ who is able to hack into your instance and get root access, or\n    steal credentials\
    \ for the tenant.</li>\n</ul>\n<p>In short, if you are going to enable a NeCTAR\
    \ instance to mount an NFS\nfile system, then the security of the NeCTAR instance\
    \ (the NFS client) and\nthe trustworthiness of the administrators is paramount.</p>\n\
    <h2>More information</h2>\n<p>There is more information on NFS in general and\
    \ the topic of setting\nup NFS mounts in the following places.</p>\n<p>Linux manual\
    \ entries:</p>\n<ul>\n<li><a href=\"http://linux.die.net/man/5/nfs\"><code>man\
    \ 5 nfs</code></a></li>\n<li><a href=\"http://linux.die.net/man/5/nfs\"><code>man\
    \ 5 fstab</code></a></li>\n<li><a href=\"http://linux.die.net/man/5/autofs\"><code>man\
    \ 5 autofs</code></a></li>\n<li><a href=\"http://linux.die.net/man/5/auto.master\"\
    ><code>man 5 auto.master</code></a></li>\n<li><a href=\"http://linux.die.net/man/8/mount\"\
    ><code>man 8 mount</code></a></li>\n<li><a href=\"http://linux.die.net/man/8/umount\"\
    ><code>man 8 umount</code></a></li>\n<li><a href=\"http://linux.die.net/man/8/autofs\"\
    ><code>man 8 autofs</code></a></li>\n</ul>\n<p>Ubuntu guides:</p>\n<ul>\n<li>https://help.ubuntu.com/community/SettingUpNFSHowTo</li>\n\
    <li>https://help.ubuntu.com/lts/serverguide/network-file-system.html</li>\n<li>https://help.ubuntu.com/community/Autofs</li>\n\
    </ul>"
  parent: 24
  sha1: 65f37559fc52b3c9c3cf99d07232ade055e589e0
  title: QCIF NFS Mounting
98:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-12-01T18:14:28-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Introduction \n The TPAC Aurora cluster is an implementation\
          \ of a CaaS service (Cluster-as-a-Service)\nthat provides a dynamic processing\
          \ environment similar to HPC environments. Unlike\ntraditional HPC systems,\
          \ the cloud implementation focuses on on-demand resource\nprovisioning and\
          \ is best suited for smaller scale computational tasks that can be\neasily\
          \ managed by a batch job scheduler. The cluster provides a static baseline\n\
          of nodes on standby and is able to scale up to hundreds of computational\
          \ nodes\non demand. \n Technical overview \n The cluster consists of two\
          \ special nodes, a service node and a submit node, as\nwell as of a number\
          \ of worker nodes that are provisioned, and terminated, as\nrequired. Each\
          \ worker node has 8 vCPUs and 16GB of RAM, shared storage provided\nby the\
          \ service node and MPI capabilities for inter-node communication. All nodes\n\
          run Scientific Linux, which is a derivate of RHEL. \n The submit node is\
          \ used for logins and job submission to the job scheduler,\nTorque/Maui,\
          \ while the service node handles centralised configuration management,\n\
          storage and worker provisioning. \n \n Who can use the TPAC Aurora cluster\
          \ \n The University of Tasmania researchers and collaborators may use the\
          \ cluster,\nafter requesting a HPC account. In the case of a non-UTas employee\
          \ requesting an\naccount, the individual will need to be sponsored by a\
          \ UTas section/school to\nfirst obtain a Non-University Member Account (NUMA)\
          \ before requesting a HPC\naccount. Details are included in the request\
          \ form. \n Getting an Account \n Accounts for HPC can be requested via the\
          \ form; based on stated resources\nrequirements the Aurora or an alternative\
          \ cluster may be suggested. Existing HPC\naccount holders can request access\
          \ to Aurora by contacting TPAC. \n Accessing Aurora \n Aurora can be accessed\
          \ using the SSH protocol connecting to the host\naurora.tpac.org.au with\
          \ the user\u2019s HPC account details (See \u2018Getting an Account\u2019\
          ).\nThe SSH tool is available from the terminal in most operating systems;\
          \ Windows\nusers will need a client installed, for example Putty.For graphical\n\
          applications, the submit node runs X2Go Server; the X2Go client is available\
          \ on\nLinux/OSX/Windows can be used for persistent GUI sessions. You can\
          \ download X2Go\nfrom this link. \n Major file systems \n There are two\
          \ filesystems worthy of mentioning that are shared throughout the\ncluster,\
          \ /home and /apps. \n /home/username \n This is your home directory and\
          \ the place to store and run your workloads from.\nThere are currently no\
          \ individual quotas, but total capacity is limited to 10TB\nand fair usage\
          \ patterns are expected. \n /apps \n This is a read-only application share\
          \ that is accessible from all nodes. \n The batch system \n The Aurora Cluster\
          \ uses the open-source TORQUE (version 4.2.10) as it's queue\nmanager and\
          \ Maui (version 3.3) as the scheduler. User guides and more information\n\
          can be found at adaptive computing website. \n Usage accounting \n For the\
          \ initial rollout period the usage policy is \u201Cfree for all\u201D, however\n\
          reasonable workloads and fair use is expected as the environment is a shared\
          \ facility. \n Modules, applications, compilers, debuggers \n The cluster\
          \ offers a standard set of utilities, compilers and libraries, as well\n\
          as commercial software packages such as STAR-CCM+ and Matlab. Most software\
          \ is\nusable by default, but some need to be enabled via environment modules.\
          \ You can \net a list of currently available modules with module available\
          \ and enable a\ndesired module with module load modulename. \n The below\
          \ provides TPAC Aurora software list: \n Java OpenJDK (1.6, 1.7)\nPython\
          \ (2.6, 2.7)\nPerl (5.10.1)\nGCC toolchain (4.4.7) and GCC devtoolset (4.9.2)\n\
          Tcl and Tk (8.5.7) \n Libraries: mpich, openmpi, boost, hdf5, lapack, atlas,\
          \ blas \n STAR-CCM+\nMatlab \n Getting help \n If you have problems with\
          \ TPAC Aurora Cluster as a service, please contact TPAC\nhelp desk via helpdesk@tpac.org.au,\
          \ or any help desks from your local E-research\nservice providers. "
        description: "<h2>Introduction</h2>\n<p>The TPAC Aurora cluster is an implementation\
          \ of a CaaS service (Cluster-as-a-Service)\nthat provides a dynamic processing\
          \ environment similar to HPC environments. Unlike\ntraditional HPC systems,\
          \ the cloud implementation focuses on on-demand resource\nprovisioning and\
          \ is best suited for smaller scale computational tasks that can be\neasily\
          \ managed by a batch job scheduler. The cluster provides a static baseline\n\
          of nodes on standby and is able to scale up to hundreds of computational\
          \ nodes\non demand.</p>\n<h2>Technical overview</h2>\n<p>The cluster consists\
          \ of two special nodes, a service node and a submit node, as\nwell as of\
          \ a number of worker nodes that are provisioned, and terminated, as\nrequired.\
          \ Each worker node has 8 vCPUs and 16GB of RAM, shared storage provided\n\
          by the service node and MPI capabilities for inter-node communication. All\
          \ nodes\nrun Scientific Linux, which is a derivate of RHEL.</p>\n<p>The\
          \ submit node is used for logins and job submission to the job scheduler,\n\
          Torque/Maui, while the service node handles centralised configuration management,\n\
          storage and worker provisioning.</p>\n<p><img alt=\"snapshot1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/aurora1.png?raw=true\"\
          ></p>\n<h2>Who can use the TPAC Aurora cluster</h2>\n<p>The University of\
          \ Tasmania researchers and collaborators may use the cluster,\nafter requesting\
          \ a HPC account. In the case of a non-UTas employee requesting an\naccount,\
          \ the individual will need to be sponsored by a UTas section/school to\n\
          first obtain a Non-University Member Account (NUMA) before requesting a\
          \ HPC\naccount. Details are included in the request <a href=\"http://www.tpac.org.au/resources/accounts/hpc-new-account-form/\"\
          >form</a>.</p>\n<h2>Getting an Account</h2>\n<p>Accounts for HPC can be\
          \ requested via the <a href=\"http://www.tpac.org.au/resources/accounts/hpc-new-account-form/\"\
          >form</a>; based on stated resources\nrequirements the Aurora or an alternative\
          \ cluster may be suggested. Existing HPC\naccount holders can request access\
          \ to Aurora by contacting <a href=\"http://www.tpac.org.au/contact/\">TPAC</a>.</p>\n\
          <h2>Accessing Aurora</h2>\n<p>Aurora can be accessed using the SSH protocol\
          \ connecting to the host\naurora.tpac.org.au with the user\u2019s HPC account\
          \ details (See \u2018Getting an Account\u2019).\nThe SSH tool is available\
          \ from the terminal in most operating systems; Windows\nusers will need\
          \ a client installed, for example <a href=\"http://www.chiark.greenend.org.uk/~sgtatham/putty/\"\
          >Putty</a>.For graphical\napplications, the submit node runs X2Go Server;\
          \ the X2Go client is available on\nLinux/OSX/Windows can be used for persistent\
          \ GUI sessions. You can download X2Go\nfrom this <a href=\"http://wiki.x2go.org/doku.php\"\
          >link</a>.</p>\n<h2>Major file systems</h2>\n<p>There are two filesystems\
          \ worthy of mentioning that are shared throughout the\ncluster, /home and\
          \ /apps.</p>\n<p>/home/username</p>\n<p>This is your home directory and\
          \ the place to store and run your workloads from.\nThere are currently no\
          \ individual quotas, but total capacity is limited to 10TB\nand fair usage\
          \ patterns are expected.</p>\n<p>/apps</p>\n<p>This is a read-only application\
          \ share that is accessible from all nodes.</p>\n<h2>The batch system</h2>\n\
          <p>The Aurora Cluster uses the open-source TORQUE (version 4.2.10) as it's\
          \ queue\nmanager and Maui (version 3.3) as the scheduler. User guides and\
          \ more information\ncan be found at <a href=\"http://docs.adaptivecomputing.com\"\
          >adaptive computing website</a>.</p>\n<h2>Usage accounting</h2>\n<p>For\
          \ the initial rollout period the usage policy is \u201Cfree for all\u201D\
          , however\nreasonable workloads and fair use is expected as the environment\
          \ is a shared facility.</p>\n<h2>Modules, applications, compilers, debuggers</h2>\n\
          <p>The cluster offers a standard set of utilities, compilers and libraries,\
          \ as well\nas commercial software packages such as STAR-CCM+ and Matlab.\
          \ Most software is\nusable by default, but some need to be enabled via environment\
          \ modules. You can \net a list of currently available modules with module\
          \ available and enable a\ndesired module with module load modulename.</p>\n\
          <p>The below provides TPAC Aurora software list:</p>\n<p>Java OpenJDK (1.6,\
          \ 1.7)\nPython (2.6, 2.7)\nPerl (5.10.1)\nGCC toolchain (4.4.7) and GCC\
          \ devtoolset (4.9.2)\nTcl and Tk (8.5.7)</p>\n<p>Libraries: mpich, openmpi,\
          \ boost, hdf5, lapack, atlas, blas</p>\n<p>STAR-CCM+\nMatlab</p>\n<h2>Getting\
          \ help</h2>\n<p>If you have problems with TPAC Aurora Cluster as a service,\
          \ please contact TPAC\nhelp desk via helpdesk@tpac.org.au, or any help desks\
          \ from your local E-research\nservice providers.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000093164
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-01T18:14:28-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000093164
        position: 11
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: TPAC Aurora User Guide
        updated_at: '2015-12-01T18:14:28-05:00'
        user_id: 6002464727
  html: "<h2>Introduction</h2>\n<p>The TPAC Aurora cluster is an implementation of\
    \ a CaaS service (Cluster-as-a-Service)\nthat provides a dynamic processing environment\
    \ similar to HPC environments. Unlike\ntraditional HPC systems, the cloud implementation\
    \ focuses on on-demand resource\nprovisioning and is best suited for smaller scale\
    \ computational tasks that can be\neasily managed by a batch job scheduler. The\
    \ cluster provides a static baseline\nof nodes on standby and is able to scale\
    \ up to hundreds of computational nodes\non demand.</p>\n<h2>Technical overview</h2>\n\
    <p>The cluster consists of two special nodes, a service node and a submit node,\
    \ as\nwell as of a number of worker nodes that are provisioned, and terminated,\
    \ as\nrequired. Each worker node has 8 vCPUs and 16GB of RAM, shared storage provided\n\
    by the service node and MPI capabilities for inter-node communication. All nodes\n\
    run Scientific Linux, which is a derivate of RHEL.</p>\n<p>The submit node is\
    \ used for logins and job submission to the job scheduler,\nTorque/Maui, while\
    \ the service node handles centralised configuration management,\nstorage and\
    \ worker provisioning.</p>\n<p><img alt=\"snapshot1\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/aurora1.png?raw=true\"\
    ></p>\n<h2>Who can use the TPAC Aurora cluster</h2>\n<p>The University of Tasmania\
    \ researchers and collaborators may use the cluster,\nafter requesting a HPC account.\
    \ In the case of a non-UTas employee requesting an\naccount, the individual will\
    \ need to be sponsored by a UTas section/school to\nfirst obtain a Non-University\
    \ Member Account (NUMA) before requesting a HPC\naccount. Details are included\
    \ in the request <a href=\"http://www.tpac.org.au/resources/accounts/hpc-new-account-form/\"\
    >form</a>.</p>\n<h2>Getting an Account</h2>\n<p>Accounts for HPC can be requested\
    \ via the <a href=\"http://www.tpac.org.au/resources/accounts/hpc-new-account-form/\"\
    >form</a>; based on stated resources\nrequirements the Aurora or an alternative\
    \ cluster may be suggested. Existing HPC\naccount holders can request access to\
    \ Aurora by contacting <a href=\"http://www.tpac.org.au/contact/\">TPAC</a>.</p>\n\
    <h2>Accessing Aurora</h2>\n<p>Aurora can be accessed using the SSH protocol connecting\
    \ to the host\naurora.tpac.org.au with the user\u2019s HPC account details (See\
    \ \u2018Getting an Account\u2019).\nThe SSH tool is available from the terminal\
    \ in most operating systems; Windows\nusers will need a client installed, for\
    \ example <a href=\"http://www.chiark.greenend.org.uk/~sgtatham/putty/\">Putty</a>.For\
    \ graphical\napplications, the submit node runs X2Go Server; the X2Go client is\
    \ available on\nLinux/OSX/Windows can be used for persistent GUI sessions. You\
    \ can download X2Go\nfrom this <a href=\"http://wiki.x2go.org/doku.php\">link</a>.</p>\n\
    <h2>Major file systems</h2>\n<p>There are two filesystems worthy of mentioning\
    \ that are shared throughout the\ncluster, /home and /apps.</p>\n<p>/home/username</p>\n\
    <p>This is your home directory and the place to store and run your workloads from.\n\
    There are currently no individual quotas, but total capacity is limited to 10TB\n\
    and fair usage patterns are expected.</p>\n<p>/apps</p>\n<p>This is a read-only\
    \ application share that is accessible from all nodes.</p>\n<h2>The batch system</h2>\n\
    <p>The Aurora Cluster uses the open-source TORQUE (version 4.2.10) as it's queue\n\
    manager and Maui (version 3.3) as the scheduler. User guides and more information\n\
    can be found at <a href=\"http://docs.adaptivecomputing.com\">adaptive computing\
    \ website</a>.</p>\n<h2>Usage accounting</h2>\n<p>For the initial rollout period\
    \ the usage policy is \u201Cfree for all\u201D, however\nreasonable workloads\
    \ and fair use is expected as the environment is a shared facility.</p>\n<h2>Modules,\
    \ applications, compilers, debuggers</h2>\n<p>The cluster offers a standard set\
    \ of utilities, compilers and libraries, as well\nas commercial software packages\
    \ such as STAR-CCM+ and Matlab. Most software is\nusable by default, but some\
    \ need to be enabled via environment modules. You can \net a list of currently\
    \ available modules with module available and enable a\ndesired module with module\
    \ load modulename.</p>\n<p>The below provides TPAC Aurora software list:</p>\n\
    <p>Java OpenJDK (1.6, 1.7)\nPython (2.6, 2.7)\nPerl (5.10.1)\nGCC toolchain (4.4.7)\
    \ and GCC devtoolset (4.9.2)\nTcl and Tk (8.5.7)</p>\n<p>Libraries: mpich, openmpi,\
    \ boost, hdf5, lapack, atlas, blas</p>\n<p>STAR-CCM+\nMatlab</p>\n<h2>Getting\
    \ help</h2>\n<p>If you have problems with TPAC Aurora Cluster as a service, please\
    \ contact TPAC\nhelp desk via helpdesk@tpac.org.au, or any help desks from your\
    \ local E-research\nservice providers.</p>"
  parent: 24
  sha1: 96d9097503dfc18445585dd2f725b7bb0dc2ec34
  title: TPAC Aurora User Guide
99:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2015-12-01T18:22:35-05:00'
        desc_un_html: " Introduction to Networking \n Network Fundamentals \n Ethernet\
          \ \n Ethernet is the most common network protocol used in the local area\
          \ network (LAN) and\nit is specified by the IEEE 802.3 standard. Ethernet\
          \ operates in the second layer\nin the OSI model of networking protocols.\
          \ \n Hosts communicate by exchanging frames in a Ethernet network and each\
          \ host is uniquely\nidentified by an media access control(MAC) address.\
          \ In NecTAR Cloud, every virtual\nmachine has a unique MAC address and it\
          \ is different from the MAC address of the\nhost machine. The MAC address\
          \ contains 48 bits and looks like 02:03:22:a2:c2:33.\nA host in a Ethernet\
          \ network can communicate with each other by using the MAC address.\nA host\
          \ can also sent a frame to all hosts (broadcast) in the same Ethernet network\n\
          by using MAC address ff:ff:ff:ff:ff:ff. \n When a host receives a Ethernet\
          \ frame, it checks its destination MAC address and\nsee whether it matches\
          \ its own MAC address. If it matches, the host receives the\nframe and if\
          \ it doesn't, the host just simply drop the frame. \n VLAN \n In Ethernet\
          \ network, every hosts share the same network segment and therefore share\n\
          the same network traffic. However, it is useful to divide hosts into different\
          \ groups\nin order to isolate the network traffic and also for better management.\
          \ \n VLAN is the technology to enable grouping of hosts in a Ethernet network\
          \ and each\nhost can only see traffic within the group. Specifically, hosts\
          \ can be grouped by\nVLANs and they cannot see traffic on different VLANs.In\
          \ NecTAR Cloud, virtual\nmachines can also take advantages to isolate the\
          \ traffic among them. Even the virtual\nmachines are on the same hosts.\
          \ By creating a VLAN, each VLAN is identified by an\nunique ID, between\
          \ 1 and 4095. \n VLAN can be implemented by assign a switch port to a VLAN\
          \ Id to only allow traffic\nfrom that VLAN to pass through that port or\
          \ by assigning a tag to Ethernet Frame\nto allow frames are only pass through\
          \ based on the same tag. \n IP \n Ethernet specifies how hosts can communicate\
          \ in local area networks and there are\nneeds to interconnect multiple Ethernet\
          \ networks. The Internet Protocol (IP)\ndefines how packets (encapsulated\
          \ frames) can travel between hosts that are connected\nto different local\
          \ networks. The IP protocol defines IP addresses to uniquely identify\n\
          a host and IP address is 32 bits (IP version 4) and looks like 10.10.12.123.\
          \ To\nmake this work, IP replies on routers or gateways. A router is a device\
          \ that connects\ntwo or more local networks and can forward packets from\
          \ one network to another.\nRouter operates in layer 3 in the OSI model of\
          \ networking protocols. \n Before sending a packet, a host checks its routing\
          \ table to find out any hosts\nin the local network matches the IP address.\
          \ The routing table maintains a list of\nsubnets as well as a list of routers\
          \ in the local network. \n If no IP matches in the local network, packets\
          \ are forwarded to the default router\n(default gateway). \n Subnets \n\
          \ IP addresses (IP version 4) are 32 bits and contains 2 parts: a network\
          \ number\nand a host identifier. If two hosts have the same network number,\
          \ then they are\non the same network and can communicate with each other\
          \ directly without routers\n(same as they are on the Ethernet network).\
          \ \n To get the network part of a IP address, netmask is used. A netmask\
          \ indicates\nhow many bits in the IP address make up the network part. The\
          \ network part of\na IP address can be 8, 16, 24 bits. For example, consider\
          \ an IP address of\n192.168.1.1, where the first 24 bits of the address\
          \ are the network number. In\ndotted quad notation, the netmask would be\
          \ written as 255.255.255.0 and the network\nnumber is 192.168.1.0. \n DHCP\
          \ \n DHCP defines how hosts can dynamically obtain IP addresses. A DHCP\
          \ server assign\nIP addresses to hosts, which are the DHCP clients. \n Ports\
          \ \n As there are many applications can be run on a host, ports are used\
          \ to identify\nwhich application should receive packages when packet have\
          \ been received on\nthe host. When a host sending a packet to a remote host,\
          \ it needs to specify the\nport number for the destination host to use.\
          \ Port numbers range from 0 to 65525.\nPort numbers from 0 to 1-24 are reserved\
          \ for well-known services such as port 22\nfor SSH service. \n Network Components\
          \ \n NICs and VNICs \n Network Interface Card (NIC) is a physical card that\
          \ enables computers to connect\nto network. It has a unique MAC address\
          \ associated with it and a port allows\na physical capable to connect to\
          \ it. A VNIC is a virtualized network interface card,\nused by a virtual\
          \ machine as its network interface. A VNIC also has a MAC address\nassociated\
          \ with it. However, this MAC address not same as the MAC address binded\n\
          with NIC and it depends on the Hypervisor or a virtual machine service provider.\n\
          A VNIC is created when a virtual machine is created. \n Switches \n A switch\
          \ is a network device that connects other network devices such as NICs or\n\
          another switch. It contains multiple ports and forward data frame among\
          \ devices\nconnected via the ports. Switches operate at layer 2 in a OSI\
          \ model. \n Routers \n A router is a network device that connects multiple\
          \ local networks together. When\nit receives a data packet, it uses a routing\
          \ table to determine which networks\nto pass the data packet to. \n Network\
          \ address translation (NAT) \n NAT is a process of changing the source or\
          \ destination IP address of a IP packet when\nthe packet is in transit.\
          \ NAT is commonly used to enables hosts with private addresses\nto communicate\
          \ with servers on the public Internet. OpenStack uses NAT to enable\napplications\
          \ running inside of virtual machines to connect out to the public Internet.\
          \ \n Introduction to OpenStack Networking (Neutron) \n The OpenStack Network\
          \ service (Neutron) provides network connectivity and addressing\nin the\
          \ NeCTAR Cloud. It handles the creation and management of a virtual network\n\
          infrastructure, including networks, switches, subnets and routers for virtual\
          \ machines. \n OpenStack Compute(nova) uses Neutron to plug each virtual\
          \ NIC on the virtual machine\ninto a network. Users can also OpenStack dashboard(horizon)\
          \ to create and manage\nnetwork services through a web-based graphical interface.\
          \ \n Network Types \n There are three supported networks in Neutron. External\
          \ network, provider network\nand tenant network. \n External Network \n\
          \ External network is a Internet routable network, which is the physical\
          \ network that\nconnects the network node to Internet via a router or firewall.\
          \ \n Provider Network \n Provider network is created by cloud administrator\
          \ and it is mapped to the external\nnetwork and run top of the external\
          \ network. The physical NICs on compute nodes\nare connected to physical\
          \ switch ports, which are configured as a trunk containing\nall of the VLANs\
          \ in the environment.Provder networks are created mapping to the\ndifferent\
          \ VLANs in the trunk. After virtual machine is created, the provider network\n\
          can be attached to the virtual machine and a IP address associated with\
          \ the VLAN\nwill be assigned to VNIC on the virtual machine. Therefore,\
          \ the instances can\nbegin to communicate. \n Tenant Network \n Tenant network\
          \ is provisioned by users and isolated from other tenants(projects) and\n\
          it functions as a user created VLAN and can be utilized based on users'\
          \ requirements.\nIt can be configured to connect to virtual machines in\
          \ other tenants and\nprovider networks (Internet access) via a Neutron L3\
          \ router. Virtual machines can\nbe attached to provider network directly\
          \ without the need of tenant network. "
        description: '<h1>Introduction to Networking</h1>

          <h2>Network Fundamentals</h2>

          <h3>Ethernet</h3>

          <p>Ethernet is the most common network protocol used in the local area network
          (LAN) and

          it is specified by the IEEE 802.3 standard. Ethernet operates in the second
          layer

          in the OSI model of networking protocols.</p>

          <p>Hosts communicate by exchanging frames in a Ethernet network and each
          host is uniquely

          identified by an media access control(MAC) address. In NecTAR Cloud, every
          virtual

          machine has a unique MAC address and it is different from the MAC address
          of the

          host machine. The MAC address contains 48 bits and looks like 02:03:22:a2:c2:33.

          A host in a Ethernet network can communicate with each other by using the
          MAC address.

          A host can also sent a frame to all hosts (broadcast) in the same Ethernet
          network

          by using MAC address ff:ff:ff:ff:ff:ff.</p>

          <p>When a host receives a Ethernet frame, it checks its destination MAC
          address and

          see whether it matches its own MAC address. If it matches, the host receives
          the

          frame and if it doesn''t, the host just simply drop the frame.</p>

          <h3>VLAN</h3>

          <p>In Ethernet network, every hosts share the same network segment and therefore
          share

          the same network traffic. However, it is useful to divide hosts into different
          groups

          in order to isolate the network traffic and also for better management.</p>

          <p>VLAN is the technology to enable grouping of hosts in a Ethernet network
          and each

          host can only see traffic within the group. Specifically, hosts can be grouped
          by

          VLANs and they cannot see traffic on different VLANs.In NecTAR Cloud, virtual

          machines can also take advantages to isolate the traffic among them. Even
          the virtual

          machines are on the same hosts. By creating a VLAN, each VLAN is identified
          by an

          unique ID, between 1 and 4095.</p>

          <p>VLAN can be implemented by assign a switch port to a VLAN Id to only
          allow traffic

          from that VLAN to pass through that port or by assigning a tag to Ethernet
          Frame

          to allow frames are only pass through based on the same tag.</p>

          <h3>IP</h3>

          <p>Ethernet specifies how hosts can communicate in local area networks and
          there are

          needs to interconnect multiple Ethernet networks. The Internet Protocol
          (IP)

          defines how packets (encapsulated frames) can travel between hosts that
          are connected

          to different local networks. The IP protocol defines IP addresses to uniquely
          identify

          a host and IP address is 32 bits (IP version 4) and looks like 10.10.12.123.
          To

          make this work, IP replies on routers or gateways. A router is a device
          that connects

          two or more local networks and can forward packets from one network to another.

          Router operates in layer 3 in the OSI model of networking protocols.</p>

          <p>Before sending a packet, a host checks its routing table to find out
          any hosts

          in the local network matches the IP address. The routing table maintains
          a list of

          subnets as well as a list of routers in the local network.</p>

          <p>If no IP matches in the local network, packets are forwarded to the default
          router

          (default gateway).</p>

          <h3>Subnets</h3>

          <p>IP addresses (IP version 4) are 32 bits and contains 2 parts: a network
          number

          and a host identifier. If two hosts have the same network number, then they
          are

          on the same network and can communicate with each other directly without
          routers

          (same as they are on the Ethernet network).</p>

          <p>To get the network part of a IP address, netmask is used. A netmask indicates

          how many bits in the IP address make up the network part. The network part
          of

          a IP address can be 8, 16, 24 bits. For example, consider an IP address
          of

          192.168.1.1, where the first 24 bits of the address are the network number.
          In

          dotted quad notation, the netmask would be written as 255.255.255.0 and
          the network

          number is 192.168.1.0.</p>

          <h3>DHCP</h3>

          <p>DHCP defines how hosts can dynamically obtain IP addresses. A DHCP server
          assign

          IP addresses to hosts, which are the DHCP clients.</p>

          <h3>Ports</h3>

          <p>As there are many applications can be run on a host, ports are used to
          identify

          which application should receive packages when packet have been received
          on

          the host. When a host sending a packet to a remote host, it needs to specify
          the

          port number for the destination host to use. Port numbers range from 0 to
          65525.

          Port numbers from 0 to 1-24 are reserved for well-known services such as
          port 22

          for SSH service.</p>

          <h2>Network Components</h2>

          <h3>NICs and VNICs</h3>

          <p>Network Interface Card (NIC) is a physical card that enables computers
          to connect

          to network. It has a unique MAC address associated with it and a port allows

          a physical capable to connect to it. A VNIC is a virtualized network interface
          card,

          used by a virtual machine as its network interface. A VNIC also has a MAC
          address

          associated with it. However, this MAC address not same as the MAC address
          binded

          with NIC and it depends on the Hypervisor or a virtual machine service provider.

          A VNIC is created when a virtual machine is created.</p>

          <h3>Switches</h3>

          <p>A switch is a network device that connects other network devices such
          as NICs or

          another switch. It contains multiple ports and forward data frame among
          devices

          connected via the ports. Switches operate at layer 2 in a OSI model.</p>

          <h3>Routers</h3>

          <p>A router is a network device that connects multiple local networks together.
          When

          it receives a data packet, it uses a routing table to determine which networks

          to pass the data packet to.</p>

          <h3>Network address translation (NAT)</h3>

          <p>NAT is a process of changing the source or destination IP address of
          a IP packet when

          the packet is in transit. NAT is commonly used to enables hosts with private
          addresses

          to communicate with servers on the public Internet. OpenStack uses NAT to
          enable

          applications running inside of virtual machines to connect out to the public
          Internet.</p>

          <h2>Introduction to OpenStack Networking (Neutron)</h2>

          <p>The OpenStack Network service (Neutron) provides network connectivity
          and addressing

          in the NeCTAR Cloud. It handles the creation and management of a virtual
          network

          infrastructure, including networks, switches, subnets and routers for virtual
          machines.</p>

          <p>OpenStack Compute(nova) uses Neutron to plug each virtual NIC on the
          virtual machine

          into a network. Users can also OpenStack dashboard(horizon) to create and
          manage

          network services through a web-based graphical interface.</p>

          <h3>Network Types</h3>

          <p>There are three supported networks in Neutron. External network, provider
          network

          and tenant network.</p>

          <h4>External Network</h4>

          <p>External network is a Internet routable network, which is the physical
          network that

          connects the network node to Internet via a router or firewall.</p>

          <h4>Provider Network</h4>

          <p>Provider network is created by cloud administrator and it is mapped to
          the external

          network and run top of the external network. The physical NICs on compute
          nodes

          are connected to physical switch ports, which are configured as a trunk
          containing

          all of the VLANs in the environment.Provder networks are created mapping
          to the

          different VLANs in the trunk. After virtual machine is created, the provider
          network

          can be attached to the virtual machine and a IP address associated with
          the VLAN

          will be assigned to VNIC on the virtual machine. Therefore, the instances
          can

          begin to communicate.</p>

          <h4>Tenant Network</h4>

          <p>Tenant network is provisioned by users and isolated from other tenants(projects)
          and

          it functions as a user created VLAN and can be utilized based on users''
          requirements.

          It can be configured to connect to virtual machines in other tenants and

          provider networks (Internet access) via a Neutron L3 router. Virtual machines
          can

          be attached to provider network directly without the need of tenant network.</p>'
        folder:
          category_id: 6000122279
          created_at: '2015-12-01T18:22:33-05:00'
          customer_folders: []
          description: Networking
          id: 6000210730
          is_default: false
          language_id: 6
          name: Networking
          parent_id: 6000210730
          position: 6
          updated_at: '2015-12-07T19:43:55-05:00'
          visibility: 1
        folder_id: 6000210730
        hits: 52
        id: 6000093166
        modified_at: '2016-04-15T02:27:30-04:00'
        modified_by: null
        position: 1
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Introduction
        updated_at: '2016-04-15T02:27:30-04:00'
        user_id: 6002464727
  html: '<h1>Introduction to Networking</h1>

    <h2>Network Fundamentals</h2>

    <h3>Ethernet</h3>

    <p>Ethernet is the most common network protocol used in the local area network
    (LAN) and

    it is specified by the IEEE 802.3 standard. Ethernet operates in the second layer

    in the OSI model of networking protocols.</p>

    <p>Hosts communicate by exchanging frames in a Ethernet network and each host
    is uniquely

    identified by an media access control(MAC) address. In NecTAR Cloud, every virtual

    machine has a unique MAC address and it is different from the MAC address of the

    host machine. The MAC address contains 48 bits and looks like 02:03:22:a2:c2:33.

    A host in a Ethernet network can communicate with each other by using the MAC
    address.

    A host can also sent a frame to all hosts (broadcast) in the same Ethernet network

    by using MAC address ff:ff:ff:ff:ff:ff.</p>

    <p>When a host receives a Ethernet frame, it checks its destination MAC address
    and

    see whether it matches its own MAC address. If it matches, the host receives the

    frame and if it doesn''t, the host just simply drop the frame.</p>

    <h3>VLAN</h3>

    <p>In Ethernet network, every hosts share the same network segment and therefore
    share

    the same network traffic. However, it is useful to divide hosts into different
    groups

    in order to isolate the network traffic and also for better management.</p>

    <p>VLAN is the technology to enable grouping of hosts in a Ethernet network and
    each

    host can only see traffic within the group. Specifically, hosts can be grouped
    by

    VLANs and they cannot see traffic on different VLANs.In NecTAR Cloud, virtual

    machines can also take advantages to isolate the traffic among them. Even the
    virtual

    machines are on the same hosts. By creating a VLAN, each VLAN is identified by
    an

    unique ID, between 1 and 4095.</p>

    <p>VLAN can be implemented by assign a switch port to a VLAN Id to only allow
    traffic

    from that VLAN to pass through that port or by assigning a tag to Ethernet Frame

    to allow frames are only pass through based on the same tag.</p>

    <h3>IP</h3>

    <p>Ethernet specifies how hosts can communicate in local area networks and there
    are

    needs to interconnect multiple Ethernet networks. The Internet Protocol (IP)

    defines how packets (encapsulated frames) can travel between hosts that are connected

    to different local networks. The IP protocol defines IP addresses to uniquely
    identify

    a host and IP address is 32 bits (IP version 4) and looks like 10.10.12.123. To

    make this work, IP replies on routers or gateways. A router is a device that connects

    two or more local networks and can forward packets from one network to another.

    Router operates in layer 3 in the OSI model of networking protocols.</p>

    <p>Before sending a packet, a host checks its routing table to find out any hosts

    in the local network matches the IP address. The routing table maintains a list
    of

    subnets as well as a list of routers in the local network.</p>

    <p>If no IP matches in the local network, packets are forwarded to the default
    router

    (default gateway).</p>

    <h3>Subnets</h3>

    <p>IP addresses (IP version 4) are 32 bits and contains 2 parts: a network number

    and a host identifier. If two hosts have the same network number, then they are

    on the same network and can communicate with each other directly without routers

    (same as they are on the Ethernet network).</p>

    <p>To get the network part of a IP address, netmask is used. A netmask indicates

    how many bits in the IP address make up the network part. The network part of

    a IP address can be 8, 16, 24 bits. For example, consider an IP address of

    192.168.1.1, where the first 24 bits of the address are the network number. In

    dotted quad notation, the netmask would be written as 255.255.255.0 and the network

    number is 192.168.1.0.</p>

    <h3>DHCP</h3>

    <p>DHCP defines how hosts can dynamically obtain IP addresses. A DHCP server assign

    IP addresses to hosts, which are the DHCP clients.</p>

    <h3>Ports</h3>

    <p>As there are many applications can be run on a host, ports are used to identify

    which application should receive packages when packet have been received on

    the host. When a host sending a packet to a remote host, it needs to specify the

    port number for the destination host to use. Port numbers range from 0 to 65525.

    Port numbers from 0 to 1-24 are reserved for well-known services such as port
    22

    for SSH service.</p>

    <h2>Network Components</h2>

    <h3>NICs and VNICs</h3>

    <p>Network Interface Card (NIC) is a physical card that enables computers to connect

    to network. It has a unique MAC address associated with it and a port allows

    a physical capable to connect to it. A VNIC is a virtualized network interface
    card,

    used by a virtual machine as its network interface. A VNIC also has a MAC address

    associated with it. However, this MAC address not same as the MAC address binded

    with NIC and it depends on the Hypervisor or a virtual machine service provider.

    A VNIC is created when a virtual machine is created.</p>

    <h3>Switches</h3>

    <p>A switch is a network device that connects other network devices such as NICs
    or

    another switch. It contains multiple ports and forward data frame among devices

    connected via the ports. Switches operate at layer 2 in a OSI model.</p>

    <h3>Routers</h3>

    <p>A router is a network device that connects multiple local networks together.
    When

    it receives a data packet, it uses a routing table to determine which networks

    to pass the data packet to.</p>

    <h3>Network address translation (NAT)</h3>

    <p>NAT is a process of changing the source or destination IP address of a IP packet
    when

    the packet is in transit. NAT is commonly used to enables hosts with private addresses

    to communicate with servers on the public Internet. OpenStack uses NAT to enable

    applications running inside of virtual machines to connect out to the public Internet.</p>

    <h2>Introduction to OpenStack Networking (Neutron)</h2>

    <p>The OpenStack Network service (Neutron) provides network connectivity and addressing

    in the NeCTAR Cloud. It handles the creation and management of a virtual network

    infrastructure, including networks, switches, subnets and routers for virtual
    machines.</p>

    <p>OpenStack Compute(nova) uses Neutron to plug each virtual NIC on the virtual
    machine

    into a network. Users can also OpenStack dashboard(horizon) to create and manage

    network services through a web-based graphical interface.</p>

    <h3>Network Types</h3>

    <p>There are three supported networks in Neutron. External network, provider network

    and tenant network.</p>

    <h4>External Network</h4>

    <p>External network is a Internet routable network, which is the physical network
    that

    connects the network node to Internet via a router or firewall.</p>

    <h4>Provider Network</h4>

    <p>Provider network is created by cloud administrator and it is mapped to the
    external

    network and run top of the external network. The physical NICs on compute nodes

    are connected to physical switch ports, which are configured as a trunk containing

    all of the VLANs in the environment.Provder networks are created mapping to the

    different VLANs in the trunk. After virtual machine is created, the provider network

    can be attached to the virtual machine and a IP address associated with the VLAN

    will be assigned to VNIC on the virtual machine. Therefore, the instances can

    begin to communicate.</p>

    <h4>Tenant Network</h4>

    <p>Tenant network is provisioned by users and isolated from other tenants(projects)
    and

    it functions as a user created VLAN and can be utilized based on users'' requirements.

    It can be configured to connect to virtual machines in other tenants and

    provider networks (Internet access) via a Neutron L3 router. Virtual machines
    can

    be attached to provider network directly without the need of tenant network.</p>'
  parent: 44
  sha1: 5e5f0f9e4bd039e4390aed73fe7820fe0fb4d261
  title: Introduction
100:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-12-02T19:33:41-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Bioinformatics Training Platform (BTP) User Guide \n Introduction\
          \ \n Monash eResearch Centre have been partnering with Bioplatforms\nAustralia\
          \ (BPA) and CSIRO for delivering hands-on bioinformatics workshops to Australian\
          \ researchers. This partnership started back in 2012 when the first next-generation\
          \ sequencing workshop was delivered at Monash University. The Bioinformatics\
          \ Training Platform (BTP) has been developed as a broadly accessible solution\
          \ for delivering these workshops using cloud computing infrastructures and\
          \ addressing the increasing demand for training workshops in Australia.\
          \ \n The standard NGS workshop delivered by BPA and CSIRO is composed of\
          \ a number of training modules. Each training module is composed of the\
          \ following components: analysis tools, datasets and training materials.\
          \ The analysis tools are essential to a hands-on bioinformatics workshop\
          \ as it teaches scientists how such tools are used to interrogate and interpret\
          \ results. Most of the analysis tools used by the BTP are open source and\
          \ easily accessible on various platforms. The BTP maintains these analysis\
          \ tools on BPA-CSIRO GitHub Project. To support the hands-on bioinformatics\
          \ workshop, analysis and reference datasets are used together for analysis.\
          \ Datasets are stored and managed on the NeCTAR object storage service.\
          \ The training materials (presentations and handouts) are also developed\
          \ and maintained as part of the BTP. A high level overview of the BTP architecture\
          \ is show below: \n \n A workshop is composed of a number of training modules.\
          \ Each training module has an associated analysis tools and datasets metadata.\
          \ These metadata are used by the orchestration system for automation of\
          \ tools installation during BTP image creation and datasets syncing during\
          \ BTP instance deployments. \n \n Components \n The BTP as a solution is\
          \ composed of a number of components: Analysis Tools, Datasets and Training\
          \ Materials. These components are encapsulated on each of the training modules.\
          \ A brief summary of each one are included below. \n Analysis Tools \n Analysis\
          \ tools are essential for delivering hands-on training workshops.\nThe BTP\
          \ teaches trainees how these tools can be used to help interrogate and interpret\
          \ their analysis results. Most of these analysis tools are available as\
          \ stand alone executables while others have to be built from source. The\
          \ most common analysis tools used and packaged in the BTP are listed in\
          \ the table below: \n\n\n\nTools\nFunction\n\n\n\n\nAMOS Hawkeye\nGenome\
          \ data visualization\n\n\nBEDTools\nGenome data manipulation\n\n\nBLAT\n\
          Sequence location lookup in the genome\n\n\nBowtie\nRead Alignment\n\n\n\
          CummeRbund\nRNA-Seq analysis using R\n\n\nCufflinks\nRNA-Seq analysis\n\n\
          \nDESeq2\nDifferential gene expression analysis using R\n\n\nedgeR\nEmpirical\
          \ gene expression analysis using R\n\n\nFastQC\nFastQC\n\n\nFASTX\nToolkit\
          \ for short reads preprocessing\n\n\nIGV\nInteractive exploration of genomic\
          \ data\n\n\nigvtools\nPreprocessing of data before loading to IGV\n\n\n\
          MACS\nChIP-Seq analysis\n\n\nMUMmer\nRapid genome alignment, a dependency\
          \ for AMOS\n\n\nPeakAnalyzer\nMulti-peak data analysis\n\n\nPicard\nSequence\
          \ data analysis\n\n\nSAMtools\nFor manipulating alignments in the SAM format\n\
          \n\nSkewer\nAdapter trimmer for paired-end reads\n\n\n\n These analysis\
          \ tools are packaged and installed into the BTP Image upon creation. This\
          \ process is described in detail in the [BTP Workflows][#btp-workflows]\
          \ section below. \n Packaging of Analysis Tools \n To make maintenance and\
          \ deployment of the BTP easier, most of the analysis tools included in the\
          \ BTP are packaged as stand-alone *.deb installers, installable on Ubuntu-based\
          \ operating systems. fpm-cookery is used to create the *.deb installers\
          \ using recipes. The current BTP Images are based on Ubuntu Precise LTS\
          \ which is supported until 2017. The BTP maintains a set of recipes on GitHub\
          \ which is also integrated with Travis CI for continuous integration. Whenever\
          \ a tool recipe is updated or new recipe is added into the repository, Travis\
          \ CI ensures that the recipes builds correctly. \n The .deb installers can\
          \ also be manually created on a client machine. This step is not mandatory\
          \ for creating the BTP images and deployment of BTP instances. One can clone\
          \ the BTP Tools repository, and using fpm-cookery, create the .deb installers.\
          \ \n Clone the BTP Tools repository: \n git clone https://github.com/BPA-CSIRO-Workshops/btp-tools.git\
          \ \n The .deb installer for a particular analysis tool can then be built\
          \ using fpm-cookery: \n cd btp-tools/bwa\nfpm-cookery . \n fpm-cookery will\
          \ read the instructions in the recipe and build the .deb installer. In the\
          \ example above, fpm-cookery will get the source code for bwa from GitHub,\
          \ then will proceed with the standard configuration, compilation and building\
          \ of the tool. fpm-cookery will place the resulting .deb installer inside\
          \ the pkg subdirectory: \n ls pkg/\nbwa_0.7.12-0_amd64.deb \n Datasets \n\
          \ Datasets used by the BTP are stored on NeCTAR Object Storage (Swift).\
          \ Each training modules has a corresponding publicly readable container\
          \ where its datasets are accessible. The containers for the NGS training\
          \ modules are listed in the table below: \n\n\n\nModule\nContainer\n\n\n\
          \n\nIntroduction to CLI\nNGSDataCommandLine\n\n\nQuality Control\nNGSDataQC\n\
          \n\nAlignment\nNGSDataChIPSeq\n\n\nChIP-Seq\nNGSDataChIPSeq\n\n\nRNA-Seq\n\
          NGSDataRNASeq\n\n\nDe novo Assembly\nNGSDataDeNovo\n\n\n\n The complete\
          \ container URL are used to pull down the datasets into the BTP instances.\
          \ The URLs are defined on the datasets metadata file, which is used by Puppet\
          \ to pull down the datasets into the BTP instances upon deployment. \n Training\
          \ Materials \n \n BTP Workflows \n Creating the BTP Image \n Prerequisites\
          \ for Creating BTP Images \n \n git \n Packer \n OpenStack Glance Command\
          \ Line Client \n NeCTAR OpenStack Credentials \n internet access \n \n The\
          \ BTP uses the Packer tool for creating new virtual machine images compatible\
          \ with NeCTAR Research Cloud. \n Get Workshop Repository \n A collection\
          \ of Packer recipes are included as part of the orchestration module inside\
          \ the BPA-CSIRO Workshop NGS Repository. This repository must be cloned\
          \ together with the training submodules on the client machine where the\
          \ BTP image will be created: \n git clone --recurse-submodules https://github.com/BPA-CSIRO-Workshops/btp-workshop-ngs.git\
          \ \n Orchestration \n Once the workshop repository and the training submodules\
          \ have been cloned, the local copy will have the following contents structure:\
          \ \n \u251C\u2500\u2500 010_trainers\n\u251C\u2500\u2500 015_preamble\n\u251C\
          \u2500\u2500 050_ngs-qc\n\u251C\u2500\u2500 060_alignment\n\u251C\u2500\u2500\
          \ 070_chip-seq\n\u251C\u2500\u2500 080_rna-seq\n\u251C\u2500\u2500 090_velvet\n\
          \u251C\u2500\u2500 905_post-workshop\n\u251C\u2500\u2500 Makefile\n\u251C\
          \u2500\u2500 README.md\n\u251C\u2500\u2500 developers\n\u251C\u2500\u2500\
          \ licences\n\u251C\u2500\u2500 orchestration\n\u251C\u2500\u2500 style\n\
          \u2514\u2500\u2500 template.tex \n The numberings (e.g 010_trainers, 015_preamble)\
          \ are used by the build system to order by which the training modules are\
          \ ordered in the training handouts. Each training module has an associated\
          \ handouts subdirectory where the LaTeX file for that module is located.\
          \ Going inside the orchestration/packer subdirectory will show the available\
          \ Packer recipes including the one compatible with the NeCTAR Research Cloud,\
          \ btp-qemu.json. The available Packer recipes for the BTP are: \n \u251C\
          \u2500\u2500 btp-aws.json\n\u251C\u2500\u2500 btp-qemu.json\n\u251C\u2500\
          \u2500 btp-virtualbox.json\n\u251C\u2500\u2500 btp-vmware.json \n Launch\
          \ Packer \n Before launching Packer, the content of the recipe file btp-qemu.json\
          \ can be viewed. Descriptions for each recipe section are highlighted below.\
          \ \n The image creation process can then be started by feeding the recipe\
          \ into Packer. This assumes that the Packer is already installed on the\
          \ client (build) machine. Packer can then be launched, with the recipe filename\
          \ passed as a command line argument: \n packer build btp-qemu.json \n Packer\
          \ will start the image creation process and the first thing this will do\
          \ is to download the latest available alternate Ubuntu ISO from the internet.\
          \ So the client machine must have access to the internet to download the\
          \ ISO file. \n Upload Image \n Deploying BTP Instances \n Prerequisites\
          \ for Deploying BTP Instances \n \n NeCTAR OpenStack Credentials \n OpenStack\
          \ Nova Command Line Client \n NoMachine (NX) Client \n \n Using the BTP\
          \ Instances for Training \n\n\n"
        description: "<h1>Bioinformatics Training Platform (BTP) User Guide</h1>\n\
          <h2>Introduction</h2>\n<p><a href=\"https://platforms.monash.edu/eresearch/\"\
          >Monash eResearch Centre</a> have been <a href=\"https://rcblog.erc.monash.edu.au/blog/2013/12/bioinformatics-training-on-rcmon/\"\
          >partnering</a> with <a href=\"http://www.bioplatforms.com/\">Bioplatforms\n\
          Australia (BPA)</a> and <a href=\"http://www.csiro.au/\">CSIRO</a> for delivering\
          \ hands-on bioinformatics workshops to Australian researchers. This partnership\
          \ started back in 2012 when the first next-generation sequencing workshop\
          \ was delivered at Monash University. The <strong>Bioinformatics Training\
          \ Platform (BTP)</strong> has been developed as a broadly accessible solution\
          \ for delivering these workshops using cloud computing infrastructures and\
          \ <a href=\"http://bib.oxfordjournals.org/content/early/2013/03/29/bib.bbt022.full.pdf+html\"\
          >addressing the increasing demand</a> for training workshops in Australia.</p>\n\
          <p>The standard NGS workshop delivered by BPA and CSIRO is composed of a\
          \ number of training modules. Each training module is composed of the following\
          \ components: analysis tools, datasets and training materials. The analysis\
          \ tools are essential to a hands-on bioinformatics workshop as it teaches\
          \ scientists how such tools are used to interrogate and interpret results.\
          \ Most of the analysis tools used by the BTP are open source and easily\
          \ accessible on various platforms. The BTP maintains these analysis tools\
          \ on <a href=\"https://github.com/BPA-CSIRO-Workshops\">BPA-CSIRO GitHub\
          \ Project</a>. To support the hands-on bioinformatics workshop, analysis\
          \ and reference datasets are used together for analysis. Datasets are stored\
          \ and managed on the NeCTAR object storage service. The training materials\
          \ (presentations and handouts) are also developed and maintained as part\
          \ of the BTP. A high level overview of the BTP architecture is show below:</p>\n\
          <p><img alt=\"Bioinformatics Training Platform Architecture\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/btp-architecture.png?raw=true\"\
          ></p>\n<p>A workshop is composed of a number of training modules. Each training\
          \ module has an associated analysis tools and datasets metadata. These metadata\
          \ are used by the orchestration system for automation of tools installation\
          \ during BTP image creation and datasets syncing during BTP instance deployments.</p>\n\
          <hr>\n<h2>Components</h2>\n<p>The BTP as a solution is composed of a number\
          \ of components: <strong>Analysis Tools</strong>, <strong>Datasets</strong>\
          \ and <strong>Training Materials</strong>. These components are encapsulated\
          \ on each of the training modules. A brief summary of each one are included\
          \ below.</p>\n<h3>Analysis Tools</h3>\n<p>Analysis tools are essential for\
          \ delivering hands-on training workshops.\nThe BTP teaches trainees how\
          \ these tools can be used to help interrogate and interpret their analysis\
          \ results. Most of these analysis tools are available as stand alone executables\
          \ while others have to be built from source. The most common analysis tools\
          \ used and packaged in the BTP are listed in the table below:</p>\n<table>\n\
          <thead>\n<tr>\n<th align=\"left\">Tools</th>\n<th align=\"left\">Function</th>\n\
          </tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">AMOS Hawkeye</td>\n<td\
          \ align=\"left\">Genome data visualization</td>\n</tr>\n<tr>\n<td align=\"\
          left\">BEDTools</td>\n<td align=\"left\">Genome data manipulation</td>\n\
          </tr>\n<tr>\n<td align=\"left\">BLAT</td>\n<td align=\"left\">Sequence location\
          \ lookup in the genome</td>\n</tr>\n<tr>\n<td align=\"left\">Bowtie</td>\n\
          <td align=\"left\">Read Alignment</td>\n</tr>\n<tr>\n<td align=\"left\"\
          >CummeRbund</td>\n<td align=\"left\">RNA-Seq analysis using R</td>\n</tr>\n\
          <tr>\n<td align=\"left\">Cufflinks</td>\n<td align=\"left\">RNA-Seq analysis</td>\n\
          </tr>\n<tr>\n<td align=\"left\">DESeq2</td>\n<td align=\"left\">Differential\
          \ gene expression analysis using R</td>\n</tr>\n<tr>\n<td align=\"left\"\
          >edgeR</td>\n<td align=\"left\">Empirical gene expression analysis using\
          \ R</td>\n</tr>\n<tr>\n<td align=\"left\">FastQC</td>\n<td align=\"left\"\
          >FastQC</td>\n</tr>\n<tr>\n<td align=\"left\">FASTX</td>\n<td align=\"left\"\
          >Toolkit for short reads preprocessing</td>\n</tr>\n<tr>\n<td align=\"left\"\
          >IGV</td>\n<td align=\"left\">Interactive exploration of genomic data</td>\n\
          </tr>\n<tr>\n<td align=\"left\">igvtools</td>\n<td align=\"left\">Preprocessing\
          \ of data before loading to IGV</td>\n</tr>\n<tr>\n<td align=\"left\">MACS</td>\n\
          <td align=\"left\">ChIP-Seq analysis</td>\n</tr>\n<tr>\n<td align=\"left\"\
          >MUMmer</td>\n<td align=\"left\">Rapid genome alignment, a dependency for\
          \ AMOS</td>\n</tr>\n<tr>\n<td align=\"left\">PeakAnalyzer</td>\n<td align=\"\
          left\">Multi-peak data analysis</td>\n</tr>\n<tr>\n<td align=\"left\">Picard</td>\n\
          <td align=\"left\">Sequence data analysis</td>\n</tr>\n<tr>\n<td align=\"\
          left\">SAMtools</td>\n<td align=\"left\">For manipulating alignments in\
          \ the SAM format</td>\n</tr>\n<tr>\n<td align=\"left\">Skewer</td>\n<td\
          \ align=\"left\">Adapter trimmer for paired-end reads</td>\n</tr>\n</tbody>\n\
          </table>\n<p>These analysis tools are packaged and installed into the <strong>BTP\
          \ Image</strong> upon creation. This process is described in detail in the\
          \ [BTP Workflows][#btp-workflows] section below.</p>\n<h4>Packaging of Analysis\
          \ Tools</h4>\n<p>To make maintenance and deployment of the BTP easier, most\
          \ of the analysis tools included in the BTP are packaged as stand-alone\
          \ <code>*.deb</code> installers, installable on Ubuntu-based operating systems.\
          \ <a href=\"https://github.com/bernd/fpm-cookery\"><code>fpm-cookery</code></a>\
          \ is used to create the <code>*.deb</code> installers using recipes. The\
          \ current <strong>BTP Images</strong> are based on Ubuntu Precise LTS which\
          \ is supported until 2017. The BTP <a href=\"https://github.com/BPA-CSIRO-Workshops/btp-tools.git\"\
          >maintains a set of recipes on GitHub</a> which is also integrated with\
          \ <a href=\"https://travis-ci.org/BPA-CSIRO-Workshops/btp-tools\">Travis\
          \ CI</a> for continuous integration. Whenever a tool recipe is updated or\
          \ new recipe is added into the repository, <strong>Travis CI</strong> ensures\
          \ that the recipes builds correctly.</p>\n<p>The <code>.deb</code> installers\
          \ can also be manually created on a client machine. This step is not mandatory\
          \ for creating the BTP images and deployment of BTP instances. One can clone\
          \ the BTP Tools repository, and using <code>fpm-cookery</code>, create the\
          \ <code>.deb</code> installers.</p>\n<p>Clone the BTP Tools repository:</p>\n\
          <p><code>git clone https://github.com/BPA-CSIRO-Workshops/btp-tools.git</code></p>\n\
          <p>The <code>.deb</code> installer for a particular analysis tool can then\
          \ be built using <code>fpm-cookery</code>:</p>\n<p><code>cd btp-tools/bwa\n\
          fpm-cookery .</code></p>\n<p><code>fpm-cookery</code> will read the instructions\
          \ in the recipe and build the <code>.deb</code> installer. In the example\
          \ above, <code>fpm-cookery</code> will get the source code for <code>bwa</code>\
          \ from GitHub, then will proceed with the standard configuration, compilation\
          \ and building of the tool. <code>fpm-cookery</code> will place the resulting\
          \ <code>.deb</code> installer inside the <code>pkg</code> subdirectory:</p>\n\
          <p><code>ls pkg/\nbwa_0.7.12-0_amd64.deb</code></p>\n<h3>Datasets</h3>\n\
          <p>Datasets used by the BTP are stored on <a href=\"http://support.rc.nectar.org.au/docs/object-storage\"\
          >NeCTAR Object Storage (Swift)</a>. Each training modules has a corresponding\
          \ publicly readable container where its datasets are accessible. The containers\
          \ for the NGS training modules are listed in the table below:</p>\n<table>\n\
          <thead>\n<tr>\n<th align=\"left\">Module</th>\n<th align=\"left\">Container</th>\n\
          </tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Introduction to CLI</td>\n\
          <td align=\"left\">NGSDataCommandLine</td>\n</tr>\n<tr>\n<td align=\"left\"\
          >Quality Control</td>\n<td align=\"left\">NGSDataQC</td>\n</tr>\n<tr>\n\
          <td align=\"left\">Alignment</td>\n<td align=\"left\">NGSDataChIPSeq</td>\n\
          </tr>\n<tr>\n<td align=\"left\">ChIP-Seq</td>\n<td align=\"left\">NGSDataChIPSeq</td>\n\
          </tr>\n<tr>\n<td align=\"left\">RNA-Seq</td>\n<td align=\"left\">NGSDataRNASeq</td>\n\
          </tr>\n<tr>\n<td align=\"left\">De novo Assembly</td>\n<td align=\"left\"\
          >NGSDataDeNovo</td>\n</tr>\n</tbody>\n</table>\n<p>The complete container\
          \ URL are used to pull down the datasets into the BTP instances. The URLs\
          \ are defined on the datasets metadata file, which is used by <strong>Puppet</strong>\
          \ to pull down the datasets into the BTP instances upon deployment.</p>\n\
          <h3>Training Materials</h3>\n<hr>\n<h2>BTP Workflows</h2>\n<h3>Creating\
          \ the BTP Image</h3>\n<h4>Prerequisites for Creating BTP Images</h4>\n<ul>\n\
          <li>git</li>\n<li>Packer</li>\n<li>OpenStack Glance Command Line Client</li>\n\
          <li>NeCTAR OpenStack Credentials</li>\n<li>internet access</li>\n</ul>\n\
          <p>The BTP uses the <a href=\"https://www.packer.io\">Packer</a> tool for\
          \ creating new virtual machine images compatible with NeCTAR Research Cloud.</p>\n\
          <h4>Get Workshop Repository</h4>\n<p>A collection of Packer recipes are\
          \ included as part of the orchestration module inside the <a href=\"https://github.com/BPA-CSIRO-Workshops/btp-workshop-ngs\"\
          >BPA-CSIRO Workshop NGS Repository</a>. This repository must be cloned together\
          \ with the training submodules on the client machine where the BTP image\
          \ will be created:</p>\n<p><code>git clone --recurse-submodules https://github.com/BPA-CSIRO-Workshops/btp-workshop-ngs.git</code></p>\n\
          <h4>Orchestration</h4>\n<p>Once the workshop repository and the training\
          \ submodules have been cloned, the local copy will have the following contents\
          \ structure:</p>\n<p><code>\u251C\u2500\u2500 010_trainers\n\u251C\u2500\
          \u2500 015_preamble\n\u251C\u2500\u2500 050_ngs-qc\n\u251C\u2500\u2500 060_alignment\n\
          \u251C\u2500\u2500 070_chip-seq\n\u251C\u2500\u2500 080_rna-seq\n\u251C\u2500\
          \u2500 090_velvet\n\u251C\u2500\u2500 905_post-workshop\n\u251C\u2500\u2500\
          \ Makefile\n\u251C\u2500\u2500 README.md\n\u251C\u2500\u2500 developers\n\
          \u251C\u2500\u2500 licences\n\u251C\u2500\u2500 orchestration\n\u251C\u2500\
          \u2500 style\n\u2514\u2500\u2500 template.tex</code></p>\n<p>The numberings\
          \ (e.g <code>010_trainers</code>, <code>015_preamble</code>) are used by\
          \ the build system to order by which the training modules are ordered in\
          \ the training handouts. Each training module has an associated handouts\
          \ subdirectory where the <em>LaTeX</em> file for that module is located.\
          \ Going inside the <code>orchestration/packer</code> subdirectory will show\
          \ the available Packer recipes including the one compatible with the NeCTAR\
          \ Research Cloud, <code>btp-qemu.json</code>. The available Packer recipes\
          \ for the BTP are:</p>\n<p><code>\u251C\u2500\u2500 btp-aws.json\n\u251C\
          \u2500\u2500 btp-qemu.json\n\u251C\u2500\u2500 btp-virtualbox.json\n\u251C\
          \u2500\u2500 btp-vmware.json</code></p>\n<h4>Launch Packer</h4>\n<p>Before\
          \ launching Packer, the content of the recipe file <code>btp-qemu.json</code>\
          \ can be viewed. Descriptions for each recipe section are highlighted below.</p>\n\
          <p>The image creation process can then be started by feeding the recipe\
          \ into Packer. This assumes that the Packer is already installed on the\
          \ client (build) machine. Packer can then be launched, with the recipe filename\
          \ passed as a command line argument:</p>\n<p><code>packer build btp-qemu.json</code></p>\n\
          <p>Packer will start the image creation process and the first thing this\
          \ will do is to download the latest available alternate Ubuntu ISO from\
          \ the internet. So the client machine must have access to the internet to\
          \ download the ISO file.</p>\n<h4>Upload Image</h4>\n<h3>Deploying BTP Instances</h3>\n\
          <h4>Prerequisites for Deploying BTP Instances</h4>\n<ul>\n<li>NeCTAR OpenStack\
          \ Credentials</li>\n<li>OpenStack Nova Command Line Client</li>\n<li>NoMachine\
          \ (NX) Client</li>\n</ul>\n<h4>Using the BTP Instances for Training</h4>\n\
          \n\n"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 1
        id: 6000093606
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-07T16:37:19-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000093606
        position: 7
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Monash Bioinformatics Training Platform User Guide
        updated_at: '2015-12-07T16:37:19-05:00'
        user_id: 6002464727
  html: "<h1>Bioinformatics Training Platform (BTP) User Guide</h1>\n<h2>Introduction</h2>\n\
    <p><a href=\"https://platforms.monash.edu/eresearch/\">Monash eResearch Centre</a>\
    \ have been <a href=\"https://rcblog.erc.monash.edu.au/blog/2013/12/bioinformatics-training-on-rcmon/\"\
    >partnering</a> with <a href=\"http://www.bioplatforms.com/\">Bioplatforms\nAustralia\
    \ (BPA)</a> and <a href=\"http://www.csiro.au/\">CSIRO</a> for delivering hands-on\
    \ bioinformatics workshops to Australian researchers. This partnership started\
    \ back in 2012 when the first next-generation sequencing workshop was delivered\
    \ at Monash University. The <strong>Bioinformatics Training Platform (BTP)</strong>\
    \ has been developed as a broadly accessible solution for delivering these workshops\
    \ using cloud computing infrastructures and <a href=\"http://bib.oxfordjournals.org/content/early/2013/03/29/bib.bbt022.full.pdf+html\"\
    >addressing the increasing demand</a> for training workshops in Australia.</p>\n\
    <p>The standard NGS workshop delivered by BPA and CSIRO is composed of a number\
    \ of training modules. Each training module is composed of the following components:\
    \ analysis tools, datasets and training materials. The analysis tools are essential\
    \ to a hands-on bioinformatics workshop as it teaches scientists how such tools\
    \ are used to interrogate and interpret results. Most of the analysis tools used\
    \ by the BTP are open source and easily accessible on various platforms. The BTP\
    \ maintains these analysis tools on <a href=\"https://github.com/BPA-CSIRO-Workshops\"\
    >BPA-CSIRO GitHub Project</a>. To support the hands-on bioinformatics workshop,\
    \ analysis and reference datasets are used together for analysis. Datasets are\
    \ stored and managed on the NeCTAR object storage service. The training materials\
    \ (presentations and handouts) are also developed and maintained as part of the\
    \ BTP. A high level overview of the BTP architecture is show below:</p>\n<p><img\
    \ alt=\"Bioinformatics Training Platform Architecture\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/btp-architecture.png?raw=true\"\
    ></p>\n<p>A workshop is composed of a number of training modules. Each training\
    \ module has an associated analysis tools and datasets metadata. These metadata\
    \ are used by the orchestration system for automation of tools installation during\
    \ BTP image creation and datasets syncing during BTP instance deployments.</p>\n\
    <hr>\n<h2>Components</h2>\n<p>The BTP as a solution is composed of a number of\
    \ components: <strong>Analysis Tools</strong>, <strong>Datasets</strong> and <strong>Training\
    \ Materials</strong>. These components are encapsulated on each of the training\
    \ modules. A brief summary of each one are included below.</p>\n<h3>Analysis Tools</h3>\n\
    <p>Analysis tools are essential for delivering hands-on training workshops.\n\
    The BTP teaches trainees how these tools can be used to help interrogate and interpret\
    \ their analysis results. Most of these analysis tools are available as stand\
    \ alone executables while others have to be built from source. The most common\
    \ analysis tools used and packaged in the BTP are listed in the table below:</p>\n\
    <table>\n<thead>\n<tr>\n<th align=\"left\">Tools</th>\n<th align=\"left\">Function</th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">AMOS Hawkeye</td>\n<td align=\"\
    left\">Genome data visualization</td>\n</tr>\n<tr>\n<td align=\"left\">BEDTools</td>\n\
    <td align=\"left\">Genome data manipulation</td>\n</tr>\n<tr>\n<td align=\"left\"\
    >BLAT</td>\n<td align=\"left\">Sequence location lookup in the genome</td>\n</tr>\n\
    <tr>\n<td align=\"left\">Bowtie</td>\n<td align=\"left\">Read Alignment</td>\n\
    </tr>\n<tr>\n<td align=\"left\">CummeRbund</td>\n<td align=\"left\">RNA-Seq analysis\
    \ using R</td>\n</tr>\n<tr>\n<td align=\"left\">Cufflinks</td>\n<td align=\"left\"\
    >RNA-Seq analysis</td>\n</tr>\n<tr>\n<td align=\"left\">DESeq2</td>\n<td align=\"\
    left\">Differential gene expression analysis using R</td>\n</tr>\n<tr>\n<td align=\"\
    left\">edgeR</td>\n<td align=\"left\">Empirical gene expression analysis using\
    \ R</td>\n</tr>\n<tr>\n<td align=\"left\">FastQC</td>\n<td align=\"left\">FastQC</td>\n\
    </tr>\n<tr>\n<td align=\"left\">FASTX</td>\n<td align=\"left\">Toolkit for short\
    \ reads preprocessing</td>\n</tr>\n<tr>\n<td align=\"left\">IGV</td>\n<td align=\"\
    left\">Interactive exploration of genomic data</td>\n</tr>\n<tr>\n<td align=\"\
    left\">igvtools</td>\n<td align=\"left\">Preprocessing of data before loading\
    \ to IGV</td>\n</tr>\n<tr>\n<td align=\"left\">MACS</td>\n<td align=\"left\">ChIP-Seq\
    \ analysis</td>\n</tr>\n<tr>\n<td align=\"left\">MUMmer</td>\n<td align=\"left\"\
    >Rapid genome alignment, a dependency for AMOS</td>\n</tr>\n<tr>\n<td align=\"\
    left\">PeakAnalyzer</td>\n<td align=\"left\">Multi-peak data analysis</td>\n</tr>\n\
    <tr>\n<td align=\"left\">Picard</td>\n<td align=\"left\">Sequence data analysis</td>\n\
    </tr>\n<tr>\n<td align=\"left\">SAMtools</td>\n<td align=\"left\">For manipulating\
    \ alignments in the SAM format</td>\n</tr>\n<tr>\n<td align=\"left\">Skewer</td>\n\
    <td align=\"left\">Adapter trimmer for paired-end reads</td>\n</tr>\n</tbody>\n\
    </table>\n<p>These analysis tools are packaged and installed into the <strong>BTP\
    \ Image</strong> upon creation. This process is described in detail in the [BTP\
    \ Workflows][#btp-workflows] section below.</p>\n<h4>Packaging of Analysis Tools</h4>\n\
    <p>To make maintenance and deployment of the BTP easier, most of the analysis\
    \ tools included in the BTP are packaged as stand-alone <code>*.deb</code> installers,\
    \ installable on Ubuntu-based operating systems. <a href=\"https://github.com/bernd/fpm-cookery\"\
    ><code>fpm-cookery</code></a> is used to create the <code>*.deb</code> installers\
    \ using recipes. The current <strong>BTP Images</strong> are based on Ubuntu Precise\
    \ LTS which is supported until 2017. The BTP <a href=\"https://github.com/BPA-CSIRO-Workshops/btp-tools.git\"\
    >maintains a set of recipes on GitHub</a> which is also integrated with <a href=\"\
    https://travis-ci.org/BPA-CSIRO-Workshops/btp-tools\">Travis CI</a> for continuous\
    \ integration. Whenever a tool recipe is updated or new recipe is added into the\
    \ repository, <strong>Travis CI</strong> ensures that the recipes builds correctly.</p>\n\
    <p>The <code>.deb</code> installers can also be manually created on a client machine.\
    \ This step is not mandatory for creating the BTP images and deployment of BTP\
    \ instances. One can clone the BTP Tools repository, and using <code>fpm-cookery</code>,\
    \ create the <code>.deb</code> installers.</p>\n<p>Clone the BTP Tools repository:</p>\n\
    <p><code>git clone https://github.com/BPA-CSIRO-Workshops/btp-tools.git</code></p>\n\
    <p>The <code>.deb</code> installer for a particular analysis tool can then be\
    \ built using <code>fpm-cookery</code>:</p>\n<p><code>cd btp-tools/bwa\nfpm-cookery\
    \ .</code></p>\n<p><code>fpm-cookery</code> will read the instructions in the\
    \ recipe and build the <code>.deb</code> installer. In the example above, <code>fpm-cookery</code>\
    \ will get the source code for <code>bwa</code> from GitHub, then will proceed\
    \ with the standard configuration, compilation and building of the tool. <code>fpm-cookery</code>\
    \ will place the resulting <code>.deb</code> installer inside the <code>pkg</code>\
    \ subdirectory:</p>\n<p><code>ls pkg/\nbwa_0.7.12-0_amd64.deb</code></p>\n<h3>Datasets</h3>\n\
    <p>Datasets used by the BTP are stored on <a href=\"http://support.rc.nectar.org.au/docs/object-storage\"\
    >NeCTAR Object Storage (Swift)</a>. Each training modules has a corresponding\
    \ publicly readable container where its datasets are accessible. The containers\
    \ for the NGS training modules are listed in the table below:</p>\n<table>\n<thead>\n\
    <tr>\n<th align=\"left\">Module</th>\n<th align=\"left\">Container</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td align=\"left\">Introduction to CLI</td>\n<td align=\"\
    left\">NGSDataCommandLine</td>\n</tr>\n<tr>\n<td align=\"left\">Quality Control</td>\n\
    <td align=\"left\">NGSDataQC</td>\n</tr>\n<tr>\n<td align=\"left\">Alignment</td>\n\
    <td align=\"left\">NGSDataChIPSeq</td>\n</tr>\n<tr>\n<td align=\"left\">ChIP-Seq</td>\n\
    <td align=\"left\">NGSDataChIPSeq</td>\n</tr>\n<tr>\n<td align=\"left\">RNA-Seq</td>\n\
    <td align=\"left\">NGSDataRNASeq</td>\n</tr>\n<tr>\n<td align=\"left\">De novo\
    \ Assembly</td>\n<td align=\"left\">NGSDataDeNovo</td>\n</tr>\n</tbody>\n</table>\n\
    <p>The complete container URL are used to pull down the datasets into the BTP\
    \ instances. The URLs are defined on the datasets metadata file, which is used\
    \ by <strong>Puppet</strong> to pull down the datasets into the BTP instances\
    \ upon deployment.</p>\n<h3>Training Materials</h3>\n<hr>\n<h2>BTP Workflows</h2>\n\
    <h3>Creating the BTP Image</h3>\n<h4>Prerequisites for Creating BTP Images</h4>\n\
    <ul>\n<li>git</li>\n<li>Packer</li>\n<li>OpenStack Glance Command Line Client</li>\n\
    <li>NeCTAR OpenStack Credentials</li>\n<li>internet access</li>\n</ul>\n<p>The\
    \ BTP uses the <a href=\"https://www.packer.io\">Packer</a> tool for creating\
    \ new virtual machine images compatible with NeCTAR Research Cloud.</p>\n<h4>Get\
    \ Workshop Repository</h4>\n<p>A collection of Packer recipes are included as\
    \ part of the orchestration module inside the <a href=\"https://github.com/BPA-CSIRO-Workshops/btp-workshop-ngs\"\
    >BPA-CSIRO Workshop NGS Repository</a>. This repository must be cloned together\
    \ with the training submodules on the client machine where the BTP image will\
    \ be created:</p>\n<p><code>git clone --recurse-submodules https://github.com/BPA-CSIRO-Workshops/btp-workshop-ngs.git</code></p>\n\
    <h4>Orchestration</h4>\n<p>Once the workshop repository and the training submodules\
    \ have been cloned, the local copy will have the following contents structure:</p>\n\
    <p><code>\u251C\u2500\u2500 010_trainers\n\u251C\u2500\u2500 015_preamble\n\u251C\
    \u2500\u2500 050_ngs-qc\n\u251C\u2500\u2500 060_alignment\n\u251C\u2500\u2500\
    \ 070_chip-seq\n\u251C\u2500\u2500 080_rna-seq\n\u251C\u2500\u2500 090_velvet\n\
    \u251C\u2500\u2500 905_post-workshop\n\u251C\u2500\u2500 Makefile\n\u251C\u2500\
    \u2500 README.md\n\u251C\u2500\u2500 developers\n\u251C\u2500\u2500 licences\n\
    \u251C\u2500\u2500 orchestration\n\u251C\u2500\u2500 style\n\u2514\u2500\u2500\
    \ template.tex</code></p>\n<p>The numberings (e.g <code>010_trainers</code>, <code>015_preamble</code>)\
    \ are used by the build system to order by which the training modules are ordered\
    \ in the training handouts. Each training module has an associated handouts subdirectory\
    \ where the <em>LaTeX</em> file for that module is located. Going inside the <code>orchestration/packer</code>\
    \ subdirectory will show the available Packer recipes including the one compatible\
    \ with the NeCTAR Research Cloud, <code>btp-qemu.json</code>. The available Packer\
    \ recipes for the BTP are:</p>\n<p><code>\u251C\u2500\u2500 btp-aws.json\n\u251C\
    \u2500\u2500 btp-qemu.json\n\u251C\u2500\u2500 btp-virtualbox.json\n\u251C\u2500\
    \u2500 btp-vmware.json</code></p>\n<h4>Launch Packer</h4>\n<p>Before launching\
    \ Packer, the content of the recipe file <code>btp-qemu.json</code> can be viewed.\
    \ Descriptions for each recipe section are highlighted below.</p>\n<p>The image\
    \ creation process can then be started by feeding the recipe into Packer. This\
    \ assumes that the Packer is already installed on the client (build) machine.\
    \ Packer can then be launched, with the recipe filename passed as a command line\
    \ argument:</p>\n<p><code>packer build btp-qemu.json</code></p>\n<p>Packer will\
    \ start the image creation process and the first thing this will do is to download\
    \ the latest available alternate Ubuntu ISO from the internet. So the client machine\
    \ must have access to the internet to download the ISO file.</p>\n<h4>Upload Image</h4>\n\
    <h3>Deploying BTP Instances</h3>\n<h4>Prerequisites for Deploying BTP Instances</h4>\n\
    <ul>\n<li>NeCTAR OpenStack Credentials</li>\n<li>OpenStack Nova Command Line Client</li>\n\
    <li>NoMachine (NX) Client</li>\n</ul>\n<h4>Using the BTP Instances for Training</h4>\n\
    <!-- Links -->\n\n<!-- Figures -->"
  parent: 24
  sha1: 0821a4e8a8aa973a34520faaffe4fa3589885107
  title: Monash Bioinformatics Training Platform User Guide
101:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-12-06T22:48:08-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " CoESRA Remote Desktop - User Guide \n Type \n The Collaborative\
          \ Environment for Ecosystem Science Research and Analysis\n(CoESRA) is a\
          \ Platform-as-a-Service (PaaS) service developed by the\nTerrestrial Ecosystem\
          \ Research Network\nnetwork to serve the ecosystem science community. \n\
          \ Description \n The CoESRA is a workflow-based web platform that allows\
          \ researchers\n(primarily ecosystem scientists) to perform complex analyses\
          \ without\nhaving to set up experiments from scratch and worry about having\
          \ enough\nresources to run the analyses. CoESRA provides users with a cloud-based,\n\
          'remote desktop' platform with pre-loaded analytical and synthesis tools.\n\
          It was built to enable ecosystem scientists to orchestrate, compose and\n\
          execute experiments as repeatable workflows. Kepler is used within the\n\
          desktop as a composition, orchestration and execution engine. Kepler is\n\
          an open source workflow management tool for the design and execution of\n\
          scientific workflows. \n The CoESRA service provides an opportunity not\
          \ only to reuse data but\nalso to reuse tools for data manipulation, scripts\
          \ for data visualisation,\nand algorithms for analysis processes. Once a\
          \ specific analysis has been\nconducted, the entire workflow can be stored\
          \ and shared with other scientists.\nFinally, the workflow can published\
          \ to\nResearch Data Australia(RDA). \n Through use of the CoeSRA desktop,\
          \ the community will gain access\nto data streams, tools and often hidden\n\
          'pipeline' processes to leverage further knowledge about ecosystem\nscience\
          \ experiments. \n The Linux-based virtual desktop platform is best accessed\
          \ via the Chrome\nWeb browser. It enables users to access Web-based data\
          \ sources, e.g. data\nstored on DropBox, CloudStor or Google Drive, or other\
          \ data sources related\nto ecosystem science. The provenance information\
          \ for this data can be stored.\nAll registered users get a public and private\
          \ home folder which can be used\nto store data and workflows. \n Workflows\
          \ can be shared in a common public folder \"public_share_workflow\",\nwhich\
          \ is accessible by all registered users. Workflows can also be stored\n\
          on MyExperiment and the\nAustralian National Data Service's\nResearch Data\
          \ Australia by creating\na service record from the Kepler menu. \n To have\
          \ a workflow integrated into the CoESRA platform, please email\ntern.coesra@gmail.com.\
          \ \n On launch, the platform includes the following applications: R, RStudio,\n\
          Python and Kepler. It also includes\nNimrod software.\nOther software can\
          \ be added to the live desktop by users. \n The CoESRA desktop is a time-limited\
          \ service. It is provisioned initially\nfor two days. A user will get an\
          \ email notification six hours before the\nvirtual desktop is remotely terminated.\
          \ If users want to extend their access,\nthey can request an extension from\
          \ the system administrator, or by responding\nto the desktop termination\
          \ reminder email. \n Target audience \n The service has been developed to\
          \ meet the needs of the ecosystem science\ncommunity, including researchers\
          \ in the TERN network. \n Resource requirements \n CuNo installation is\
          \ required as the desktop is virtually hosted. \n Currently, CoESRA is accessible\
          \ using the Google Chrome browser only. Other\nbrowsers will eventually\
          \ be supported. \n Firefox is the only browser available as part of the\
          \ virtual desktop platform\nonce the platform has launched. \n How to access\
          \ \n Users can access CoESRA via their\nAustralian Access Federation (AAF)\
          \ credentials. \n Steps: \n 1) Go to CoESRA. \n 2) Click on Register. \n\
          \ If this is a user's first visit, s/he will be taken to the\nAAF's Log\
          \ in through your organisation service. \n \n The user should select the\
          \ institution name from the drop-down list and\nthen check one of two options\
          \ for subsequent log ins: \n \n \n Remember my organisation for this web\
          \ browser session only \n \n \n Remember my organisation permanently and\
          \ skip this selection from now on \n \n \n To simplify future access, users\
          \ should select the 'Remember my organisation\npermanently' option. \n The\
          \ user should then follow the steps to log in via their own institution.\n\
          Once the organisation has been selected, the user will be taken to the log\n\
          in site for that institution, e.g., a user coming in via\nThe University\
          \ of Queensland will see this screen: \n \n 3) Once a user has successfully\
          \ entered credentials, the screen will\nrefresh with \n \n 4) The desktop\
          \ will then deploy. \n \n A virtual desktop will load, with the Kepler environment\
          \ open by default. \n On the left-hand side menu in Kepler, click on \"\
          Coesra-tern\" and subsequent\nfolders to see the workflow icons. \n \n Double-click\
          \ on the workflow icon of your choice and the workflow will\nopen in a new\
          \ Kepler window. \n \n Click on the Run button to run a workflow. Some workflows\
          \ may require\nadditional datasets for successful execution. \n \n Non-AAF-accredited\
          \ users \n Access is possible even if an individual does not have AAF credentials.\n\
          Please contact tern.coesra@gmail.com for\nguest account access. \n Issues\
          \ \n The system has the capacity to launch only a specific number of desktops\
          \ at\nany one time. If there is no more capacity in the system, you will\
          \ get the\nfollowing error message: \n \n The only solution here is to try\
          \ again later. \n Configuration guide \n The desktop comes 'as is'. Researchers\
          \ are able to customise it, but are\nstrongly discouraged from doing so.\
          \ According to the\nFAQ on the site: \"We strongly recommend\nusers not\
          \ to make any changes to the virtual desktop setting because it may\naffect\
          \ the working of the desktop. Any changes made by users will not be\nsupported.\"\
          \ \n Technical blueprint \n These are two real-life case studies: \n \n\
          \ \n animal conservation and management plan \n \n \n ecosystem assessment\
          \ of Mountain Ash forest. \n \n \n The first case study links conservation\
          \ planning software\nMarxan and animal tracking information to increase\
          \ the\nanalytical power of these ecological tools and create a repeatable\
          \ and\nreusable workflow for subsequent studies of habitat conservation.\
          \ \n The second case study brings together data and analysis required to\
          \ apply\nIUCN Red List of Ecosystems\ncriteria to the Mountain Ash forest\
          \ ecosystem and to make a repeatable\n(e.g., able to be re-run in the future\
          \ with updated time windows and\nupdated ecological parameters) workflow\
          \ for the ecosystem assessment\nof Mountain Ash forests in the central highlands\
          \ of Victoria. The workflow\nwill also enable researchers to re-run the\
          \ entire assessment with\nadditional data for certain criteria. \n For more\
          \ information, please email\ntern.coesra@gmail.com. \n Frequently Asked\
          \ Questions \n CoESRA FAQ \n Help \n For help and support, please email\n\
          tern.coesra@gmail.com. \n Contact \n Please email tern.coesra@gmail.com. "
        description: '<h1>CoESRA Remote Desktop - User Guide</h1>

          <h2>Type</h2>

          <p>The Collaborative Environment for Ecosystem Science Research and Analysis

          (CoESRA) is a Platform-as-a-Service (PaaS) service developed by the

          <a href="http://tern.org.au/">Terrestrial Ecosystem Research Network</a>

          network to serve the ecosystem science community.</p>

          <h2>Description</h2>

          <p>The CoESRA is a workflow-based web platform that allows researchers

          (primarily ecosystem scientists) to perform complex analyses without

          having to set up experiments from scratch and worry about having enough

          resources to run the analyses. CoESRA provides users with a cloud-based,

          ''remote desktop'' platform with pre-loaded analytical and synthesis tools.

          It was built to enable ecosystem scientists to orchestrate, compose and

          execute experiments as repeatable workflows. Kepler is used within the

          desktop as a composition, orchestration and execution engine. Kepler is

          an open source workflow management tool for the design and execution of

          scientific workflows.</p>

          <p>The CoESRA service provides an opportunity not only to reuse data but

          also to reuse tools for data manipulation, scripts for data visualisation,

          and algorithms for analysis processes. Once a specific analysis has been

          conducted, the entire workflow can be stored and shared with other scientists.

          Finally, the workflow can published to

          <a href="https://researchdata.ands.org.au/">Research Data Australia</a>(RDA).</p>

          <p>Through use of the CoeSRA desktop, the community will gain access

          to data streams, tools and often hidden

          ''pipeline'' processes to leverage further knowledge about ecosystem

          science experiments.</p>

          <p>The Linux-based virtual desktop platform is best accessed via the Chrome

          Web browser. It enables users to access Web-based data sources, e.g. data

          stored on DropBox, CloudStor or Google Drive, or other data sources related

          to ecosystem science. The provenance information for this data can be stored.

          All registered users get a public and private home folder which can be used

          to store data and workflows.</p>

          <p>Workflows can be shared in a common public folder "public_share_workflow",

          which is accessible by all registered users. Workflows can also be stored

          on <a href="http://www.myexperiment.org/home">MyExperiment</a> and the

          <a href="http://ands.org.au/">Australian National Data Service</a>''s

          <a href="https://researchdata.ands.org.au/">Research Data Australia</a>
          by creating

          a service record from the Kepler menu.</p>

          <p>To have a workflow integrated into the CoESRA platform, please email

          <a href="mailto:tern.coesra@gmail.com">tern.coesra@gmail.com</a>.</p>

          <p>On launch, the platform includes the following applications: R, RStudio,

          Python and Kepler. It also includes

          <a href="https://support.nectar.org.au/support/solutions/articles/6000095294-qcif-nimrod">Nimrod
          software</a>.

          Other software can be added to the live desktop by users.</p>

          <p>The CoESRA desktop is a time-limited service. It is provisioned initially

          for two days. A user will get an email notification six hours before the

          virtual desktop is remotely terminated. If users want to extend their access,

          they can request an extension from the system administrator, or by responding

          to the desktop termination reminder email.</p>

          <h2>Target audience</h2>

          <p>The service has been developed to meet the needs of the ecosystem science

          community, including researchers in the TERN network.</p>

          <h2>Resource requirements</h2>

          <p>CuNo installation is required as the desktop is virtually hosted.</p>

          <p>Currently, CoESRA is accessible using the Google Chrome browser only.
          Other

          browsers will eventually be supported.</p>

          <p>Firefox is the only browser available as part of the virtual desktop
          platform

          once the platform has launched.</p>

          <h2>How to access</h2>

          <p>Users can access CoESRA via their

          <a href="http://aaf.edu.au/">Australian Access Federation</a> (AAF) credentials.</p>

          <p>Steps:</p>

          <p>1) Go to <a href="https://www.coesra.org.au/">CoESRA</a>.</p>

          <p>2) Click on <strong>Register</strong>.</p>

          <p>If this is a user''s first visit, s/he will be taken to the

          <a href="http://aaf.edu.au/">AAF</a>''s <strong>Log in through your organisation</strong>
          service.</p>

          <p><img alt="AAF''s Log in through your organisation service" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/coesra2.png?raw=true"></p>

          <p>The user should select the institution name from the drop-down list and

          then check one of two options for subsequent log ins:</p>

          <ul>

          <li>

          <p>Remember my organisation for this web browser session only</p>

          </li>

          <li>

          <p>Remember my organisation permanently and skip this selection from now
          on</p>

          </li>

          </ul>

          <p>To simplify future access, users should select the ''Remember my organisation

          permanently'' option.</p>

          <p>The user should then follow the steps to log in via their own institution.

          Once the organisation has been selected, the user will be taken to the log

          in site for that institution, e.g., a user coming in via

          <a href="http://www.uq.edu.au/">The University of Queensland</a> will see
          this screen:</p>

          <p><img alt="UQ log in screen" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/coesra1.png?raw=true"></p>

          <p>3) Once a user has successfully entered credentials, the screen will

          refresh with</p>

          <p><img alt="Go to your desktop message" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/coesra3.png?raw=true"></p>

          <p>4) The desktop will then deploy.</p>

          <p><img alt="Opening your desktop message" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/coesra4.png?raw=true"></p>

          <p>A virtual desktop will load, with the Kepler environment open by default.</p>

          <p>On the left-hand side menu in Kepler, click on "Coesra-tern" and subsequent

          folders to see the workflow icons.</p>

          <p><img alt="CoESRA desktop" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/coesra5.png?raw=true"></p>

          <p>Double-click on the workflow icon of your choice and the workflow will

          open in a new Kepler window.</p>

          <p><img alt="Workflows" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/coesra6.png?raw=true"></p>

          <p>Click on the Run button to run a workflow. Some workflows may require

          additional datasets for successful execution.</p>

          <p><img alt="Run a workflow" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/coesra7.png?raw=true"></p>

          <h2>Non-AAF-accredited users</h2>

          <p>Access is possible even if an individual does not have AAF credentials.

          Please contact <a href="mailto:tern.coesra@gmail.com">tern.coesra@gmail.com</a>
          for

          guest account access.</p>

          <h2>Issues</h2>

          <p>The system has the capacity to launch only a specific number of desktops
          at

          any one time. If there is no more capacity in the system, you will get the

          following error message:</p>

          <p><img alt="System unavailable message" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/coesra8.png?raw=true"></p>

          <p>The only solution here is to try again later.</p>

          <h2>Configuration guide</h2>

          <p>The desktop comes ''as is''. Researchers are able to customise it, but
          are

          strongly discouraged from doing so. According to the

          <a href="https://www.coesra.org.au/#/faq">FAQ</a> on the site: "We strongly
          recommend

          users not to make any changes to the virtual desktop setting because it
          may

          affect the working of the desktop. Any changes made by users will not be

          supported."</p>

          <h2>Technical blueprint</h2>

          <p>These are two real-life case studies:</p>

          <ol>

          <li>

          <p>animal conservation and management plan</p>

          </li>

          <li>

          <p>ecosystem assessment of Mountain Ash forest.</p>

          </li>

          </ol>

          <p>The first case study links conservation planning software

          <a href="http://marxan.net">Marxan</a> and animal tracking information to
          increase the

          analytical power of these ecological tools and create a repeatable and

          reusable workflow for subsequent studies of habitat conservation.</p>

          <p>The second case study brings together data and analysis required to apply

          <a href="http://www.iucnredlistofecosystems.org/">IUCN Red List of Ecosystems</a>

          criteria to the Mountain Ash forest ecosystem and to make a repeatable

          (e.g., able to be re-run in the future with updated time windows and

          updated ecological parameters) workflow for the ecosystem assessment

          of Mountain Ash forests in the central highlands of Victoria. The workflow

          will also enable researchers to re-run the entire assessment with

          additional data for certain criteria.</p>

          <p>For more information, please email

          <a href="mailto:tern.coesra@gmail.com">tern.coesra@gmail.com</a>.</p>

          <h2>Frequently Asked Questions</h2>

          <p><a href="https://www.coesra.org.au/#/faq">CoESRA FAQ</a></p>

          <h2>Help</h2>

          <p>For help and support, please email

          <a href="mailto:tern.coesra@gmail.com">tern.coesra@gmail.com</a>.</p>

          <h2>Contact</h2>

          <p>Please email <a href="mailto:tern.coesra@gmail.com">tern.coesra@gmail.com</a>.</p>'
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 22
        id: 6000094838
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-10T21:31:21-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000094838
        position: 10
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: QCIF TERN CoESRA
        updated_at: '2015-12-10T21:31:21-05:00'
        user_id: 6002464727
  html: '<h1>CoESRA Remote Desktop - User Guide</h1>

    <h2>Type</h2>

    <p>The Collaborative Environment for Ecosystem Science Research and Analysis

    (CoESRA) is a Platform-as-a-Service (PaaS) service developed by the

    <a href="http://tern.org.au/">Terrestrial Ecosystem Research Network</a>

    network to serve the ecosystem science community.</p>

    <h2>Description</h2>

    <p>The CoESRA is a workflow-based web platform that allows researchers

    (primarily ecosystem scientists) to perform complex analyses without

    having to set up experiments from scratch and worry about having enough

    resources to run the analyses. CoESRA provides users with a cloud-based,

    ''remote desktop'' platform with pre-loaded analytical and synthesis tools.

    It was built to enable ecosystem scientists to orchestrate, compose and

    execute experiments as repeatable workflows. Kepler is used within the

    desktop as a composition, orchestration and execution engine. Kepler is

    an open source workflow management tool for the design and execution of

    scientific workflows.</p>

    <p>The CoESRA service provides an opportunity not only to reuse data but

    also to reuse tools for data manipulation, scripts for data visualisation,

    and algorithms for analysis processes. Once a specific analysis has been

    conducted, the entire workflow can be stored and shared with other scientists.

    Finally, the workflow can published to

    <a href="https://researchdata.ands.org.au/">Research Data Australia</a>(RDA).</p>

    <p>Through use of the CoeSRA desktop, the community will gain access

    to data streams, tools and often hidden

    ''pipeline'' processes to leverage further knowledge about ecosystem

    science experiments.</p>

    <p>The Linux-based virtual desktop platform is best accessed via the Chrome

    Web browser. It enables users to access Web-based data sources, e.g. data

    stored on DropBox, CloudStor or Google Drive, or other data sources related

    to ecosystem science. The provenance information for this data can be stored.

    All registered users get a public and private home folder which can be used

    to store data and workflows.</p>

    <p>Workflows can be shared in a common public folder "public_share_workflow",

    which is accessible by all registered users. Workflows can also be stored

    on <a href="http://www.myexperiment.org/home">MyExperiment</a> and the

    <a href="http://ands.org.au/">Australian National Data Service</a>''s

    <a href="https://researchdata.ands.org.au/">Research Data Australia</a> by creating

    a service record from the Kepler menu.</p>

    <p>To have a workflow integrated into the CoESRA platform, please email

    <a href="mailto:tern.coesra@gmail.com">tern.coesra@gmail.com</a>.</p>

    <p>On launch, the platform includes the following applications: R, RStudio,

    Python and Kepler. It also includes

    <a href="https://support.nectar.org.au/support/solutions/articles/6000095294-qcif-nimrod">Nimrod
    software</a>.

    Other software can be added to the live desktop by users.</p>

    <p>The CoESRA desktop is a time-limited service. It is provisioned initially

    for two days. A user will get an email notification six hours before the

    virtual desktop is remotely terminated. If users want to extend their access,

    they can request an extension from the system administrator, or by responding

    to the desktop termination reminder email.</p>

    <h2>Target audience</h2>

    <p>The service has been developed to meet the needs of the ecosystem science

    community, including researchers in the TERN network.</p>

    <h2>Resource requirements</h2>

    <p>CuNo installation is required as the desktop is virtually hosted.</p>

    <p>Currently, CoESRA is accessible using the Google Chrome browser only. Other

    browsers will eventually be supported.</p>

    <p>Firefox is the only browser available as part of the virtual desktop platform

    once the platform has launched.</p>

    <h2>How to access</h2>

    <p>Users can access CoESRA via their

    <a href="http://aaf.edu.au/">Australian Access Federation</a> (AAF) credentials.</p>

    <p>Steps:</p>

    <p>1) Go to <a href="https://www.coesra.org.au/">CoESRA</a>.</p>

    <p>2) Click on <strong>Register</strong>.</p>

    <p>If this is a user''s first visit, s/he will be taken to the

    <a href="http://aaf.edu.au/">AAF</a>''s <strong>Log in through your organisation</strong>
    service.</p>

    <p><img alt="AAF''s Log in through your organisation service" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR
    Documentation--DOCID16/Tools and Apps--DOCID24/images/coesra2.png?raw=true"></p>

    <p>The user should select the institution name from the drop-down list and

    then check one of two options for subsequent log ins:</p>

    <ul>

    <li>

    <p>Remember my organisation for this web browser session only</p>

    </li>

    <li>

    <p>Remember my organisation permanently and skip this selection from now on</p>

    </li>

    </ul>

    <p>To simplify future access, users should select the ''Remember my organisation

    permanently'' option.</p>

    <p>The user should then follow the steps to log in via their own institution.

    Once the organisation has been selected, the user will be taken to the log

    in site for that institution, e.g., a user coming in via

    <a href="http://www.uq.edu.au/">The University of Queensland</a> will see this
    screen:</p>

    <p><img alt="UQ log in screen" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR
    Documentation--DOCID16/Tools and Apps--DOCID24/images/coesra1.png?raw=true"></p>

    <p>3) Once a user has successfully entered credentials, the screen will

    refresh with</p>

    <p><img alt="Go to your desktop message" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR
    Documentation--DOCID16/Tools and Apps--DOCID24/images/coesra3.png?raw=true"></p>

    <p>4) The desktop will then deploy.</p>

    <p><img alt="Opening your desktop message" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR
    Documentation--DOCID16/Tools and Apps--DOCID24/images/coesra4.png?raw=true"></p>

    <p>A virtual desktop will load, with the Kepler environment open by default.</p>

    <p>On the left-hand side menu in Kepler, click on "Coesra-tern" and subsequent

    folders to see the workflow icons.</p>

    <p><img alt="CoESRA desktop" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR
    Documentation--DOCID16/Tools and Apps--DOCID24/images/coesra5.png?raw=true"></p>

    <p>Double-click on the workflow icon of your choice and the workflow will

    open in a new Kepler window.</p>

    <p><img alt="Workflows" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR
    Documentation--DOCID16/Tools and Apps--DOCID24/images/coesra6.png?raw=true"></p>

    <p>Click on the Run button to run a workflow. Some workflows may require

    additional datasets for successful execution.</p>

    <p><img alt="Run a workflow" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR
    Documentation--DOCID16/Tools and Apps--DOCID24/images/coesra7.png?raw=true"></p>

    <h2>Non-AAF-accredited users</h2>

    <p>Access is possible even if an individual does not have AAF credentials.

    Please contact <a href="mailto:tern.coesra@gmail.com">tern.coesra@gmail.com</a>
    for

    guest account access.</p>

    <h2>Issues</h2>

    <p>The system has the capacity to launch only a specific number of desktops at

    any one time. If there is no more capacity in the system, you will get the

    following error message:</p>

    <p><img alt="System unavailable message" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR
    Documentation--DOCID16/Tools and Apps--DOCID24/images/coesra8.png?raw=true"></p>

    <p>The only solution here is to try again later.</p>

    <h2>Configuration guide</h2>

    <p>The desktop comes ''as is''. Researchers are able to customise it, but are

    strongly discouraged from doing so. According to the

    <a href="https://www.coesra.org.au/#/faq">FAQ</a> on the site: "We strongly recommend

    users not to make any changes to the virtual desktop setting because it may

    affect the working of the desktop. Any changes made by users will not be

    supported."</p>

    <h2>Technical blueprint</h2>

    <p>These are two real-life case studies:</p>

    <ol>

    <li>

    <p>animal conservation and management plan</p>

    </li>

    <li>

    <p>ecosystem assessment of Mountain Ash forest.</p>

    </li>

    </ol>

    <p>The first case study links conservation planning software

    <a href="http://marxan.net">Marxan</a> and animal tracking information to increase
    the

    analytical power of these ecological tools and create a repeatable and

    reusable workflow for subsequent studies of habitat conservation.</p>

    <p>The second case study brings together data and analysis required to apply

    <a href="http://www.iucnredlistofecosystems.org/">IUCN Red List of Ecosystems</a>

    criteria to the Mountain Ash forest ecosystem and to make a repeatable

    (e.g., able to be re-run in the future with updated time windows and

    updated ecological parameters) workflow for the ecosystem assessment

    of Mountain Ash forests in the central highlands of Victoria. The workflow

    will also enable researchers to re-run the entire assessment with

    additional data for certain criteria.</p>

    <p>For more information, please email

    <a href="mailto:tern.coesra@gmail.com">tern.coesra@gmail.com</a>.</p>

    <h2>Frequently Asked Questions</h2>

    <p><a href="https://www.coesra.org.au/#/faq">CoESRA FAQ</a></p>

    <h2>Help</h2>

    <p>For help and support, please email

    <a href="mailto:tern.coesra@gmail.com">tern.coesra@gmail.com</a>.</p>

    <h2>Contact</h2>

    <p>Please email <a href="mailto:tern.coesra@gmail.com">tern.coesra@gmail.com</a>.</p>'
  parent: 24
  sha1: 91d15d3b3a455215847d5af3da7780f8893f7610
  title: QCIF TERN CoESRA
102:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-12-06T22:50:54-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Installation \n Neutron command line and Python APIs can be\
          \ installed directly on RDO, openSUSE,\nSUSE Linux Enterprise, Debian, and\
          \ Ubuntu via command line. \n \n On Red Hat, CentOS or Fedora, use yum to\
          \ install: \n \n yum install python-neutronclient \n \n On Ubuntu or Debian,\
          \ use apt-get to install: \n \n sudo apt-get install python-neutronclient\
          \ \n \n On openSUSE, use zypper to install: \n \n zypper install python-neutronclient\
          \ \n \n On SUSE inux: \n \n ``` \n zypper addrepo -f obs://Cloud:OpenStack:Kilo/SLE_12\
          \ Kilo \n zypper install python-neutronclient \n ``` \n If you want to install\
          \ sources packages, you can follow the below instructions. \n \n On MacOS:\
          \ \n \n ``` \n easy_install pip \n pip install python-neutronclient \n ```\
          \ \n \n On Ubuntu and Debian \n \n ``` \n sudo apt-get install python-pip\
          \ python-dev build-essential \n sudo pip install --upgrade pip \n pip install\
          \ python-neutronclient \n ``` \n \n On Red Hat Enterprise Linux, CentOS,\
          \ or Fedora \n \n ``` \n yum install python-devel python-pip \n sudo pip\
          \ install --upgrade pip \n pip install python-neutronclient \n ``` \n \n\
          \ On openSUSE: \n \n ``` \n zypper install python-devel python-pip \n sudo\
          \ pip install --upgrade pip \n pip install python-neutronclient \n ``` \n\
          \ \n For Windows: \n \n See pip windows for instructions on installing pip\
          \ for Windows. \n ``` \n pip install python-neutronclient \n ``` \n Configuration\
          \ \n Before you can use the python Neutron client and command line API you\
          \ need to be\nauthenticated to the NeCTAR cloud. The below shows the instructions\
          \ of how to\nget username/password and get authenticated. \n \n Login to\
          \ NeCTAR Cloud Dashboard\n \n Click 'Access & Security' \n On the 'Access\
          \ & Security' page, click tab 'API Access' \n Click button \"Download OpenStack\
          \ RC File\" \n \n \n \n Save the file into a directory \n Click the drop\
          \ down list with your email on the right top of page, then click 'Settings'\
          \ \n Click 'Reset Password' and save the password appeared on the screen\
          \ \n \n \n API normally requires 4 environment variables to be set for authentication:\
          \ \n \n auth URL \n username \n project id or name (most clients can handle\
          \ either) \n password \n \n When using the script file you downloaded from\
          \ NeCTAR Dashboard, these\nvarilabels are set by the script file and you\
          \ can see these variables\nif you open the file. Example: \n \n OS_AUTH_URL:\
          \ https://keystone.rc.nectar.org.au:5000/v2.0/ \n OS_TENANT_NAME=my_science_project\
          \ \n OS_TENANT_ID=sdfsdfsfwrwewer \n OS_USERNAME=clouduser@example.edu.au\
          \ \n OS_PASSWORD=XXXXXX \n \n Authentication for Command Line API \n The\
          \ following instruction assume you use Linux operating system. \n Once you\
          \ have obtained the authentication script and password, you can execute\n\
          the script suing source file-name.sh. and type in the password you\nobtained\
          \ from Dashboard. \n Authentication for python Neutron API \n You can use\
          \ the below sample code to get authenticated.  \n ``` \n from neutronclient.v2_0\
          \ import client \n username='adminUser' \n password='secretword' \n tenant_name='openstackDemo'\
          \ \n auth_url='http://192.168.206.130:5000/v2.0' \n neutron = client.Client(username=username,\
          \ password=password, tenant_name=tenant_name, auth_url=auth_url) \n ```\
          \ \n You can get username, tenant_name and auth_url from the above .sh file\
          \ obtained\nfrom the NeCTAR Dashboard and you can also get the password\
          \ from above as copied\nfrom the NeCTAR Dashboard. \n How to use \n Once\
          \ the client is authenticated, you can start to use them. See below for\
          \ how\nto get started. \n Command Line API \n You can use Neutron command\
          \ to manage your objects storage, you can type: \n neutron --help to find\
          \ out all the available options. \n Python Neutron API \n You can also use\
          \ Python Neutron API in your python code to access object storage. \n See\
          \ below for a sample code: \n ``` \n from neutronclient.v2_0 import client\
          \ \n username='adminUser' \n password='secretword' \n tenant_name='openstackDemo'\
          \ \n auth_url='http://192.168.206.130:5000/v2.0' \n neutron = client.Client(username=username,\
          \ password=password, tenant_name=tenant_name, auth_url=auth_url) \n networks\
          \ = neutron.list_networks() \n ``` \n You can find more information in the\
          \ Networking API section.  "
        description: '<h2>Installation</h2>

          <p>Neutron command line and Python APIs can be installed directly on RDO,
          openSUSE,

          SUSE Linux Enterprise, Debian, and Ubuntu via command line.</p>

          <ul>

          <li>On Red Hat, CentOS or Fedora, use yum to install:</li>

          </ul>

          <p><code>yum install python-neutronclient</code></p>

          <ul>

          <li>On Ubuntu or Debian, use apt-get to install:</li>

          </ul>

          <p><code>sudo apt-get install python-neutronclient</code></p>

          <ul>

          <li>On openSUSE, use zypper to install:</li>

          </ul>

          <p><code>zypper install python-neutronclient</code></p>

          <ul>

          <li>On SUSE inux:</li>

          </ul>

          <p>```</p>

          <p>zypper addrepo -f obs://Cloud:OpenStack:Kilo/SLE_12 Kilo</p>

          <p>zypper install python-neutronclient</p>

          <p>```</p>

          <p>If you want to install sources packages, you can follow the below instructions.</p>

          <ul>

          <li>On MacOS:</li>

          </ul>

          <p>```</p>

          <p>easy_install pip</p>

          <p>pip install python-neutronclient</p>

          <p>```</p>

          <ul>

          <li>On Ubuntu and Debian</li>

          </ul>

          <p>```</p>

          <p>sudo apt-get install python-pip python-dev build-essential</p>

          <p>sudo pip install --upgrade pip</p>

          <p>pip install python-neutronclient</p>

          <p>```</p>

          <ul>

          <li>On Red Hat Enterprise Linux, CentOS, or Fedora</li>

          </ul>

          <p>```</p>

          <p>yum install python-devel python-pip</p>

          <p>sudo pip install --upgrade pip</p>

          <p>pip install python-neutronclient</p>

          <p>```</p>

          <ul>

          <li>On openSUSE:</li>

          </ul>

          <p>```</p>

          <p>zypper install python-devel python-pip</p>

          <p>sudo pip install --upgrade pip</p>

          <p>pip install python-neutronclient</p>

          <p>```</p>

          <ul>

          <li>For Windows:</li>

          </ul>

          <p>See <a href="http://docs.python-guide.org/en/latest/starting/install/win.html#distribute-pip">pip
          windows</a> for instructions on installing pip for Windows.</p>

          <p>```</p>

          <p>pip install python-neutronclient</p>

          <p>```</p>

          <h2>Configuration</h2>

          <p>Before you can use the python Neutron client and command line API you
          need to be

          authenticated to the NeCTAR cloud. The below shows the instructions of how
          to

          get username/password and get authenticated.</p>

          <ol>

          <li>Login to NeCTAR Cloud <a href="https://dashboard.rc.nectar.org.au">Dashboard</a>

          </li>

          <li>Click ''Access &amp; Security''</li>

          <li>On the ''Access &amp; Security'' page, click tab ''API Access''</li>

          <li>Click button "Download OpenStack RC File"</li>

          </ol>

          <p><img alt="network" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Networking--DOCID44/images/network2.png?raw=true"></p>

          <ol>

          <li>Save the file into a directory</li>

          <li>Click the drop down list with your email on the right top of page, then
          click ''Settings''</li>

          <li>Click ''Reset Password'' and save the password appeared on the screen</li>

          </ol>

          <p><img alt="network" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud%20Expert--DOCID19/Networking--DOCID44/images/network3.png?raw=true"></p>

          <p>API normally requires 4 environment variables to be set for authentication:</p>

          <ul>

          <li>auth URL</li>

          <li>username</li>

          <li>project id or name (most clients can handle either)</li>

          <li>password</li>

          </ul>

          <p>When using the script file you downloaded from NeCTAR Dashboard, these

          varilabels are set by the script file and you can see these variables

          if you open the file. Example:</p>

          <blockquote>

          <p>OS_AUTH_URL: https://keystone.rc.nectar.org.au:5000/v2.0/</p>

          <p>OS_TENANT_NAME=my_science_project</p>

          <p>OS_TENANT_ID=sdfsdfsfwrwewer</p>

          <p>OS_USERNAME=clouduser@example.edu.au</p>

          <p>OS_PASSWORD=XXXXXX</p>

          </blockquote>

          <h3>Authentication for Command Line API</h3>

          <p>The following instruction assume you use Linux operating system.</p>

          <p>Once you have obtained the authentication script and password, you can
          execute

          the script suing <code>source file-name.sh</code>. and type in the password
          you

          obtained from Dashboard.</p>

          <h3>Authentication for python Neutron API</h3>

          <p>You can use the below sample code to get authenticated. </p>

          <p>```</p>

          <p>from neutronclient.v2_0 import client</p>

          <p>username=''adminUser''</p>

          <p>password=''secretword''</p>

          <p>tenant_name=''openstackDemo''</p>

          <p>auth_url=''http://192.168.206.130:5000/v2.0''</p>

          <p>neutron = client.Client(username=username, password=password, tenant_name=tenant_name,
          auth_url=auth_url)</p>

          <p>```</p>

          <p>You can get username, tenant_name and auth_url from the above .sh file
          obtained

          from the NeCTAR Dashboard and you can also get the password from above as
          copied

          from the NeCTAR Dashboard.</p>

          <h2>How to use</h2>

          <p>Once the client is authenticated, you can start to use them. See below
          for how

          to get started.</p>

          <h3>Command Line API</h3>

          <p>You can use Neutron command to manage your objects storage, you can type:</p>

          <p><code>neutron --help</code> to find out all the available options.</p>

          <h3>Python Neutron API</h3>

          <p>You can also use Python Neutron API in your python code to access object
          storage.</p>

          <p>See below for a sample code:</p>

          <p>```</p>

          <p>from neutronclient.v2_0 import client</p>

          <p>username=''adminUser''</p>

          <p>password=''secretword''</p>

          <p>tenant_name=''openstackDemo''</p>

          <p>auth_url=''http://192.168.206.130:5000/v2.0''</p>

          <p>neutron = client.Client(username=username, password=password, tenant_name=tenant_name,
          auth_url=auth_url)</p>

          <p>networks = neutron.list_networks()</p>

          <p>```</p>

          <p>You can find more information in the Networking API section. </p>'
        folder:
          category_id: 6000122279
          created_at: '2015-12-01T18:22:33-05:00'
          customer_folders: []
          description: Networking
          id: 6000210730
          is_default: false
          language_id: 6
          name: Networking
          parent_id: 6000210730
          position: 8
          updated_at: '2015-12-01T18:22:33-05:00'
          visibility: 1
        folder_id: 6000210730
        hits: 2
        id: 6000094839
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-06T23:54:33-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000094839
        position: 2
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Getting Started
        updated_at: '2015-12-06T23:54:33-05:00'
        user_id: 6002464727
  html: '<h2>Installation</h2>

    <p>Neutron command line and Python APIs can be installed directly on RDO, openSUSE,

    SUSE Linux Enterprise, Debian, and Ubuntu via command line.</p>

    <ul>

    <li>On Red Hat, CentOS or Fedora, use yum to install:</li>

    </ul>

    <p><code>yum install python-neutronclient</code></p>

    <ul>

    <li>On Ubuntu or Debian, use apt-get to install:</li>

    </ul>

    <p><code>sudo apt-get install python-neutronclient</code></p>

    <ul>

    <li>On openSUSE, use zypper to install:</li>

    </ul>

    <p><code>zypper install python-neutronclient</code></p>

    <ul>

    <li>On SUSE inux:</li>

    </ul>

    <p>```</p>

    <p>zypper addrepo -f obs://Cloud:OpenStack:Kilo/SLE_12 Kilo</p>

    <p>zypper install python-neutronclient</p>

    <p>```</p>

    <p>If you want to install sources packages, you can follow the below instructions.</p>

    <ul>

    <li>On MacOS:</li>

    </ul>

    <p>```</p>

    <p>easy_install pip</p>

    <p>pip install python-neutronclient</p>

    <p>```</p>

    <ul>

    <li>On Ubuntu and Debian</li>

    </ul>

    <p>```</p>

    <p>sudo apt-get install python-pip python-dev build-essential</p>

    <p>sudo pip install --upgrade pip</p>

    <p>pip install python-neutronclient</p>

    <p>```</p>

    <ul>

    <li>On Red Hat Enterprise Linux, CentOS, or Fedora</li>

    </ul>

    <p>```</p>

    <p>yum install python-devel python-pip</p>

    <p>sudo pip install --upgrade pip</p>

    <p>pip install python-neutronclient</p>

    <p>```</p>

    <ul>

    <li>On openSUSE:</li>

    </ul>

    <p>```</p>

    <p>zypper install python-devel python-pip</p>

    <p>sudo pip install --upgrade pip</p>

    <p>pip install python-neutronclient</p>

    <p>```</p>

    <ul>

    <li>For Windows:</li>

    </ul>

    <p>See <a href="http://docs.python-guide.org/en/latest/starting/install/win.html#distribute-pip">pip
    windows</a> for instructions on installing pip for Windows.</p>

    <p>```</p>

    <p>pip install python-neutronclient</p>

    <p>```</p>

    <h2>Configuration</h2>

    <p>Before you can use the python Neutron client and command line API you need
    to be

    authenticated to the NeCTAR cloud. The below shows the instructions of how to

    get username/password and get authenticated.</p>

    <ol>

    <li>Login to NeCTAR Cloud <a href="https://dashboard.rc.nectar.org.au">Dashboard</a></li>

    <li>Click ''Access &amp; Security''</li>

    <li>On the ''Access &amp; Security'' page, click tab ''API Access''</li>

    <li>Click button "Download OpenStack RC File"</li>

    </ol>

    <p><img alt="network" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud
    Expert--DOCID19/Networking--DOCID44/images/network2.png?raw=true"></p>

    <ol>

    <li>Save the file into a directory</li>

    <li>Click the drop down list with your email on the right top of page, then click
    ''Settings''</li>

    <li>Click ''Reset Password'' and save the password appeared on the screen</li>

    </ol>

    <p><img alt="network" src="https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/Cloud
    Expert--DOCID19/Networking--DOCID44/images/network3.png?raw=true"></p>

    <p>API normally requires 4 environment variables to be set for authentication:</p>

    <ul>

    <li>auth URL</li>

    <li>username</li>

    <li>project id or name (most clients can handle either)</li>

    <li>password</li>

    </ul>

    <p>When using the script file you downloaded from NeCTAR Dashboard, these

    varilabels are set by the script file and you can see these variables

    if you open the file. Example:</p>

    <blockquote>

    <p>OS_AUTH_URL: https://keystone.rc.nectar.org.au:5000/v2.0/</p>

    <p>OS_TENANT_NAME=my_science_project</p>

    <p>OS_TENANT_ID=sdfsdfsfwrwewer</p>

    <p>OS_USERNAME=clouduser@example.edu.au</p>

    <p>OS_PASSWORD=XXXXXX</p>

    </blockquote>

    <h3>Authentication for Command Line API</h3>

    <p>The following instruction assume you use Linux operating system.</p>

    <p>Once you have obtained the authentication script and password, you can execute

    the script suing <code>source file-name.sh</code>. and type in the password you

    obtained from Dashboard.</p>

    <h3>Authentication for python Neutron API</h3>

    <p>You can use the below sample code to get authenticated. </p>

    <p>```</p>

    <p>from neutronclient.v2_0 import client</p>

    <p>username=''adminUser''</p>

    <p>password=''secretword''</p>

    <p>tenant_name=''openstackDemo''</p>

    <p>auth_url=''http://192.168.206.130:5000/v2.0''</p>

    <p>neutron = client.Client(username=username, password=password, tenant_name=tenant_name,
    auth_url=auth_url)</p>

    <p>```</p>

    <p>You can get username, tenant_name and auth_url from the above .sh file obtained

    from the NeCTAR Dashboard and you can also get the password from above as copied

    from the NeCTAR Dashboard.</p>

    <h2>How to use</h2>

    <p>Once the client is authenticated, you can start to use them. See below for
    how

    to get started.</p>

    <h3>Command Line API</h3>

    <p>You can use Neutron command to manage your objects storage, you can type:</p>

    <p><code>neutron --help</code> to find out all the available options.</p>

    <h3>Python Neutron API</h3>

    <p>You can also use Python Neutron API in your python code to access object storage.</p>

    <p>See below for a sample code:</p>

    <p>```</p>

    <p>from neutronclient.v2_0 import client</p>

    <p>username=''adminUser''</p>

    <p>password=''secretword''</p>

    <p>tenant_name=''openstackDemo''</p>

    <p>auth_url=''http://192.168.206.130:5000/v2.0''</p>

    <p>neutron = client.Client(username=username, password=password, tenant_name=tenant_name,
    auth_url=auth_url)</p>

    <p>networks = neutron.list_networks()</p>

    <p>```</p>

    <p>You can find more information in the Networking API section. </p>'
  parent: 44
  sha1: 7d4091507e81e37b92d790232484619e35754299
  title: Getting Started
103:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-12-07T19:41:23-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Neutron Command Line API \n The Neutron client is the command-line\
          \ interface (CLI) for the OpenStack Network\nAPI and its extensions. \n\
          \ It is same as nova client and any other OpenStack APIs, you need to authenticate\n\
          before you can use it. Please refer the Networking Getting Started\narticle\
          \ to see how to get authenticated. \n Please also refer to Networking Getting\
          \ Started for\nhow to install the Neutron client. \n The below shows some\
          \ Neutron commands: \n\n\n\nShell Command\nAction\n\n\n\n\nneutron net-list\n\
          list all networks that belong to a given tenant\n\n\nneutron security-group-list\n\
          list all security groups\n\n\nneutron security-group-create\ncreate a security\
          \ group\n\n\nneutron subnet-list\nlist all subnet that belong to a given\
          \ tenant\n\n\nneutron subnet-delete\ndelete a subnet\n\n\nneutron subnet\
          \ show\nshow information of a given subnet\n\n\n\n The below shows an example\
          \ about how to create a subnet: \n neutron subnet-create   \n  positional\
          \ arguments: \n \n \n network name: network id or name this subnet belongs\
          \ to, example: my-network \n \n \n CIDR: CIDR of subnet to create, example:\
          \ 192.168.1.0/24 \n \n \n Optional arguments: \n \n \n name: name of the\
          \ subnet, example: my-subnet \n \n \n ip-version (4,6): IP version with\
          \ default 4. \n \n \n gateway: gateway IP of this subnet, example: 192.168.1.1\
          \ \n \n \n no-gateway: no distribution of gateway \n \n \n dns-nameserver:\
          \ DNS name server for this subnet (This option can be repeated),\n example:\
          \ 192.168.0.1 \n \n \n disable-dhcp: Disable DHCP for this subnet \n \n\
          \ \n To create a subnet: \n neutron subnet-create my-network 192.168.1.0/24\
          \ --gateway 192.168.1.1 \n You can execute neutron help to see what commands\
          \ are available and\nrun neutron help <command> find out more information\
          \ about a command. \n Neutron Python Client \n You can also use Neutron\
          \ python API to access and manage the networking. \n Sample Python code:\
          \ \n ``` \n from neutronclient.v2_0 import client \n username='adminUser'\
          \ \n password='secretword' \n tenant_name='openstackDemo' \n auth_url='http://192.168.206.130:5000/v2.0'\
          \ \n neutron = client.Client(username=username, password=password, tenant_name=tenant_name,\
          \ auth_url=auth_url) \n nets = neutron.list_networks() \n sub_nets = neutron.list_subnets()\
          \ \n ``` \n The above authurl, user, password and tenant_name are only for\
          \ demonstration purpose.\nPlease refer to instruction for how to obtain\
          \ authurl,\nuser, password and tenant_name. \n Some commands are listed\
          \ as below: \n\n\n\nPython Command\nAction\n\n\n\n\nlist_networks()\nlist\
          \ all networks\n\n\nlist_subnets()\nlist all sub networks\n\n\nlist_ports()\n\
          list all ports\n\n\ncreate_subnet()\ncreate a new subnet\n\n\ncreate_network()\n\
          upload data to the container\n\n\nupdate_network()\nupdate an exisitng network\n\
          \n\n\n Please refer to the Neutron python client document for more\ninformation.\
          \ You can also read the source file in /usr/lib/python2.7/dist-packages/neutronclient/v2_0/client.py\
          \ (for Ubuntu) to get the completed list of what methods you can call. "
        description: "<h2>Neutron Command Line API</h2>\n<p>The Neutron client is\
          \ the command-line interface (CLI) for the OpenStack Network\nAPI and its\
          \ extensions.</p>\n<p>It is same as nova client and any other OpenStack\
          \ APIs, you need to authenticate\nbefore you can use it. Please refer the\
          \ <a href=\"https://support.nectar.org.au/support/solutions/articles/6000094839-getting-started\"\
          >Networking Getting Started</a>\narticle to see how to get authenticated.</p>\n\
          <p>Please also refer to <a href=\"https://support.nectar.org.au/support/solutions/articles/6000094839-getting-started\"\
          >Networking Getting Started</a> for\nhow to install the Neutron client.</p>\n\
          <p>The below shows some Neutron commands:</p>\n<table>\n<thead>\n<tr>\n\
          <th>Shell Command</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
          <td><code>neutron net-list</code></td>\n<td>list all networks that belong\
          \ to a given tenant</td>\n</tr>\n<tr>\n<td><code>neutron security-group-list</code></td>\n\
          <td>list all security groups</td>\n</tr>\n<tr>\n<td><code>neutron security-group-create</code></td>\n\
          <td>create a security group</td>\n</tr>\n<tr>\n<td><code>neutron subnet-list</code></td>\n\
          <td>list all subnet that belong to a given tenant</td>\n</tr>\n<tr>\n<td><code>neutron\
          \ subnet-delete</code></td>\n<td>delete a subnet</td>\n</tr>\n<tr>\n<td><code>neutron\
          \ subnet show</code></td>\n<td>show information of a given subnet</td>\n\
          </tr>\n</tbody>\n</table>\n<p>The below shows an example about how to create\
          \ a subnet:</p>\n<p>neutron subnet-create  </p>\n<p><strong> positional\
          \ arguments</strong>:</p>\n<ul>\n<li>\n<p>network name: network id or name\
          \ this subnet belongs to, example: my-network</p>\n</li>\n<li>\n<p>CIDR:\
          \ CIDR of subnet to create, example: 192.168.1.0/24</p>\n</li>\n</ul>\n\
          <p><strong>Optional arguments</strong>:</p>\n<ul>\n<li>\n<p>name: name of\
          \ the subnet, example: my-subnet</p>\n</li>\n<li>\n<p>ip-version (4,6):\
          \ IP version with default 4.</p>\n</li>\n<li>\n<p>gateway: gateway IP of\
          \ this subnet, example: 192.168.1.1</p>\n</li>\n<li>\n<p>no-gateway: no\
          \ distribution of gateway</p>\n</li>\n<li>\n<p>dns-nameserver: DNS name\
          \ server for this subnet (This option can be repeated),\n example: 192.168.0.1</p>\n\
          </li>\n<li>\n<p>disable-dhcp: Disable DHCP for this subnet</p>\n</li>\n\
          </ul>\n<p>To create a subnet:</p>\n<p><code>neutron subnet-create my-network\
          \ 192.168.1.0/24 --gateway 192.168.1.1</code></p>\n<p>You can execute <code>neutron\
          \ help</code> to see what commands are available and\nrun <code>neutron\
          \ help &lt;command&gt;</code> find out more information about a command.</p>\n\
          <h2>Neutron Python Client</h2>\n<p>You can also use Neutron python API to\
          \ access and manage the networking.</p>\n<p>Sample Python code:</p>\n<p>```</p>\n\
          <p>from neutronclient.v2_0 import client</p>\n<p>username='adminUser'</p>\n\
          <p>password='secretword'</p>\n<p>tenant_name='openstackDemo'</p>\n<p>auth_url='http://192.168.206.130:5000/v2.0'</p>\n\
          <p>neutron = client.Client(username=username, password=password, tenant_name=tenant_name,\
          \ auth_url=auth_url)</p>\n<p>nets = neutron.list_networks()</p>\n<p>sub_nets\
          \ = neutron.list_subnets()</p>\n<p>```</p>\n<p>The above authurl, user,\
          \ password and tenant_name are only for demonstration purpose.\nPlease refer\
          \ to <a href=\"https://support.nectar.org.au/support/solutions/articles/6000094839-getting-started\"\
          >instruction</a> for how to obtain authurl,\nuser, password and tenant_name.</p>\n\
          <p>Some commands are listed as below:</p>\n<table>\n<thead>\n<tr>\n<th>Python\
          \ Command</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>list_networks()</code></td>\n\
          <td>list all networks</td>\n</tr>\n<tr>\n<td><code>list_subnets()</code></td>\n\
          <td>list all sub networks</td>\n</tr>\n<tr>\n<td><code>list_ports()</code></td>\n\
          <td>list all ports</td>\n</tr>\n<tr>\n<td><code>create_subnet()</code></td>\n\
          <td>create a new subnet</td>\n</tr>\n<tr>\n<td><code>create_network()</code></td>\n\
          <td>upload data to the container</td>\n</tr>\n<tr>\n<td><code>update_network()</code></td>\n\
          <td>update an exisitng network</td>\n</tr>\n</tbody>\n</table>\n<p>Please\
          \ refer to the <a href=\"http://docs.openstack.org/developer/python-neutronclient/\"\
          >Neutron python client document</a> for more\ninformation. You can also\
          \ read the source file in /usr/lib/python2.7/dist-packages/neutronclient/v2_0/client.py\
          \ (for Ubuntu) to get the completed list of what methods you can call.</p>"
        folder:
          category_id: 6000122279
          created_at: '2015-12-01T18:22:33-05:00'
          customer_folders: []
          description: Networking
          id: 6000210730
          is_default: false
          language_id: 6
          name: Networking
          parent_id: 6000210730
          position: 8
          updated_at: '2015-12-01T18:22:33-05:00'
          visibility: 1
        folder_id: 6000210730
        hits: 0
        id: 6000095293
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-07T19:41:23-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000095293
        position: 3
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: API
        updated_at: '2015-12-07T19:41:23-05:00'
        user_id: 6002464727
  html: "<h2>Neutron Command Line API</h2>\n<p>The Neutron client is the command-line\
    \ interface (CLI) for the OpenStack Network\nAPI and its extensions.</p>\n<p>It\
    \ is same as nova client and any other OpenStack APIs, you need to authenticate\n\
    before you can use it. Please refer the <a href=\"https://support.nectar.org.au/support/solutions/articles/6000094839-getting-started\"\
    >Networking Getting Started</a>\narticle to see how to get authenticated.</p>\n\
    <p>Please also refer to <a href=\"https://support.nectar.org.au/support/solutions/articles/6000094839-getting-started\"\
    >Networking Getting Started</a> for\nhow to install the Neutron client.</p>\n\
    <p>The below shows some Neutron commands:</p>\n<table>\n<thead>\n<tr>\n<th>Shell\
    \ Command</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>neutron\
    \ net-list</code></td>\n<td>list all networks that belong to a given tenant</td>\n\
    </tr>\n<tr>\n<td><code>neutron security-group-list</code></td>\n<td>list all security\
    \ groups</td>\n</tr>\n<tr>\n<td><code>neutron security-group-create</code></td>\n\
    <td>create a security group</td>\n</tr>\n<tr>\n<td><code>neutron subnet-list</code></td>\n\
    <td>list all subnet that belong to a given tenant</td>\n</tr>\n<tr>\n<td><code>neutron\
    \ subnet-delete</code></td>\n<td>delete a subnet</td>\n</tr>\n<tr>\n<td><code>neutron\
    \ subnet show</code></td>\n<td>show information of a given subnet</td>\n</tr>\n\
    </tbody>\n</table>\n<p>The below shows an example about how to create a subnet:</p>\n\
    <p>neutron subnet-create <network name> <CIDR></p>\n<p><strong> positional arguments</strong>:</p>\n\
    <ul>\n<li>\n<p>network name: network id or name this subnet belongs to, example:\
    \ my-network</p>\n</li>\n<li>\n<p>CIDR: CIDR of subnet to create, example: 192.168.1.0/24</p>\n\
    </li>\n</ul>\n<p><strong>Optional arguments</strong>:</p>\n<ul>\n<li>\n<p>name:\
    \ name of the subnet, example: my-subnet</p>\n</li>\n<li>\n<p>ip-version (4,6):\
    \ IP version with default 4.</p>\n</li>\n<li>\n<p>gateway: gateway IP of this\
    \ subnet, example: 192.168.1.1</p>\n</li>\n<li>\n<p>no-gateway: no distribution\
    \ of gateway</p>\n</li>\n<li>\n<p>dns-nameserver: DNS name server for this subnet\
    \ (This option can be repeated),\n example: 192.168.0.1</p>\n</li>\n<li>\n<p>disable-dhcp:\
    \ Disable DHCP for this subnet</p>\n</li>\n</ul>\n<p>To create a subnet:</p>\n\
    <p><code>neutron subnet-create my-network 192.168.1.0/24 --gateway 192.168.1.1</code></p>\n\
    <p>You can execute <code>neutron help</code> to see what commands are available\
    \ and\nrun <code>neutron help &lt;command&gt;</code> find out more information\
    \ about a command.</p>\n<h2>Neutron Python Client</h2>\n<p>You can also use Neutron\
    \ python API to access and manage the networking.</p>\n<p>Sample Python code:</p>\n\
    <p>```</p>\n<p>from neutronclient.v2_0 import client</p>\n<p>username='adminUser'</p>\n\
    <p>password='secretword'</p>\n<p>tenant_name='openstackDemo'</p>\n<p>auth_url='http://192.168.206.130:5000/v2.0'</p>\n\
    <p>neutron = client.Client(username=username, password=password, tenant_name=tenant_name,\
    \ auth_url=auth_url)</p>\n<p>nets = neutron.list_networks()</p>\n<p>sub_nets =\
    \ neutron.list_subnets()</p>\n<p>```</p>\n<p>The above authurl, user, password\
    \ and tenant_name are only for demonstration purpose.\nPlease refer to <a href=\"\
    https://support.nectar.org.au/support/solutions/articles/6000094839-getting-started\"\
    >instruction</a> for how to obtain authurl,\nuser, password and tenant_name.</p>\n\
    <p>Some commands are listed as below:</p>\n<table>\n<thead>\n<tr>\n<th>Python\
    \ Command</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>list_networks()</code></td>\n\
    <td>list all networks</td>\n</tr>\n<tr>\n<td><code>list_subnets()</code></td>\n\
    <td>list all sub networks</td>\n</tr>\n<tr>\n<td><code>list_ports()</code></td>\n\
    <td>list all ports</td>\n</tr>\n<tr>\n<td><code>create_subnet()</code></td>\n\
    <td>create a new subnet</td>\n</tr>\n<tr>\n<td><code>create_network()</code></td>\n\
    <td>upload data to the container</td>\n</tr>\n<tr>\n<td><code>update_network()</code></td>\n\
    <td>update an exisitng network</td>\n</tr>\n</tbody>\n</table>\n<p>Please refer\
    \ to the <a href=\"http://docs.openstack.org/developer/python-neutronclient/\"\
    >Neutron python client document</a> for more\ninformation. You can also read the\
    \ source file in /usr/lib/python2.7/dist-packages/neutronclient/v2_0/client.py\
    \ (for Ubuntu) to get the completed list of what methods you can call.</p>"
  parent: 44
  sha1: 558d3322391589a032322e1e93e1ea66964cb9b4
  title: API
104:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-12-07T20:00:50-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Nimrod toolkit for high throughput computing in the cloud\
          \ \n Introduction \n The Nimrod tool family facilitates high-throughput\
          \ science by allowing\nresearchers to use computational models to explore\
          \ complex design\nspaces. Models can be executed across changing input parameters.\n\
          Different members of the tool family support complete and partial\nparameter\
          \ sweeps, numerical search by non-linear optimisation, and even\nworkflows.\
          \ Further, Nimrod allows computational researchers to use a\nmixture of\
          \ university-level infrastructure and commercial clouds. \n There are several\
          \ \u2018flavours\u2019 of Nimrod. Which Nimrod you choose to use,\neither\
          \ singly, or in combination, will depend on the kind of experiment\nyou\
          \ want to run. \n Nimrod/G \n Nimrod/G can directly execute large-scale\
          \ distributed parameter sweep\nand Monte-Carlo computational experiments.\
          \ It provides a simple means to\ndramatically scale-up your computational\
          \ experiments. Each experiment\ncan run over an aggregated ad-hoc computational\
          \ grid/pool/cloud; start\nfrom your desktop, local server or cluster; add\
          \ grid resources (e.g.\nclusters and Condor pools); overflow to pay-as-go\
          \ cloud services and\ncontrol your budget with Nimrod/G's economic scheduling\
          \ capabilities. \n Nimrod/K \n Nimrod/K is built on Kepler using Kepler\u2019\
          s runtime engine Ptolemy. It\nextends Kepler by adding parameter tools and\
          \ grid/cloud services and by\nproviding dynamic parallelism in workflows.\
          \ \n It uses a dataflow execution model that was originally developed for\n\
          highly parallel dataflow computers in the 1980\u2019s, and this provides\
          \ an\nextremely rich execution mechanism. It leverages a number of the\n\
          techniques developed in the earlier Nimrod tools for distributing tasks\n\
          to the Grid. \n Nimrod/O \n Provides an optimisation framework for optimising\
          \ a target output value\nof an application. It allows a user to run an arbitrary\
          \ computational\nmodel as the core of a non-linear optimization process.\
          \ Nimrod/O allows\na user to specify the domain and type of parameters to\
          \ the model, and\nalso a specification of which output variable is to be\
          \ minimized or\nmaximized. Accordingly, a user can formulate a question\
          \ like: what\nparameter settings will minimize the model output? Nimrod/O\
          \ currently\nemploys a number of built-in optimization algorithms: \n \n\
          \ \n BFGS \n \n \n Simplex \n \n \n Divide and Conquer \n \n \n Simulated\
          \ Annealing. \n \n \n Jobs can be executed on a variety of platforms, which\
          \ when combined with\nNimrod/G includes distributed clusters and Computational\
          \ Grid resources. \n Target Audience \n The following research activities\
          \ can benefit from using Nimrod. \n \n \n You need to run your computational\
          \ model many times and average the\n    results because the model is stochastic.\
          \ These types of Monte Carlo\n    simulations are greatly facilitated by\
          \ Nimrod/G. It will generate\n    multiple jobs, furnishing them with different\
          \ random number seeds\n    and execute them concurrently on the grid. \n\
          \ \n \n You wish to explore the effect of varying the inputs to your model.\n\
          \    Inputs may be in the form of command line parameters or of values in\n\
          \    some input file; in Nimrod these are both called parameters. Either\n\
          \    way Nimrod/G will let you specify values for each parameter, will\n\
          \    generate the jobs for all possible combinations of these values and\n\
          \    execute the jobs on the Grid. \n \n \n You wish to explore the effect\
          \ of input parameters but for certain\n    combinations are not allowed.\
          \ There are several possible ways to\n    do this. If the disallowed combinations\
          \ give jobs that quickly fail\n    then you may schedule all possible combinations\
          \ and let those bad\n    jobs fail. However, if those jobs will use substantial\
          \ resources\n    then it would be better to filter them out first. This\
          \ can be done\n    in Nimrod/G by processing the run file. Alternatively\
          \ Nimrod/O may\n    be used in sweep mode as it provides the functionality\
          \ to add\n    formulas for constraints on the parameters. \n \n \n You are\
          \ running several different experiments. They may produce some\n    jobs\
          \ with the same inputs and you don't want to waste resources\n    duplicating\
          \ these jobs. Nimrod/O can be invoked with a persistent\n    cache shared\
          \ by the experiments, so avoiding duplications. \n \n \n You wish to find\
          \ the combination of input parameters that produce an\n    optimal output.\
          \ Nimrod/O allows you to specify the inputs that vary,\n    any constraints\
          \ on those inputs, and the output to be maximized\n    or minimized. It\
          \ offers a selection of search methods for finding\n    the optimum. Multiple\
          \ searches, perhaps using different optimization\n    methods, may be run\
          \ in parallel. \n \n \n You want to find the inputs that generate the best\
          \ output. Nimrod/O\n    allows optimization where human input may be used\
          \ to assess the\n    quality of an output. This is especially useful for\
          \ complex outputs\n    such as images or animations. \n \n \n There are\
          \ several aspects of your model output that you wish\n    to optimize. Nimrod/O\
          \ is currently being modified to facilitate such\n    multi-objective optimization.\
          \ \n \n \n You wish to perform multiple optimizations on the output of your\n\
          \    model, one optimization for each combination of some\n    parameter\
          \ settings. This can be done using Nimrod/G to sweep over\n    the setting\
          \ and having it call Nimrod/O to do each optimization. \n \n \n You wish\
          \ to run your model in reverse. In other words you want to\n    find the\
          \ input values that will produce a given output. Nimrod/O is\n    commonly\
          \ used for this task. You need to have a way of measuring the\n    discrepancy\
          \ between your output and the desired one. Then run an\n    optimization\
          \ to minimize this discrepancy. \n \n \n You have developed your own optimization\
          \ method. You wish to use the\n    method, taking advantage of the distributed\
          \ execution of jobs and\n    the caching supplied in Nimrod/O. \n \n \n\
          \ Different parts of your model need to run on different machines\n    because\
          \ of data files perhaps or licence requirements. Nimrod/G can\n    schedule\
          \ such workflow experiments and perform the appropriate\n    communication\
          \ between the parts. Where possible a downstream\n    component may start\
          \ processing its input file before an upstream\n    component has completed\
          \ that file. \n \n \n Some of your model executions require prior execution\
          \ of\n    other models. Nimrod/G can handle such dependencies. \n \n \n\
          \ How to install \n Nimrod allows computational researchers to use a mixture\
          \ of\nuniversity-level infrastructure and commercial clouds. \n Users can\
          \ trial their Nimrod experiments using the Nimrod Portal\nresource pool.\
          \ Users are encouraged to bring their own compute resources\n(e.g. cluster,\
          \ cloud allocation) to use with Nimrod. Please contact Minh\nDinh and Hoang\
          \ Anh Nguyen regarding adding new remote compute resources\nto their experiments.\
          \ \n Users can still opt to install Nimrod Toolkit on their local system,\n\
          provided that system meets the software and operating system\nrequirements\
          \ outlined in the Resource Requirements section. If the user\nchooses to\
          \ do that, here are step by step procedures for installing\nindividual Nimrod\
          \ Toolkit. \n Installing Nimrod/G \n Users must executed the following steps\
          \ to install Nimrod/G: \n \n \n Download Nimrod/G source distribution \n\
          \ \n \n Setup Nimrod/G environment \n \n \n Create experiments directory\
          \ \n \n \n Install Nimrod/G \n \n \n Setup Nimrod/G database \n \n \n Download\
          \ Nimrod/G Distribution \n Download from following link: \n \n https://messagelab.monash.edu.au/Downloads\
          \ \n \n Download the Nimrod/G source archive to your home directory, which\n\
          should create a file: \n \n $HOME/nimrodg-[version].tar.gz \n \n Setup Nimrod/G\
          \ Environment \n We recommend editing your shell\_rc\_scripts\n(.profile\_\
          or\_.bashrc\_or\_.cshrc, etc), or adding\nan\_/etc/profile.d/nimrod.sh\_\
          script for system-wide installs.\nFor\_sh\_based shells you will need something\
          \ like (paths should be\naltered as appropriate for your install/system):\
          \ \n \n export NIMROD_INSTALL=$HOME/bin/nimrodg export\nNIMROD_DATABASE=pgsql-pool\
          \ \n export PSQL_LOCATION=/usr/bin # in this case /usr/bin/psql should be\n\
          a valid path \n export PYTHONPATH=${NIMROD_INSTALL}/share/nimrod:${PYTHONPATH}\\\
          \nexport PATH=${NIMROD_INSTALL}/bin:${PATH} \n \n Create Experiments Directory\
          \ \n Nimrod/G keeps all the experiments it runs in a subdirectory of user's\n\
          home directory\_$HOME/.nimrod/experiments. Create that directory by\nexecuting\
          \ the following command: \n \n $ mkdir -p $HOME/.nimrod/experiments \n \n\
          \ Install Nimrod/G \n \n Decompress Nimrod/G source archive. Let\u2019s\
          \ assume we downloaded a\n    source archive for Nimrod/G version 4.0.2:\
          \ \n \n \n $ cd $HOME \n $ tar -zxvf nimrodg-4.0.2.tar.gz \n \n \n Configure\
          \ and install Nimrod/G \n \n \n $ cd nimrodg-4.0.2 \n $ ./configure --prefix=$NIMROD_INSTALL\
          \ \n $ make; make install \n \n Setup Nimrod/G Database \n Nimrod/G runs\
          \ on top of PostgreSQL relational database. Before anything\ncan be done,\
          \ user must create a database which will be used by Nimrod/G.\nEach Nimrod/G\
          \ user requires their own PostgreSQL database. \n \n As a PostgreSQL admin\
          \ user create a PostgreSQL user. Must ensure\n    > that the user can create\
          \ databases (prompted during the process): \n \n \n $ createuser <username>\
          \ \n \n \n As the user, create a database \n \n \n $ createdb \n \n \n As\
          \ the user, populate that database with Nimrod/G database schema \n \n \n\
          \ $ nimrod dbcreate \n \n Platform and Version Specific Notes \n \n Python\
          \ 2.6 \n \n \n To configure the Nimrod build files against Python2.6 (confirmed\
          \ on\nUbuntu 10.04) it seems to be necessary to set LDFLAGS=-lm. \n \n \n\
          \ Ubuntu 10.04 \n \n \n To configure the Nimrod build files against the\
          \ included Python2.6 on\nUbuntu 10.04 it seems to be necessary to set LDFLAGS=-lm.\
          \ \n \n \n RHEL6 \n \n \n Using the OS default Python (2.6) to install Nimrod\
          \ may result in the\nmake install step failing to install 3rd party modules\
          \ that are\npackaged with Nimrod, with an error message like: \n You are\
          \ attempting to install a package to a directory that is not on\nPYTHONPATH\
          \ and which Python does not read \".pth\" files from. \n This can be remedied\
          \ by ensuring $NIMROD_INSTALL/share/nimrod is in\nyour $PYTHONPATH environment\
          \ variable. \n \n Installing Nimrod/K \n Users must executed the following\
          \ steps to install Nimrod/K: \n \n \n Download Nimrod/K distribution \n\
          \ \n \n Install Nimrod/K \n \n \n Download Nimrod/K Distribution \n This\
          \ can be done by following Nimrod/K link at: \n \n https://messagelab.monash.edu.au/Downloads\
          \ \n \n Download the Nimrod/K distribution to your home directory which\
          \ should\ncreate a file: \n \n $HOME/nimrodk-[version].jar \n \n Steps to\
          \ install Nimrod/K \n For the purposes of this installation guide, we will\
          \ assume that the\nversion we are working on is 2.0.0. Nimrod/K major version\
          \ number will\nalways follow Kepler's major version number so version 2.0.0\
          \ means that\nthis version of Nimrod/K will work with latest version of\
          \ Kepler with\nmajor version number \n Nimrod/K jar file has following install\
          \ options: \n \n options: \n --help|-h -- print this message \n --acceptlicense|-a\
          \ -- accept Nimrod/K license without prompting. If\nomitted user will be\
          \ \n given a choice (declining will stop the installation). \n --prefix=<path>\
          \ -- set a location of where all Nimrod/K modules\nare installed (eg. \u2013\
          \ \n prefix=/usr/local/kepler/2.4/lib). If omitted it will prompt for \n\
          \ the prefix \n --keplerversion=<major version number> -- set a kepler version\n\
          (eg. --keplerversion=2.4). \n If ommitted installer will look for it in\
          \ the following files and \n in the order they are listed here: \n a) <prefix>/build-area/install-id.txt\
          \ \n b) $KEPLER/build-area/install-id.txt \n --version|-v -- prints the\
          \ Nimrod/K version \n \n Using the above options install Nimrod/K: \n \n\
          \ java -jar nimrodk-2.0.0.jar [options] \n \n Installing Nimrod/O \n A comprehensive\
          \ manual for Nimrod/O can be downloaded from: \n http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&upname=NimrodOUsersGuide3.1.pdf.\
          \ \n It contains information on how to install Nimrod/O. \n How to launch\
          \ \n Running Nimrod/G \n In order to run Nimrod/G experiments from command\
          \ line user needs to do\nthe following: \n \n \n Manage Resources \n \n\
          \ \n Manage Experiments \n \n \n Once these are done, experiments can be\
          \ executed on selected resources. \n Resource Management \n Adding Resources\
          \ \n Nimrod resources need to be first added to the database before they\
          \ can\nbe assigned to and used by experiments. Syntax for adding resources\
          \ is\nas follows: \n \n $ nimrod resource add <resource_type>\n<resource_details>\
          \ \n \n Resource types supported by Nimrod/G include: \n \n Fork \n \n \n\
          \ $ nimrod resource add fork \n \n \n \nPBS\_- With PBS we need to know\
          \ the name of a PBS queue and the\n    > hostname of the PBS server. Lets\
          \ say queue name is\_workq\_and\n    > the hostname is\_localhost\n \n \n\
          \ \n $ nimrod resource add pbs workq@localhost \n \n \n \n SGE\_- Same as\
          \ PBS \n \n \n EC2 \n \n \n Removing Resources \n Syntax for removing resources\
          \ is as follows: \n \n $ nimrod resource remove <resource_type>\n<resource_details>\
          \ \n \n Experiment Management \n This section will describe how to create,\
          \ monitor and manage Nimrod/G\nexperiments. \n Creating a Plan File \n Nimrod/G\
          \ uses a simple declarative language to describe the experiments.\nThis\
          \ description is usually written as a simple script file we call\na\_plan\
          \ file. \n There are two sections in this plan file. The first one describes\
          \ the\nparameters that your experiment has while the second one describes\
          \ the\ntask/s that Nimrod/G needs to execute to complete a single instance\
          \ (or\na job) from your experiment. The example below shows a fictional\
          \ plan\nfile for an experiment investigating wing performance. \n \n parameter\
          \ aircraft_model files select anyof \"A3??.dat\" \"737-*.dat\"; \n parameter\
          \ AoA label \"Angle of attack\" float range from -45 to 45 step\n2.5; \n\
          \ parameter winglets text select anyof \"none\" \"fence\" \"blended\" \"\
          raked\"; \n parameter airspeed integer range from 50 to 600 step 50; \n\
          \ parameter turbulence label \"Normalized Reynolds\" float random from 1\n\
          to 2; \n task main \n copy ${aircraft_model} node:. \n copy wing_test.zip\
          \ node:. \n node:execute unzip wing_test.zip \n node:execute ./run_wing_test.sh\
          \ ${aircraft_model} ${winglets}\n${AoA} \\ \n ${airspeed} ${turbulence}\
          \ >> output.${jobname} \n node:execute zip results.${jobname} * \n copy\
          \ node:results.${jobname}.zip . \n endtask \n \n This is a somewhat contrived\
          \ example demonstrating various parameter\ntypes but it illustrates the\
          \ basic functionality of defining parameters\nfor the main task and handling\
          \ input, execution and output for each of\nthe parameter combinations. The\
          \ two subsections below explain the\n'parameter' and 'task' definitions\
          \ in the plan file. \n Parameters \n Parameters define lists of values,\
          \ constant single values or dynamic\nvalues (of various types). A unique\
          \ combination of parameter values is\nassigned to each job and each parameter\
          \ value is bound to a named\nidentifier in the job environment. Nimrod/G\
          \ experiments usually create a\ncross-product of all parameters to define\
          \ the jobs which make up the\nexperiment, we call this a full parameter\
          \ sweep. The syntax for\nparameter lines in the plan file is: \n \n parameter\
          \ <name> <type> [<domain>]; \n \n \n \n name\_- This is the parameter name\
          \ which must be unique. \n \n \n type\_- This part of the parameter tells\
          \ Nimrod/G what type of\n    parameter this is. There are five types and\
          \ they are \n \n \n float\_- floating point number \n \n \n integer\_- integer\
          \ (whole) number \n \n \n text\_- textual values as shown in the example\
          \ above \n \n \n files\_- this type allow you to apply glob style file name\n\
          \    matching to create a list of files names within the experiment\n  \
          \  directory which match the given pattern(s), you could use this\n    to\
          \ parameterize the input files for your computation (like the\n    example\
          \ above). The files type\_must be\_used with the \"select\n    anyof\" domain.\
          \ \n \n \n fromfile\_- this type must refer to a text file that contains\n\
          \    a list of values, i.e., the file contains the entire range. \n \n \n\
          \ \n \n domain\_- A parameter domain is optional in some cases but\n   \
          \ usually required. The following domains are available: \n \n \ndefault-\
          \ this domain type has only a single value. The\n    syntax for this domain\
          \ is: \n \n \n \n \n default <value \n \n \n \nrange\_- this domain type\
          \ has a number of values (points) that\n    are within a specified range.\
          \ The syntax for the range domain is: \n \n \n range from <value> to <value>\
          \ points <value> \n range from <value> to <value> step <value> \n \n \n\
          \ \nrandom\_- this domain type has a number of random points\n    generated\
          \ between specified lower and upper bounds. The syntax for\n    this domain\
          \ is \n \n \n random from <value> to <value> [points <value>] \n \n \n \n\
          select anyof\_- this domain type is usually used for text and\n    files\
          \ but is also useful for listing fixed numerical values. The\n    syntax\
          \ for this domain is: \n \n \n select anyof <value_list> [default <value_list>]\
          \ \n \n \n \nselect oneof\_- Similar to 'select anyof' except that only\
          \ one\n    value will be selected for use from this list. If the default\
          \ value\n    is not specified the first value in the value_list is used.\
          \ The\n    syntax for this domain is: \n \n \n select oneof <value_list>\
          \ [default <value>] \n \n \n \n(some input file)\_- when using the fromfile\
          \ type, the domain is\n    an input file that lists the values for the parameter.\
          \ For example: \n \n \n parameter x fromfile inputfile.txt \n means that\_\
          inputfile.txt\_contains a list of single values (one per\nline) for parameter\_\
          x. \n \n Tasks \n This part of the plan file describes the process of executing\
          \ a single\ninstance of your experiment. There are a number of\noperations/commands/directives\
          \ that can be performed in a task: \n \n \n Copy files to and from compute\
          \ resources \n \n \n Executing an experiment executable \n \n \n Substituting\
          \ place-holders in the input files with the real values \n \n \n What to\
          \ do in case the job fails. \n \n \n Task operations are typically location\n\
          dependent.\_copy\_and\_execute\_directives must specify where the\noperation\
          \ should be performed or where the file locations are while\ncopying. This\
          \ is done by using\_node:\_or\_root:\_modifiers. \n \n \n node:\_indicates\
          \ remote location for the operation. In case\n    of\_copy\_operation it\
          \ indicates that the file resides on remote\n    machine, while in case\
          \ of execute\_command it indicates that the\n    executable should be run\
          \ on the remote server. \n \n \n root:\_on the other hand indicates that\
          \ files are on the same\n    machine where Nimrod/G is running, and that\_\
          execute\_command that\n    executables are to be run on that same machine,\
          \ and not on the\n    remote server. Please note that\_root:execute\_can\
          \ only be\n    executed in\_rootstart\_and\_rootfinishtasks. \n \n \n NOTE:\
          \ In a typical parameter sweep all program invocations will\noccur on computational\
          \ nodes and hence the main task will only use\nnode:execute. \n Following\
          \ is a more thorough description of the task operations: \n \n \ncopy\_\
          - this operation is used to copy both input and\n    > output files. Syntax\
          \ for this operations is as follows: \n \n \n copy <source> <destination>\
          \ \n For example if you are copying input file to a remote location: \n\
          \ copy root:input.txt node:input.txt \n And if you are copying output file\
          \ back to the server where Nimrod/G\nis running: \n copy node:result.txt\
          \ root:result.txt \n \n \n \nexecute\_- this operation is used to execute\
          \ some executable. The\n    syntax for this operatio is: \n \n \n node:execute\
          \ <user_command> \n user_command\_is passed to shell (/bin/sh), so it can\
          \ contain\nshell constructs (redirection like >, >> etc). \n For example\
          \ if we wanted to execute\_hostname\_command and redirect\nits output into\
          \ a file called\_hostname.txt\_this is what\nthe\_executeoperation would\
          \ look like: \n node:execute /bin/hostname > hostname.txt \n \n \n onerror\_\
          - this operation indicates how Nimrod/G should behave in\n    case some\
          \ part of the job fails. It has a scope which is from the\n    point it\
          \ appears until another\_onerror\_statement is found. The\n    syntax for\
          \ this operation is: \n \n \n onerror <option> \n Valid options are: \n\
          \ \n \n \n fail\_- fail the job. This is the default behaviour and will\
          \ be\n    > used even if\_onerror\_is never specified in the plan file \n\
          \ \n \n ignore\_- ignore the error and proceed with the task, ie. move\n\
          \    > onto the next line in the plan file and continue executing it. \n\
          \ \n \n\n\n \n \nsubstitute\_- Nimrod/G allows can use skeleton input file\
          \ for\n    > their experiments. This skeleton input file may contain\n \
          \   > placeholders in it that are to be substituted by the actual\n    >\
          \ parameter values before the execution begins. \n \n \n This operation\
          \ is used to replace the parameter placeholders in input\nfile with a job\
          \ parameter value. The syntax of this operation is: \n substitute <source>\
          \ <destination> \n Both source and destination require neither 'node:' nor\
          \ 'root:' in\nfront of them, i.e. they are just plain filenames. For example,\
          \ this\ncould be a main task of a plan file: \n task main \n copy input.skeleton\
          \ node:. \n substitute input.skeleton input.txt \n node:execute ./process.sh\
          \ input.txt > result.txt \n copy node:result.txt . \n endtask \n \n Creating\
          \ Experiments \n Nimrod/G stores experiments in a specific location in user's\
          \ home\ndirectory: \n \n $HOME/.nimrod/experiments/ \n \n Each experiment\
          \ will have a dedicated subdirectory in that location that\nmatches experiment\
          \ name. For example: \n \n \n Experiment named\_demo\_will be\n    > in\_\
          $HOME/.nimrod/experiments/demo/ \n \n \n Plan file called\_demo.pln\_will\
          \ be in that directory \n \n \n All files related to that experiment will\
          \ also be location in\n    > that directory \n \n \n \n \n In order to create\
          \ experiment execute the following steps: \n \n \n Create a plan file following\
          \ instructions from the previous section.\n    > Lets assume we create a\
          \ plan file called\_demo.pln \n \n \n Create an experiment directory: \n\
          \ \n \n \n $ mkdir -p $HOME/.nimrod/experiments/demo \n \n \n \n Place the\_\
          demo.pln\_file in that directory \n \n \n Create a file containing all possible\
          \ parameter combinations: \n \n \n \n nimrod generate demo.pln \n \n \n\
          \ Add the experiment to the Nimrod/G database: \n \n \n nimrod create demo\
          \ \n \n Assign Resources to Experiments \n In section\_Resource Management\_\
          we added compute resources to the\ndatabase. In order for them to be used\
          \ by an experiment they have to be\nassigned to that experiment. The syntax\
          \ for adding resources to\nexperiments is as follows: \n \n nimrod addserver\
          \ <exp_name> <resource_details>\n<resource_type> \n \n Resource type and\
          \ resource details are exact same details that were used\nwhen resources\
          \ were added to database. An example of adding a PBS\nresource to a demo\
          \ experiment can be seen below: \n \n nimrod addserver demo workq@localhost\
          \ pbs \n \n Launching Nimrod/G \n With experiments defined and configured\
          \ Nimrod/G can be launched. The\nsyntax for this command is as follows:\
          \ \n \n nimrod startexp <exp_name> \n \n For example, to start the experiment\
          \ called\_demo\_run: \n \n nimrod startexp demo \n \n Using Nimrod/K \n\
          \ Nimrod/K extends\_Kepler by adding parameter tools and grid/cloud\nservices\
          \ and by providing dynamic parallelism in workflows. As such\nNimrod/K functionality\
          \ is simply used by adding the Nimrod/K director\nand Nimrod/K actors to\
          \ Kepler workflows. \n Using Nimrod/O \n A comprehensive manual for Nimrod/O\
          \ can be downloaded from: \n http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&upname=NimrodOUsersGuide3.1.pdf.\
          \ \n It contains information on how to launch Nimrod/O. \n Resource Requirements\
          \ \n Nimrod Toolkit runs on Unix based platforms only, which includes all\n\
          flavours of Linux as well as Mac OS X. However, Nimrod Portal component\n\
          is browser based which allows users of all platforms (including Windows)\n\
          to access Nimrod and execute computational experiments through any\nbrowser.\
          \ \n \n \n Software Requirements: \n \n \n Python \u2013 version 2.5 or\
          \ higher \n \n \n PostgreSQL \u2013 version 8.4 or higher \n \n \n \n \n\
          \ Operating System Requirements \n \n \n Linux \n \n \n Mac OS X \n \n \n\
          \ \n \n Nimrod/O can run in standalone mode, in which case Nimrod/G is not\n\
          required. However in standalone mode Nimrod/O loses the ability to run\n\
          its jobs on distributed clusters and computational grid resources.\nFor\
          \ distributing jobs, Nimrod/G 4.0 or higher required \n Similar to Nimrod/O,\
          \ Nimrod/K can run as a standalone application, in\nwhich case Nimrod/G\
          \ is not required. When running in standalone mode\nNimrod/K can be installed\
          \ and used on Windows machines. \n Compute Resources \n Nimrod allows computational\
          \ researchers to use a mixture of\nuniversity-level infrastructure and commercial\
          \ clouds. For beginners,\nusers can trial their Nimrod experiments using\
          \ the Nimrod_Portal[^1]\nresource pool. Users are encouraged to bring their\
          \ own compute resources\n(e.g. cluster, cloud allocation) to use with Nimrod.\
          \ Please contact Minh\nDinh and Hoang Anh Nguyen regarding adding new remote\
          \ compute resources\nto their experiments. \n Nimrod Portal \n A web service\
          \ for using Nimrod/G. Nimrod portal provides a web interface\nfor users\
          \ to use Nimrod and its resources. Users can create Nimrod/G\nexperiments\
          \ without installing Nimrod toolkit on their local system.\nThis allows\
          \ users develop, execute, maintain and share Nimrod parameter\nsweep experiments.\
          \ \n Installation \n Nimrod portal consists of two components: a RESTful\
          \ Web service and a\nWeb portal. The RESTful service is to expose Nimrod\
          \ functionality to the\nWeb and the Web portal provides user-friendly interface\
          \ to the users. \n The installation process requires two steps: installation\
          \ of the Web\nservice and installation of the Web portal. This two-step\
          \ process takes\nplace in two separate VMs. Nimrod needs to be installed\
          \ in the Web\nservice VM. \n Install Nimrod Web service \n The Web service\
          \ is currently available at:\nhttps://bitbucket.org/jhtngu/nimrod.webservice.\
          \ \n This is not a public repository. Please email hoangnguyen177@gmail.com\n\
          to gain access. \n \n Once clone the repository, modify the buildout.cfg\
          \ as followed \n \n \n [sources] \n Nimrodrestapi = git\nhttps://yournamehere@bitbucket.org/jhtngu/nimrod.restfulweb.git\n\
          branch=addresources \n nimrodrpcdaemon = git https:// yournamehere\n@bitbucket.org/jhtngu/nimrod.rpcdaemon.git\
          \ branch=addresources \n \n \n \n Execute \u201Cpython bootstrap.py\u201D\
          \ to setup the environment. This\n    requires setuptools installed. \n\
          \ \n \n Execute \u201C./bin/buildout\u201D to clone and install necessary\
          \ packages,\n    including Nimrod Web service. \n \n \n Install any missing\
          \ dependencies as suggested by the build process. \n \n \n Modify configuration\
          \ files in the \u201Cetc\u201D folder accordingly. \n \n \n Install the\
          \ Web portal \n \n \n Install Liferay 6.1\n    (http://sourceforge.net/projects/lportal/files/Liferay%20Portal/6.1.1%20GA2/).\n\
          \    The recommended location is: /var/www. \n \n \n Follow Liferay instructions\
          \ to install with Postgres DB\n    (https://www.liferay.com/community/wiki/-/wiki/Main/Quick+Installation+Instructions)\
          \ \n \n \n Go to Liferay market and install Private Plugin Installer\n \
          \   (https://www.liferay.com/marketplace/-/mp/application/15474932) \n \n\
          \ \n Install Vaadin into Liferay\n    (https://vaadin.com/wiki/-/wiki/Main/Integrating+Vaadin+7+with+Liferay)\
          \ \n \n \n Install Nimrod portlets, which are available at:\n    https://bitbucket.org/hoangnguyen177/nimrodportal2.\
          \ Or contact\n    hoangnguyen177@gmail.com for compiled version. \n \n \n\
          \ Install Nimrod portlets \n \n \n Configure the portal and the Web service\
          \ VM \n From NeCTAR dashboard, make sure the port of the Web service (8081\
          \ by\ndefault) is accessible by the Web portal and Nimrod ports (40000 -\n\
          41000) are accessible by all. \n Launch \n Launch the Web portal first:\
          \ \n \n cd /var/www/liferay-portal-xxxx/tomcat-xxx/bin; sudo ./startup.sh\
          \ \n \n Then launch the Web service: \n \n cd \\~/nimrod.webservice/bin;\
          \ ./supervisord; \n \n Plan file web editor \n Instead of using a text editor,\
          \ the Nimrod Portal provides a simple\nfriendly GUI for users to develop\
          \ plan file for Nimrod/G experiments. \n \n How to access it \n Interested\
          \ users can register for an account using their AAF credential\nat the following\
          \ page (will need to be updated later):\nhttp://vm-203-101-224-118.qld.nectar.org.au/\
          \ \n The portal provides a friendly web interface for users to define,\n\
          execute and monitor their experiments. For users who have existing\nNimrod\
          \ experiments, they can upload the plan files. User can also create\nnew\
          \ experiments using a simple GUI. Input and output files can be\nuploaded\
          \ and downloaded using the web interface. For technical supports\nand learning\
          \ to use Nimrod, please contact Minh Dinh and/or Hoang Anh\nNguyen. \n Configuration\
          \ guide \n Configuring Nimrod/G \n Nimrod/G installation comes with two\
          \ configuration files, both located\nin\_$NIMROD_INSTALL\_directory: \n\
          \ \n \n nimrod.cfg\_- Configuration values contained within can be\n   \
          \ overridden by a user level configuration file of the same name,\n    which\
          \ may be located in $HOME/.nimrod/ directory, or by an\n    immutable configuration\
          \ file described below. \n \n \n nimrod.immutable.cfg\_- Configuration values\
          \ contained within\n    will override any other configuration, either user\
          \ or system level. \n \n \n Most of the configuration values can be left\
          \ as is but some may be\nchanged to match the system requirements. \n Each\
          \ configuration file may contain following sections: \n \n \n email\_- used\
          \ to configure email settings. This is used to report\n    experiment completion.\
          \ \n \n \n nimserver\_- configures Nimrod/G component called Nimrod Server.\n\
          \    Nimrod/G uses executables called\_Agents\_to execute jobs on\n    remote\
          \ resources.\_Agents\_use Nimrod Server to communicate with\n    database\
          \ as well as to copy files to and from remote locations. \n \n \n \n Most\
          \ of the configuration can be left as is. It is important however\nto ensure\
          \ that\_default_port_range\_configuration value has a\nrange of ports that\
          \ can be reached by outside networks. When it\nstarts,\_Nimrod Server\_\
          will select a first available port from that\nrange and will use that to\
          \ listen for incoming connectinos\nfrom\_Agents. If the port it selects\
          \ is unreachable, no jobs will\nrun. \n For example (port will be selected\
          \ anywhere between 30000 and 31000\ninclusive): \n nimserver: { \n default_port_range:\
          \ '30000,31000' \n key_path: $user_dir + '.nimserver' \n remote_suffix:\
          \ $remote_suffix \n remote_key_fname: '.nimserver' + $nimserver.remote_suffix\
          \ + '.pub' \n port_path: $user_dir + '.nimport' + $nimserver.remote_suffix\
          \ \n remote_port_fname: '.nimport' + $nimserver.remote_suffix \n } \n \n\
          \ \n \n actuator\_- configures resource actuators, components that\n   \
          \ control how resources are used. It can be used to change how often\n \
          \   actuators poll database to see if there are any work they need\n   \
          \ to do. Configuration can apply to actuators for all resource types,\n\
          \    but can also only apply to a specific resource type. \n \n \n azure\_\
          - configure\_azure\_resource settings. Can be left\n    as is. \n \n \n\
          \ ec2\_- configures\_ec2\_resource settings. Can be left as is \n \n \n\
          \ generate\_- configures\_generate\_subcommand. This subcommand\n    is\
          \ used to parse the plan file and create another files that\n    contains\
          \ a cross-product of all parameters. Some of the settings\n    include limits\
          \ on how many jobs single experiment can have, or how\n    long a parameter\
          \ name can be. \n \n \n \n For example: \n generate: { \n max_jobs: 100000\
          \ \n param_len_limit: 56 \n } \n \n Configuring Nimrod/K \n There is no\
          \ Nimrod/K specific configuration. \n Configuring Nimrod/O \n A comprehensive\
          \ manual for Nimrod/O can be downloaded from: \n http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&upname=NimrodOUsersGuide3.1.pdf.\
          \ \n It contains information on how to configure Nimrod/O. \n Technical\
          \ blueprint \n To date, Nimrod tools are deployed through several Nimrod\
          \ portals\nstationed at Monash University, Griffith University and The University\n\
          of Queensland. These portals provide the machinery to automate the tasks\n\
          of formulating complex experiments and workflows, and execute them\nacross\
          \ a variety of computing resources including NecTAR VMs. In\nparticular,\
          \ we ran several projects to test the migration of scientific\nsoftware\
          \ to HPC platforms, including the NeCTAR research cloud, to\nprovide enhanced\
          \ utility for the following research projects. \n Terrestrial Ecosystem\
          \ Research Network (TERN) \n Supporting the creation and execution of sensory\
          \ data analysis using\nNimrod portal to access available computing resources\
          \ in the NecTAR\ncloud. \n \n CVL Symmetric Model Creation \n Coupling Nimrod\
          \ to perform expensive computations efficiently and\nintegrating visualization\
          \ library to enable examination of intermediate\nmodels. \n \n MARXAN \n\
          \ Coupling the MARXAN web portal with Nimrod to provide access to HPC and\n\
          cloud resources. \n \n Troubleshooting \n There are multiple points of failure\
          \ that are possible when running\nNimrod/G experiments: \n \n Problem with\
          \ executables (applications) that Nimrod/G is trying to\n    execute \n\
          \ \n \n These will be reported back to database. In scenario like this is\n\
          highly possible that all jobs will fail because of it. However the\nproblem\
          \ can be environmental in which case it will only fail on a\nparticular\
          \ resource or even a particular machine on that resource. \n \n \n Problem\
          \ with remote machines where Nimrod Agents are running \n \n \n These kind\
          \ of problems occur when a particular machine on a\ncomputational resource\
          \ is not working correctly. There are many\nreasons this may occur, which\
          \ includes missing libraries, faulty\nhardware etc. \n If the agents manage\
          \ to start then these are easy to identify. Nimrod\nAgents will fail the\
          \ jobs and record which host the job failed on.\nListing failed jobs, and\
          \ seeing that all failed on a particular host\nwill indicate a problem with\
          \ that host. \n \n \n Firewall issues preventing Nimrod Agents connecting\
          \ back to Nimrod\n    Server \n \n \n If Agents are perpetually stuck in\_\
          pending/queued\_state, it\nusually indicates that they cannot connect back\
          \ to Nimrod Server. One\nreason is that there is a faulty host and\_Agents\_\
          never start, and\nsecond reason is that firewall on either host is preventing\n\
          those\_Agents\_connections. \n \n There are number of commands that can\
          \ be executed to collect information\nthat may help identify the issue:\
          \ \n \n Get reported errors \n \n \n $ nimrod geterrors <exp_name> \n \n\
          \ \n Check if there are any agents running on resources \n \n \n $ nimrod\
          \ getagents <exp_name> \n Output returns a list of resources where each\
          \ line has the resource\nname and agent information in following order:\
          \ \n \n \n \n Agents that have stopped running (cleanly) \n \n \n Agents\
          \ that are still running \n \n \n Agents that have been submitted to a remote\
          \ queue \n \n \n Agents that have been created in database, but not submitted\
          \ to a\n    remote queue \n \n \n Agents that have failed to start. Some\
          \ agents may fail to start but\n    won't be reported here. This will occur\
          \ if firewall is blocking\n    the connections. \n \n \n Check the progress\
          \ of experiment and see if there any failed jobs: \n \n \n \n $ nimrod enfapi\
          \ <exp_name> jobstatus \n \n \n If there are failed jobs, get errors for\
          \ all failed jobs: \n \n \n $ nimrod enfapi <exp_name> getjobinfo all error\
          \ \n \n Support \n Administration \n Please contact Hoang Anh Nguyen or\
          \ Minh Dinh for the Nimrod Portal \n Technical Support \n All queries regarding\
          \ the for the Nimrod Portal and WorkWays portal,\nplease contact Hoang Anh\
          \ Nguyen or Minh Dinh \n Learning to use Nimrod or integrating Nimrod into\
          \ your internal service \n Please contact Minh Dinh regarding learning to\
          \ use Kepler and Nimrod.\nFor consultation on how Kepler and Nimrod can\
          \ be applicable for specific\nresearch fields, please contact Minh Dinh.\
          \ \n Contact \n Dr Minh Dinh \n QCIF - eResearch Analyst \n Reserch Fellow\
          \ - Research Computing Center (RCC) \n Email: m.dinh1@uq.edu.au \n Mr Hoang\
          \ Anh Nguyen \n Email: hoangnguyen177@gmail.com \n Glossary of Terms \n\
          \ [^1]: Nimrod_Portal is a Nectar allocation that consists of up 120\n \
          \   compute cores. It is designated for deploying Nimrod services and\n\
          \    conducting Nimrod runs. It is an independent testbed for new users\n\
          \    to trial Nimrod and its tools "
        description: "<h1>Nimrod toolkit for high throughput computing in the cloud</h1>\n\
          <h2>Introduction</h2>\n<p>The Nimrod tool family facilitates high-throughput\
          \ science by allowing\nresearchers to use computational models to explore\
          \ complex design\nspaces. Models can be executed across changing input parameters.\n\
          Different members of the tool family support complete and partial\nparameter\
          \ sweeps, numerical search by non-linear optimisation, and even\nworkflows.\
          \ Further, Nimrod allows computational researchers to use a\nmixture of\
          \ university-level infrastructure and commercial clouds.</p>\n<p>There are\
          \ several \u2018flavours\u2019 of Nimrod. Which Nimrod you choose to use,\n\
          either singly, or in combination, will depend on the kind of experiment\n\
          you want to run.</p>\n<h3>Nimrod/G</h3>\n<p>Nimrod/G can directly execute\
          \ large-scale distributed parameter sweep\nand Monte-Carlo computational\
          \ experiments. It provides a simple means to\ndramatically scale-up your\
          \ computational experiments. Each experiment\ncan run over an aggregated\
          \ ad-hoc computational grid/pool/cloud; start\nfrom your desktop, local\
          \ server or cluster; add grid resources (e.g.\nclusters and Condor pools);\
          \ overflow to pay-as-go cloud services and\ncontrol your budget with Nimrod/G's\
          \ economic scheduling capabilities.</p>\n<h3>Nimrod/K</h3>\n<p>Nimrod/K\
          \ is built on Kepler using Kepler\u2019s runtime engine Ptolemy. It\nextends\
          \ Kepler by adding parameter tools and grid/cloud services and by\nproviding\
          \ dynamic parallelism in workflows.</p>\n<p>It uses a dataflow execution\
          \ model that was originally developed for\nhighly parallel dataflow computers\
          \ in the 1980\u2019s, and this provides an\nextremely rich execution mechanism.\
          \ It leverages a number of the\ntechniques developed in the earlier Nimrod\
          \ tools for distributing tasks\nto the Grid.</p>\n<h3>Nimrod/O</h3>\n<p>Provides\
          \ an optimisation framework for optimising a target output value\nof an\
          \ application. It allows a user to run an arbitrary computational\nmodel\
          \ as the core of a non-linear optimization process. Nimrod/O allows\na user\
          \ to specify the domain and type of parameters to the model, and\nalso a\
          \ specification of which output variable is to be minimized or\nmaximized.\
          \ Accordingly, a user can formulate a question like: what\nparameter settings\
          \ will minimize the model output? Nimrod/O currently\nemploys a number of\
          \ built-in optimization algorithms:</p>\n<ul>\n<li>\n<p>BFGS</p>\n</li>\n\
          <li>\n<p>Simplex</p>\n</li>\n<li>\n<p>Divide and Conquer</p>\n</li>\n<li>\n\
          <p>Simulated Annealing.</p>\n</li>\n</ul>\n<p>Jobs can be executed on a\
          \ variety of platforms, which when combined with\nNimrod/G includes distributed\
          \ clusters and Computational Grid resources.</p>\n<h2>Target Audience</h2>\n\
          <p>The following research activities can benefit from using Nimrod.</p>\n\
          <ol>\n<li>\n<p>You need to run your computational model many times and average\
          \ the\n    results because the model is stochastic. These types of Monte\
          \ Carlo\n    simulations are greatly facilitated by Nimrod/G. It will generate\n\
          \    multiple jobs, furnishing them with different random number seeds\n\
          \    and execute them concurrently on the grid.</p>\n</li>\n<li>\n<p>You\
          \ wish to explore the effect of varying the inputs to your model.\n    Inputs\
          \ may be in the form of command line parameters or of values in\n    some\
          \ input file; in Nimrod these are both called parameters. Either\n    way\
          \ Nimrod/G will let you specify values for each parameter, will\n    generate\
          \ the jobs for all possible combinations of these values and\n    execute\
          \ the jobs on the Grid.</p>\n</li>\n<li>\n<p>You wish to explore the effect\
          \ of input parameters but for certain\n    combinations are not allowed.\
          \ There are several possible ways to\n    do this. If the disallowed combinations\
          \ give jobs that quickly fail\n    then you may schedule all possible combinations\
          \ and let those bad\n    jobs fail. However, if those jobs will use substantial\
          \ resources\n    then it would be better to filter them out first. This\
          \ can be done\n    in Nimrod/G by processing the run file. Alternatively\
          \ Nimrod/O may\n    be used in sweep mode as it provides the functionality\
          \ to add\n    formulas for constraints on the parameters.</p>\n</li>\n<li>\n\
          <p>You are running several different experiments. They may produce some\n\
          \    jobs with the same inputs and you don't want to waste resources\n \
          \   duplicating these jobs. Nimrod/O can be invoked with a persistent\n\
          \    cache shared by the experiments, so avoiding duplications.</p>\n</li>\n\
          <li>\n<p>You wish to find the combination of input parameters that produce\
          \ an\n    optimal output. Nimrod/O allows you to specify the inputs that\
          \ vary,\n    any constraints on those inputs, and the output to be maximized\n\
          \    or minimized. It offers a selection of search methods for finding\n\
          \    the optimum. Multiple searches, perhaps using different optimization\n\
          \    methods, may be run in parallel.</p>\n</li>\n<li>\n<p>You want to find\
          \ the inputs that generate the best output. Nimrod/O\n    allows optimization\
          \ where human input may be used to assess the\n    quality of an output.\
          \ This is especially useful for complex outputs\n    such as images or animations.</p>\n\
          </li>\n<li>\n<p>There are several aspects of your model output that you\
          \ wish\n    to optimize. Nimrod/O is currently being modified to facilitate\
          \ such\n    multi-objective optimization.</p>\n</li>\n<li>\n<p>You wish\
          \ to perform multiple optimizations on the output of your\n    model, one\
          \ optimization for each combination of some\n    parameter settings. This\
          \ can be done using Nimrod/G to sweep over\n    the setting and having it\
          \ call Nimrod/O to do each optimization.</p>\n</li>\n<li>\n<p>You wish to\
          \ run your model in reverse. In other words you want to\n    find the input\
          \ values that will produce a given output. Nimrod/O is\n    commonly used\
          \ for this task. You need to have a way of measuring the\n    discrepancy\
          \ between your output and the desired one. Then run an\n    optimization\
          \ to minimize this discrepancy.</p>\n</li>\n<li>\n<p>You have developed\
          \ your own optimization method. You wish to use the\n    method, taking\
          \ advantage of the distributed execution of jobs and\n    the caching supplied\
          \ in Nimrod/O.</p>\n</li>\n<li>\n<p>Different parts of your model need to\
          \ run on different machines\n    because of data files perhaps or licence\
          \ requirements. Nimrod/G can\n    schedule such workflow experiments and\
          \ perform the appropriate\n    communication between the parts. Where possible\
          \ a downstream\n    component may start processing its input file before\
          \ an upstream\n    component has completed that file.</p>\n</li>\n<li>\n\
          <p>Some of your model executions require prior execution of\n    other models.\
          \ Nimrod/G can handle such dependencies.</p>\n</li>\n</ol>\n<h2>How to install</h2>\n\
          <p>Nimrod allows computational researchers to use a mixture of\nuniversity-level\
          \ infrastructure and commercial clouds.</p>\n<p>Users can trial their Nimrod\
          \ experiments using the Nimrod Portal\nresource pool. Users are encouraged\
          \ to bring their own compute resources\n(e.g. cluster, cloud allocation)\
          \ to use with Nimrod. Please contact Minh\nDinh and Hoang Anh Nguyen regarding\
          \ adding new remote compute resources\nto their experiments.</p>\n<p>Users\
          \ can still opt to install Nimrod Toolkit on their local system,\nprovided\
          \ that system meets the software and operating system\nrequirements outlined\
          \ in the Resource Requirements section. If the user\nchooses to do that,\
          \ here are step by step procedures for installing\nindividual Nimrod Toolkit.</p>\n\
          <h3>Installing Nimrod/G</h3>\n<p>Users must executed the following steps\
          \ to install Nimrod/G:</p>\n<ol>\n<li>\n<p>Download Nimrod/G source distribution</p>\n\
          </li>\n<li>\n<p>Setup Nimrod/G environment</p>\n</li>\n<li>\n<p>Create experiments\
          \ directory</p>\n</li>\n<li>\n<p>Install Nimrod/G</p>\n</li>\n<li>\n<p>Setup\
          \ Nimrod/G database</p>\n</li>\n</ol>\n<h4>Download Nimrod/G Distribution</h4>\n\
          <p>Download from following link:</p>\n<ul>\n<li>https://messagelab.monash.edu.au/Downloads</li>\n\
          </ul>\n<p>Download the Nimrod/G source archive to your home directory, which\n\
          should create a file:</p>\n<ul>\n<li><strong>$HOME/nimrodg-[version].tar.gz</strong></li>\n\
          </ul>\n<h4>Setup Nimrod/G Environment</h4>\n<p>We recommend editing your\
          \ shell\_<strong>rc</strong>\_scripts\n(<strong>.profile</strong>\_or\_\
          <strong>.bashrc</strong>\_or\_<strong>.cshrc</strong>, etc), or adding\n\
          an\_<strong>/etc/profile.d/nimrod.sh</strong>\_script for system-wide installs.\n\
          For\_<strong>sh</strong>\_based shells you will need something like (paths\
          \ should be\naltered as appropriate for your install/system):</p>\n<blockquote>\n\
          <p>export NIMROD_INSTALL=$HOME/bin/nimrodg export\nNIMROD_DATABASE=pgsql-pool</p>\n\
          <p>export PSQL_LOCATION=/usr/bin # in this case /usr/bin/psql should be\n\
          a valid path</p>\n<p>export PYTHONPATH=${NIMROD_INSTALL}/share/nimrod:${PYTHONPATH}\\\
          \nexport PATH=${NIMROD_INSTALL}/bin:${PATH}</p>\n</blockquote>\n<h4>Create\
          \ Experiments Directory</h4>\n<p>Nimrod/G keeps all the experiments it runs\
          \ in a subdirectory of user's\nhome directory\_$HOME/.nimrod/experiments.\
          \ Create that directory by\nexecuting the following command:</p>\n<blockquote>\n\
          <p>$ mkdir -p $HOME/.nimrod/experiments</p>\n</blockquote>\n<h4>Install\
          \ Nimrod/G</h4>\n<ol>\n<li>Decompress Nimrod/G source archive. Let\u2019\
          s assume we downloaded a\n    source archive for Nimrod/G version 4.0.2:</li>\n\
          </ol>\n<blockquote>\n<p>$ cd $HOME</p>\n<p>$ tar -zxvf nimrodg-4.0.2.tar.gz</p>\n\
          </blockquote>\n<ol>\n<li>Configure and install Nimrod/G</li>\n</ol>\n<blockquote>\n\
          <p>$ cd nimrodg-4.0.2</p>\n<p>$ ./configure --prefix=$NIMROD_INSTALL</p>\n\
          <p>$ make; make install</p>\n</blockquote>\n<h4>Setup Nimrod/G Database</h4>\n\
          <p>Nimrod/G runs on top of PostgreSQL relational database. Before anything\n\
          can be done, user must create a database which will be used by Nimrod/G.\n\
          Each Nimrod/G user requires their own PostgreSQL database.</p>\n<ol>\n<li>As\
          \ a PostgreSQL admin user create a PostgreSQL user. Must ensure\n    &gt;\
          \ that the user can create databases (prompted during the process):</li>\n\
          </ol>\n<blockquote>\n<p>$ createuser &lt;username&gt;</p>\n</blockquote>\n\
          <ol>\n<li>As the user, create a database</li>\n</ol>\n<blockquote>\n<p>$\
          \ createdb</p>\n</blockquote>\n<ol>\n<li>As the user, populate that database\
          \ with Nimrod/G database schema</li>\n</ol>\n<blockquote>\n<p>$ nimrod dbcreate</p>\n\
          </blockquote>\n<h4>Platform and Version Specific Notes</h4>\n<ul>\n<li>Python\
          \ 2.6</li>\n</ul>\n<blockquote>\n<p>To configure the Nimrod build files\
          \ against Python2.6 (confirmed on\nUbuntu 10.04) it seems to be necessary\
          \ to set LDFLAGS=-lm.</p>\n</blockquote>\n<ul>\n<li>Ubuntu 10.04</li>\n\
          </ul>\n<blockquote>\n<p>To configure the Nimrod build files against the\
          \ included Python2.6 on\nUbuntu 10.04 it seems to be necessary to set LDFLAGS=-lm.</p>\n\
          </blockquote>\n<ul>\n<li>RHEL6</li>\n</ul>\n<blockquote>\n<p>Using the OS\
          \ default Python (2.6) to install Nimrod may result in the\nmake install\
          \ step failing to install 3rd party modules that are\npackaged with Nimrod,\
          \ with an error message like:</p>\n<p>You are attempting to install a package\
          \ to a directory that is not on\nPYTHONPATH and which Python does not read\
          \ \".pth\" files from.</p>\n<p>This can be remedied by ensuring $NIMROD_INSTALL/share/nimrod\
          \ is in\nyour $PYTHONPATH environment variable.</p>\n</blockquote>\n<h3>Installing\
          \ Nimrod/K</h3>\n<p>Users must executed the following steps to install Nimrod/K:</p>\n\
          <ol>\n<li>\n<p>Download Nimrod/K distribution</p>\n</li>\n<li>\n<p>Install\
          \ Nimrod/K</p>\n</li>\n</ol>\n<h4>Download Nimrod/K Distribution</h4>\n\
          <p>This can be done by following Nimrod/K link at:</p>\n<ul>\n<li>https://messagelab.monash.edu.au/Downloads</li>\n\
          </ul>\n<p>Download the Nimrod/K distribution to your home directory which\
          \ should\ncreate a file:</p>\n<ul>\n<li>$HOME/nimrodk-[version].jar</li>\n\
          </ul>\n<h4>Steps to install Nimrod/K</h4>\n<p>For the purposes of this installation\
          \ guide, we will assume that the\nversion we are working on is 2.0.0. Nimrod/K\
          \ major version number will\nalways follow Kepler's major version number\
          \ so version 2.0.0 means that\nthis version of Nimrod/K will work with latest\
          \ version of Kepler with\nmajor version number</p>\n<p>Nimrod/K jar file\
          \ has following install options:</p>\n<blockquote>\n<p>options:</p>\n<p>--help|-h\
          \ -- print this message</p>\n<p>--acceptlicense|-a -- accept Nimrod/K license\
          \ without prompting. If\nomitted user will be</p>\n<p>given a choice (declining\
          \ will stop the installation).</p>\n<p>--prefix=&lt;path&gt; -- set a location\
          \ of where all Nimrod/K modules\nare installed (eg. \u2013</p>\n<p>prefix=/usr/local/kepler/2.4/lib).\
          \ If omitted it will prompt for</p>\n<p>the prefix</p>\n<p>--keplerversion=&lt;major\
          \ version number&gt; -- set a kepler version\n(eg. --keplerversion=2.4).</p>\n\
          <p>If ommitted installer will look for it in the following files and</p>\n\
          <p>in the order they are listed here:</p>\n<p>a) &lt;prefix&gt;/build-area/install-id.txt</p>\n\
          <p>b) $KEPLER/build-area/install-id.txt</p>\n<p>--version|-v -- prints the\
          \ Nimrod/K version</p>\n</blockquote>\n<p>Using the above options install\
          \ Nimrod/K:</p>\n<blockquote>\n<p>java -jar nimrodk-2.0.0.jar [options]</p>\n\
          </blockquote>\n<h3>Installing Nimrod/O</h3>\n<p>A comprehensive manual for\
          \ Nimrod/O can be downloaded from:</p>\n<p><a href=\"http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf\"\
          >http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf</a>.</p>\n\
          <p>It contains information on how to install Nimrod/O.</p>\n<h2>How to launch</h2>\n\
          <h3>Running Nimrod/G</h3>\n<p>In order to run Nimrod/G experiments from\
          \ command line user needs to do\nthe following:</p>\n<ul>\n<li>\n<p>Manage\
          \ Resources</p>\n</li>\n<li>\n<p>Manage Experiments</p>\n</li>\n</ul>\n\
          <p>Once these are done, experiments can be executed on selected resources.</p>\n\
          <h4>Resource Management</h4>\n<h5>Adding Resources</h5>\n<p>Nimrod resources\
          \ need to be first added to the database before they can\nbe assigned to\
          \ and used by experiments. Syntax for adding resources is\nas follows:</p>\n\
          <blockquote>\n<p>$ nimrod resource add &lt;resource_type&gt;\n&lt;resource_details&gt;</p>\n\
          </blockquote>\n<p>Resource types supported by Nimrod/G include:</p>\n<ul>\n\
          <li><strong>Fork</strong></li>\n</ul>\n<blockquote>\n<p>$ nimrod resource\
          \ add fork</p>\n</blockquote>\n<ul>\n<li>\n<strong>PBS</strong>\_- With\
          \ PBS we need to know the name of a PBS queue and the\n    &gt; hostname\
          \ of the PBS server. Lets say queue name is\_<strong>workq</strong>\_and\n\
          \    &gt; the hostname is\_<strong>localhost</strong>\n</li>\n</ul>\n<blockquote>\n\
          <p>$ nimrod resource add pbs workq@localhost</p>\n</blockquote>\n<ul>\n\
          <li>\n<p><strong>SGE</strong>\_- Same as PBS</p>\n</li>\n<li>\n<p><strong>EC2</strong></p>\n\
          </li>\n</ul>\n<h5>Removing Resources</h5>\n<p>Syntax for removing resources\
          \ is as follows:</p>\n<blockquote>\n<p>$ nimrod resource remove &lt;resource_type&gt;\n\
          &lt;resource_details&gt;</p>\n</blockquote>\n<h4>Experiment Management</h4>\n\
          <p>This section will describe how to create, monitor and manage Nimrod/G\n\
          experiments.</p>\n<h5>Creating a Plan File</h5>\n<p>Nimrod/G uses a simple\
          \ declarative language to describe the experiments.\nThis description is\
          \ usually written as a simple script file we call\na\_<strong>plan file</strong>.</p>\n\
          <p>There are two sections in this plan file. The first one describes the\n\
          parameters that your experiment has while the second one describes the\n\
          task/s that Nimrod/G needs to execute to complete a single instance (or\n\
          a job) from your experiment. The example below shows a fictional plan\n\
          file for an experiment investigating wing performance.</p>\n<blockquote>\n\
          <p>parameter aircraft_model files select anyof \"A3??.dat\" \"737-*.dat\"\
          ;</p>\n<p>parameter AoA label \"Angle of attack\" float range from -45 to\
          \ 45 step\n2.5;</p>\n<p>parameter winglets text select anyof \"none\" \"\
          fence\" \"blended\" \"raked\";</p>\n<p>parameter airspeed integer range\
          \ from 50 to 600 step 50;</p>\n<p>parameter turbulence label \"Normalized\
          \ Reynolds\" float random from 1\nto 2;</p>\n<p>task main</p>\n<p>copy ${aircraft_model}\
          \ node:.</p>\n<p>copy wing_test.zip node:.</p>\n<p>node:execute unzip wing_test.zip</p>\n\
          <p>node:execute ./run_wing_test.sh ${aircraft_model} ${winglets}\n${AoA}\
          \ \\</p>\n<p>${airspeed} ${turbulence} &gt;&gt; output.${jobname}</p>\n\
          <p>node:execute zip results.${jobname} *</p>\n<p>copy node:results.${jobname}.zip\
          \ .</p>\n<p>endtask</p>\n</blockquote>\n<p>This is a somewhat contrived\
          \ example demonstrating various parameter\ntypes but it illustrates the\
          \ basic functionality of defining parameters\nfor the main task and handling\
          \ input, execution and output for each of\nthe parameter combinations. The\
          \ two subsections below explain the\n'parameter' and 'task' definitions\
          \ in the plan file.</p>\n<h5>Parameters</h5>\n<p>Parameters define lists\
          \ of values, constant single values or dynamic\nvalues (of various types).\
          \ A unique combination of parameter values is\nassigned to each job and\
          \ each parameter value is bound to a named\nidentifier in the job environment.\
          \ Nimrod/G experiments usually create a\ncross-product of all parameters\
          \ to define the jobs which make up the\nexperiment, we call this a full\
          \ parameter sweep. The syntax for\nparameter lines in the plan file is:</p>\n\
          <blockquote>\n<p>parameter &lt;name&gt; &lt;type&gt; [&lt;domain&gt;];</p>\n\
          </blockquote>\n<ul>\n<li>\n<p><strong>name</strong>\_- This is the parameter\
          \ name which must be unique.</p>\n</li>\n<li>\n<p><strong>type</strong>\_\
          - This part of the parameter tells Nimrod/G what type of\n    parameter\
          \ this is. There are five types and they are</p>\n<ul>\n<li>\n<p><strong>float</strong>\_\
          - floating point number</p>\n</li>\n<li>\n<p><strong>integer</strong>\_\
          - integer (whole) number</p>\n</li>\n<li>\n<p><strong>text</strong>\_- textual\
          \ values as shown in the example above</p>\n</li>\n<li>\n<p><strong>files</strong>\_\
          - this type allow you to apply glob style file name\n    matching to create\
          \ a list of files names within the experiment\n    directory which match\
          \ the given pattern(s), you could use this\n    to parameterize the input\
          \ files for your computation (like the\n    example above). The files type\_\
          <strong>must be</strong>\_used with the \"select\n    anyof\" domain.</p>\n\
          </li>\n<li>\n<p><strong>fromfile</strong>\_- this type must refer to a text\
          \ file that contains\n    a list of values, i.e., the file contains the\
          \ entire range.</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>domain</strong>\_\
          - A parameter domain is optional in some cases but\n    usually required.\
          \ The following domains are available:</p>\n<ul>\n<li>\n<strong>default</strong>-\
          \ this domain type has only a single value. The\n    syntax for this domain\
          \ is:</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>default &lt;value</p>\n\
          </blockquote>\n<ul>\n<li>\n<strong>range</strong>\_- this domain type has\
          \ a number of values (points) that\n    are within a specified range. The\
          \ syntax for the range domain is:</li>\n</ul>\n<blockquote>\n<p>range from\
          \ &lt;value&gt; to &lt;value&gt; points &lt;value&gt;</p>\n<p>range from\
          \ &lt;value&gt; to &lt;value&gt; step &lt;value&gt;</p>\n</blockquote>\n\
          <ul>\n<li>\n<strong>random</strong>\_- this domain type has a number of\
          \ random points\n    generated between specified lower and upper bounds.\
          \ The syntax for\n    this domain is</li>\n</ul>\n<blockquote>\n<p>random\
          \ from &lt;value&gt; to &lt;value&gt; [points &lt;value&gt;]</p>\n</blockquote>\n\
          <ul>\n<li>\n<strong>select anyof</strong>\_- this domain type is usually\
          \ used for text and\n    files but is also useful for listing fixed numerical\
          \ values. The\n    syntax for this domain is:</li>\n</ul>\n<blockquote>\n\
          <p>select anyof &lt;value_list&gt; [default &lt;value_list&gt;]</p>\n</blockquote>\n\
          <ul>\n<li>\n<strong>select oneof</strong>\_- Similar to 'select anyof' except\
          \ that only one\n    value will be selected for use from this list. If the\
          \ default value\n    is not specified the first value in the value_list\
          \ is used. The\n    syntax for this domain is:</li>\n</ul>\n<blockquote>\n\
          <p>select oneof &lt;value_list&gt; [default &lt;value&gt;]</p>\n</blockquote>\n\
          <ul>\n<li>\n<strong>(some input file)</strong>\_- when using the fromfile\
          \ type, the domain is\n    an input file that lists the values for the parameter.\
          \ For example:</li>\n</ul>\n<blockquote>\n<p>parameter x fromfile inputfile.txt</p>\n\
          <p>means that\_<strong>inputfile.txt</strong>\_contains a list of single\
          \ values (one per\nline) for parameter\_<strong>x</strong>.</p>\n</blockquote>\n\
          <h5>Tasks</h5>\n<p>This part of the plan file describes the process of executing\
          \ a single\ninstance of your experiment. There are a number of\noperations/commands/directives\
          \ that can be performed in a task:</p>\n<ul>\n<li>\n<p>Copy files to and\
          \ from compute resources</p>\n</li>\n<li>\n<p>Executing an experiment executable</p>\n\
          </li>\n<li>\n<p>Substituting place-holders in the input files with the real\
          \ values</p>\n</li>\n<li>\n<p>What to do in case the job fails.</p>\n</li>\n\
          </ul>\n<p>Task operations are typically location\ndependent.\_<strong>copy</strong>\_\
          and\_<strong>execute</strong>\_directives must specify where the\noperation\
          \ should be performed or where the file locations are while\ncopying. This\
          \ is done by using\_<strong>node:</strong>\_or\_<strong>root:</strong>\_\
          modifiers.</p>\n<ul>\n<li>\n<p><strong>node:</strong>\_indicates remote\
          \ location for the operation. In case\n    of\_<strong>copy</strong>\_operation\
          \ it indicates that the file resides on remote\n    machine, while in case\
          \ of <strong>execute</strong>\_command it indicates that the\n    executable\
          \ should be run on the remote server.</p>\n</li>\n<li>\n<p><strong>root:</strong>\_\
          on the other hand indicates that files are on the same\n    machine where\
          \ Nimrod/G is running, and that\_<strong>execute</strong>\_command that\n\
          \    executables are to be run on that same machine, and not on the\n  \
          \  remote server. Please note that\_<strong>root:execute</strong>\_can only\
          \ be\n    executed in\_<strong>rootstart</strong>\_and\_<strong>rootfinish</strong>tasks.</p>\n\
          </li>\n</ul>\n<p><strong>NOTE</strong>: In a typical parameter sweep all\
          \ program invocations will\noccur on computational nodes and hence the main\
          \ task will only use\n<strong>node:execute</strong>.</p>\n<p>Following is\
          \ a more thorough description of the task operations:</p>\n<ul>\n<li>\n\
          <strong>copy</strong>\_- this operation is used to copy both input and\n\
          \    &gt; output files. Syntax for this operations is as follows:</li>\n\
          </ul>\n<blockquote>\n<p>copy &lt;source&gt; &lt;destination&gt;</p>\n<p>For\
          \ example if you are copying input file to a remote location:</p>\n<p>copy\
          \ root:input.txt node:input.txt</p>\n<p>And if you are copying output file\
          \ back to the server where Nimrod/G\nis running:</p>\n<p>copy node:result.txt\
          \ root:result.txt</p>\n</blockquote>\n<ul>\n<li>\n<strong>execute</strong>\_\
          - this operation is used to execute some executable. The\n    syntax for\
          \ this operatio is:</li>\n</ul>\n<blockquote>\n<p>node:execute &lt;user_command&gt;</p>\n\
          <p><strong>user_command</strong>\_is passed to shell (<strong>/bin/sh</strong>),\
          \ so it can contain\nshell constructs (redirection like &gt;, &gt;&gt; etc).</p>\n\
          <p>For example if we wanted to execute\_<strong>hostname</strong>\_command\
          \ and redirect\nits output into a file called\_<strong>hostname.txt</strong>\_\
          this is what\nthe\_<strong>execute</strong>operation would look like:</p>\n\
          <p>node:execute /bin/hostname &gt; hostname.txt</p>\n</blockquote>\n<ul>\n\
          <li><strong>onerror\_- this operation indicates how Nimrod/G should behave\
          \ in\n    case some part of the job fails. It has a scope which is from\
          \ the\n    point it appears until another\_onerror\_statement is found.\
          \ The\n    syntax for this operation is:</strong></li>\n</ul>\n<blockquote>\n\
          <p>onerror &lt;option&gt;</p>\n<p>Valid options are:</p>\n</blockquote>\n\
          <ul>\n<li>\n<p><strong>fail</strong>\_- fail the job. This is the default\
          \ behaviour and will be\n    &gt; used even if\_<strong>onerror</strong>\_\
          is never specified in the plan file</p>\n</li>\n<li>\n<p><strong>ignore</strong>\_\
          - ignore the error and proceed with the task, ie. move\n    &gt; onto the\
          \ next line in the plan file and continue executing it.</p>\n</li>\n</ul>\n\
          \n\n<ul>\n<li>\n<strong>substitute</strong>\_- Nimrod/G allows can use skeleton\
          \ input file for\n    &gt; their experiments. This skeleton input file may\
          \ contain\n    &gt; placeholders in it that are to be substituted by the\
          \ actual\n    &gt; parameter values before the execution begins.</li>\n\
          </ul>\n<blockquote>\n<p>This operation is used to replace the parameter\
          \ placeholders in input\nfile with a job parameter value. The syntax of\
          \ this operation is:</p>\n<p>substitute &lt;source&gt; &lt;destination&gt;</p>\n\
          <p>Both source and destination require neither 'node:' nor 'root:' in\n\
          front of them, i.e. they are just plain filenames. For example, this\ncould\
          \ be a main task of a plan file:</p>\n<p>task main</p>\n<p>copy input.skeleton\
          \ node:.</p>\n<p>substitute input.skeleton input.txt</p>\n<p>node:execute\
          \ ./process.sh input.txt &gt; result.txt</p>\n<p>copy node:result.txt .</p>\n\
          <p>endtask</p>\n</blockquote>\n<h4>Creating Experiments</h4>\n<p>Nimrod/G\
          \ stores experiments in a specific location in user's home\ndirectory:</p>\n\
          <blockquote>\n<p>$HOME/.nimrod/experiments/</p>\n</blockquote>\n<p>Each\
          \ experiment will have a dedicated subdirectory in that location that\n\
          matches experiment name. For example:</p>\n<ul>\n<li>\n<p>Experiment named\_\
          <strong>demo</strong>\_will be\n    &gt; in\_<strong>$HOME/.nimrod/experiments/demo/</strong></p>\n\
          <ul>\n<li>\n<p>Plan file called\_<strong>demo.pln</strong>\_will be in that\
          \ directory</p>\n</li>\n<li>\n<p>All files related to that experiment will\
          \ also be location in\n    &gt; that directory</p>\n</li>\n</ul>\n</li>\n\
          </ul>\n<p>In order to create experiment execute the following steps:</p>\n\
          <ol>\n<li>\n<p>Create a plan file following instructions from the previous\
          \ section.\n    &gt; Lets assume we create a plan file called\_<strong>demo.pln</strong></p>\n\
          </li>\n<li>\n<p>Create an experiment directory:</p>\n</li>\n</ol>\n<blockquote>\n\
          <p>$ mkdir -p $HOME/.nimrod/experiments/demo</p>\n</blockquote>\n<ol>\n\
          <li>\n<p>Place the\_demo.pln\_file in that directory</p>\n</li>\n<li>\n\
          <p>Create a file containing all possible parameter combinations:</p>\n</li>\n\
          </ol>\n<blockquote>\n<p>nimrod generate demo.pln</p>\n</blockquote>\n<ol>\n\
          <li>Add the experiment to the Nimrod/G database:</li>\n</ol>\n<blockquote>\n\
          <p>nimrod create demo</p>\n</blockquote>\n<h4>Assign Resources to Experiments</h4>\n\
          <p>In section\_Resource Management\_we added compute resources to the\n\
          database. In order for them to be used by an experiment they have to be\n\
          assigned to that experiment. The syntax for adding resources to\nexperiments\
          \ is as follows:</p>\n<blockquote>\n<p>nimrod addserver &lt;exp_name&gt;\
          \ &lt;resource_details&gt;\n&lt;resource_type&gt;</p>\n</blockquote>\n<p>Resource\
          \ type and resource details are exact same details that were used\nwhen\
          \ resources were added to database. An example of adding a PBS\nresource\
          \ to a demo experiment can be seen below:</p>\n<blockquote>\n<p>nimrod addserver\
          \ demo workq@localhost pbs</p>\n</blockquote>\n<h4>Launching Nimrod/G</h4>\n\
          <p>With experiments defined and configured Nimrod/G can be launched. The\n\
          syntax for this command is as follows:</p>\n<blockquote>\n<p>nimrod startexp\
          \ &lt;exp_name&gt;</p>\n</blockquote>\n<p>For example, to start the experiment\
          \ called\_demo\_run:</p>\n<blockquote>\n<p>nimrod startexp demo</p>\n</blockquote>\n\
          <h3>Using Nimrod/K</h3>\n<p>Nimrod/K extends\_Kepler by adding parameter\
          \ tools and grid/cloud\nservices and by providing dynamic parallelism in\
          \ workflows. As such\nNimrod/K functionality is simply used by adding the\
          \ Nimrod/K director\nand Nimrod/K actors to Kepler workflows.</p>\n<h3>Using\
          \ Nimrod/O</h3>\n<p>A comprehensive manual for Nimrod/O can be downloaded\
          \ from:</p>\n<p><a href=\"http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf\"\
          >http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf</a>.</p>\n\
          <p>It contains information on how to launch Nimrod/O.</p>\n<h2>Resource\
          \ Requirements</h2>\n<p>Nimrod Toolkit runs on Unix based platforms only,\
          \ which includes all\nflavours of Linux as well as Mac OS X. However, Nimrod\
          \ Portal component\nis browser based which allows users of all platforms\
          \ (including Windows)\nto access Nimrod and execute computational experiments\
          \ through any\nbrowser.</p>\n<ul>\n<li>\n<p>Software Requirements:</p>\n\
          <ul>\n<li>\n<p>Python \u2013 version 2.5 or higher</p>\n</li>\n<li>\n<p>PostgreSQL\
          \ \u2013 version 8.4 or higher</p>\n</li>\n</ul>\n</li>\n<li>\n<p>Operating\
          \ System Requirements</p>\n<ul>\n<li>\n<p>Linux</p>\n</li>\n<li>\n<p>Mac\
          \ OS X</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>Nimrod/O can run in standalone\
          \ mode, in which case Nimrod/G is not\nrequired. However in standalone mode\
          \ Nimrod/O loses the ability to run\nits jobs on distributed clusters and\
          \ computational grid resources.\nFor distributing jobs, Nimrod/G 4.0 or\
          \ higher required</p>\n<p>Similar to Nimrod/O, Nimrod/K can run as a standalone\
          \ application, in\nwhich case Nimrod/G is not required. When running in\
          \ standalone mode\nNimrod/K can be installed and used on Windows machines.</p>\n\
          <h3>Compute Resources</h3>\n<p>Nimrod allows computational researchers to\
          \ use a mixture of\nuniversity-level infrastructure and commercial clouds.\
          \ For beginners,\nusers can trial their Nimrod experiments using the Nimrod_Portal[^1]\n\
          resource pool. Users are encouraged to bring their own compute resources\n\
          (e.g. cluster, cloud allocation) to use with Nimrod. Please contact Minh\n\
          Dinh and Hoang Anh Nguyen regarding adding new remote compute resources\n\
          to their experiments.</p>\n<h2>Nimrod Portal</h2>\n<p>A web service for\
          \ using Nimrod/G. Nimrod portal provides a web interface\nfor users to use\
          \ Nimrod and its resources. Users can create Nimrod/G\nexperiments without\
          \ installing Nimrod toolkit on their local system.\nThis allows users develop,\
          \ execute, maintain and share Nimrod parameter\nsweep experiments.</p>\n\
          <h3>Installation</h3>\n<p>Nimrod portal consists of two components: a RESTful\
          \ Web service and a\nWeb portal. The RESTful service is to expose Nimrod\
          \ functionality to the\nWeb and the Web portal provides user-friendly interface\
          \ to the users.</p>\n<p>The installation process requires two steps: installation\
          \ of the Web\nservice and installation of the Web portal. This two-step\
          \ process takes\nplace in two separate VMs. Nimrod needs to be installed\
          \ in the Web\nservice VM.</p>\n<h4>Install Nimrod Web service</h4>\n<p>The\
          \ Web service is currently available at:\n<a href=\"https://bitbucket.org/jhtngu/nimrod.webservice\"\
          >https://bitbucket.org/jhtngu/nimrod.webservice</a>.</p>\n<p>This is not\
          \ a public repository. Please email <a href=\"mailto:hoangnguyen177@gmail.com\"\
          >hoangnguyen177@gmail.com</a>\nto gain access.</p>\n<ul>\n<li>Once clone\
          \ the repository, modify the buildout.cfg as followed</li>\n</ul>\n<blockquote>\n\
          <p>[sources]</p>\n<p>Nimrodrestapi = git\nhttps://yournamehere@bitbucket.org/jhtngu/nimrod.restfulweb.git\n\
          branch=addresources</p>\n<p>nimrodrpcdaemon = git https:// yournamehere\n\
          @bitbucket.org/jhtngu/nimrod.rpcdaemon.git branch=addresources</p>\n</blockquote>\n\
          <ul>\n<li>\n<p>Execute \u201Cpython bootstrap.py\u201D to setup the environment.\
          \ This\n    requires setuptools installed.</p>\n</li>\n<li>\n<p>Execute\
          \ \u201C./bin/buildout\u201D to clone and install necessary packages,\n\
          \    including Nimrod Web service.</p>\n</li>\n<li>\n<p>Install any missing\
          \ dependencies as suggested by the build process.</p>\n</li>\n<li>\n<p>Modify\
          \ configuration files in the \u201Cetc\u201D folder accordingly.</p>\n</li>\n\
          </ul>\n<h4>Install the Web portal</h4>\n<ul>\n<li>\n<p>Install Liferay 6.1\n\
          \    (<a href=\"http://sourceforge.net/projects/lportal/files/Liferay%20Portal/6.1.1%20GA2/\"\
          >http://sourceforge.net/projects/lportal/files/Liferay%20Portal/6.1.1%20GA2/</a>).\n\
          \    The recommended location is: /var/www.</p>\n</li>\n<li>\n<p>Follow\
          \ Liferay instructions to install with Postgres DB\n    (<a href=\"https://www.liferay.com/community/wiki/-/wiki/Main/Quick+Installation+Instructions\"\
          >https://www.liferay.com/community/wiki/-/wiki/Main/Quick+Installation+Instructions</a>)</p>\n\
          </li>\n<li>\n<p>Go to Liferay market and install Private Plugin Installer\n\
          \    (<a href=\"https://www.liferay.com/marketplace/-/mp/application/15474932\"\
          >https://www.liferay.com/marketplace/-/mp/application/15474932</a>)</p>\n\
          </li>\n<li>\n<p>Install Vaadin into Liferay\n    (<a href=\"https://vaadin.com/wiki/-/wiki/Main/Integrating+Vaadin+7+with+Liferay\"\
          >https://vaadin.com/wiki/-/wiki/Main/Integrating+Vaadin+7+with+Liferay</a>)</p>\n\
          </li>\n<li>\n<p>Install Nimrod portlets, which are available at:\n    <a\
          \ href=\"https://bitbucket.org/hoangnguyen177/nimrodportal2\">https://bitbucket.org/hoangnguyen177/nimrodportal2</a>.\
          \ Or contact\n    <a href=\"mailto:hoangnguyen177@gmail.com\">hoangnguyen177@gmail.com</a>\
          \ for compiled version.</p>\n</li>\n<li>\n<p>Install Nimrod portlets</p>\n\
          </li>\n</ul>\n<h4>Configure the portal and the Web service VM</h4>\n<p>From\
          \ NeCTAR dashboard, make sure the port of the Web service (8081 by\ndefault)\
          \ is accessible by the Web portal and Nimrod ports (40000 -\n41000) are\
          \ accessible by all.</p>\n<h3>Launch</h3>\n<p>Launch the Web portal first:</p>\n\
          <blockquote>\n<p>cd /var/www/liferay-portal-xxxx/tomcat-xxx/bin; sudo ./startup.sh</p>\n\
          </blockquote>\n<p>Then launch the Web service:</p>\n<blockquote>\n<p>cd\
          \ \\~/nimrod.webservice/bin; ./supervisord;</p>\n</blockquote>\n<h3>Plan\
          \ file web editor</h3>\n<p>Instead of using a text editor, the Nimrod Portal\
          \ provides a simple\nfriendly GUI for users to develop plan file for Nimrod/G\
          \ experiments.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/nimrod_qcif1.png?raw=true\"\
          ></p>\n<h2>How to access it</h2>\n<p>Interested users can register for an\
          \ account using their AAF credential\nat the following page (will need to\
          \ be updated later):\n<a href=\"http://vm-203-101-224-118.qld.nectar.org.au/\"\
          >http://vm-203-101-224-118.qld.nectar.org.au/</a></p>\n<p>The portal provides\
          \ a friendly web interface for users to define,\nexecute and monitor their\
          \ experiments. For users who have existing\nNimrod experiments, they can\
          \ upload the plan files. User can also create\nnew experiments using a simple\
          \ GUI. Input and output files can be\nuploaded and downloaded using the\
          \ web interface. For technical supports\nand learning to use Nimrod, please\
          \ contact Minh Dinh and/or Hoang Anh\nNguyen.</p>\n<h2>Configuration guide</h2>\n\
          <h3>Configuring Nimrod/G</h3>\n<p>Nimrod/G installation comes with two configuration\
          \ files, both located\nin\_<strong>$NIMROD_INSTALL</strong>\_directory:</p>\n\
          <ul>\n<li>\n<p><strong>nimrod.cfg</strong>\_- Configuration values contained\
          \ within can be\n    overridden by a user level configuration file of the\
          \ same name,\n    which may be located in $HOME/.nimrod/ directory, or by\
          \ an\n    immutable configuration file described below.</p>\n</li>\n<li>\n\
          <p><strong>nimrod.immutable.cfg</strong>\_- Configuration values contained\
          \ within\n    will override any other configuration, either user or system\
          \ level.</p>\n</li>\n</ul>\n<p>Most of the configuration values can be left\
          \ as is but some may be\nchanged to match the system requirements.</p>\n\
          <p>Each configuration file may contain following sections:</p>\n<ul>\n<li>\n\
          <p><strong>email</strong>\_- used to configure email settings. This is used\
          \ to report\n    experiment completion.</p>\n</li>\n<li>\n<p><strong>nimserver</strong>\_\
          - configures Nimrod/G component called Nimrod Server.\n    Nimrod/G uses\
          \ executables called\_<strong>Agents</strong>\_to execute jobs on\n    remote\
          \ resources.\_<strong>Agents</strong>\_use Nimrod Server to communicate\
          \ with\n    database as well as to copy files to and from remote locations.</p>\n\
          </li>\n</ul>\n<blockquote>\n<p>Most of the configuration can be left as\
          \ is. It is important however\nto ensure that\_<strong>default_port_range</strong>\_\
          configuration value has a\nrange of ports that can be reached by outside\
          \ networks. When it\nstarts,\_<strong>Nimrod Server</strong>\_will select\
          \ a first available port from that\nrange and will use that to listen for\
          \ incoming connectinos\nfrom\_<strong>Agents</strong>. If the port it selects\
          \ is unreachable, no jobs will\nrun.</p>\n<p>For example (port will be selected\
          \ anywhere between 30000 and 31000\ninclusive):</p>\n<p>nimserver: {</p>\n\
          <p>default_port_range: '30000,31000'</p>\n<p>key_path: $user_dir + '.nimserver'</p>\n\
          <p>remote_suffix: $remote_suffix</p>\n<p>remote_key_fname: '.nimserver'\
          \ + $nimserver.remote_suffix + '.pub'</p>\n<p>port_path: $user_dir + '.nimport'\
          \ + $nimserver.remote_suffix</p>\n<p>remote_port_fname: '.nimport' + $nimserver.remote_suffix</p>\n\
          <p>}</p>\n</blockquote>\n<ul>\n<li>\n<p><strong>actuator</strong>\_- configures\
          \ resource actuators, components that\n    control how resources are used.\
          \ It can be used to change how often\n    actuators poll database to see\
          \ if there are any work they need\n    to do. Configuration can apply to\
          \ actuators for all resource types,\n    but can also only apply to a specific\
          \ resource type.</p>\n</li>\n<li>\n<p><strong>azure</strong>\_- configure\_\
          <strong>azure</strong>\_resource settings. Can be left\n    as is.</p>\n\
          </li>\n<li>\n<p><strong>ec2</strong>\_- configures\_<strong>ec2</strong>\_\
          resource settings. Can be left as is</p>\n</li>\n<li>\n<p><strong>generate</strong>\_\
          - configures\_<strong>generate</strong>\_subcommand. This subcommand\n \
          \   is used to parse the plan file and create another files that\n    contains\
          \ a cross-product of all parameters. Some of the settings\n    include limits\
          \ on how many jobs single experiment can have, or how\n    long a parameter\
          \ name can be.</p>\n</li>\n</ul>\n<blockquote>\n<p>For example:</p>\n<p>generate:\
          \ {</p>\n<p>max_jobs: 100000</p>\n<p>param_len_limit: 56</p>\n<p>}</p>\n\
          </blockquote>\n<h3>Configuring Nimrod/K</h3>\n<p>There is no Nimrod/K specific\
          \ configuration.</p>\n<h3>Configuring Nimrod/O</h3>\n<p>A comprehensive\
          \ manual for Nimrod/O can be downloaded from:</p>\n<p><a href=\"http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf\"\
          >http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf</a>.</p>\n\
          <p>It contains information on how to configure Nimrod/O.</p>\n<h2>Technical\
          \ blueprint</h2>\n<p>To date, Nimrod tools are deployed through several\
          \ Nimrod portals\nstationed at Monash University, Griffith University and\
          \ The University\nof Queensland. These portals provide the machinery to\
          \ automate the tasks\nof formulating complex experiments and workflows,\
          \ and execute them\nacross a variety of computing resources including NecTAR\
          \ VMs. In\nparticular, we ran several projects to test the migration of\
          \ scientific\nsoftware to HPC platforms, including the NeCTAR research cloud,\
          \ to\nprovide enhanced utility for the following research projects.</p>\n\
          <h3>Terrestrial Ecosystem Research Network (TERN)</h3>\n<p>Supporting the\
          \ creation and execution of sensory data analysis using\nNimrod portal to\
          \ access available computing resources in the NecTAR\ncloud.</p>\n<p><img\
          \ alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/nimrod_qcif2.png?raw=true\"\
          ></p>\n<h3>CVL Symmetric Model Creation</h3>\n<p>Coupling Nimrod to perform\
          \ expensive computations efficiently and\nintegrating visualization library\
          \ to enable examination of intermediate\nmodels.</p>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/nimrod_qcif3.png?raw=true\"\
          ></p>\n<h3>MARXAN</h3>\n<p>Coupling the MARXAN web portal with Nimrod to\
          \ provide access to HPC and\ncloud resources.</p>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/nimrod_qcif4.png?raw=true\"\
          ></p>\n<h2>Troubleshooting</h2>\n<p>There are multiple points of failure\
          \ that are possible when running\nNimrod/G experiments:</p>\n<ul>\n<li>Problem\
          \ with executables (applications) that Nimrod/G is trying to\n    execute</li>\n\
          </ul>\n<blockquote>\n<p>These will be reported back to database. In scenario\
          \ like this is\nhighly possible that all jobs will fail because of it. However\
          \ the\nproblem can be environmental in which case it will only fail on a\n\
          particular resource or even a particular machine on that resource.</p>\n\
          </blockquote>\n<ul>\n<li>Problem with remote machines where Nimrod Agents\
          \ are running</li>\n</ul>\n<blockquote>\n<p>These kind of problems occur\
          \ when a particular machine on a\ncomputational resource is not working\
          \ correctly. There are many\nreasons this may occur, which includes missing\
          \ libraries, faulty\nhardware etc.</p>\n<p>If the agents manage to start\
          \ then these are easy to identify. Nimrod\nAgents will fail the jobs and\
          \ record which host the job failed on.\nListing failed jobs, and seeing\
          \ that all failed on a particular host\nwill indicate a problem with that\
          \ host.</p>\n</blockquote>\n<ul>\n<li>Firewall issues preventing Nimrod\
          \ Agents connecting back to Nimrod\n    Server</li>\n</ul>\n<blockquote>\n\
          <p>If Agents are perpetually stuck in\_<strong>pending/queued</strong>\_\
          state, it\nusually indicates that they cannot connect back to Nimrod Server.\
          \ One\nreason is that there is a faulty host and\_<strong>Agents</strong>\_\
          never start, and\nsecond reason is that firewall on either host is preventing\n\
          those\_<strong>Agents</strong>\_connections.</p>\n</blockquote>\n<p>There\
          \ are number of commands that can be executed to collect information\nthat\
          \ may help identify the issue:</p>\n<ol>\n<li>Get reported errors</li>\n\
          </ol>\n<blockquote>\n<p>$ nimrod geterrors &lt;exp_name&gt;</p>\n</blockquote>\n\
          <ol>\n<li>Check if there are any agents running on resources</li>\n</ol>\n\
          <blockquote>\n<p>$ nimrod getagents &lt;exp_name&gt;</p>\n<p>Output returns\
          \ a list of resources where each line has the resource\nname and agent information\
          \ in following order:</p>\n</blockquote>\n<ul>\n<li>\n<p>Agents that have\
          \ stopped running (cleanly)</p>\n</li>\n<li>\n<p>Agents that are still running</p>\n\
          </li>\n<li>\n<p>Agents that have been submitted to a remote queue</p>\n\
          </li>\n<li>\n<p>Agents that have been created in database, but not submitted\
          \ to a\n    remote queue</p>\n</li>\n<li>\n<p>Agents that have failed to\
          \ start. Some agents may fail to start but\n    won't be reported here.\
          \ This will occur if firewall is blocking\n    the connections.</p>\n</li>\n\
          <li>\n<p>Check the progress of experiment and see if there any failed jobs:</p>\n\
          </li>\n</ul>\n<blockquote>\n<p>$ nimrod enfapi &lt;exp_name&gt; jobstatus</p>\n\
          </blockquote>\n<ol>\n<li>If there are failed jobs, get errors for all failed\
          \ jobs:</li>\n</ol>\n<blockquote>\n<p>$ nimrod enfapi &lt;exp_name&gt; getjobinfo\
          \ all error</p>\n</blockquote>\n<h2>Support</h2>\n<h3>Administration</h3>\n\
          <p>Please contact Hoang Anh Nguyen or Minh Dinh for the Nimrod Portal</p>\n\
          <h3>Technical Support</h3>\n<p>All queries regarding the for the Nimrod\
          \ Portal and WorkWays portal,\nplease contact Hoang Anh Nguyen or Minh Dinh</p>\n\
          <h3>Learning to use Nimrod or integrating Nimrod into your internal service</h3>\n\
          <p>Please contact Minh Dinh regarding learning to use Kepler and Nimrod.\n\
          For consultation on how Kepler and Nimrod can be applicable for specific\n\
          research fields, please contact Minh Dinh.</p>\n<h2>Contact</h2>\n<p>Dr\
          \ Minh Dinh</p>\n<p>QCIF - eResearch Analyst</p>\n<p>Reserch Fellow - Research\
          \ Computing Center (RCC)</p>\n<p>Email: <a href=\"mailto:m.dinh1@uq.edu.au\"\
          >m.dinh1@uq.edu.au</a></p>\n<p>Mr Hoang Anh Nguyen</p>\n<p>Email: <a href=\"\
          mailto:hoangnguyen177@gmail.com\">hoangnguyen177@gmail.com</a></p>\n<h2>Glossary\
          \ of Terms</h2>\n<p>[^1]: Nimrod_Portal is a Nectar allocation that consists\
          \ of up 120\n    compute cores. It is designated for deploying Nimrod services\
          \ and\n    conducting Nimrod runs. It is an independent testbed for new\
          \ users\n    to trial Nimrod and its tools</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000095294
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-07T20:00:50-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000095294
        position: 14
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: QCIF Nimrod
        updated_at: '2015-12-07T20:00:50-05:00'
        user_id: 6002464727
  html: "<h1>Nimrod toolkit for high throughput computing in the cloud</h1>\n<h2>Introduction</h2>\n\
    <p>The Nimrod tool family facilitates high-throughput science by allowing\nresearchers\
    \ to use computational models to explore complex design\nspaces. Models can be\
    \ executed across changing input parameters.\nDifferent members of the tool family\
    \ support complete and partial\nparameter sweeps, numerical search by non-linear\
    \ optimisation, and even\nworkflows. Further, Nimrod allows computational researchers\
    \ to use a\nmixture of university-level infrastructure and commercial clouds.</p>\n\
    <p>There are several \u2018flavours\u2019 of Nimrod. Which Nimrod you choose to\
    \ use,\neither singly, or in combination, will depend on the kind of experiment\n\
    you want to run.</p>\n<h3>Nimrod/G</h3>\n<p>Nimrod/G can directly execute large-scale\
    \ distributed parameter sweep\nand Monte-Carlo computational experiments. It provides\
    \ a simple means to\ndramatically scale-up your computational experiments. Each\
    \ experiment\ncan run over an aggregated ad-hoc computational grid/pool/cloud;\
    \ start\nfrom your desktop, local server or cluster; add grid resources (e.g.\n\
    clusters and Condor pools); overflow to pay-as-go cloud services and\ncontrol\
    \ your budget with Nimrod/G's economic scheduling capabilities.</p>\n<h3>Nimrod/K</h3>\n\
    <p>Nimrod/K is built on Kepler using Kepler\u2019s runtime engine Ptolemy. It\n\
    extends Kepler by adding parameter tools and grid/cloud services and by\nproviding\
    \ dynamic parallelism in workflows.</p>\n<p>It uses a dataflow execution model\
    \ that was originally developed for\nhighly parallel dataflow computers in the\
    \ 1980\u2019s, and this provides an\nextremely rich execution mechanism. It leverages\
    \ a number of the\ntechniques developed in the earlier Nimrod tools for distributing\
    \ tasks\nto the Grid.</p>\n<h3>Nimrod/O</h3>\n<p>Provides an optimisation framework\
    \ for optimising a target output value\nof an application. It allows a user to\
    \ run an arbitrary computational\nmodel as the core of a non-linear optimization\
    \ process. Nimrod/O allows\na user to specify the domain and type of parameters\
    \ to the model, and\nalso a specification of which output variable is to be minimized\
    \ or\nmaximized. Accordingly, a user can formulate a question like: what\nparameter\
    \ settings will minimize the model output? Nimrod/O currently\nemploys a number\
    \ of built-in optimization algorithms:</p>\n<ul>\n<li>\n<p>BFGS</p>\n</li>\n<li>\n\
    <p>Simplex</p>\n</li>\n<li>\n<p>Divide and Conquer</p>\n</li>\n<li>\n<p>Simulated\
    \ Annealing.</p>\n</li>\n</ul>\n<p>Jobs can be executed on a variety of platforms,\
    \ which when combined with\nNimrod/G includes distributed clusters and Computational\
    \ Grid resources.</p>\n<h2>Target Audience</h2>\n<p>The following research activities\
    \ can benefit from using Nimrod.</p>\n<ol>\n<li>\n<p>You need to run your computational\
    \ model many times and average the\n    results because the model is stochastic.\
    \ These types of Monte Carlo\n    simulations are greatly facilitated by Nimrod/G.\
    \ It will generate\n    multiple jobs, furnishing them with different random number\
    \ seeds\n    and execute them concurrently on the grid.</p>\n</li>\n<li>\n<p>You\
    \ wish to explore the effect of varying the inputs to your model.\n    Inputs\
    \ may be in the form of command line parameters or of values in\n    some input\
    \ file; in Nimrod these are both called parameters. Either\n    way Nimrod/G will\
    \ let you specify values for each parameter, will\n    generate the jobs for all\
    \ possible combinations of these values and\n    execute the jobs on the Grid.</p>\n\
    </li>\n<li>\n<p>You wish to explore the effect of input parameters but for certain\n\
    \    combinations are not allowed. There are several possible ways to\n    do\
    \ this. If the disallowed combinations give jobs that quickly fail\n    then you\
    \ may schedule all possible combinations and let those bad\n    jobs fail. However,\
    \ if those jobs will use substantial resources\n    then it would be better to\
    \ filter them out first. This can be done\n    in Nimrod/G by processing the run\
    \ file. Alternatively Nimrod/O may\n    be used in sweep mode as it provides the\
    \ functionality to add\n    formulas for constraints on the parameters.</p>\n\
    </li>\n<li>\n<p>You are running several different experiments. They may produce\
    \ some\n    jobs with the same inputs and you don't want to waste resources\n\
    \    duplicating these jobs. Nimrod/O can be invoked with a persistent\n    cache\
    \ shared by the experiments, so avoiding duplications.</p>\n</li>\n<li>\n<p>You\
    \ wish to find the combination of input parameters that produce an\n    optimal\
    \ output. Nimrod/O allows you to specify the inputs that vary,\n    any constraints\
    \ on those inputs, and the output to be maximized\n    or minimized. It offers\
    \ a selection of search methods for finding\n    the optimum. Multiple searches,\
    \ perhaps using different optimization\n    methods, may be run in parallel.</p>\n\
    </li>\n<li>\n<p>You want to find the inputs that generate the best output. Nimrod/O\n\
    \    allows optimization where human input may be used to assess the\n    quality\
    \ of an output. This is especially useful for complex outputs\n    such as images\
    \ or animations.</p>\n</li>\n<li>\n<p>There are several aspects of your model\
    \ output that you wish\n    to optimize. Nimrod/O is currently being modified\
    \ to facilitate such\n    multi-objective optimization.</p>\n</li>\n<li>\n<p>You\
    \ wish to perform multiple optimizations on the output of your\n    model, one\
    \ optimization for each combination of some\n    parameter settings. This can\
    \ be done using Nimrod/G to sweep over\n    the setting and having it call Nimrod/O\
    \ to do each optimization.</p>\n</li>\n<li>\n<p>You wish to run your model in\
    \ reverse. In other words you want to\n    find the input values that will produce\
    \ a given output. Nimrod/O is\n    commonly used for this task. You need to have\
    \ a way of measuring the\n    discrepancy between your output and the desired\
    \ one. Then run an\n    optimization to minimize this discrepancy.</p>\n</li>\n\
    <li>\n<p>You have developed your own optimization method. You wish to use the\n\
    \    method, taking advantage of the distributed execution of jobs and\n    the\
    \ caching supplied in Nimrod/O.</p>\n</li>\n<li>\n<p>Different parts of your model\
    \ need to run on different machines\n    because of data files perhaps or licence\
    \ requirements. Nimrod/G can\n    schedule such workflow experiments and perform\
    \ the appropriate\n    communication between the parts. Where possible a downstream\n\
    \    component may start processing its input file before an upstream\n    component\
    \ has completed that file.</p>\n</li>\n<li>\n<p>Some of your model executions\
    \ require prior execution of\n    other models. Nimrod/G can handle such dependencies.</p>\n\
    </li>\n</ol>\n<h2>How to install</h2>\n<p>Nimrod allows computational researchers\
    \ to use a mixture of\nuniversity-level infrastructure and commercial clouds.</p>\n\
    <p>Users can trial their Nimrod experiments using the Nimrod Portal\nresource\
    \ pool. Users are encouraged to bring their own compute resources\n(e.g. cluster,\
    \ cloud allocation) to use with Nimrod. Please contact Minh\nDinh and Hoang Anh\
    \ Nguyen regarding adding new remote compute resources\nto their experiments.</p>\n\
    <p>Users can still opt to install Nimrod Toolkit on their local system,\nprovided\
    \ that system meets the software and operating system\nrequirements outlined in\
    \ the Resource Requirements section. If the user\nchooses to do that, here are\
    \ step by step procedures for installing\nindividual Nimrod Toolkit.</p>\n<h3>Installing\
    \ Nimrod/G</h3>\n<p>Users must executed the following steps to install Nimrod/G:</p>\n\
    <ol>\n<li>\n<p>Download Nimrod/G source distribution</p>\n</li>\n<li>\n<p>Setup\
    \ Nimrod/G environment</p>\n</li>\n<li>\n<p>Create experiments directory</p>\n\
    </li>\n<li>\n<p>Install Nimrod/G</p>\n</li>\n<li>\n<p>Setup Nimrod/G database</p>\n\
    </li>\n</ol>\n<h4>Download Nimrod/G Distribution</h4>\n<p>Download from following\
    \ link:</p>\n<ul>\n<li>https://messagelab.monash.edu.au/Downloads</li>\n</ul>\n\
    <p>Download the Nimrod/G source archive to your home directory, which\nshould\
    \ create a file:</p>\n<ul>\n<li><strong>$HOME/nimrodg-[version].tar.gz</strong></li>\n\
    </ul>\n<h4>Setup Nimrod/G Environment</h4>\n<p>We recommend editing your shell\_\
    <strong>rc</strong>\_scripts\n(<strong>.profile</strong>\_or\_<strong>.bashrc</strong>\_\
    or\_<strong>.cshrc</strong>, etc), or adding\nan\_<strong>/etc/profile.d/nimrod.sh</strong>\_\
    script for system-wide installs.\nFor\_<strong>sh</strong>\_based shells you will\
    \ need something like (paths should be\naltered as appropriate for your install/system):</p>\n\
    <blockquote>\n<p>export NIMROD_INSTALL=$HOME/bin/nimrodg export\nNIMROD_DATABASE=pgsql-pool</p>\n\
    <p>export PSQL_LOCATION=/usr/bin # in this case /usr/bin/psql should be\na valid\
    \ path</p>\n<p>export PYTHONPATH=${NIMROD_INSTALL}/share/nimrod:${PYTHONPATH}\\\
    \nexport PATH=${NIMROD_INSTALL}/bin:${PATH}</p>\n</blockquote>\n<h4>Create Experiments\
    \ Directory</h4>\n<p>Nimrod/G keeps all the experiments it runs in a subdirectory\
    \ of user's\nhome directory\_$HOME/.nimrod/experiments. Create that directory\
    \ by\nexecuting the following command:</p>\n<blockquote>\n<p>$ mkdir -p $HOME/.nimrod/experiments</p>\n\
    </blockquote>\n<h4>Install Nimrod/G</h4>\n<ol>\n<li>Decompress Nimrod/G source\
    \ archive. Let\u2019s assume we downloaded a\n    source archive for Nimrod/G\
    \ version 4.0.2:</li>\n</ol>\n<blockquote>\n<p>$ cd $HOME</p>\n<p>$ tar -zxvf\
    \ nimrodg-4.0.2.tar.gz</p>\n</blockquote>\n<ol>\n<li>Configure and install Nimrod/G</li>\n\
    </ol>\n<blockquote>\n<p>$ cd nimrodg-4.0.2</p>\n<p>$ ./configure --prefix=$NIMROD_INSTALL</p>\n\
    <p>$ make; make install</p>\n</blockquote>\n<h4>Setup Nimrod/G Database</h4>\n\
    <p>Nimrod/G runs on top of PostgreSQL relational database. Before anything\ncan\
    \ be done, user must create a database which will be used by Nimrod/G.\nEach Nimrod/G\
    \ user requires their own PostgreSQL database.</p>\n<ol>\n<li>As a PostgreSQL\
    \ admin user create a PostgreSQL user. Must ensure\n    &gt; that the user can\
    \ create databases (prompted during the process):</li>\n</ol>\n<blockquote>\n\
    <p>$ createuser &lt;username&gt;</p>\n</blockquote>\n<ol>\n<li>As the user, create\
    \ a database</li>\n</ol>\n<blockquote>\n<p>$ createdb</p>\n</blockquote>\n<ol>\n\
    <li>As the user, populate that database with Nimrod/G database schema</li>\n</ol>\n\
    <blockquote>\n<p>$ nimrod dbcreate</p>\n</blockquote>\n<h4>Platform and Version\
    \ Specific Notes</h4>\n<ul>\n<li>Python 2.6</li>\n</ul>\n<blockquote>\n<p>To configure\
    \ the Nimrod build files against Python2.6 (confirmed on\nUbuntu 10.04) it seems\
    \ to be necessary to set LDFLAGS=-lm.</p>\n</blockquote>\n<ul>\n<li>Ubuntu 10.04</li>\n\
    </ul>\n<blockquote>\n<p>To configure the Nimrod build files against the included\
    \ Python2.6 on\nUbuntu 10.04 it seems to be necessary to set LDFLAGS=-lm.</p>\n\
    </blockquote>\n<ul>\n<li>RHEL6</li>\n</ul>\n<blockquote>\n<p>Using the OS default\
    \ Python (2.6) to install Nimrod may result in the\nmake install step failing\
    \ to install 3rd party modules that are\npackaged with Nimrod, with an error message\
    \ like:</p>\n<p>You are attempting to install a package to a directory that is\
    \ not on\nPYTHONPATH and which Python does not read \".pth\" files from.</p>\n\
    <p>This can be remedied by ensuring $NIMROD_INSTALL/share/nimrod is in\nyour $PYTHONPATH\
    \ environment variable.</p>\n</blockquote>\n<h3>Installing Nimrod/K</h3>\n<p>Users\
    \ must executed the following steps to install Nimrod/K:</p>\n<ol>\n<li>\n<p>Download\
    \ Nimrod/K distribution</p>\n</li>\n<li>\n<p>Install Nimrod/K</p>\n</li>\n</ol>\n\
    <h4>Download Nimrod/K Distribution</h4>\n<p>This can be done by following Nimrod/K\
    \ link at:</p>\n<ul>\n<li>https://messagelab.monash.edu.au/Downloads</li>\n</ul>\n\
    <p>Download the Nimrod/K distribution to your home directory which should\ncreate\
    \ a file:</p>\n<ul>\n<li>$HOME/nimrodk-[version].jar</li>\n</ul>\n<h4>Steps to\
    \ install Nimrod/K</h4>\n<p>For the purposes of this installation guide, we will\
    \ assume that the\nversion we are working on is 2.0.0. Nimrod/K major version\
    \ number will\nalways follow Kepler's major version number so version 2.0.0 means\
    \ that\nthis version of Nimrod/K will work with latest version of Kepler with\n\
    major version number</p>\n<p>Nimrod/K jar file has following install options:</p>\n\
    <blockquote>\n<p>options:</p>\n<p>--help|-h -- print this message</p>\n<p>--acceptlicense|-a\
    \ -- accept Nimrod/K license without prompting. If\nomitted user will be</p>\n\
    <p>given a choice (declining will stop the installation).</p>\n<p>--prefix=&lt;path&gt;\
    \ -- set a location of where all Nimrod/K modules\nare installed (eg. \u2013</p>\n\
    <p>prefix=/usr/local/kepler/2.4/lib). If omitted it will prompt for</p>\n<p>the\
    \ prefix</p>\n<p>--keplerversion=&lt;major version number&gt; -- set a kepler\
    \ version\n(eg. --keplerversion=2.4).</p>\n<p>If ommitted installer will look\
    \ for it in the following files and</p>\n<p>in the order they are listed here:</p>\n\
    <p>a) &lt;prefix&gt;/build-area/install-id.txt</p>\n<p>b) $KEPLER/build-area/install-id.txt</p>\n\
    <p>--version|-v -- prints the Nimrod/K version</p>\n</blockquote>\n<p>Using the\
    \ above options install Nimrod/K:</p>\n<blockquote>\n<p>java -jar nimrodk-2.0.0.jar\
    \ [options]</p>\n</blockquote>\n<h3>Installing Nimrod/O</h3>\n<p>A comprehensive\
    \ manual for Nimrod/O can be downloaded from:</p>\n<p><a href=\"http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf\"\
    >http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf</a>.</p>\n\
    <p>It contains information on how to install Nimrod/O.</p>\n<h2>How to launch</h2>\n\
    <h3>Running Nimrod/G</h3>\n<p>In order to run Nimrod/G experiments from command\
    \ line user needs to do\nthe following:</p>\n<ul>\n<li>\n<p>Manage Resources</p>\n\
    </li>\n<li>\n<p>Manage Experiments</p>\n</li>\n</ul>\n<p>Once these are done,\
    \ experiments can be executed on selected resources.</p>\n<h4>Resource Management</h4>\n\
    <h5>Adding Resources</h5>\n<p>Nimrod resources need to be first added to the database\
    \ before they can\nbe assigned to and used by experiments. Syntax for adding resources\
    \ is\nas follows:</p>\n<blockquote>\n<p>$ nimrod resource add &lt;resource_type&gt;\n\
    &lt;resource_details&gt;</p>\n</blockquote>\n<p>Resource types supported by Nimrod/G\
    \ include:</p>\n<ul>\n<li><strong>Fork</strong></li>\n</ul>\n<blockquote>\n<p>$\
    \ nimrod resource add fork</p>\n</blockquote>\n<ul>\n<li><strong>PBS</strong>\_\
    - With PBS we need to know the name of a PBS queue and the\n    &gt; hostname\
    \ of the PBS server. Lets say queue name is\_<strong>workq</strong>\_and\n   \
    \ &gt; the hostname is\_<strong>localhost</strong></li>\n</ul>\n<blockquote>\n\
    <p>$ nimrod resource add pbs workq@localhost</p>\n</blockquote>\n<ul>\n<li>\n\
    <p><strong>SGE</strong>\_- Same as PBS</p>\n</li>\n<li>\n<p><strong>EC2</strong></p>\n\
    </li>\n</ul>\n<h5>Removing Resources</h5>\n<p>Syntax for removing resources is\
    \ as follows:</p>\n<blockquote>\n<p>$ nimrod resource remove &lt;resource_type&gt;\n\
    &lt;resource_details&gt;</p>\n</blockquote>\n<h4>Experiment Management</h4>\n\
    <p>This section will describe how to create, monitor and manage Nimrod/G\nexperiments.</p>\n\
    <h5>Creating a Plan File</h5>\n<p>Nimrod/G uses a simple declarative language\
    \ to describe the experiments.\nThis description is usually written as a simple\
    \ script file we call\na\_<strong>plan file</strong>.</p>\n<p>There are two sections\
    \ in this plan file. The first one describes the\nparameters that your experiment\
    \ has while the second one describes the\ntask/s that Nimrod/G needs to execute\
    \ to complete a single instance (or\na job) from your experiment. The example\
    \ below shows a fictional plan\nfile for an experiment investigating wing performance.</p>\n\
    <blockquote>\n<p>parameter aircraft_model files select anyof \"A3??.dat\" \"737-*.dat\"\
    ;</p>\n<p>parameter AoA label \"Angle of attack\" float range from -45 to 45 step\n\
    2.5;</p>\n<p>parameter winglets text select anyof \"none\" \"fence\" \"blended\"\
    \ \"raked\";</p>\n<p>parameter airspeed integer range from 50 to 600 step 50;</p>\n\
    <p>parameter turbulence label \"Normalized Reynolds\" float random from 1\nto\
    \ 2;</p>\n<p>task main</p>\n<p>copy ${aircraft_model} node:.</p>\n<p>copy wing_test.zip\
    \ node:.</p>\n<p>node:execute unzip wing_test.zip</p>\n<p>node:execute ./run_wing_test.sh\
    \ ${aircraft_model} ${winglets}\n${AoA} \\</p>\n<p>${airspeed} ${turbulence} &gt;&gt;\
    \ output.${jobname}</p>\n<p>node:execute zip results.${jobname} *</p>\n<p>copy\
    \ node:results.${jobname}.zip .</p>\n<p>endtask</p>\n</blockquote>\n<p>This is\
    \ a somewhat contrived example demonstrating various parameter\ntypes but it illustrates\
    \ the basic functionality of defining parameters\nfor the main task and handling\
    \ input, execution and output for each of\nthe parameter combinations. The two\
    \ subsections below explain the\n'parameter' and 'task' definitions in the plan\
    \ file.</p>\n<h5>Parameters</h5>\n<p>Parameters define lists of values, constant\
    \ single values or dynamic\nvalues (of various types). A unique combination of\
    \ parameter values is\nassigned to each job and each parameter value is bound\
    \ to a named\nidentifier in the job environment. Nimrod/G experiments usually\
    \ create a\ncross-product of all parameters to define the jobs which make up the\n\
    experiment, we call this a full parameter sweep. The syntax for\nparameter lines\
    \ in the plan file is:</p>\n<blockquote>\n<p>parameter &lt;name&gt; &lt;type&gt;\
    \ [&lt;domain&gt;];</p>\n</blockquote>\n<ul>\n<li>\n<p><strong>name</strong>\_\
    - This is the parameter name which must be unique.</p>\n</li>\n<li>\n<p><strong>type</strong>\_\
    - This part of the parameter tells Nimrod/G what type of\n    parameter this is.\
    \ There are five types and they are</p>\n<ul>\n<li>\n<p><strong>float</strong>\_\
    - floating point number</p>\n</li>\n<li>\n<p><strong>integer</strong>\_- integer\
    \ (whole) number</p>\n</li>\n<li>\n<p><strong>text</strong>\_- textual values\
    \ as shown in the example above</p>\n</li>\n<li>\n<p><strong>files</strong>\_\
    - this type allow you to apply glob style file name\n    matching to create a\
    \ list of files names within the experiment\n    directory which match the given\
    \ pattern(s), you could use this\n    to parameterize the input files for your\
    \ computation (like the\n    example above). The files type\_<strong>must be</strong>\_\
    used with the \"select\n    anyof\" domain.</p>\n</li>\n<li>\n<p><strong>fromfile</strong>\_\
    - this type must refer to a text file that contains\n    a list of values, i.e.,\
    \ the file contains the entire range.</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>domain</strong>\_\
    - A parameter domain is optional in some cases but\n    usually required. The\
    \ following domains are available:</p>\n<ul>\n<li><strong>default</strong>- this\
    \ domain type has only a single value. The\n    syntax for this domain is:</li>\n\
    </ul>\n</li>\n</ul>\n<blockquote>\n<p>default &lt;value</p>\n</blockquote>\n<ul>\n\
    <li><strong>range</strong>\_- this domain type has a number of values (points)\
    \ that\n    are within a specified range. The syntax for the range domain is:</li>\n\
    </ul>\n<blockquote>\n<p>range from &lt;value&gt; to &lt;value&gt; points &lt;value&gt;</p>\n\
    <p>range from &lt;value&gt; to &lt;value&gt; step &lt;value&gt;</p>\n</blockquote>\n\
    <ul>\n<li><strong>random</strong>\_- this domain type has a number of random points\n\
    \    generated between specified lower and upper bounds. The syntax for\n    this\
    \ domain is</li>\n</ul>\n<blockquote>\n<p>random from &lt;value&gt; to &lt;value&gt;\
    \ [points &lt;value&gt;]</p>\n</blockquote>\n<ul>\n<li><strong>select anyof</strong>\_\
    - this domain type is usually used for text and\n    files but is also useful\
    \ for listing fixed numerical values. The\n    syntax for this domain is:</li>\n\
    </ul>\n<blockquote>\n<p>select anyof &lt;value_list&gt; [default &lt;value_list&gt;]</p>\n\
    </blockquote>\n<ul>\n<li><strong>select oneof</strong>\_- Similar to 'select anyof'\
    \ except that only one\n    value will be selected for use from this list. If\
    \ the default value\n    is not specified the first value in the value_list is\
    \ used. The\n    syntax for this domain is:</li>\n</ul>\n<blockquote>\n<p>select\
    \ oneof &lt;value_list&gt; [default &lt;value&gt;]</p>\n</blockquote>\n<ul>\n\
    <li><strong>(some input file)</strong>\_- when using the fromfile type, the domain\
    \ is\n    an input file that lists the values for the parameter. For example:</li>\n\
    </ul>\n<blockquote>\n<p>parameter x fromfile inputfile.txt</p>\n<p>means that\_\
    <strong>inputfile.txt</strong>\_contains a list of single values (one per\nline)\
    \ for parameter\_<strong>x</strong>.</p>\n</blockquote>\n<h5>Tasks</h5>\n<p>This\
    \ part of the plan file describes the process of executing a single\ninstance\
    \ of your experiment. There are a number of\noperations/commands/directives that\
    \ can be performed in a task:</p>\n<ul>\n<li>\n<p>Copy files to and from compute\
    \ resources</p>\n</li>\n<li>\n<p>Executing an experiment executable</p>\n</li>\n\
    <li>\n<p>Substituting place-holders in the input files with the real values</p>\n\
    </li>\n<li>\n<p>What to do in case the job fails.</p>\n</li>\n</ul>\n<p>Task operations\
    \ are typically location\ndependent.\_<strong>copy</strong>\_and\_<strong>execute</strong>\_\
    directives must specify where the\noperation should be performed or where the\
    \ file locations are while\ncopying. This is done by using\_<strong>node:</strong>\_\
    or\_<strong>root:</strong>\_modifiers.</p>\n<ul>\n<li>\n<p><strong>node:</strong>\_\
    indicates remote location for the operation. In case\n    of\_<strong>copy</strong>\_\
    operation it indicates that the file resides on remote\n    machine, while in\
    \ case of <strong>execute</strong>\_command it indicates that the\n    executable\
    \ should be run on the remote server.</p>\n</li>\n<li>\n<p><strong>root:</strong>\_\
    on the other hand indicates that files are on the same\n    machine where Nimrod/G\
    \ is running, and that\_<strong>execute</strong>\_command that\n    executables\
    \ are to be run on that same machine, and not on the\n    remote server. Please\
    \ note that\_<strong>root:execute</strong>\_can only be\n    executed in\_<strong>rootstart</strong>\_\
    and\_<strong>rootfinish</strong>tasks.</p>\n</li>\n</ul>\n<p><strong>NOTE</strong>:\
    \ In a typical parameter sweep all program invocations will\noccur on computational\
    \ nodes and hence the main task will only use\n<strong>node:execute</strong>.</p>\n\
    <p>Following is a more thorough description of the task operations:</p>\n<ul>\n\
    <li><strong>copy</strong>\_- this operation is used to copy both input and\n \
    \   &gt; output files. Syntax for this operations is as follows:</li>\n</ul>\n\
    <blockquote>\n<p>copy &lt;source&gt; &lt;destination&gt;</p>\n<p>For example if\
    \ you are copying input file to a remote location:</p>\n<p>copy root:input.txt\
    \ node:input.txt</p>\n<p>And if you are copying output file back to the server\
    \ where Nimrod/G\nis running:</p>\n<p>copy node:result.txt root:result.txt</p>\n\
    </blockquote>\n<ul>\n<li><strong>execute</strong>\_- this operation is used to\
    \ execute some executable. The\n    syntax for this operatio is:</li>\n</ul>\n\
    <blockquote>\n<p>node:execute &lt;user_command&gt;</p>\n<p><strong>user_command</strong>\_\
    is passed to shell (<strong>/bin/sh</strong>), so it can contain\nshell constructs\
    \ (redirection like &gt;, &gt;&gt; etc).</p>\n<p>For example if we wanted to execute\_\
    <strong>hostname</strong>\_command and redirect\nits output into a file called\_\
    <strong>hostname.txt</strong>\_this is what\nthe\_<strong>execute</strong>operation\
    \ would look like:</p>\n<p>node:execute /bin/hostname &gt; hostname.txt</p>\n\
    </blockquote>\n<ul>\n<li><strong>onerror\_- this operation indicates how Nimrod/G\
    \ should behave in\n    case some part of the job fails. It has a scope which\
    \ is from the\n    point it appears until another\_onerror\_statement is found.\
    \ The\n    syntax for this operation is:</strong></li>\n</ul>\n<blockquote>\n\
    <p>onerror &lt;option&gt;</p>\n<p>Valid options are:</p>\n</blockquote>\n<ul>\n\
    <li>\n<p><strong>fail</strong>\_- fail the job. This is the default behaviour\
    \ and will be\n    &gt; used even if\_<strong>onerror</strong>\_is never specified\
    \ in the plan file</p>\n</li>\n<li>\n<p><strong>ignore</strong>\_- ignore the\
    \ error and proceed with the task, ie. move\n    &gt; onto the next line in the\
    \ plan file and continue executing it.</p>\n</li>\n</ul>\n<!-- -->\n\n<ul>\n<li><strong>substitute</strong>\_\
    - Nimrod/G allows can use skeleton input file for\n    &gt; their experiments.\
    \ This skeleton input file may contain\n    &gt; placeholders in it that are to\
    \ be substituted by the actual\n    &gt; parameter values before the execution\
    \ begins.</li>\n</ul>\n<blockquote>\n<p>This operation is used to replace the\
    \ parameter placeholders in input\nfile with a job parameter value. The syntax\
    \ of this operation is:</p>\n<p>substitute &lt;source&gt; &lt;destination&gt;</p>\n\
    <p>Both source and destination require neither 'node:' nor 'root:' in\nfront of\
    \ them, i.e. they are just plain filenames. For example, this\ncould be a main\
    \ task of a plan file:</p>\n<p>task main</p>\n<p>copy input.skeleton node:.</p>\n\
    <p>substitute input.skeleton input.txt</p>\n<p>node:execute ./process.sh input.txt\
    \ &gt; result.txt</p>\n<p>copy node:result.txt .</p>\n<p>endtask</p>\n</blockquote>\n\
    <h4>Creating Experiments</h4>\n<p>Nimrod/G stores experiments in a specific location\
    \ in user's home\ndirectory:</p>\n<blockquote>\n<p>$HOME/.nimrod/experiments/</p>\n\
    </blockquote>\n<p>Each experiment will have a dedicated subdirectory in that location\
    \ that\nmatches experiment name. For example:</p>\n<ul>\n<li>\n<p>Experiment named\_\
    <strong>demo</strong>\_will be\n    &gt; in\_<strong>$HOME/.nimrod/experiments/demo/</strong></p>\n\
    <ul>\n<li>\n<p>Plan file called\_<strong>demo.pln</strong>\_will be in that directory</p>\n\
    </li>\n<li>\n<p>All files related to that experiment will also be location in\n\
    \    &gt; that directory</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>In order to create\
    \ experiment execute the following steps:</p>\n<ol>\n<li>\n<p>Create a plan file\
    \ following instructions from the previous section.\n    &gt; Lets assume we create\
    \ a plan file called\_<strong>demo.pln</strong></p>\n</li>\n<li>\n<p>Create an\
    \ experiment directory:</p>\n</li>\n</ol>\n<blockquote>\n<p>$ mkdir -p $HOME/.nimrod/experiments/demo</p>\n\
    </blockquote>\n<ol>\n<li>\n<p>Place the\_demo.pln\_file in that directory</p>\n\
    </li>\n<li>\n<p>Create a file containing all possible parameter combinations:</p>\n\
    </li>\n</ol>\n<blockquote>\n<p>nimrod generate demo.pln</p>\n</blockquote>\n<ol>\n\
    <li>Add the experiment to the Nimrod/G database:</li>\n</ol>\n<blockquote>\n<p>nimrod\
    \ create demo</p>\n</blockquote>\n<h4>Assign Resources to Experiments</h4>\n<p>In\
    \ section\_Resource Management\_we added compute resources to the\ndatabase. In\
    \ order for them to be used by an experiment they have to be\nassigned to that\
    \ experiment. The syntax for adding resources to\nexperiments is as follows:</p>\n\
    <blockquote>\n<p>nimrod addserver &lt;exp_name&gt; &lt;resource_details&gt;\n\
    &lt;resource_type&gt;</p>\n</blockquote>\n<p>Resource type and resource details\
    \ are exact same details that were used\nwhen resources were added to database.\
    \ An example of adding a PBS\nresource to a demo experiment can be seen below:</p>\n\
    <blockquote>\n<p>nimrod addserver demo workq@localhost pbs</p>\n</blockquote>\n\
    <h4>Launching Nimrod/G</h4>\n<p>With experiments defined and configured Nimrod/G\
    \ can be launched. The\nsyntax for this command is as follows:</p>\n<blockquote>\n\
    <p>nimrod startexp &lt;exp_name&gt;</p>\n</blockquote>\n<p>For example, to start\
    \ the experiment called\_demo\_run:</p>\n<blockquote>\n<p>nimrod startexp demo</p>\n\
    </blockquote>\n<h3>Using Nimrod/K</h3>\n<p>Nimrod/K extends\_Kepler by adding\
    \ parameter tools and grid/cloud\nservices and by providing dynamic parallelism\
    \ in workflows. As such\nNimrod/K functionality is simply used by adding the Nimrod/K\
    \ director\nand Nimrod/K actors to Kepler workflows.</p>\n<h3>Using Nimrod/O</h3>\n\
    <p>A comprehensive manual for Nimrod/O can be downloaded from:</p>\n<p><a href=\"\
    http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf\"\
    >http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf</a>.</p>\n\
    <p>It contains information on how to launch Nimrod/O.</p>\n<h2>Resource Requirements</h2>\n\
    <p>Nimrod Toolkit runs on Unix based platforms only, which includes all\nflavours\
    \ of Linux as well as Mac OS X. However, Nimrod Portal component\nis browser based\
    \ which allows users of all platforms (including Windows)\nto access Nimrod and\
    \ execute computational experiments through any\nbrowser.</p>\n<ul>\n<li>\n<p>Software\
    \ Requirements:</p>\n<ul>\n<li>\n<p>Python \u2013 version 2.5 or higher</p>\n\
    </li>\n<li>\n<p>PostgreSQL \u2013 version 8.4 or higher</p>\n</li>\n</ul>\n</li>\n\
    <li>\n<p>Operating System Requirements</p>\n<ul>\n<li>\n<p>Linux</p>\n</li>\n\
    <li>\n<p>Mac OS X</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>Nimrod/O can run in standalone\
    \ mode, in which case Nimrod/G is not\nrequired. However in standalone mode Nimrod/O\
    \ loses the ability to run\nits jobs on distributed clusters and computational\
    \ grid resources.\nFor distributing jobs, Nimrod/G 4.0 or higher required</p>\n\
    <p>Similar to Nimrod/O, Nimrod/K can run as a standalone application, in\nwhich\
    \ case Nimrod/G is not required. When running in standalone mode\nNimrod/K can\
    \ be installed and used on Windows machines.</p>\n<h3>Compute Resources</h3>\n\
    <p>Nimrod allows computational researchers to use a mixture of\nuniversity-level\
    \ infrastructure and commercial clouds. For beginners,\nusers can trial their\
    \ Nimrod experiments using the Nimrod_Portal[^1]\nresource pool. Users are encouraged\
    \ to bring their own compute resources\n(e.g. cluster, cloud allocation) to use\
    \ with Nimrod. Please contact Minh\nDinh and Hoang Anh Nguyen regarding adding\
    \ new remote compute resources\nto their experiments.</p>\n<h2>Nimrod Portal</h2>\n\
    <p>A web service for using Nimrod/G. Nimrod portal provides a web interface\n\
    for users to use Nimrod and its resources. Users can create Nimrod/G\nexperiments\
    \ without installing Nimrod toolkit on their local system.\nThis allows users\
    \ develop, execute, maintain and share Nimrod parameter\nsweep experiments.</p>\n\
    <h3>Installation</h3>\n<p>Nimrod portal consists of two components: a RESTful\
    \ Web service and a\nWeb portal. The RESTful service is to expose Nimrod functionality\
    \ to the\nWeb and the Web portal provides user-friendly interface to the users.</p>\n\
    <p>The installation process requires two steps: installation of the Web\nservice\
    \ and installation of the Web portal. This two-step process takes\nplace in two\
    \ separate VMs. Nimrod needs to be installed in the Web\nservice VM.</p>\n<h4>Install\
    \ Nimrod Web service</h4>\n<p>The Web service is currently available at:\n<a href=\"\
    https://bitbucket.org/jhtngu/nimrod.webservice\">https://bitbucket.org/jhtngu/nimrod.webservice</a>.</p>\n\
    <p>This is not a public repository. Please email <a href=\"&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#104;&#111;&#97;&#110;&#103;&#110;&#103;&#117;&#121;&#101;&#110;&#49;&#55;&#55;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\"\
    >&#104;&#111;&#97;&#110;&#103;&#110;&#103;&#117;&#121;&#101;&#110;&#49;&#55;&#55;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a>\n\
    to gain access.</p>\n<ul>\n<li>Once clone the repository, modify the buildout.cfg\
    \ as followed</li>\n</ul>\n<blockquote>\n<p>[sources]</p>\n<p>Nimrodrestapi =\
    \ git\nhttps://yournamehere@bitbucket.org/jhtngu/nimrod.restfulweb.git\nbranch=addresources</p>\n\
    <p>nimrodrpcdaemon = git https:// yournamehere\n@bitbucket.org/jhtngu/nimrod.rpcdaemon.git\
    \ branch=addresources</p>\n</blockquote>\n<ul>\n<li>\n<p>Execute \u201Cpython\
    \ bootstrap.py\u201D to setup the environment. This\n    requires setuptools installed.</p>\n\
    </li>\n<li>\n<p>Execute \u201C./bin/buildout\u201D to clone and install necessary\
    \ packages,\n    including Nimrod Web service.</p>\n</li>\n<li>\n<p>Install any\
    \ missing dependencies as suggested by the build process.</p>\n</li>\n<li>\n<p>Modify\
    \ configuration files in the \u201Cetc\u201D folder accordingly.</p>\n</li>\n\
    </ul>\n<h4>Install the Web portal</h4>\n<ul>\n<li>\n<p>Install Liferay 6.1\n \
    \   (<a href=\"http://sourceforge.net/projects/lportal/files/Liferay%20Portal/6.1.1%20GA2/\"\
    >http://sourceforge.net/projects/lportal/files/Liferay%20Portal/6.1.1%20GA2/</a>).\n\
    \    The recommended location is: /var/www.</p>\n</li>\n<li>\n<p>Follow Liferay\
    \ instructions to install with Postgres DB\n    (<a href=\"https://www.liferay.com/community/wiki/-/wiki/Main/Quick+Installation+Instructions\"\
    >https://www.liferay.com/community/wiki/-/wiki/Main/Quick+Installation+Instructions</a>)</p>\n\
    </li>\n<li>\n<p>Go to Liferay market and install Private Plugin Installer\n  \
    \  (<a href=\"https://www.liferay.com/marketplace/-/mp/application/15474932\"\
    >https://www.liferay.com/marketplace/-/mp/application/15474932</a>)</p>\n</li>\n\
    <li>\n<p>Install Vaadin into Liferay\n    (<a href=\"https://vaadin.com/wiki/-/wiki/Main/Integrating+Vaadin+7+with+Liferay\"\
    >https://vaadin.com/wiki/-/wiki/Main/Integrating+Vaadin+7+with+Liferay</a>)</p>\n\
    </li>\n<li>\n<p>Install Nimrod portlets, which are available at:\n    <a href=\"\
    https://bitbucket.org/hoangnguyen177/nimrodportal2\">https://bitbucket.org/hoangnguyen177/nimrodportal2</a>.\
    \ Or contact\n    <a href=\"&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#104;&#111;&#97;&#110;&#103;&#110;&#103;&#117;&#121;&#101;&#110;&#49;&#55;&#55;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\"\
    >&#104;&#111;&#97;&#110;&#103;&#110;&#103;&#117;&#121;&#101;&#110;&#49;&#55;&#55;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a>\
    \ for compiled version.</p>\n</li>\n<li>\n<p>Install Nimrod portlets</p>\n</li>\n\
    </ul>\n<h4>Configure the portal and the Web service VM</h4>\n<p>From NeCTAR dashboard,\
    \ make sure the port of the Web service (8081 by\ndefault) is accessible by the\
    \ Web portal and Nimrod ports (40000 -\n41000) are accessible by all.</p>\n<h3>Launch</h3>\n\
    <p>Launch the Web portal first:</p>\n<blockquote>\n<p>cd /var/www/liferay-portal-xxxx/tomcat-xxx/bin;\
    \ sudo ./startup.sh</p>\n</blockquote>\n<p>Then launch the Web service:</p>\n\
    <blockquote>\n<p>cd \\~/nimrod.webservice/bin; ./supervisord;</p>\n</blockquote>\n\
    <h3>Plan file web editor</h3>\n<p>Instead of using a text editor, the Nimrod Portal\
    \ provides a simple\nfriendly GUI for users to develop plan file for Nimrod/G\
    \ experiments.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/nimrod_qcif1.png?raw=true\"\
    ></p>\n<h2>How to access it</h2>\n<p>Interested users can register for an account\
    \ using their AAF credential\nat the following page (will need to be updated later):\n\
    <a href=\"http://vm-203-101-224-118.qld.nectar.org.au/\">http://vm-203-101-224-118.qld.nectar.org.au/</a></p>\n\
    <p>The portal provides a friendly web interface for users to define,\nexecute\
    \ and monitor their experiments. For users who have existing\nNimrod experiments,\
    \ they can upload the plan files. User can also create\nnew experiments using\
    \ a simple GUI. Input and output files can be\nuploaded and downloaded using the\
    \ web interface. For technical supports\nand learning to use Nimrod, please contact\
    \ Minh Dinh and/or Hoang Anh\nNguyen.</p>\n<h2>Configuration guide</h2>\n<h3>Configuring\
    \ Nimrod/G</h3>\n<p>Nimrod/G installation comes with two configuration files,\
    \ both located\nin\_<strong>$NIMROD_INSTALL</strong>\_directory:</p>\n<ul>\n<li>\n\
    <p><strong>nimrod.cfg</strong>\_- Configuration values contained within can be\n\
    \    overridden by a user level configuration file of the same name,\n    which\
    \ may be located in $HOME/.nimrod/ directory, or by an\n    immutable configuration\
    \ file described below.</p>\n</li>\n<li>\n<p><strong>nimrod.immutable.cfg</strong>\_\
    - Configuration values contained within\n    will override any other configuration,\
    \ either user or system level.</p>\n</li>\n</ul>\n<p>Most of the configuration\
    \ values can be left as is but some may be\nchanged to match the system requirements.</p>\n\
    <p>Each configuration file may contain following sections:</p>\n<ul>\n<li>\n<p><strong>email</strong>\_\
    - used to configure email settings. This is used to report\n    experiment completion.</p>\n\
    </li>\n<li>\n<p><strong>nimserver</strong>\_- configures Nimrod/G component called\
    \ Nimrod Server.\n    Nimrod/G uses executables called\_<strong>Agents</strong>\_\
    to execute jobs on\n    remote resources.\_<strong>Agents</strong>\_use Nimrod\
    \ Server to communicate with\n    database as well as to copy files to and from\
    \ remote locations.</p>\n</li>\n</ul>\n<blockquote>\n<p>Most of the configuration\
    \ can be left as is. It is important however\nto ensure that\_<strong>default_port_range</strong>\_\
    configuration value has a\nrange of ports that can be reached by outside networks.\
    \ When it\nstarts,\_<strong>Nimrod Server</strong>\_will select a first available\
    \ port from that\nrange and will use that to listen for incoming connectinos\n\
    from\_<strong>Agents</strong>. If the port it selects is unreachable, no jobs\
    \ will\nrun.</p>\n<p>For example (port will be selected anywhere between 30000\
    \ and 31000\ninclusive):</p>\n<p>nimserver: {</p>\n<p>default_port_range: '30000,31000'</p>\n\
    <p>key_path: $user_dir + '.nimserver'</p>\n<p>remote_suffix: $remote_suffix</p>\n\
    <p>remote_key_fname: '.nimserver' + $nimserver.remote_suffix + '.pub'</p>\n<p>port_path:\
    \ $user_dir + '.nimport' + $nimserver.remote_suffix</p>\n<p>remote_port_fname:\
    \ '.nimport' + $nimserver.remote_suffix</p>\n<p>}</p>\n</blockquote>\n<ul>\n<li>\n\
    <p><strong>actuator</strong>\_- configures resource actuators, components that\n\
    \    control how resources are used. It can be used to change how often\n    actuators\
    \ poll database to see if there are any work they need\n    to do. Configuration\
    \ can apply to actuators for all resource types,\n    but can also only apply\
    \ to a specific resource type.</p>\n</li>\n<li>\n<p><strong>azure</strong>\_-\
    \ configure\_<strong>azure</strong>\_resource settings. Can be left\n    as is.</p>\n\
    </li>\n<li>\n<p><strong>ec2</strong>\_- configures\_<strong>ec2</strong>\_resource\
    \ settings. Can be left as is</p>\n</li>\n<li>\n<p><strong>generate</strong>\_\
    - configures\_<strong>generate</strong>\_subcommand. This subcommand\n    is used\
    \ to parse the plan file and create another files that\n    contains a cross-product\
    \ of all parameters. Some of the settings\n    include limits on how many jobs\
    \ single experiment can have, or how\n    long a parameter name can be.</p>\n\
    </li>\n</ul>\n<blockquote>\n<p>For example:</p>\n<p>generate: {</p>\n<p>max_jobs:\
    \ 100000</p>\n<p>param_len_limit: 56</p>\n<p>}</p>\n</blockquote>\n<h3>Configuring\
    \ Nimrod/K</h3>\n<p>There is no Nimrod/K specific configuration.</p>\n<h3>Configuring\
    \ Nimrod/O</h3>\n<p>A comprehensive manual for Nimrod/O can be downloaded from:</p>\n\
    <p><a href=\"http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf\"\
    >http://messagelab.monash.edu.au/NimrodO/Documentation?action=download&amp;upname=NimrodOUsersGuide3.1.pdf</a>.</p>\n\
    <p>It contains information on how to configure Nimrod/O.</p>\n<h2>Technical blueprint</h2>\n\
    <p>To date, Nimrod tools are deployed through several Nimrod portals\nstationed\
    \ at Monash University, Griffith University and The University\nof Queensland.\
    \ These portals provide the machinery to automate the tasks\nof formulating complex\
    \ experiments and workflows, and execute them\nacross a variety of computing resources\
    \ including NecTAR VMs. In\nparticular, we ran several projects to test the migration\
    \ of scientific\nsoftware to HPC platforms, including the NeCTAR research cloud,\
    \ to\nprovide enhanced utility for the following research projects.</p>\n<h3>Terrestrial\
    \ Ecosystem Research Network (TERN)</h3>\n<p>Supporting the creation and execution\
    \ of sensory data analysis using\nNimrod portal to access available computing\
    \ resources in the NecTAR\ncloud.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/nimrod_qcif2.png?raw=true\"\
    ></p>\n<h3>CVL Symmetric Model Creation</h3>\n<p>Coupling Nimrod to perform expensive\
    \ computations efficiently and\nintegrating visualization library to enable examination\
    \ of intermediate\nmodels.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/nimrod_qcif3.png?raw=true\"\
    ></p>\n<h3>MARXAN</h3>\n<p>Coupling the MARXAN web portal with Nimrod to provide\
    \ access to HPC and\ncloud resources.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/nimrod_qcif4.png?raw=true\"\
    ></p>\n<h2>Troubleshooting</h2>\n<p>There are multiple points of failure that\
    \ are possible when running\nNimrod/G experiments:</p>\n<ul>\n<li>Problem with\
    \ executables (applications) that Nimrod/G is trying to\n    execute</li>\n</ul>\n\
    <blockquote>\n<p>These will be reported back to database. In scenario like this\
    \ is\nhighly possible that all jobs will fail because of it. However the\nproblem\
    \ can be environmental in which case it will only fail on a\nparticular resource\
    \ or even a particular machine on that resource.</p>\n</blockquote>\n<ul>\n<li>Problem\
    \ with remote machines where Nimrod Agents are running</li>\n</ul>\n<blockquote>\n\
    <p>These kind of problems occur when a particular machine on a\ncomputational\
    \ resource is not working correctly. There are many\nreasons this may occur, which\
    \ includes missing libraries, faulty\nhardware etc.</p>\n<p>If the agents manage\
    \ to start then these are easy to identify. Nimrod\nAgents will fail the jobs\
    \ and record which host the job failed on.\nListing failed jobs, and seeing that\
    \ all failed on a particular host\nwill indicate a problem with that host.</p>\n\
    </blockquote>\n<ul>\n<li>Firewall issues preventing Nimrod Agents connecting back\
    \ to Nimrod\n    Server</li>\n</ul>\n<blockquote>\n<p>If Agents are perpetually\
    \ stuck in\_<strong>pending/queued</strong>\_state, it\nusually indicates that\
    \ they cannot connect back to Nimrod Server. One\nreason is that there is a faulty\
    \ host and\_<strong>Agents</strong>\_never start, and\nsecond reason is that firewall\
    \ on either host is preventing\nthose\_<strong>Agents</strong>\_connections.</p>\n\
    </blockquote>\n<p>There are number of commands that can be executed to collect\
    \ information\nthat may help identify the issue:</p>\n<ol>\n<li>Get reported errors</li>\n\
    </ol>\n<blockquote>\n<p>$ nimrod geterrors &lt;exp_name&gt;</p>\n</blockquote>\n\
    <ol>\n<li>Check if there are any agents running on resources</li>\n</ol>\n<blockquote>\n\
    <p>$ nimrod getagents &lt;exp_name&gt;</p>\n<p>Output returns a list of resources\
    \ where each line has the resource\nname and agent information in following order:</p>\n\
    </blockquote>\n<ul>\n<li>\n<p>Agents that have stopped running (cleanly)</p>\n\
    </li>\n<li>\n<p>Agents that are still running</p>\n</li>\n<li>\n<p>Agents that\
    \ have been submitted to a remote queue</p>\n</li>\n<li>\n<p>Agents that have\
    \ been created in database, but not submitted to a\n    remote queue</p>\n</li>\n\
    <li>\n<p>Agents that have failed to start. Some agents may fail to start but\n\
    \    won't be reported here. This will occur if firewall is blocking\n    the\
    \ connections.</p>\n</li>\n<li>\n<p>Check the progress of experiment and see if\
    \ there any failed jobs:</p>\n</li>\n</ul>\n<blockquote>\n<p>$ nimrod enfapi &lt;exp_name&gt;\
    \ jobstatus</p>\n</blockquote>\n<ol>\n<li>If there are failed jobs, get errors\
    \ for all failed jobs:</li>\n</ol>\n<blockquote>\n<p>$ nimrod enfapi &lt;exp_name&gt;\
    \ getjobinfo all error</p>\n</blockquote>\n<h2>Support</h2>\n<h3>Administration</h3>\n\
    <p>Please contact Hoang Anh Nguyen or Minh Dinh for the Nimrod Portal</p>\n<h3>Technical\
    \ Support</h3>\n<p>All queries regarding the for the Nimrod Portal and WorkWays\
    \ portal,\nplease contact Hoang Anh Nguyen or Minh Dinh</p>\n<h3>Learning to use\
    \ Nimrod or integrating Nimrod into your internal service</h3>\n<p>Please contact\
    \ Minh Dinh regarding learning to use Kepler and Nimrod.\nFor consultation on\
    \ how Kepler and Nimrod can be applicable for specific\nresearch fields, please\
    \ contact Minh Dinh.</p>\n<h2>Contact</h2>\n<p>Dr Minh Dinh</p>\n<p>QCIF - eResearch\
    \ Analyst</p>\n<p>Reserch Fellow - Research Computing Center (RCC)</p>\n<p>Email:\
    \ <a href=\"&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#109;&#46;&#100;&#105;&#110;&#104;&#49;&#64;&#117;&#113;&#46;&#101;&#100;&#117;&#46;&#97;&#117;\"\
    >&#109;&#46;&#100;&#105;&#110;&#104;&#49;&#64;&#117;&#113;&#46;&#101;&#100;&#117;&#46;&#97;&#117;</a></p>\n\
    <p>Mr Hoang Anh Nguyen</p>\n<p>Email: <a href=\"&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#104;&#111;&#97;&#110;&#103;&#110;&#103;&#117;&#121;&#101;&#110;&#49;&#55;&#55;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\"\
    >&#104;&#111;&#97;&#110;&#103;&#110;&#103;&#117;&#121;&#101;&#110;&#49;&#55;&#55;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a></p>\n\
    <h2>Glossary of Terms</h2>\n<p>[^1]: Nimrod_Portal is a Nectar allocation that\
    \ consists of up 120\n    compute cores. It is designated for deploying Nimrod\
    \ services and\n    conducting Nimrod runs. It is an independent testbed for new\
    \ users\n    to trial Nimrod and its tools</p>"
  parent: 24
  sha1: 7c38bf34d75a35fd33a877021bb51828bed70c33
  title: QCIF Nimrod
105:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2015-12-07T23:28:52-05:00'
        desc_un_html: " Documentation \n The following documentations provides reference\
          \ and guidance information for the\nNeutron API: \n \n \n Neutron Python\
          \ API reference \n \n \n Neutron Command Line API Reference \n \n \n Neutron\
          \ API Reference \n \n \n NeCTAR Support \n If you have a problem and you\
          \ cannot resolve it, you can always go to NecTAR\nHelpDesk to log a support\
          \ ticket and the NeCTAR support staff are\nmore than happy to help you. "
        description: '<h1>Documentation</h1>

          <p>The following documentations provides reference and guidance information
          for the

          Neutron API:</p>

          <ul>

          <li>

          <p><a href="http://docs.openstack.org/developer/python-neutronclient/#id1">Neutron
          Python API reference</a></p>

          </li>

          <li>

          <p><a href="http://docs.openstack.org/cli-reference/content/neutronclient_commands.html">Neutron
          Command Line API Reference</a></p>

          </li>

          <li>

          <p><a href="http://developer.openstack.org/api-ref-networking-v2.html">Neutron
          API Reference</a></p>

          </li>

          </ul>

          <h2>NeCTAR Support</h2>

          <p>If you have a problem and you cannot resolve it, you can always go to
          NecTAR

          <a href="https://support.nectar.org.au/support/home">HelpDesk</a> to log
          a support ticket and the NeCTAR support staff are

          more than happy to help you.</p>'
        folder:
          category_id: 6000122279
          created_at: '2015-12-01T18:22:33-05:00'
          customer_folders: []
          description: Networking
          id: 6000210730
          is_default: false
          language_id: 6
          name: Networking
          parent_id: 6000210730
          position: 6
          updated_at: '2015-12-07T19:43:55-05:00'
          visibility: 1
        folder_id: 6000210730
        hits: 16
        id: 6000095317
        modified_at: '2016-04-15T02:27:29-04:00'
        modified_by: null
        position: 5
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: More Info
        updated_at: '2016-04-15T02:27:29-04:00'
        user_id: 6002464727
  html: '<h1>Documentation</h1>

    <p>The following documentations provides reference and guidance information for
    the

    Neutron API:</p>

    <ul>

    <li>

    <p><a href="http://docs.openstack.org/developer/python-neutronclient/#id1">Neutron
    Python API reference</a></p>

    </li>

    <li>

    <p><a href="http://docs.openstack.org/cli-reference/content/neutronclient_commands.html">Neutron
    Command Line API Reference</a></p>

    </li>

    <li>

    <p><a href="http://developer.openstack.org/api-ref-networking-v2.html">Neutron
    API Reference</a></p>

    </li>

    </ul>

    <h2>NeCTAR Support</h2>

    <p>If you have a problem and you cannot resolve it, you can always go to NecTAR

    <a href="https://support.nectar.org.au/support/home">HelpDesk</a> to log a support
    ticket and the NeCTAR support staff are

    more than happy to help you.</p>'
  parent: 44
  sha1: 5ee296e2cd83cb92912c7e804069bf6b39a24a95
  title: More Info
106:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-12-07T23:28:53-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Debugging Neutron Command line Client \n These instructions\
          \ assume you have installed Neutron command client in a Linux\nenvironment.\
          \ If you have other operating systems, the debugging process might be\n\
          a slightly different, however, the general rules should still apply. \n\
          \ Neutron command line client is very much like other Linux commands, it\
          \ outputs\nerrors in the standard output, which is the monitor. \n If you\
          \ get an error, you can always read the error message and generally it give\n\
          you very good hints about what might be wrong. \n For example, if you execute\
          \ neutron net-list on the command line without\nauthentication, the error\
          \ message might look like this: \n ERROR: You must provide a username via\
          \ either --os-username or env[OS_USERNAME] \n The above message indicates\
          \ you need to be authenticated before you can use the\nAPI. The authentication\
          \ requires some environment variables to be set. To set\nthese environment\
          \ variables you can either source the script file obtained from\nNeCTAR\
          \ Dashboard or you can override it by using command line options. \n Please\
          \ refer to Networking Getting Started article. \n You can always execute\
          \ man neutron or simply neutron help to get\nmore help information and to\
          \ learn each supported options. \n If you find a useful command, you can\
          \ also execute nova help command,\nthis will give your more specific help\
          \ for the command. \n Debugging Neutron Python API \n Debugging Neutron\
          \ Python API takes more effects as it depends on how familiar\nwith Python\
          \ programming and what development environment you use. \n The below provides\
          \ some basic information about how you debug the Neutron Python\nAPI. \n\
          \ You can debug your python code using Python debugger called pdb and you\
          \ can find\nmore information here. \n The below code uses pdb debuuger to\
          \ debug a python file contains clinet python\nAPI code. \n pdb file_name.py\
          \ \n Once you executed the above code, the command line will be stopped\
          \ on the first\nline of code and you can use some commands to control the\
          \ execution flow. \n Some useful ones to use are: \n\n\n\nCommand\nAction\n\
          \n\n\n\nb\nset a breakpoint\n\n\nc\ncontinue debugging until you hit a breakpoint\n\
          \n\ns\nstep through the code\n\n\nn\nto go to next line of code\n\n\nl\n\
          list source code for the current file\n\n\nu\nnavigate up a stack frame\n\
          \n\nd\nnavigate down a stack frame\n\n\np\nto print the value of an expression\
          \ in the current context\n\n\n\n Debugging Via HTTP \n The both of command\
          \ line API and python API are restful web service client.\nThus the requests\
          \ are all made by using HTTP and you can always refer to\nOpenStack Service\
          \ End for further references about what should be\npresented in the HTTP\
          \ requests. The Neutron API uses requests library\nto send and receive HTTP\
          \ requests/responses. \n For command line client, you can add --debug option\
          \ to print out HTTP request\nheader and HTTP response header, which give\
          \ you a lot of more insight\ninformation. To verify parameters in the request\
          \ header, you can refer to\nOpenStack service API to see what are expected.\
          \ \n To enable debugging information on the standard out for Python API,\
          \ you can add\nthe below code: \n ``` \n import logging \n logger = logging.getLogger(\"\
          neutronclient\") \n logging.basicConfig(level=logging.DEBUG) \n ``` \n The\
          \ will print the same output as adding --debug option for command line API.\
          \ \n Debugging via Source Code \n If the above techniques are still not\
          \ helpful, you can always look at the source\ncode to find the problems.\
          \ \n The below source file structure is based on the installation in Ubuntu.\
          \ \n The command line neutron command is located in '/usr/bin/neutron'.\
          \ By looking at this\nfile, you should get a idea of how the various options\
          \ are interpreted. This file\nacts as an interface for Python API. \n The\
          \ Python API files are located under\n'/usr/lib/python2.7/dist-packages/neutronclient/v2_0/'\
          \ and the most important file to look\nat is 'client.py'. This file does\
          \ all the request preparation, sending request and\nreceiving response.\
          \ It is also used by the command line Neutron client. "
        description: '<h2>Debugging Neutron Command line Client</h2>

          <p>These instructions assume you have installed Neutron command client in
          a Linux

          environment. If you have other operating systems, the debugging process
          might be

          a slightly different, however, the general rules should still apply.</p>

          <p>Neutron command line client is very much like other Linux commands, it
          outputs

          errors in the standard output, which is the monitor.</p>

          <p>If you get an error, you can always read the error message and generally
          it give

          you very good hints about what might be wrong.</p>

          <p>For example, if you execute <code>neutron net-list</code> on the command
          line without

          authentication, the error message might look like this:</p>

          <p><code>ERROR: You must provide a username via either --os-username or
          env[OS_USERNAME]</code></p>

          <p>The above message indicates you need to be authenticated before you can
          use the

          API. The authentication requires some environment variables to be set. To
          set

          these environment variables you can either source the script file obtained
          from

          NeCTAR <a href="https://dashboard.rc.nectar.org.au">Dashboard</a> or you
          can override it by using command line options.</p>

          <p>Please refer to <a href="https://support.nectar.org.au/support/solutions/articles/6000094839-getting-started">Networking
          Getting Started</a> article.</p>

          <p>You can always execute <code>man neutron</code> or simply <code>neutron
          help</code> to get

          more help information and to learn each supported options.</p>

          <p>If you find a useful command, you can also execute <code>nova help command</code>,

          this will give your more specific help for the command.</p>

          <h2>Debugging Neutron Python API</h2>

          <p>Debugging Neutron Python API takes more effects as it depends on how
          familiar

          with Python programming and what development environment you use.</p>

          <p>The below provides some basic information about how you debug the Neutron
          Python

          API.</p>

          <p>You can debug your python code using Python debugger called pdb and you
          can find

          more information <a href="https://docs.python.org/2/library/pdb.html">here</a>.</p>

          <p>The below code uses pdb debuuger to debug a python file contains clinet
          python

          API code.</p>

          <p><code>pdb file_name.py</code></p>

          <p>Once you executed the above code, the command line will be stopped on
          the first

          line of code and you can use some commands to control the execution flow.</p>

          <p>Some useful ones to use are:</p>

          <table>

          <thead>

          <tr>

          <th align="right">Command</th>

          <th align="left">Action</th>

          </tr>

          </thead>

          <tbody>

          <tr>

          <td align="right">b</td>

          <td align="left">set a breakpoint</td>

          </tr>

          <tr>

          <td align="right">c</td>

          <td align="left">continue debugging until you hit a breakpoint</td>

          </tr>

          <tr>

          <td align="right">s</td>

          <td align="left">step through the code</td>

          </tr>

          <tr>

          <td align="right">n</td>

          <td align="left">to go to next line of code</td>

          </tr>

          <tr>

          <td align="right">l</td>

          <td align="left">list source code for the current file</td>

          </tr>

          <tr>

          <td align="right">u</td>

          <td align="left">navigate up a stack frame</td>

          </tr>

          <tr>

          <td align="right">d</td>

          <td align="left">navigate down a stack frame</td>

          </tr>

          <tr>

          <td align="right">p</td>

          <td align="left">to print the value of an expression in the current context</td>

          </tr>

          </tbody>

          </table>

          <h2>Debugging Via HTTP</h2>

          <p>The both of command line API and python API are restful web service client.

          Thus the requests are all made by using HTTP and you can always refer to

          <a href="http://developer.openstack.org/api-ref-networking-v2.html">OpenStack
          Service End</a> for further references about what should be

          presented in the HTTP requests. The Neutron API uses <a href="http://www.python-requests.org/en/latest/">requests</a>
          library

          to send and receive HTTP requests/responses.</p>

          <p>For command line client, you can add --debug option to print out HTTP
          request

          header and HTTP response header, which give you a lot of more insight

          information. To verify parameters in the request header, you can refer to

          OpenStack service <a href="http://developer.openstack.org/api-ref-networking-v2.html">API</a>
          to see what are expected.</p>

          <p>To enable debugging information on the standard out for Python API, you
          can add

          the below code:</p>

          <p>```</p>

          <p>import logging</p>

          <p>logger = logging.getLogger("neutronclient")</p>

          <p>logging.basicConfig(level=logging.DEBUG)</p>

          <p>```</p>

          <p>The will print the same output as adding --debug option for command line
          API.</p>

          <h2>Debugging via Source Code</h2>

          <p>If the above techniques are still not helpful, you can always look at
          the source

          code to find the problems.</p>

          <p>The below source file structure is based on the installation in Ubuntu.</p>

          <p>The command line neutron command is located in ''/usr/bin/neutron''.
          By looking at this

          file, you should get a idea of how the various options are interpreted.
          This file

          acts as an interface for Python API.</p>

          <p>The Python API files are located under

          ''/usr/lib/python2.7/dist-packages/neutronclient/v2_0/'' and the most important
          file to look

          at is ''client.py''. This file does all the request preparation, sending
          request and

          receiving response. It is also used by the command line Neutron client.</p>'
        folder:
          category_id: 6000122279
          created_at: '2015-12-01T18:22:33-05:00'
          customer_folders: []
          description: Networking
          id: 6000210730
          is_default: false
          language_id: 6
          name: Networking
          parent_id: 6000210730
          position: 6
          updated_at: '2015-12-07T19:43:55-05:00'
          visibility: 1
        folder_id: 6000210730
        hits: 0
        id: 6000095318
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-07T23:28:53-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000095318
        position: 5
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Trouble Shooting
        updated_at: '2015-12-07T23:28:53-05:00'
        user_id: 6002464727
  html: '<h2>Debugging Neutron Command line Client</h2>

    <p>These instructions assume you have installed Neutron command client in a Linux

    environment. If you have other operating systems, the debugging process might
    be

    a slightly different, however, the general rules should still apply.</p>

    <p>Neutron command line client is very much like other Linux commands, it outputs

    errors in the standard output, which is the monitor.</p>

    <p>If you get an error, you can always read the error message and generally it
    give

    you very good hints about what might be wrong.</p>

    <p>For example, if you execute <code>neutron net-list</code> on the command line
    without

    authentication, the error message might look like this:</p>

    <p><code>ERROR: You must provide a username via either --os-username or env[OS_USERNAME]</code></p>

    <p>The above message indicates you need to be authenticated before you can use
    the

    API. The authentication requires some environment variables to be set. To set

    these environment variables you can either source the script file obtained from

    NeCTAR <a href="https://dashboard.rc.nectar.org.au">Dashboard</a> or you can override
    it by using command line options.</p>

    <p>Please refer to <a href="https://support.nectar.org.au/support/solutions/articles/6000094839-getting-started">Networking
    Getting Started</a> article.</p>

    <p>You can always execute <code>man neutron</code> or simply <code>neutron help</code>
    to get

    more help information and to learn each supported options.</p>

    <p>If you find a useful command, you can also execute <code>nova help command</code>,

    this will give your more specific help for the command.</p>

    <h2>Debugging Neutron Python API</h2>

    <p>Debugging Neutron Python API takes more effects as it depends on how familiar

    with Python programming and what development environment you use.</p>

    <p>The below provides some basic information about how you debug the Neutron Python

    API.</p>

    <p>You can debug your python code using Python debugger called pdb and you can
    find

    more information <a href="https://docs.python.org/2/library/pdb.html">here</a>.</p>

    <p>The below code uses pdb debuuger to debug a python file contains clinet python

    API code.</p>

    <p><code>pdb file_name.py</code></p>

    <p>Once you executed the above code, the command line will be stopped on the first

    line of code and you can use some commands to control the execution flow.</p>

    <p>Some useful ones to use are:</p>

    <table>

    <thead>

    <tr>

    <th align="right">Command</th>

    <th align="left">Action</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td align="right">b</td>

    <td align="left">set a breakpoint</td>

    </tr>

    <tr>

    <td align="right">c</td>

    <td align="left">continue debugging until you hit a breakpoint</td>

    </tr>

    <tr>

    <td align="right">s</td>

    <td align="left">step through the code</td>

    </tr>

    <tr>

    <td align="right">n</td>

    <td align="left">to go to next line of code</td>

    </tr>

    <tr>

    <td align="right">l</td>

    <td align="left">list source code for the current file</td>

    </tr>

    <tr>

    <td align="right">u</td>

    <td align="left">navigate up a stack frame</td>

    </tr>

    <tr>

    <td align="right">d</td>

    <td align="left">navigate down a stack frame</td>

    </tr>

    <tr>

    <td align="right">p</td>

    <td align="left">to print the value of an expression in the current context</td>

    </tr>

    </tbody>

    </table>

    <h2>Debugging Via HTTP</h2>

    <p>The both of command line API and python API are restful web service client.

    Thus the requests are all made by using HTTP and you can always refer to

    <a href="http://developer.openstack.org/api-ref-networking-v2.html">OpenStack
    Service End</a> for further references about what should be

    presented in the HTTP requests. The Neutron API uses <a href="http://www.python-requests.org/en/latest/">requests</a>
    library

    to send and receive HTTP requests/responses.</p>

    <p>For command line client, you can add --debug option to print out HTTP request

    header and HTTP response header, which give you a lot of more insight

    information. To verify parameters in the request header, you can refer to

    OpenStack service <a href="http://developer.openstack.org/api-ref-networking-v2.html">API</a>
    to see what are expected.</p>

    <p>To enable debugging information on the standard out for Python API, you can
    add

    the below code:</p>

    <p>```</p>

    <p>import logging</p>

    <p>logger = logging.getLogger("neutronclient")</p>

    <p>logging.basicConfig(level=logging.DEBUG)</p>

    <p>```</p>

    <p>The will print the same output as adding --debug option for command line API.</p>

    <h2>Debugging via Source Code</h2>

    <p>If the above techniques are still not helpful, you can always look at the source

    code to find the problems.</p>

    <p>The below source file structure is based on the installation in Ubuntu.</p>

    <p>The command line neutron command is located in ''/usr/bin/neutron''. By looking
    at this

    file, you should get a idea of how the various options are interpreted. This file

    acts as an interface for Python API.</p>

    <p>The Python API files are located under

    ''/usr/lib/python2.7/dist-packages/neutronclient/v2_0/'' and the most important
    file to look

    at is ''client.py''. This file does all the request preparation, sending request
    and

    receiving response. It is also used by the command line Neutron client.</p>'
  parent: 44
  sha1: 9acbb5d011cc0ca185cceb3755b02ccde3f6dd89
  title: Trouble Shooting
107:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        bool_01: null
        created_at: '2015-12-15T21:34:49-05:00'
        datetime_01: null
        delta: true
        desc_un_html: " Table of Contents \n \n Introduction \n Installing R \n Updating\
          \ to the newest version of R \n Installing RStudio Server GUI \n Troubleshooting\
          \ and server management \n Installing and switching between multiple versions\
          \ of R \n Using RStudio under multiple versions of R \n Transferring files\
          \ between your local and remote systems \n Transferring files to your remote\
          \ instance \n Transferring files from your remote system \n Installation\
          \ and management of R packages \n Running R in the cloud \n \n Installing\
          \ R and RStudio Server in a NeCTAR Cloud Instance \n Introduction \n This\
          \ documentation provides a step-by-step guide for installing and configuring\
          \ a ready-to-use R environment, and optional RStudio Server graphical user\
          \ interface, within the NeCTAR Research Cloud. Beyond basic software installation\
          \ and version management, information is also provided for how to import\
          \ and export data to and from your cloud instance as well as guidance for\
          \ how to actually run R in the cloud. The commands are relevant for Ubuntu\
          \ and Debian users and were tested on a Mac and PC, through MobaXterm virtual\
          \ Linux emulator. \n There is an assumption that the user already has a\
          \ basic understanding of Linux command line coding and is familiar with\
          \ the NeCTAR research cloud (i.e. setting up ssh-keypairs and launching\
          \ and logging into instances, etc.). However, guidance is provided throughout\
          \ if experience is limited. Security and maintenance of NeCTAR cloud instances\
          \ are the responsibility of the user, although some support is provided\
          \ by the NeCTAR Helpdesk as well as extensive documentation available for\
          \ using the NeCTAR Research Cloud. \n Installing R \n R is available for\
          \ installation in many Linux distribution package repositories, including\
          \ the most commonly used Ubuntu and Debian operating systems. To install\
          \ the default version of R and dependent packages for the distribution you\
          \ are using, perform these commands in your terminal window: \n ```\n$ sudo\
          \ apt-get update\n$ sudo apt-get install r-base \n$ R  \n \n ``` \n \n Your\
          \ terminal window is now your R console. \n Updating to the newest version\
          \ of R \n As new versions of R are released more regularly than versions\
          \ of operating systems are, your Linux distribution will not always have\
          \ the newest, or required, version of R in its software package repository.\
          \ To install the newest version of R you will need to add the repository\
          \ address to your package sources file so it will be downloaded when you\
          \ perform a system update. \n $ sudo nano /etc/apt/sources.list \n Note:\
          \ nano is a text editor, but you can use other similar editors. To install\
          \ nano:\n$ sudo apt-get install nano. \n The command will open your sources.list\
          \ file and allow you to perform edits to it. The address you add will depend\
          \ on both your preferred CRAN mirror and the specific Linux distribution\
          \ you are using.  \n deb http://<cran.mirror>/bin/linux/<OS type and version>\
          \ \n \n You will then need to obtain and add the appropriate public key:\
          \ \n The Ubuntu archives on CRAN are signed with the key of \"Michael Rutter\"\
          \ with key ID E084DAB9. You can fetch and add this key with: \n $ sudo apt-key\
          \ adv --keyserver keyserver.ubuntu.com --recv-key E084DAB9  \n The Debian\
          \ archives on CRAN are signed with the key of \"Johannes Ranke\" with key\
          \ ID 381BA480. You can fetch and add this key with: \n $ sudo apt-key adv\
          \ --keyserver keys.gnupg.net --recv-key 381BA480   \n Now perform an update\
          \ to install the most recent version of R: \n ```\n$ sudo apt-get update\
          \ \n$ sudo apt-get install r-base\n$ R  \n \n ``` \n \n Installing RStudio\
          \ Server GUI \n RStudio Server can be installed on Debian (8+) or Ubuntu\
          \ (12.04+) systems. \nFor installation guidelines for other distributions\
          \ reference the RStudio Server website.  \n In the cloud, RStudio is accessed\
          \ via your web browser using your instance's IP address and a unique username\
          \ and password to authenticate users. By default RStudio Server uses port\
          \ 8787. If your instance's current security group rules do not allow for\
          \ connections across this port you can change this in your NeCTAR Dashboard.\
          \ To add this rule go to the Access & Security tab from the left hand toolbar\
          \ and select Manage Rules and then Add Rule, for the relevant security group.\
          \ In the pop-up window, create a new Custom TCP Rule and add port 8787.\
          \  \n \n Before you can connect to your RStudio Server you must download\
          \ and install the package from within your terminal window.  \n Note: installation\
          \ of .deb files requires prior installation of package gdebi-core:\n$ sudo\
          \ apt-get install gdebi-core \n Next, download and install your preferred\
          \ RStudio package (Check the RStudio website for an updated version): \n\
          \ 64bit \nVersion: 0.99.489 \n $ wget https://download2.rstudio.org/rstudio-server-0.99.489-amd64.deb\
          \ \n $ sudo gdebi rstudio-server-0.99.489-amd64.deb \n 32bit \nVersion:\
          \ 0.99.489 \n $ wget https://download2.rstudio.org/rstudio-server-0.99.489-i386.deb\
          \ \n $ sudo gdebi rstudio-server-0.99.489-i386.deb \n Now that RStudio Server\
          \ is installed, you can access the server from your local web browser, specifying\
          \ your instance's IP address and the RStudio Server default port.  \n http://<IP\
          \ address>:8787 \n \n If you get this in your browser, RStudio Server was\
          \ successfully installed. To be able to log-in to RStudio, you will need\
          \ to create a new user account in your instance using this command: \n $\
          \ sudo adduser <username> \n This new user account will be separate from\
          \ your NeCTAR instance log-in, i.e. the default administrator (ubuntu/debian)\
          \ and associated keypair, meaning it alone cannot be used to ssh into your\
          \ remote system. To allow this new user access to ephemeral storage (/mnt)\
          \ you will need to change its permissions. \n Reminder: your ephemeral storage\
          \ (/mnt) can be thought of as your cloud 'workspace' since it contains the\
          \ greatest amount of memory. This is where you should store data and run\
          \ scripts to avoid filling up your home directory. By default ubuntu/debian\
          \ do not have permissions for this directory; if you have not already changed\
          \ your permissions for /mnt perform the following command:\n$ sudo chown\
          \ ubuntu. For more information on this topic visit NeCTAR Support.  \n $\
          \ sudo usermod -a -G ubuntu <username> \n Now, this new username and password\
          \ can be used to login to RStudio Server. You can access /mnt by selecting\
          \ [...] at the top right of the Files tab, and upload or export between\
          \ your local system and /mnt using Upload and More -> Export.... \n Troubleshooting\
          \ and server management \n The following commands are useful for management\
          \ of your RStudio Server, and for troubleshooting installation and server\
          \ access issues. For further information see the RStudio Server Administrator's\
          \ Guide. \n Tests correct installation and connection with installed R:\
          \ \n$ sudo rstudio-server verify-installation \n Restarts RStudio after\
          \ changes or updates are made: \n$ sudo rstudio-server restart \n Returns\
          \ current status: \n$ sudo rstudio-server status \n Takes system online\
          \ or offline: \n$ sudo rstudio-server online\n$ sudo rstudio-server offline\
          \ \n Views system log, filtering for RStudio: \n$ more /var/log/syslog |\
          \ grep RStudio \n Installing and switching between multiple versions of\
          \ R \n Older versions of R must be built from their source code. The easiest\
          \ way to manage multiple versions of R within your instance is to create\
          \ a special directory in which to hold and configure these files. For example:\
          \ \n $ mkdir R.versions\n$ cd R.versions\n~/R.versions$ \n To install any\
          \ compatible version of R from source you first need to obtain the build\
          \ dependencies: \n $ sudo apt-get build-dep r-base \n Next, within this\
          \ new directory, obtain and unarchive the source code for the version of\
          \ R you require. The example here will install R 3.2.2: \n $ wget https://cran.rstudio.com/src/base/R-3/R-3.2.2.tar.gz\
          \ \n Unpack the file: \n $ tar -xvzf R-3.2.2.tar.gz \n Now from within the\
          \ extracted directory, configure and install R from source. \nNote: Defining\
          \ the prefix to a specific path is required to allow RStudio to find the\
          \ relevant directory and shared libraries must be enabled for RStudio to\
          \ access them. \n $ ./configure --prefix=/local/bin/R-3.2.2 --enable-R-shlib\
          \ \n $ make \n R can be run at this point, without being fully installed,\
          \ by executing the following command from within the directory where R-3.2.2\
          \ was configured: \n ```\n$ bin/R \n \n ``` \n \n However, for RStudio to\
          \ run you will need to perform a full installation: \n $ sudo make install\
          \    \n Other optional commands: \n $ more INSTALL  -> reads installation\
          \ guide \n$ make check  -> checks installation built correctly \n$ make\
          \ pdf        -> writes PDF manuals \n$ make info       -> writes info files\
          \ \n Note: to go back to using the default version of R, you use the same\
          \ command (within any directory) as prior to installing the additional version\
          \ ($ R). \n Using RStudio under multiple versions of R \n At this point\
          \ RStudio is ready to run under any installed version of R- you only need\
          \ to specify which version to run in the configuration file, adding a line\
          \ to the file which indicates the directory for RStudio to use. \n $ sudo\
          \ nano /etc/rstudio/rserver.conf \n The line you add will depend on the\
          \ path you specified when R was configured and the version of R: \n rsession-which-r=/local/bin/R-3.2.2/bin/R\
          \ \n \n Next, restart RStudio to allow the changes to take effect: \n $\
          \ sudo rstudio-server restart \n Note: you may also need to quit your current\
          \ RStudio session in your browser: File -> Quit RStudio (which will reopen\
          \ a new session). Then, type this command in your R console to confirm the\
          \ appropriate version is running. \n ``` \n \n R.version.string\n[1] \"\
          version 3.2.2 (2015-08-14)\"\n``` \n \n Transferring files between your\
          \ local and remote systems \n How you transfer files in and out of your\
          \ instance will depend on a number of factors, including where your input\
          \ data is stored and how much of it there is, and whether you are using\
          \ R through your terminal window or RStudio Server in your web browser.\
          \ If you are using RStudio you already have a direct connection from your\
          \ local computer to your instance to facilitate file transfers. If you are\
          \ using R through your terminal window there are a couple options for this\
          \ (See NeCTAR Support). This section will provide a short overview for transferring\
          \ files via SFTP, or Secure File Transfer Protocol. \n For information on\
          \ how to attach NeCTAR Volume or Object storage see additional NeCTAR Tier\
          \ 0 Documentation \n SFTP is related to SSH (secure shell) as it uses the\
          \ same key-pair you generated to initially log into your instance, to create\
          \ a secure connection for transferring files. To initialise a SFTP link\
          \ between your computer and remote instance you use a similar command as\
          \ when using SSH. The prompt you see when the connection has been established\
          \ is similar to the R console command line. \n $sftp -i ~/directory/key_name.key\
          \ ubuntu@<IPaddress>\nsftp> \n The commands you use under SFTP are essentially\
          \ the same standard Linux commands used for navigating and managing file\
          \ systems when SSH'd into your instance. Some differences include that you\
          \ must specify when you want to refer to your local directory by placing\
          \ a 'l' or an '!' before each command, and that the SFTP prompt does not\
          \ change based on what directory you are in. \n First, check your current\
          \ local and remote directories \n ``` \n \n pwd\nlpwd\n``` \n \n Now, navigate\
          \ through your local and remote file systems to the appropriate directories\
          \ where your files are currently stored and where you would like them to\
          \ be moved to, using the following common Linux commands (alternatively\
          \ you can specify directory within the transfer command).  \n\n\n\nRemote\
          \ instance\nLocal computer\nCommand use\n\n\n\n\nls\nlls\nlists all visible\
          \ files in current directory\n\n\nls -al\nlls -al\nlists visible and hidden\
          \ files in current directory\n\n\ncd\nlcd\nchanges directory\n\n\nmkdir\n\
          ! mkdir\ncreates new directory\n\n\n\n Transferring files to your remote\
          \ instance \n To transfer data files, scripts, or entire directories from\
          \ your local terminal, the command put is used. Here is an example showing\
          \ how to transfer an individual csv file.  \n > put data.csv \n \n To transfer\
          \ an entire directory you will need to first create a destination directory\
          \ with the same name. \n ``` \n \n mkdir R_scripts \nput -r R_scripts\n\
          ``` \n \n \n Transferring files from your remote system \n When transferring\
          \ files from your remote instance, the command get is used. Note: you can\
          \ change a file/directory name by specifying a new name at the end of the\
          \ command, and if names contain spaces they must be enclosed in ' '.  \n\
          \ ``` \n \n get     \n mkdir \nget -r \n``` \n \n \n To terminate your SFTP\
          \ connection use the same command as when connected through ssh: \n > exit\
          \ \n Installation and management of R packages \n A number of R packages,\
          \ all part of the r-recommended bundle, are included in R installation packages\
          \ for Ubuntu and Debian Linux distributions. A list of these can be found\
          \ at the CRAN website or by executing library(), which will also return\
          \ the default library directory. \n When installing additional packages\
          \ you will be prompted to create a personal library where all supplementary\
          \ packages will be installed to. R creates this directory on its own, once\
          \ permissions have been given, however a pop-up window will appear requesting\
          \ you to select your preferred CRAN mirror. Your personal library will act\
          \ as a second default library, meaning loading packages does not require\
          \ you to specify the directory.  \n Running R in the cloud \n Scientists\
          \ may want to conduct their research in the cloud for a variety of reasons,\
          \ and this diversity holds for those using R in the cloud. How you run scripts\
          \ in R and whether you use R through your terminal window or with RStudio\
          \ Server will depend on a multitude of factors, including individual preferences.\
          \ In general, the cloud is most useful for non-interactive scripts, which\
          \ can run in the 'background' allowing you to terminate the ssh connection\
          \ between your local and remote systems, or logout and close your RStudio\
          \ browser. \n While RStudio automatically runs R in the background, running\
          \ R through your terminal window requires you to use commands to specify\
          \ this (Note: ssh connections will break after periods of inactivity and,\
          \ therefore, any jobs running in the forefront will be terminated). The\
          \ command nohup coupled with either Rscript or R CMD BATCH can be used to\
          \ submit R scripts to run in the background of your instance. Here are examples\
          \ of each: \n $ nohup Rscript Rcode_test.R  \n $ nohup R CMD BATCH Rcode_test.R\
          \ Rcode_test.Rout \n The difference between Rscript and R CMD BATCH is mainly\
          \ in the output files. BATCH creates an output file which echos what you\
          \ would normally see in your R console, while Rscript does not create this.\
          \ The command nohup also creates an output file, nohup.out, in the directory\
          \ from which you submitted the job. The nohup.out file echos errors, warnings,\
          \ system.time and some random initial commands, but does not echo all commands\
          \ passed through R. This file would also be automatically overwritten if\
          \ multiple jobs were submitted, whereas the output BATCH file name and directory\
          \ can be specified: \n $ nohup R CMD BATCH Rcode_test.R Project_test/Output_files/Rcode_test.Rout\
          \ \n Note: when a job is submitted, the following notification will be returned\
          \ and is not an error- it is telling you that the normal outputs to your\
          \ console will be redirected to the nohup.out file and provides the PID\
          \ or process identifier.  \n nohup: ignoring input and appending output\
          \ to 'nohup.out' \n To check on your job, use the command top followed by\
          \ 1. This will print all the processes running on your instance and what\
          \ is running on each core. In the example image below there is a process\
          \ running by user 'test', the command 'rsession' indicates it is RStudio,\
          \ and a process owned by ubuntu (user ssh'd into instance) and the command\
          \ indicates R is running. The last example command below is for terminating\
          \ a job by its PID. \n $ top\n1\n$ kill -9 <PID> \n "
        description: "<h2>Table of Contents</h2>\n<ul>\n<li><a href=\"#%20Introduction\"\
          >Introduction</a></li>\n<li><a href=\"#%20Installing%20R\">Installing R</a></li>\n\
          <li><a href=\"#%20Updating%20to%20the%20newest%20version%20of%20R\">Updating\
          \ to the newest version of R</a></li>\n<li><a href=\"#%20Installing%20RStudio%20Server%20GUI\"\
          >Installing RStudio Server GUI</a></li>\n<li><a href=\"#%20Troubleshooting%20and%20server%20management\"\
          >Troubleshooting and server management</a></li>\n<li><a href=\"#%20Installing%20and%20switching%20between%20multiple%20versions%20of%20R\"\
          >Installing and switching between multiple versions of R</a></li>\n<li><a\
          \ href=\"#%20Using%20RStudio%20under%20multiple%20versions%20of%20R\">Using\
          \ RStudio under multiple versions of R</a></li>\n<li><a href=\"#%20Transferring%20files%20between%20your%20local%20and%20remote%20systems\"\
          >Transferring files between your local and remote systems</a></li>\n<li><a\
          \ href=\"#%20Transferring%20files%20to%20your%20remote%20instance\">Transferring\
          \ files to your remote instance</a></li>\n<li><a href=\"#%20Transferring%20files%20from%20your%20remote%20system\"\
          >Transferring files from your remote system</a></li>\n<li><a href=\"#%20Installation%20and%20management%20of%20R%20packages\"\
          >Installation and management of R packages</a></li>\n<li><a href=\"#%20Running%20R%20in%20the%20cloud\"\
          >Running R in the cloud</a></li>\n</ul>\n<h1>Installing R and RStudio Server\
          \ in a NeCTAR Cloud Instance</h1>\n<h2>Introduction</h2>\n<p>This documentation\
          \ provides a step-by-step guide for installing and configuring a ready-to-use\
          \ R environment, and optional RStudio Server graphical user interface, within\
          \ the NeCTAR Research Cloud. Beyond basic software installation and version\
          \ management, information is also provided for how to import and export\
          \ data to and from your cloud instance as well as guidance for how to actually\
          \ run R in the cloud. The commands are relevant for Ubuntu and Debian users\
          \ and were tested on a Mac and PC, through MobaXterm virtual Linux emulator.</p>\n\
          <p>There is an assumption that the user already has a basic understanding\
          \ of Linux command line coding and is familiar with the NeCTAR research\
          \ cloud (i.e. setting up ssh-keypairs and launching and logging into instances,\
          \ etc.). However, guidance is provided throughout if experience is limited.\
          \ Security and maintenance of NeCTAR cloud instances are the responsibility\
          \ of the user, although some support is provided by the <a href=\"https://support.rc.nectar.org.au/docs/support\"\
          >NeCTAR Helpdesk</a> as well as extensive documentation available for using\
          \ the <a href=\"https://support.rc.nectar.org.au/docs/getting-started\"\
          >NeCTAR Research Cloud</a>.</p>\n<h2>Installing R</h2>\n<p>R is available\
          \ for installation in many Linux distribution package repositories, including\
          \ the most commonly used Ubuntu and Debian operating systems. To install\
          \ the default version of R and dependent packages for the distribution you\
          \ are using, perform these commands in your terminal window:</p>\n<p>```\n\
          $ sudo apt-get update\n$ sudo apt-get install r-base \n$ R </p>\n<blockquote>\n\
          <p>```</p>\n</blockquote>\n<p>Your terminal window is now your R console.</p>\n\
          <h3>Updating to the newest version of R</h3>\n<p>As new versions of R are\
          \ released more regularly than versions of operating systems are, your Linux\
          \ distribution will not always have the newest, or required, version of\
          \ R in its software package repository. To install the newest version of\
          \ R you will need to add the repository address to your package sources\
          \ file so it will be downloaded when you perform a system update.</p>\n\
          <p><code>$ sudo nano /etc/apt/sources.list</code></p>\n<p>Note: nano is\
          \ a text editor, but you can use other similar editors. To install nano:\n\
          <code>$ sudo apt-get install nano</code>.</p>\n<p>The command will open\
          \ your sources.list file and allow you to perform edits to it. The address\
          \ you add will depend on both your preferred <a href=\"https://cran.r-project.org/mirrors.html\"\
          >CRAN mirror</a> and the specific <a href=\"https://cran.rstudio.com/bin/linux/\"\
          >Linux distribution</a> you are using. </p>\n<p><code>deb http://&lt;cran.mirror&gt;/bin/linux/&lt;OS\
          \ type and version&gt;</code></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/R1_sources.list.png?raw=true\"\
          ></p>\n<p>You will then need to obtain and add the appropriate public key:</p>\n\
          <p>The <strong>Ubuntu</strong> archives on CRAN are signed with the key\
          \ of \"Michael Rutter\" with key ID E084DAB9. You can fetch and add this\
          \ key with:</p>\n<p><code>$ sudo apt-key adv --keyserver keyserver.ubuntu.com\
          \ --recv-key E084DAB9</code> </p>\n<p>The <strong>Debian</strong> archives\
          \ on CRAN are signed with the key of \"Johannes Ranke\" with key ID 381BA480.\
          \ You can fetch and add this key with:</p>\n<p><code>$ sudo apt-key adv\
          \ --keyserver keys.gnupg.net --recv-key 381BA480</code>  </p>\n<p>Now perform\
          \ an update to install the most recent version of R:</p>\n<p>```\n$ sudo\
          \ apt-get update \n$ sudo apt-get install r-base\n$ R </p>\n<blockquote>\n\
          <p>```</p>\n</blockquote>\n<h2>Installing RStudio Server GUI</h2>\n<p>RStudio\
          \ Server can be installed on Debian (8+) or Ubuntu (12.04+) systems. \n\
          For installation guidelines for other distributions reference the <a href=\"\
          https://www.rstudio.com/products/rstudio/download-server/\">RStudio Server\
          \ website</a>. </p>\n<p>In the cloud, RStudio is accessed via your web browser\
          \ using your instance's IP address and a unique username and password to\
          \ authenticate users. By default RStudio Server uses port 8787. If your\
          \ instance's current security group rules do not allow for connections across\
          \ this port you can change this in your NeCTAR Dashboard. To add this rule\
          \ go to the <strong>Access &amp; Security</strong> tab from the left hand\
          \ toolbar and select <strong>Manage Rules</strong> and then <strong>Add\
          \ Rule</strong>, for the relevant security group. In the pop-up window,\
          \ create a new <strong>Custom TCP Rule</strong> and add port <strong>8787</strong>.\
          \ </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/R2_newrule.png?raw=true\"\
          ></p>\n<p>Before you can connect to your RStudio Server you must download\
          \ and install the package from within your terminal window. </p>\n<p>Note:\
          \ installation of .deb files requires prior installation of package gdebi-core:\n\
          <code>$ sudo apt-get install gdebi-core</code></p>\n<p>Next, download and\
          \ install your preferred RStudio package (Check the <a href=\"www.rstudio.com/products/rstudio/download-server/\"\
          >RStudio website</a> for an updated version):</p>\n<p><strong>64bit</strong><br>\n\
          <strong>Version: 0.99.489</strong></p>\n<p><code>$ wget https://download2.rstudio.org/rstudio-server-0.99.489-amd64.deb</code></p>\n\
          <p><code>$ sudo gdebi rstudio-server-0.99.489-amd64.deb</code></p>\n<p><strong>32bit</strong><br>\n\
          <strong>Version: 0.99.489</strong></p>\n<p><code>$ wget https://download2.rstudio.org/rstudio-server-0.99.489-i386.deb</code></p>\n\
          <p><code>$ sudo gdebi rstudio-server-0.99.489-i386.deb</code></p>\n<p>Now\
          \ that RStudio Server is installed, you can access the server from your\
          \ local web browser, specifying your instance's IP address and the RStudio\
          \ Server default port. </p>\n<p><code>http://&lt;IP address&gt;:8787</code></p>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/R3_Rstudio.png?raw=true\"\
          ></p>\n<p>If you get this in your browser, RStudio Server was successfully\
          \ installed. To be able to log-in to RStudio, you will need to create a\
          \ new user account in your instance using this command:</p>\n<p><code>$\
          \ sudo adduser &lt;username&gt;</code></p>\n<p>This new user account will\
          \ be separate from your NeCTAR instance log-in, i.e. the default administrator\
          \ (ubuntu/debian) and associated keypair, meaning it alone cannot be used\
          \ to ssh into your remote system. To allow this new user access to ephemeral\
          \ storage (/mnt) you will need to change its permissions.</p>\n<p><strong><em>Reminder:</em></strong>\
          \ your ephemeral storage (/mnt) can be thought of as your cloud 'workspace'\
          \ since it contains the greatest amount of memory. This is where you should\
          \ store data and run scripts to avoid filling up your home directory. By\
          \ default ubuntu/debian do not have permissions for this directory; if you\
          \ have not already changed your permissions for /mnt perform the following\
          \ command:\n<code>$ sudo chown ubuntu</code>. For more information on this\
          \ topic visit <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055382-introduction-to-cloud-storage\"\
          >NeCTAR Support</a>. </p>\n<p><code>$ sudo usermod -a -G ubuntu &lt;username&gt;</code></p>\n\
          <p>Now, this new username and password can be used to login to RStudio Server.\
          \ You can access /mnt by selecting <strong>[...]</strong> at the top right\
          \ of the <strong>Files</strong> tab, and upload or export between your local\
          \ system and /mnt using <strong>Upload</strong> and <strong>More</strong>\
          \ -&gt; <strong>Export...</strong>.</p>\n<h3>Troubleshooting and server\
          \ management</h3>\n<p>The following commands are useful for management of\
          \ your RStudio Server, and for troubleshooting installation and server access\
          \ issues. For further information see the <a href=\"https://s3.amazonaws.com/rstudio-server/rstudio-server-pro-0.98.507-admin-guide.pdf\"\
          >RStudio Server Administrator's Guide</a>.</p>\n<p>Tests correct installation\
          \ and connection with installed R:<br>\n<code>$ sudo rstudio-server verify-installation</code></p>\n\
          <p>Restarts RStudio after changes or updates are made:<br>\n<code>$ sudo\
          \ rstudio-server restart</code></p>\n<p>Returns current status:<br>\n<code>$\
          \ sudo rstudio-server status</code></p>\n<p>Takes system online or offline:<br>\n\
          <code>$ sudo rstudio-server online</code>\n<code>$ sudo rstudio-server offline</code></p>\n\
          <p>Views system log, filtering for RStudio:<br>\n<code>$ more /var/log/syslog\
          \ | grep RStudio</code></p>\n<h2>Installing and switching between multiple\
          \ versions of R</h2>\n<p>Older versions of R must be built from their source\
          \ code. The easiest way to manage multiple versions of R within your instance\
          \ is to create a special directory in which to hold and configure these\
          \ files. For example:</p>\n<p><code>$ mkdir R.versions\n$ cd R.versions\n\
          ~/R.versions$</code></p>\n<p>To install any compatible version of R from\
          \ source you first need to obtain the build dependencies:</p>\n<p><code>$\
          \ sudo apt-get build-dep r-base</code></p>\n<p>Next, <strong>within</strong>\
          \ this new directory, <a href=\"https://cran.rstudio.com/src/base\">obtain</a>\
          \ and unarchive the source code for the version of R you require. The example\
          \ here will install R 3.2.2:</p>\n<p><code>$ wget https://cran.rstudio.com/src/base/R-3/R-3.2.2.tar.gz</code></p>\n\
          <p>Unpack the file:</p>\n<p><code>$ tar -xvzf R-3.2.2.tar.gz</code></p>\n\
          <p>Now from <strong>within</strong> the extracted directory, configure and\
          \ install R from source. \nNote: Defining the prefix to a specific path\
          \ is required to allow RStudio to find the relevant directory and shared\
          \ libraries must be enabled for RStudio to access them.</p>\n<p><code>$\
          \ ./configure --prefix=/local/bin/R-3.2.2 --enable-R-shlib</code></p>\n\
          <p><code>$ make</code></p>\n<p>R can be run at this point, without being\
          \ fully installed, by executing the following command from within the directory\
          \ where R-3.2.2 was configured:</p>\n<p>```\n$ bin/R</p>\n<blockquote>\n\
          <p>```</p>\n</blockquote>\n<p>However, for RStudio to run you will need\
          \ to perform a full installation:</p>\n<p><code>$ sudo make install</code>\
          \   </p>\n<p>Other optional commands:</p>\n<p><code>$ more INSTALL</code>\
          \  -&gt; reads installation guide<br>\n<code>$ make check</code>  -&gt;\
          \ checks installation built correctly<br>\n<code>$ make pdf</code>     \
          \   -&gt; writes PDF manuals<br>\n<code>$ make info</code>       -&gt; writes\
          \ info files</p>\n<p>Note: to go back to using the default version of R,\
          \ you use the same command (within any directory) as prior to installing\
          \ the additional version (<code>$ R</code>).</p>\n<h3>Using RStudio under\
          \ multiple versions of R</h3>\n<p>At this point RStudio is ready to run\
          \ under any installed version of R- you only need to specify which version\
          \ to run in the configuration file, adding a line to the file which indicates\
          \ the directory for RStudio to use.</p>\n<p><code>$ sudo nano /etc/rstudio/rserver.conf</code></p>\n\
          <p>The line you add will depend on the path you specified when R was configured\
          \ and the version of R:</p>\n<p><code>rsession-which-r=/local/bin/R-3.2.2/bin/R</code></p>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/R4_Rversion.png?raw=true\"\
          ></p>\n<p>Next, restart RStudio to allow the changes to take effect:</p>\n\
          <p><code>$ sudo rstudio-server restart</code></p>\n<p>Note: you may also\
          \ need to quit your current RStudio session in your browser: <strong>File</strong>\
          \ -&gt; <strong>Quit RStudio</strong> (which will reopen a new session).\
          \ Then, type this command in your R console to confirm the appropriate version\
          \ is running.</p>\n<p>```</p>\n<blockquote>\n<p>R.version.string\n[1] \"\
          version 3.2.2 (2015-08-14)\"\n```</p>\n</blockquote>\n<h2>Transferring files\
          \ between your local and remote systems</h2>\n<p>How you transfer files\
          \ in and out of your instance will depend on a number of factors, including\
          \ where your input data is stored and how much of it there is, and whether\
          \ you are using R through your terminal window or RStudio Server in your\
          \ web browser. If you are using RStudio you already have a direct connection\
          \ from your local computer to your instance to facilitate file transfers.\
          \ If you are using R through your terminal window there are a couple options\
          \ for this (<a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
          >See NeCTAR Support</a>). This section will provide a short overview for\
          \ transferring files via SFTP, or Secure File Transfer Protocol.</p>\n<p>For\
          \ information on how to attach NeCTAR Volume or Object storage see additional\
          \ <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055382-introduction-to-cloud-storage\"\
          >NeCTAR Tier 0 Documentation</a></p>\n<p>SFTP is related to SSH (secure\
          \ shell) as it uses the same key-pair you generated to initially log into\
          \ your instance, to create a secure connection for transferring files. To\
          \ initialise a SFTP link between your computer and remote instance you use\
          \ a similar command as when using SSH. The prompt you see when the connection\
          \ has been established is similar to the R console command line.</p>\n<p><code>$sftp\
          \ -i ~/directory/key_name.key ubuntu@&lt;IPaddress&gt;\nsftp&gt;</code></p>\n\
          <p>The commands you use under SFTP are essentially the same standard Linux\
          \ commands used for navigating and managing file systems when SSH'd into\
          \ your instance. Some differences include that you must specify when you\
          \ want to refer to your local directory by placing a '<code>l</code>' or\
          \ an '<code>!</code>' before each command, and that the SFTP prompt does\
          \ not change based on what directory you are in.</p>\n<p>First, check your\
          \ current local and remote directories</p>\n<p>```</p>\n<blockquote>\n<p>pwd\n\
          lpwd\n```</p>\n</blockquote>\n<p>Now, navigate through your local and remote\
          \ file systems to the appropriate directories where your files are currently\
          \ stored and where you would like them to be moved to, using the following\
          \ common Linux commands (alternatively you can specify directory within\
          \ the transfer command). </p>\n<table>\n<thead>\n<tr>\n<th><strong>Remote\
          \ instance</strong></th>\n<th><strong>Local computer</strong></th>\n<th\
          \ align=\"left\"><strong>Command use</strong></th>\n</tr>\n</thead>\n<tbody>\n\
          <tr>\n<td>ls</td>\n<td>lls</td>\n<td align=\"left\">lists all visible files\
          \ in current directory</td>\n</tr>\n<tr>\n<td>ls -al</td>\n<td>lls -al</td>\n\
          <td align=\"left\">lists visible and hidden files in current directory</td>\n\
          </tr>\n<tr>\n<td>cd</td>\n<td>lcd</td>\n<td align=\"left\">changes directory</td>\n\
          </tr>\n<tr>\n<td>mkdir</td>\n<td>! mkdir</td>\n<td align=\"left\">creates\
          \ new directory</td>\n</tr>\n</tbody>\n</table>\n<h3>Transferring files\
          \ to your remote instance</h3>\n<p>To transfer data files, scripts, or entire\
          \ directories from your local terminal, the command <code>put</code> is\
          \ used. Here is an example showing how to transfer an individual csv file.\
          \ </p>\n<p><code>&gt; put data.csv</code></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/R5_sftp.png?raw=true\"\
          ></p>\n<p>To transfer an entire directory you will need to first create\
          \ a destination directory with the same name.</p>\n<p>```</p>\n<blockquote>\n\
          <p>mkdir R_scripts \nput -r R_scripts\n```</p>\n</blockquote>\n<p><img alt=\"\
          \" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/R6_sftp.png?raw=true\"\
          ></p>\n<h3>Transferring files from your remote system</h3>\n<p>When transferring\
          \ files from your remote instance, the command <code>get</code> is used.\
          \ Note: you can change a file/directory name by specifying a new name at\
          \ the end of the command, and if names contain spaces they must be enclosed\
          \ in ' '. </p>\n<p>```</p>\n<blockquote>\n<p>get    </p>\n<p>mkdir \nget\
          \ -r \n```</p>\n</blockquote>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/R7_sftp.png?raw=true\"\
          ></p>\n<p>To terminate your SFTP connection use the same command as when\
          \ connected through ssh:</p>\n<p><code>&gt; exit</code></p>\n<h2>Installation\
          \ and management of R packages</h2>\n<p>A number of R packages, all part\
          \ of the r-recommended bundle, are included in R installation packages for\
          \ Ubuntu and Debian Linux distributions. A list of these can be found at\
          \ the <a href=\"https://cran.r-project.org/bin/linux/\">CRAN website</a>\
          \ or by executing <code>library()</code>, which will also return the default\
          \ library directory.</p>\n<p>When installing additional packages you will\
          \ be prompted to create a personal library where all supplementary packages\
          \ will be installed to. R creates this directory on its own, once permissions\
          \ have been given, however a pop-up window will appear requesting you to\
          \ select your preferred CRAN mirror. Your personal library will act as a\
          \ second default library, meaning loading packages does not require you\
          \ to specify the directory. </p>\n<h2>Running R in the cloud</h2>\n<p>Scientists\
          \ may want to conduct their research in the cloud for a variety of reasons,\
          \ and this diversity holds for those using R in the cloud. How you run scripts\
          \ in R and whether you use R through your terminal window or with RStudio\
          \ Server will depend on a multitude of factors, including individual preferences.\
          \ In general, the cloud is most useful for non-interactive scripts, which\
          \ can run in the 'background' allowing you to terminate the ssh connection\
          \ between your local and remote systems, or logout and close your RStudio\
          \ browser.</p>\n<p>While RStudio automatically runs R in the background,\
          \ running R through your terminal window requires you to use commands to\
          \ specify this (Note: ssh connections will break after periods of inactivity\
          \ and, therefore, any jobs running in the forefront will be terminated).\
          \ The command <code>nohup</code> coupled with either <a href=\"http://www.rdocumentation.org/packages/utils/functions/Rscript\"\
          ><code>Rscript</code></a> or <a href=\"http://www.rdocumentation.org/packages/utils/functions/BATCH\"\
          ><code>R CMD BATCH</code></a> can be used to submit R scripts to run in\
          \ the background of your instance. Here are examples of each:</p>\n<p><code>$\
          \ nohup Rscript Rcode_test.R</code> </p>\n<p><code>$ nohup R CMD BATCH Rcode_test.R\
          \ Rcode_test.Rout</code></p>\n<p>The difference between <code>Rscript</code>\
          \ and <code>R CMD BATCH</code> is mainly in the output files. BATCH creates\
          \ an output file which echos what you would normally see in your R console,\
          \ while Rscript does not create this. The command <code>nohup</code> also\
          \ creates an output file, nohup.out, in the directory from which you submitted\
          \ the job. The nohup.out file echos errors, warnings, system.time and some\
          \ random initial commands, but does not echo all commands passed through\
          \ R. This file would also be automatically overwritten if multiple jobs\
          \ were submitted, whereas the output BATCH file name and directory can be\
          \ specified:</p>\n<p><code>$ nohup R CMD BATCH Rcode_test.R Project_test/Output_files/Rcode_test.Rout</code></p>\n\
          <p>Note: when a job is submitted, the following notification will be returned\
          \ and is not an error- it is telling you that the normal outputs to your\
          \ console will be redirected to the nohup.out file and provides the PID\
          \ or process identifier. </p>\n<p><code>nohup: ignoring input and appending\
          \ output to 'nohup.out'</code></p>\n<p>To check on your job, use the command\
          \ <code>top</code> followed by <code>1</code>. This will print all the processes\
          \ running on your instance and what is running on each core. In the example\
          \ image below there is a process running by user 'test', the command 'rsession'\
          \ indicates it is RStudio, and a process owned by ubuntu (user ssh'd into\
          \ instance) and the command indicates R is running. The last example command\
          \ below is for terminating a job by its PID.</p>\n<p><code>$ top\n1\n$ kill\
          \ -9 &lt;PID&gt;</code></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/R8_top.jpg?raw=true\"\
          ></p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000098750
        int_01: null
        int_02: null
        int_03: null
        language_id: 6
        modified_at: '2015-12-15T21:34:49-05:00'
        modified_by: null
        outdated: false
        parent_id: 6000098750
        position: 15
        seo_data: {}
        status: 2
        string_01: null
        string_02: null
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Pawsey Installing R and RStudio
        updated_at: '2015-12-15T21:34:49-05:00'
        user_id: 6002464727
  html: "<h2>Table of Contents</h2>\n<ul>\n<li><a href=\"# Introduction\">Introduction</a></li>\n\
    <li><a href=\"# Installing R\">Installing R</a></li>\n<li><a href=\"# Updating\
    \ to the newest version of R\">Updating to the newest version of R</a></li>\n\
    <li><a href=\"# Installing RStudio Server GUI\">Installing RStudio Server GUI</a></li>\n\
    <li><a href=\"# Troubleshooting and server management\">Troubleshooting and server\
    \ management</a></li>\n<li><a href=\"# Installing and switching between multiple\
    \ versions of R\">Installing and switching between multiple versions of R</a></li>\n\
    <li><a href=\"# Using RStudio under multiple versions of R\">Using RStudio under\
    \ multiple versions of R</a></li>\n<li><a href=\"# Transferring files between\
    \ your local and remote systems\">Transferring files between your local and remote\
    \ systems</a></li>\n<li><a href=\"# Transferring files to your remote instance\"\
    >Transferring files to your remote instance</a></li>\n<li><a href=\"# Transferring\
    \ files from your remote system\">Transferring files from your remote system</a></li>\n\
    <li><a href=\"# Installation and management of R packages\">Installation and management\
    \ of R packages</a></li>\n<li><a href=\"# Running R in the cloud\">Running R in\
    \ the cloud</a></li>\n</ul>\n<h1>Installing R and RStudio Server in a NeCTAR Cloud\
    \ Instance</h1>\n<h2>Introduction</h2>\n<p>This documentation provides a step-by-step\
    \ guide for installing and configuring a ready-to-use R environment, and optional\
    \ RStudio Server graphical user interface, within the NeCTAR Research Cloud. Beyond\
    \ basic software installation and version management, information is also provided\
    \ for how to import and export data to and from your cloud instance as well as\
    \ guidance for how to actually run R in the cloud. The commands are relevant for\
    \ Ubuntu and Debian users and were tested on a Mac and PC, through MobaXterm virtual\
    \ Linux emulator.</p>\n<p>There is an assumption that the user already has a basic\
    \ understanding of Linux command line coding and is familiar with the NeCTAR research\
    \ cloud (i.e. setting up ssh-keypairs and launching and logging into instances,\
    \ etc.). However, guidance is provided throughout if experience is limited. Security\
    \ and maintenance of NeCTAR cloud instances are the responsibility of the user,\
    \ although some support is provided by the <a href=\"https://support.rc.nectar.org.au/docs/support\"\
    >NeCTAR Helpdesk</a> as well as extensive documentation available for using the\
    \ <a href=\"https://support.rc.nectar.org.au/docs/getting-started\">NeCTAR Research\
    \ Cloud</a>.</p>\n<h2>Installing R</h2>\n<p>R is available for installation in\
    \ many Linux distribution package repositories, including the most commonly used\
    \ Ubuntu and Debian operating systems. To install the default version of R and\
    \ dependent packages for the distribution you are using, perform these commands\
    \ in your terminal window:</p>\n<p>```\n$ sudo apt-get update\n$ sudo apt-get\
    \ install r-base \n$ R </p>\n<blockquote>\n<p>```</p>\n</blockquote>\n<p>Your\
    \ terminal window is now your R console.</p>\n<h3>Updating to the newest version\
    \ of R</h3>\n<p>As new versions of R are released more regularly than versions\
    \ of operating systems are, your Linux distribution will not always have the newest,\
    \ or required, version of R in its software package repository. To install the\
    \ newest version of R you will need to add the repository address to your package\
    \ sources file so it will be downloaded when you perform a system update.</p>\n\
    <p><code>$ sudo nano /etc/apt/sources.list</code></p>\n<p>Note: nano is a text\
    \ editor, but you can use other similar editors. To install nano:\n<code>$ sudo\
    \ apt-get install nano</code>.</p>\n<p>The command will open your sources.list\
    \ file and allow you to perform edits to it. The address you add will depend on\
    \ both your preferred <a href=\"https://cran.r-project.org/mirrors.html\">CRAN\
    \ mirror</a> and the specific <a href=\"https://cran.rstudio.com/bin/linux/\"\
    >Linux distribution</a> you are using. </p>\n<p><code>deb http://&lt;cran.mirror&gt;/bin/linux/&lt;OS\
    \ type and version&gt;</code></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/R1_sources.list.png?raw=true\"\
    ></p>\n<p>You will then need to obtain and add the appropriate public key:</p>\n\
    <p>The <strong>Ubuntu</strong> archives on CRAN are signed with the key of \"\
    Michael Rutter\" with key ID E084DAB9. You can fetch and add this key with:</p>\n\
    <p><code>$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key E084DAB9</code>\
    \ </p>\n<p>The <strong>Debian</strong> archives on CRAN are signed with the key\
    \ of \"Johannes Ranke\" with key ID 381BA480. You can fetch and add this key with:</p>\n\
    <p><code>$ sudo apt-key adv --keyserver keys.gnupg.net --recv-key 381BA480</code>\
    \  </p>\n<p>Now perform an update to install the most recent version of R:</p>\n\
    <p>```\n$ sudo apt-get update \n$ sudo apt-get install r-base\n$ R </p>\n<blockquote>\n\
    <p>```</p>\n</blockquote>\n<h2>Installing RStudio Server GUI</h2>\n<p>RStudio\
    \ Server can be installed on Debian (8+) or Ubuntu (12.04+) systems. \nFor installation\
    \ guidelines for other distributions reference the <a href=\"https://www.rstudio.com/products/rstudio/download-server/\"\
    >RStudio Server website</a>. </p>\n<p>In the cloud, RStudio is accessed via your\
    \ web browser using your instance's IP address and a unique username and password\
    \ to authenticate users. By default RStudio Server uses port 8787. If your instance's\
    \ current security group rules do not allow for connections across this port you\
    \ can change this in your NeCTAR Dashboard. To add this rule go to the <strong>Access\
    \ &amp; Security</strong> tab from the left hand toolbar and select <strong>Manage\
    \ Rules</strong> and then <strong>Add Rule</strong>, for the relevant security\
    \ group. In the pop-up window, create a new <strong>Custom TCP Rule</strong> and\
    \ add port <strong>8787</strong>. </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/R2_newrule.png?raw=true\"\
    ></p>\n<p>Before you can connect to your RStudio Server you must download and\
    \ install the package from within your terminal window. </p>\n<p>Note: installation\
    \ of .deb files requires prior installation of package gdebi-core:\n<code>$ sudo\
    \ apt-get install gdebi-core</code></p>\n<p>Next, download and install your preferred\
    \ RStudio package (Check the <a href=\"www.rstudio.com/products/rstudio/download-server/\"\
    >RStudio website</a> for an updated version):</p>\n<p><strong>64bit</strong><br>\n\
    <strong>Version: 0.99.489</strong></p>\n<p><code>$ wget https://download2.rstudio.org/rstudio-server-0.99.489-amd64.deb</code></p>\n\
    <p><code>$ sudo gdebi rstudio-server-0.99.489-amd64.deb</code></p>\n<p><strong>32bit</strong><br>\n\
    <strong>Version: 0.99.489</strong></p>\n<p><code>$ wget https://download2.rstudio.org/rstudio-server-0.99.489-i386.deb</code></p>\n\
    <p><code>$ sudo gdebi rstudio-server-0.99.489-i386.deb</code></p>\n<p>Now that\
    \ RStudio Server is installed, you can access the server from your local web browser,\
    \ specifying your instance's IP address and the RStudio Server default port. </p>\n\
    <p><code>http://&lt;IP address&gt;:8787</code></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/R3_Rstudio.png?raw=true\"\
    ></p>\n<p>If you get this in your browser, RStudio Server was successfully installed.\
    \ To be able to log-in to RStudio, you will need to create a new user account\
    \ in your instance using this command:</p>\n<p><code>$ sudo adduser &lt;username&gt;</code></p>\n\
    <p>This new user account will be separate from your NeCTAR instance log-in, i.e.\
    \ the default administrator (ubuntu/debian) and associated keypair, meaning it\
    \ alone cannot be used to ssh into your remote system. To allow this new user\
    \ access to ephemeral storage (/mnt) you will need to change its permissions.</p>\n\
    <p><strong><em>Reminder:</em></strong> your ephemeral storage (/mnt) can be thought\
    \ of as your cloud 'workspace' since it contains the greatest amount of memory.\
    \ This is where you should store data and run scripts to avoid filling up your\
    \ home directory. By default ubuntu/debian do not have permissions for this directory;\
    \ if you have not already changed your permissions for /mnt perform the following\
    \ command:\n<code>$ sudo chown ubuntu</code>. For more information on this topic\
    \ visit <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055382-introduction-to-cloud-storage\"\
    >NeCTAR Support</a>. </p>\n<p><code>$ sudo usermod -a -G ubuntu &lt;username&gt;</code></p>\n\
    <p>Now, this new username and password can be used to login to RStudio Server.\
    \ You can access /mnt by selecting <strong>[...]</strong> at the top right of\
    \ the <strong>Files</strong> tab, and upload or export between your local system\
    \ and /mnt using <strong>Upload</strong> and <strong>More</strong> -&gt; <strong>Export...</strong>.</p>\n\
    <h3>Troubleshooting and server management</h3>\n<p>The following commands are\
    \ useful for management of your RStudio Server, and for troubleshooting installation\
    \ and server access issues. For further information see the <a href=\"https://s3.amazonaws.com/rstudio-server/rstudio-server-pro-0.98.507-admin-guide.pdf\"\
    >RStudio Server Administrator's Guide</a>.</p>\n<p>Tests correct installation\
    \ and connection with installed R:<br>\n<code>$ sudo rstudio-server verify-installation</code></p>\n\
    <p>Restarts RStudio after changes or updates are made:<br>\n<code>$ sudo rstudio-server\
    \ restart</code></p>\n<p>Returns current status:<br>\n<code>$ sudo rstudio-server\
    \ status</code></p>\n<p>Takes system online or offline:<br>\n<code>$ sudo rstudio-server\
    \ online</code>\n<code>$ sudo rstudio-server offline</code></p>\n<p>Views system\
    \ log, filtering for RStudio:<br>\n<code>$ more /var/log/syslog | grep RStudio</code></p>\n\
    <h2>Installing and switching between multiple versions of R</h2>\n<p>Older versions\
    \ of R must be built from their source code. The easiest way to manage multiple\
    \ versions of R within your instance is to create a special directory in which\
    \ to hold and configure these files. For example:</p>\n<p><code>$ mkdir R.versions\n\
    $ cd R.versions\n~/R.versions$</code></p>\n<p>To install any compatible version\
    \ of R from source you first need to obtain the build dependencies:</p>\n<p><code>$\
    \ sudo apt-get build-dep r-base</code></p>\n<p>Next, <strong>within</strong> this\
    \ new directory, <a href=\"https://cran.rstudio.com/src/base\">obtain</a> and\
    \ unarchive the source code for the version of R you require. The example here\
    \ will install R 3.2.2:</p>\n<p><code>$ wget https://cran.rstudio.com/src/base/R-3/R-3.2.2.tar.gz</code></p>\n\
    <p>Unpack the file:</p>\n<p><code>$ tar -xvzf R-3.2.2.tar.gz</code></p>\n<p>Now\
    \ from <strong>within</strong> the extracted directory, configure and install\
    \ R from source. \nNote: Defining the prefix to a specific path is required to\
    \ allow RStudio to find the relevant directory and shared libraries must be enabled\
    \ for RStudio to access them.</p>\n<p><code>$ ./configure --prefix=/local/bin/R-3.2.2\
    \ --enable-R-shlib</code></p>\n<p><code>$ make</code></p>\n<p>R can be run at\
    \ this point, without being fully installed, by executing the following command\
    \ from within the directory where R-3.2.2 was configured:</p>\n<p>```\n$ bin/R</p>\n\
    <blockquote>\n<p>```</p>\n</blockquote>\n<p>However, for RStudio to run you will\
    \ need to perform a full installation:</p>\n<p><code>$ sudo make install</code>\
    \   </p>\n<p>Other optional commands:</p>\n<p><code>$ more INSTALL</code>  -&gt;\
    \ reads installation guide<br>\n<code>$ make check</code>  -&gt; checks installation\
    \ built correctly<br>\n<code>$ make pdf</code>        -&gt; writes PDF manuals<br>\n\
    <code>$ make info</code>       -&gt; writes info files</p>\n<p>Note: to go back\
    \ to using the default version of R, you use the same command (within any directory)\
    \ as prior to installing the additional version (<code>$ R</code>).</p>\n<h3>Using\
    \ RStudio under multiple versions of R</h3>\n<p>At this point RStudio is ready\
    \ to run under any installed version of R- you only need to specify which version\
    \ to run in the configuration file, adding a line to the file which indicates\
    \ the directory for RStudio to use.</p>\n<p><code>$ sudo nano /etc/rstudio/rserver.conf</code></p>\n\
    <p>The line you add will depend on the path you specified when R was configured\
    \ and the version of R:</p>\n<p><code>rsession-which-r=/local/bin/R-3.2.2/bin/R</code></p>\n\
    <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/R4_Rversion.png?raw=true\"\
    ></p>\n<p>Next, restart RStudio to allow the changes to take effect:</p>\n<p><code>$\
    \ sudo rstudio-server restart</code></p>\n<p>Note: you may also need to quit your\
    \ current RStudio session in your browser: <strong>File</strong> -&gt; <strong>Quit\
    \ RStudio</strong> (which will reopen a new session). Then, type this command\
    \ in your R console to confirm the appropriate version is running.</p>\n<p>```</p>\n\
    <blockquote>\n<p>R.version.string\n[1] \"version 3.2.2 (2015-08-14)\"\n```</p>\n\
    </blockquote>\n<h2>Transferring files between your local and remote systems</h2>\n\
    <p>How you transfer files in and out of your instance will depend on a number\
    \ of factors, including where your input data is stored and how much of it there\
    \ is, and whether you are using R through your terminal window or RStudio Server\
    \ in your web browser. If you are using RStudio you already have a direct connection\
    \ from your local computer to your instance to facilitate file transfers. If you\
    \ are using R through your terminal window there are a couple options for this\
    \ (<a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
    >See NeCTAR Support</a>). This section will provide a short overview for transferring\
    \ files via SFTP, or Secure File Transfer Protocol.</p>\n<p>For information on\
    \ how to attach NeCTAR Volume or Object storage see additional <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055382-introduction-to-cloud-storage\"\
    >NeCTAR Tier 0 Documentation</a></p>\n<p>SFTP is related to SSH (secure shell)\
    \ as it uses the same key-pair you generated to initially log into your instance,\
    \ to create a secure connection for transferring files. To initialise a SFTP link\
    \ between your computer and remote instance you use a similar command as when\
    \ using SSH. The prompt you see when the connection has been established is similar\
    \ to the R console command line.</p>\n<p><code>$sftp -i ~/directory/key_name.key\
    \ ubuntu@&lt;IPaddress&gt;\nsftp&gt;</code></p>\n<p>The commands you use under\
    \ SFTP are essentially the same standard Linux commands used for navigating and\
    \ managing file systems when SSH'd into your instance. Some differences include\
    \ that you must specify when you want to refer to your local directory by placing\
    \ a '<code>l</code>' or an '<code>!</code>' before each command, and that the\
    \ SFTP prompt does not change based on what directory you are in.</p>\n<p>First,\
    \ check your current local and remote directories</p>\n<p>```</p>\n<blockquote>\n\
    <p>pwd\nlpwd\n```</p>\n</blockquote>\n<p>Now, navigate through your local and\
    \ remote file systems to the appropriate directories where your files are currently\
    \ stored and where you would like them to be moved to, using the following common\
    \ Linux commands (alternatively you can specify directory within the transfer\
    \ command). </p>\n<table>\n<thead>\n<tr>\n<th><strong>Remote instance</strong></th>\n\
    <th><strong>Local computer</strong></th>\n<th align=\"left\"><strong>Command use</strong></th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td>ls</td>\n<td>lls</td>\n<td align=\"left\"\
    >lists all visible files in current directory</td>\n</tr>\n<tr>\n<td>ls -al</td>\n\
    <td>lls -al</td>\n<td align=\"left\">lists visible and hidden files in current\
    \ directory</td>\n</tr>\n<tr>\n<td>cd</td>\n<td>lcd</td>\n<td align=\"left\">changes\
    \ directory</td>\n</tr>\n<tr>\n<td>mkdir</td>\n<td>! mkdir</td>\n<td align=\"\
    left\">creates new directory</td>\n</tr>\n</tbody>\n</table>\n<h3>Transferring\
    \ files to your remote instance</h3>\n<p>To transfer data files, scripts, or entire\
    \ directories from your local terminal, the command <code>put</code> is used.\
    \ Here is an example showing how to transfer an individual csv file. </p>\n<p><code>&gt;\
    \ put data.csv</code></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/R5_sftp.png?raw=true\"\
    ></p>\n<p>To transfer an entire directory you will need to first create a destination\
    \ directory with the same name.</p>\n<p>```</p>\n<blockquote>\n<p>mkdir R_scripts\
    \ \nput -r R_scripts\n```</p>\n</blockquote>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/R6_sftp.png?raw=true\"\
    ></p>\n<h3>Transferring files from your remote system</h3>\n<p>When transferring\
    \ files from your remote instance, the command <code>get</code> is used. Note:\
    \ you can change a file/directory name by specifying a new name at the end of\
    \ the command, and if names contain spaces they must be enclosed in ' '. </p>\n\
    <p>```</p>\n<blockquote>\n<p>get <file_name> <new_file_name>  </p>\n<p>mkdir <directory>\n\
    get -r <directory>\n```</p>\n</blockquote>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/R7_sftp.png?raw=true\"\
    ></p>\n<p>To terminate your SFTP connection use the same command as when connected\
    \ through ssh:</p>\n<p><code>&gt; exit</code></p>\n<h2>Installation and management\
    \ of R packages</h2>\n<p>A number of R packages, all part of the r-recommended\
    \ bundle, are included in R installation packages for Ubuntu and Debian Linux\
    \ distributions. A list of these can be found at the <a href=\"https://cran.r-project.org/bin/linux/\"\
    >CRAN website</a> or by executing <code>library()</code>, which will also return\
    \ the default library directory.</p>\n<p>When installing additional packages you\
    \ will be prompted to create a personal library where all supplementary packages\
    \ will be installed to. R creates this directory on its own, once permissions\
    \ have been given, however a pop-up window will appear requesting you to select\
    \ your preferred CRAN mirror. Your personal library will act as a second default\
    \ library, meaning loading packages does not require you to specify the directory.\
    \ </p>\n<h2>Running R in the cloud</h2>\n<p>Scientists may want to conduct their\
    \ research in the cloud for a variety of reasons, and this diversity holds for\
    \ those using R in the cloud. How you run scripts in R and whether you use R through\
    \ your terminal window or with RStudio Server will depend on a multitude of factors,\
    \ including individual preferences. In general, the cloud is most useful for non-interactive\
    \ scripts, which can run in the 'background' allowing you to terminate the ssh\
    \ connection between your local and remote systems, or logout and close your RStudio\
    \ browser.</p>\n<p>While RStudio automatically runs R in the background, running\
    \ R through your terminal window requires you to use commands to specify this\
    \ (Note: ssh connections will break after periods of inactivity and, therefore,\
    \ any jobs running in the forefront will be terminated). The command <code>nohup</code>\
    \ coupled with either <a href=\"http://www.rdocumentation.org/packages/utils/functions/Rscript\"\
    ><code>Rscript</code></a> or <a href=\"http://www.rdocumentation.org/packages/utils/functions/BATCH\"\
    ><code>R CMD BATCH</code></a> can be used to submit R scripts to run in the background\
    \ of your instance. Here are examples of each:</p>\n<p><code>$ nohup Rscript Rcode_test.R</code>\
    \ </p>\n<p><code>$ nohup R CMD BATCH Rcode_test.R Rcode_test.Rout</code></p>\n\
    <p>The difference between <code>Rscript</code> and <code>R CMD BATCH</code> is\
    \ mainly in the output files. BATCH creates an output file which echos what you\
    \ would normally see in your R console, while Rscript does not create this. The\
    \ command <code>nohup</code> also creates an output file, nohup.out, in the directory\
    \ from which you submitted the job. The nohup.out file echos errors, warnings,\
    \ system.time and some random initial commands, but does not echo all commands\
    \ passed through R. This file would also be automatically overwritten if multiple\
    \ jobs were submitted, whereas the output BATCH file name and directory can be\
    \ specified:</p>\n<p><code>$ nohup R CMD BATCH Rcode_test.R Project_test/Output_files/Rcode_test.Rout</code></p>\n\
    <p>Note: when a job is submitted, the following notification will be returned\
    \ and is not an error- it is telling you that the normal outputs to your console\
    \ will be redirected to the nohup.out file and provides the PID or process identifier.\
    \ </p>\n<p><code>nohup: ignoring input and appending output to 'nohup.out'</code></p>\n\
    <p>To check on your job, use the command <code>top</code> followed by <code>1</code>.\
    \ This will print all the processes running on your instance and what is running\
    \ on each core. In the example image below there is a process running by user\
    \ 'test', the command 'rsession' indicates it is RStudio, and a process owned\
    \ by ubuntu (user ssh'd into instance) and the command indicates R is running.\
    \ The last example command below is for terminating a job by its PID.</p>\n<p><code>$\
    \ top\n1\n$ kill -9 &lt;PID&gt;</code></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/R8_top.jpg?raw=true\"\
    ></p>"
  parent: 24
  sha1: e47738cf88725e7285c7ac3905c41d5a9539871c
  title: Pawsey Installing R and RStudio
108: {html: "<p>In the cloud environment, billing requires multiple steps and services\
    \ to support\nit. The required steps and services are metering, rating and billing.\
    \ The Ceilometer\nproject was originally designed to provide the metering service\
    \ as it gathers the\ndata required by the billing systems that vendors would implement\
    \ for their OpenStack installations. This service collects information and required\
    \ data about the system\nand saves it in the form of samples in order to provide\
    \ data about anything that\ncan be billed.</p>\n<p>The primary purposes of the\
    \ Ceilometer are the following:</p>\n<ul>\n<li>\n<p>The efficient collection of\
    \ metering data.</p>\n</li>\n<li>\n<p>Collecting data by monitoring notifications\
    \ sent from services or by polling the \n resources.</p>\n</li>\n<li>\n<p>Configuring\
    \ the type of collected data to meet various requirements.</p>\n</li>\n<li>\n\
    <p>Accessing data through the REST API.</p>\n</li>\n<li>\n<p>Expanding the framework\
    \ to collect custom usage data by additional plugins.</p>\n</li>\n<li>\n<p>Producing\
    \ signed and non-repudiable metering messages.</p>\n</li>\n</ul>\n<p>But since\
    \ its inception more features have been added to Ceilometer, the most\nimportant\
    \ of which is the addition of alarms that can be set to fire when monitored\n\
    data streams cross user set thresholds.</p>\n<p>Unlike the rest of OpenStack there\
    \ is currently no Ceilometer dashboard component\nfor end users. You either have\
    \ to use the command line client or the RESTful web\nAPI (the command line client\
    \ does offer Python bindings).</p>\n<p>So the simplest path to follow when it\
    \ comes to Ceilometer is to grab the command\nline tool and to get going with\
    \ that.</p>\n<h2>Architecture of OpenStack Ceilometer</h2>\n<ul>\n<li>\n<p>API\
    \ Server: provides access to metering data in the database via REST API</p>\n\
    </li>\n<li>\n<p>Central agent: polls utilization data for resources not tied to\
    \ compute nodes.\n There may be only one central agent running for the infrastructure.</p>\n\
    </li>\n<li>\n<p>Compute agent: polls metering data from the compute node. Compute\
    \ agents must\n run on compute nodes.</p>\n</li>\n<li>\n<p>Collector: monitors\
    \ the message queues (data sent by the infrastructure and coming\n from agents).\
    \ The messages are processed, converted in to metering data, signed,\n and put\
    \ back to the queue.</p>\n</li>\n<li>\n<p>Data store: save the metering data from\
    \ collectors and provide the metering data\n to API server.</p>\n</li>\n</ul>\n\
    <h2>Ceilometer meters</h2>\n<p>In the Ceilometer world, \u201CMeters\u201D is\
    \ the term to indicate a tool that measures an\naspect of resource usage.</p>\n\
    <p>So for any one resource there can be many meters measuring different aspects\
    \ of\nhe resource.</p>\n<p>A meter has a name, a type and a unit of measurement\
    \ associated with it.</p>\n<p>For example:</p>\n<blockquote>\n<p>Name: cpu\nType:\
    \ cumulative\nUnit: ns\nResource ID: 0488d02d\nUser ID: 308\nProject ID: 201 \
    \   </p>\n</blockquote>\n<p>There are currently three possible types of meters:</p>\n\
    <ul>\n<li>\n<p>Cumulative: an accumulating value is recorded (i.e.: the total)</p>\n\
    </li>\n<li>\n<p>Delta: changes between values are recorded </p>\n</li>\n<li>\n\
    <p>Gauge: only the current value at the time of reading is recorded.</p>\n</li>\n\
    </ul>\n<p>Note that in older versions of Ceilometer meters were termed 'counters'.</p>\n\
    <p>You can also see the resource the meter is associated with, and the owning\n\
    project and user.</p>\n<p>More detail on meters, and their types and units can\
    \ be found in the <a href=\"http://docs.openstack.org/developer/ceilometer/measurements.html.\"\
    >OpenStack documentation</a>.</p>\n<h2>Ceilometer Meters on the NeCTAR Cloud</h2>\n\
    <p>At NeCTAR the meters available to a given project depend upon the resources\
    \ that\nare available to that project.</p>\n<p>So for a project that has volumes,\
    \ these are the meters that would typically be\nseen that relate to the guest\
    \ machines at this moment in time:</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n\
    <th>Type</th>\n<th>Unit</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>cpu</td>\n<td>cumulative</td>\n<td>ns</td>\n<td>The total CPU time used.</td>\n\
    </tr>\n<tr>\n<td>cpu_util</td>\n<td>gauge</td>\n<td>%</td>\n<td>The average CPU\
    \ utilisation.</td>\n</tr>\n<tr>\n<td>disk.ephemeral.size</td>\n<td>gauge</td>\n\
    <td>GB</td>\n<td>The ephemeral disk size.</td>\n</tr>\n<tr>\n<td>disk.read.bytes</td>\n\
    <td>cumulative</td>\n<td>B</td>\n<td>The total number of bytes read.</td>\n</tr>\n\
    <tr>\n<td>disk.read.requests</td>\n<td>cumulative</td>\n<td>request</td>\n<td>The\
    \ total number of read requests made.</td>\n</tr>\n<tr>\n<td>disk.root.size</td>\n\
    <td>gauge</td>\n<td>GB</td>\n<td>The root disk size.</td>\n</tr>\n<tr>\n<td>disk.write.bytes</td>\n\
    <td>cumulative</td>\n<td>request</td>\n<td>The total number of bytes written.</td>\n\
    </tr>\n<tr>\n<td>disk.write.request</td>\n<td>cumulative</td>\n<td>request</td>\n\
    <td>The total number of write requests.</td>\n</tr>\n<tr>\n<td>instance</td>\n\
    <td>gauge</td>\n<td>instance</td>\n<td>The number of instances in existence.</td>\n\
    </tr>\n<tr>\n<td>instance:m1.large</td>\n<td>gauge</td>\n<td>instance</td>\n<td>The\
    \ number of large instances in existence.</td>\n</tr>\n<tr>\n<td>instance:m1.medium</td>\n\
    <td>gauge</td>\n<td>instance</td>\n<td>The number of medium instances in existence.</td>\n\
    </tr>\n<tr>\n<td>instance:m1.small</td>\n<td>gauge</td>\n<td>instance</td>\n<td>The\
    \ number of small instances in existence.</td>\n</tr>\n<tr>\n<td>instance:m1.xlarge</td>\n\
    <td>gauge</td>\n<td>instance</td>\n<td>The number of extra large instances in\
    \ existence.</td>\n</tr>\n<tr>\n<td>memory</td>\n<td>gauge</td>\n<td>MB</td>\n\
    <td>The memory allocated by the hypervisor to the instance.</td>\n</tr>\n<tr>\n\
    <td>network.incoming.bytes</td>\n<td>cumulative</td>\n<td>B</td>\n<td>The total\
    \ number of bytes incoming on a network interface.</td>\n</tr>\n<tr>\n<td>network.incoming.packets</td>\n\
    <td>cumulative</td>\n<td>B</td>\n<td>The total number of packets incoming on a\
    \ network interface</td>\n</tr>\n<tr>\n<td>network.outgoing.bytes</td>\n<td>cumulative</td>\n\
    <td>B</td>\n<td>The total number of bytes outgoing on a network interface.</td>\n\
    </tr>\n<tr>\n<td>network.outgoing.packets</td>\n<td>cumulative</td>\n<td>packet</td>\n\
    <td>The total number of packets outgoing on a network interface</td>\n</tr>\n\
    <tr>\n<td>vcpus</td>\n<td>gauge</td>\n<td>vcpu</td>\n<td>The number of virtual\
    \ cpu's</td>\n</tr>\n</tbody>\n</table>\n<p>The following are the meters typically\
    \ seen on a project that relate to Glance:</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n\
    <th>Type</th>\n<th>Unit</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
    <td>image</td>\n<td>gauge</td>\n<td>image</td>\n<td>Records the existence of an\
    \ image.</td>\n</tr>\n<tr>\n<td>image.size</td>\n<td>gauge</td>\n<td>B</td>\n\
    <td>The uploaded size of the image.</td>\n</tr>\n</tbody>\n</table>\n<p>The following\
    \ are the meters typically seen on a project that relate to Swift:</p>\n<table>\n\
    <thead>\n<tr>\n<th>Name</th>\n<th>Type</th>\n<th>Unit</th>\n<th>Meaning</th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td>storage.objects</td>\n<td>gauge</td>\n<td>object</td>\n\
    <td>The total number of objects.</td>\n</tr>\n<tr>\n<td>storage.objects.containers</td>\n\
    <td>gauge</td>\n<td>container</td>\n<td>The number of containers.</td>\n</tr>\n\
    <tr>\n<td>storage.objects.size</td>\n<td>gauge</td>\n<td>B</td>\n<td>The total\
    \ size of the stored objects.</td>\n</tr>\n</tbody>\n</table>\n<p>The following\
    \ are the meters typically seen on a project that relate to Cinder:</p>\n<table>\n\
    <thead>\n<tr>\n<th>Name</th>\n<th>Type</th>\n<th>Unit</th>\n<th>Meaning</th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td>volume</td>\n<td>gauge</td>\n<td>volume</td>\n\
    <td>Records the existence of an image.</td>\n</tr>\n<tr>\n<td>volume.size</td>\n\
    <td>gauge</td>\n<td>GB</td>\n<td>The size of a volume.</td>\n</tr>\n</tbody>\n\
    </table>\n<p>A complete list of meters, and their types and units can be found\
    \ in the <a href=\"http://docs.openstack.org/developer/ceilometer/measurements.html.\"\
    >OpenStack documentation</a>.</p>", parent: 45, sha1: 30ed71aa34e561b7b3cf5d0f83d970d24dce63c8,
  title: Introduction to Ceilometer}
109:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2016-01-19T18:31:18-05:00'
        desc_un_html: " The NeCTAR Image Catalog \n Intro \n Instances on the Research\
          \ Cloud are created from Images stored in the\nOpenStack Image service known\
          \ as Glance. Available images can be viewed on\nthe Research Cloud Dashboard\
          \ or via the API clients (example\nbelow). Images include items uploaded\
          \ to and registered in Glance from\nexternal sources (e.g., these might\
          \ be published by 3rd parties or built\nusing custom processes and tools)\
          \ and snapshots created from existing\ninstances (see the Cloud Storage\
          \ doco for more info). \n Categories of Images \n There are currently four\
          \ broad categories of images: Project, NeCTAR official,\nShared with Me,\
          \ and Public. \n Project \n These are images created by a user within a\
          \ Research Cloud project that you\nare a member of (snapshots of instances\
          \ in your project will be visible in\nthis category). \n NeCTAR Official\
          \ \n These images are built and maintained by NeCTAR Core Services. They\
          \ are\nupdated on a semi-regular basis or in response to security advisories\
          \ (even\nthough they are updated regularly you should always check   and\
          \ apply updates\nafter creating a new instance). The NeCTAR images include\
          \ integration software\nsuch as cloud-init and any relevant settings particular\
          \ to the NeCTAR\nResearch Cloud that may be required for the OS in question.\
          \ They also undergo\na light-weight testing process before being published\
          \ or updated. \n Currently NeCTAR Core Services maintains and publishes\
          \ various versions of\nthe follow Linux distributions (other commercial\
          \ OSes such as Windows are\nnot able to be distributed publicly at this\
          \ stage due to licensing\nrestrictions): \n \n Ubuntu \n Debian \n Fedora\
          \ \n openSUSE \n CentOS \n CirrOS \n \n Bug reports and contributions to\
          \ the NeCTAR images are welcomed. The current\nprocess uses Packer to automate\
          \ the build process with configuration and\nscripts stored in the nectar-images\
          \ GitHub project. Bugs can be reported\ndirectly to NeCTAR support or on\
          \ GitHub. \n Shared with Me \n These are images owned by another Research\
          \ Cloud project that you are not a\nmember of that have been explicitly\
          \ shared with your project. Sharing images\nis a useful mechanism for collaboration\
          \ without making images public, for\ninformation of how to share images\
          \ see the Sharing Images section below. \n Public \n Images can be made\
          \ public at any time. A public image is visible and usable\n(including the\
          \ ability to boot an instance or download locally) by all users\nof the\
          \ Research Cloud, so think carefully before making an image public\n(especially\
          \ if it is a snapshot that may contain sensitive data). \n There is currently\
          \ no quality assurance for public images, NeCTAR Core\nServices and Support\
          \ will not be able to provide assistance with these images.\nFurthermore,\
          \ public images are often outdated and may include software and/or\nservices\
          \ with serious unpatched security vulnerabilities. \n Future Categories\
          \ \n There is ongoing work to improve the NeCTAR Image Catalog to provide\
          \ users\nwith a higher level of quality assurance with respect to available\
          \ images.\nThis will also make it easier for developers and service providers\
          \ to\ndisambiguate curated images from the general Public list. \n Advanced\
          \ Image Management \n Command Line / API Cients \n glance and openstack\
          \ cli examples of listing and filtering \n Creating Images \n Link to Glance\
          \ docs \n Sharing Images \n Example sharing a snapshot and notes about privacy. "
        description: '<h1>The NeCTAR Image Catalog</h1>

          <h2>Intro</h2>

          <p><a href="https://support.nectar.org.au/solution/articles/6000055376-launching-virtual-machines">Instances</a>
          on the Research Cloud are created from <em>Images</em> stored in the

          OpenStack Image service known as <a href="https://wiki.openstack.org/wiki/Glance">Glance</a>.
          Available images can be viewed on

          the Research Cloud <a href="https://dashboard.rc.nectar.org.au/project/images/">Dashboard</a>
          or via the API clients (example

          below). Images include items uploaded to and registered in Glance from

          external sources (e.g., these might be published by 3rd parties or built

          using custom processes and tools) and snapshots created from existing

          instances (see the <a href="https://support.nectar.org.au/solution/articles/6000055382-introduction-to-cloud-storage">Cloud
          Storage</a> doco for more info).</p>

          <h2>Categories of Images</h2>

          <p>There are currently four broad categories of images: Project, NeCTAR
          official,

          Shared with Me, and Public.</p>

          <h3>Project</h3>

          <p>These are images created by a user within a Research Cloud project that
          you

          are a member of (snapshots of instances in your project will be visible
          in

          this category).</p>

          <h3>NeCTAR Official</h3>

          <p>These images are built and maintained by NeCTAR Core Services. They are

          updated on a semi-regular basis or in response to security advisories (even

          though they are updated regularly you should always check   and apply updates

          after creating a new instance). The NeCTAR images include integration software

          such as <a href="https://cloudinit.readthedocs.org">cloud-init</a> and any
          relevant settings particular to the NeCTAR

          Research Cloud that may be required for the OS in question. They also undergo

          a light-weight testing process before being published or updated.</p>

          <p>Currently NeCTAR Core Services maintains and publishes various versions
          of

          the follow Linux distributions (other commercial OSes such as Windows are

          not able to be distributed publicly at this stage due to licensing

          restrictions):</p>

          <ul>

          <li>Ubuntu</li>

          <li>Debian</li>

          <li>Fedora</li>

          <li>openSUSE</li>

          <li>CentOS</li>

          <li>CirrOS</li>

          </ul>

          <p>Bug reports and contributions to the NeCTAR images are welcomed. The
          current

          process uses <a href="https://www.packer.io/">Packer</a> to automate the
          build process with configuration and

          scripts stored in the <a href="https://github.com/NeCTAR-RC/nectar-images">nectar-images
          GitHub project</a>. Bugs can be reported

          directly to NeCTAR support or on GitHub.</p>

          <h3>Shared with Me</h3>

          <p>These are images owned by another Research Cloud project that you are
          not a

          member of that have been explicitly shared with your project. Sharing images

          is a useful mechanism for collaboration without making images public, for

          information of how to share images see the Sharing Images section below.</p>

          <h3>Public</h3>

          <p>Images can be made public at any time. A public image is visible and
          usable

          (including the ability to boot an instance or download locally) by all users

          of the Research Cloud, so think carefully before making an image public

          (especially if it is a snapshot that may contain sensitive data).</p>

          <p>There is currently no quality assurance for public images, NeCTAR Core

          Services and Support will not be able to provide assistance with these images.

          Furthermore, public images are often outdated and may include software and/or

          services with serious unpatched security vulnerabilities.</p>

          <h3>Future Categories</h3>

          <p>There is ongoing work to improve the NeCTAR Image Catalog to provide
          users

          with a higher level of quality assurance with respect to available images.

          This will also make it easier for developers and service providers to

          disambiguate curated images from the general Public list.</p>

          <h2>Advanced Image Management</h2>

          <h3>Command Line / API Cients</h3>

          <p>glance and openstack cli examples of listing and filtering</p>

          <h3>Creating Images</h3>

          <p>Link to Glance docs</p>

          <h3>Sharing Images</h3>

          <p>Example sharing a snapshot and notes about privacy.</p>'
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:09-04:00'
          customer_folders: []
          description: NeCTAR Fundamentals
          id: 6000190155
          is_default: false
          language_id: 6
          name: NeCTAR Fundamentals
          parent_id: 6000190155
          position: 2
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190155
        hits: 64
        id: 6000106269
        modified_at: '2016-03-31T22:54:20-04:00'
        modified_by: null
        position: 4
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 4
        thumbs_up: 0
        title: Image Catalog
        updated_at: '2016-03-31T22:54:20-04:00'
        user_id: 6002464727
  html: '<h1>The NeCTAR Image Catalog</h1>

    <h2>Intro</h2>

    <p><a href="https://support.nectar.org.au/solution/articles/6000055376-launching-virtual-machines">Instances</a>
    on the Research Cloud are created from <em>Images</em> stored in the

    OpenStack Image service known as <a href="https://wiki.openstack.org/wiki/Glance">Glance</a>.
    Available images can be viewed on

    the Research Cloud <a href="https://dashboard.rc.nectar.org.au/project/images/">Dashboard</a>
    or via the API clients (example

    below). Images include items uploaded to and registered in Glance from

    external sources (e.g., these might be published by 3rd parties or built

    using custom processes and tools) and snapshots created from existing

    instances (see the <a href="https://support.nectar.org.au/solution/articles/6000055382-introduction-to-cloud-storage">Cloud
    Storage</a> doco for more info).</p>

    <h2>Categories of Images</h2>

    <p>There are currently four broad categories of images: Project, NeCTAR official,

    Shared with Me, and Public.</p>

    <h3>Project</h3>

    <p>These are images created by a user within a Research Cloud project that you

    are a member of (snapshots of instances in your project will be visible in

    this category).</p>

    <h3>NeCTAR Official</h3>

    <p>These images are built and maintained by NeCTAR Core Services. They are

    updated on a semi-regular basis or in response to security advisories (even

    though they are updated regularly you should always check   and apply updates

    after creating a new instance). The NeCTAR images include integration software

    such as <a href="https://cloudinit.readthedocs.org">cloud-init</a> and any relevant
    settings particular to the NeCTAR

    Research Cloud that may be required for the OS in question. They also undergo

    a light-weight testing process before being published or updated.</p>

    <p>Currently NeCTAR Core Services maintains and publishes various versions of

    the follow Linux distributions (other commercial OSes such as Windows are

    not able to be distributed publicly at this stage due to licensing

    restrictions):</p>

    <ul>

    <li>Ubuntu</li>

    <li>Debian</li>

    <li>Fedora</li>

    <li>openSUSE</li>

    <li>CentOS</li>

    <li>CirrOS</li>

    </ul>

    <p>Bug reports and contributions to the NeCTAR images are welcomed. The current

    process uses <a href="https://www.packer.io/">Packer</a> to automate the build
    process with configuration and

    scripts stored in the <a href="https://github.com/NeCTAR-RC/nectar-images">nectar-images
    GitHub project</a>. Bugs can be reported

    directly to NeCTAR support or on GitHub.</p>

    <h3>Shared with Me</h3>

    <p>These are images owned by another Research Cloud project that you are not a

    member of that have been explicitly shared with your project. Sharing images

    is a useful mechanism for collaboration without making images public, for

    information of how to share images see the Sharing Images section below.</p>

    <h3>Public</h3>

    <p>Images can be made public at any time. A public image is visible and usable

    (including the ability to boot an instance or download locally) by all users

    of the Research Cloud, so think carefully before making an image public

    (especially if it is a snapshot that may contain sensitive data).</p>

    <p>There is currently no quality assurance for public images, NeCTAR Core

    Services and Support will not be able to provide assistance with these images.

    Furthermore, public images are often outdated and may include software and/or

    services with serious unpatched security vulnerabilities.</p>

    <h3>Future Categories</h3>

    <p>There is ongoing work to improve the NeCTAR Image Catalog to provide users

    with a higher level of quality assurance with respect to available images.

    This will also make it easier for developers and service providers to

    disambiguate curated images from the general Public list.</p>

    <h2>Advanced Image Management</h2>

    <h3>Command Line / API Cients</h3>

    <p>glance and openstack cli examples of listing and filtering</p>

    <h3>Creating Images</h3>

    <p>Link to Glance docs</p>

    <h3>Sharing Images</h3>

    <p>Example sharing a snapshot and notes about privacy.</p>'
  parent: 26
  sha1: d976a1187881a169a2904d8f97fe4e6a1b9ef910
  title: Image Catalog
110:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2016-01-31T17:30:52-05:00'
        desc_un_html: " Tenjin -- A quick start guide \n Introduction \n Allocation\
          \ of resources on the Tenjin Cloud are available via a number of ways:-\
          \ \n \n \n You are part of an NCI partner organization; \n \n \n You are\
          \ from an NCI supported Virtual Laboratory; \n \n \n You have made a special\
          \ arrangement with NCI. \n \n \n In all cases a request to help@nci.org.au\
          \ will start the process. \n Step by step how-to \n Once access and resources\
          \ have been allocated, you will be able to get your system set up by following\
          \ this guide. \n \n \n Login to https://tenjin.nci.org.au with your NCI\
          \ credentials. Your OpenStack tenant would be same as your project ID. If\
          \ you are part of multiple projects, then please choose the appropriate\
          \ tenant. \n \n \n Click on the \u201CInstances Tab\u201D and press \u201C\
          Launch Instance\u201D to start a virtual machine. \n \n \n If you are using\
          \ Tenjin for the first time, Click \u201CAccess & Security\u201D and create/add\
          \ your KeyPair. On Linux or Mac, you can \u201Ccat\u201D your public key\
          \ and paste it here. You may give it any name. \n \n \n This is one time\
          \ only operation. However depending on your workflow/security model you\
          \ may chose to have a number of key pairs. \n \n Click \u201CDetails\u201D\
          \ and select appropriate Image Name and Flavor. \n \n \n Flavors Explained\
          \ \n NCI offers a number of virtual machine flavors to suit the needs of\
          \ a research group. The name of the flavor gives you details of the number\
          \ of cpus, memory and local disk space.\n        E.g. 8c16m80d \n      \
          \  - CPUS: 8\n\n       - Memory 16GB\n\n       - Local Disk: 80 GB\n \n\
          \ Local Disk and Cinder Volume usage guidance \n Local disk is only for\
          \ operating system and scratch. This disk is local to the compute blade\
          \ and it is NOT backed up. The main software engineering of OpenStack Cloud\
          \ requires you to have a virtual machine deployment process that is reproducible.\
          \ We strongly recommend using puppet or other alternates to deploy the operating\
          \ system. \n For persistent storage, NCI provides cinder volume and projects\
          \ should use cinder volume to store critical data e.g. web catalogs and\
          \ important data. It may also be noted while cinder volume (based on Ceph)\
          \ is replicated, we strongly suggest projects to ask /pay for long term\
          \ storage on NCI\u2019s tape drives. The data on NCI\u2019s tape drives\
          \ is backed up across two remote sites. For more information please send\
          \ an email to help@nci.org.au. \n \n \n Click \u201CAccess & Security\u201D\
          \ and select the Key pair you want to use for logging into the virtual machine\
          \ once it is provisioned. \n \n \n Click \u201CNetworking\u201D and select\
          \ the IP address. Your project may have multiple IP address associated depending\
          \ upon the requirements. \n \n \n Click Launch. \n \n \n Use \u201Cssh \u2013\
          i /path/to/keypair root@IP.ADDRESS\u201D to access the virtual machine.\
          \ \n \n \n We do not recommend putting in useful data on the VDA (root)\
          \ and (VDB) ephemeral storage. At the time of creation of the project, NCI\
          \ gives 10GB (minimum) quota for block storage (we use Ceph). \n \n \n Click\
          \ \u201CVolumes\u201D tab and create a volume. \n \n \n \n \n Attach the\
          \ volume it to the virtual machine. It will most probably get attached as\
          \ /dev/vdc but it is always a good idea to check. \n \n On your virtual\
          \ machine the fdisk \u2013l command will give you a clear idea. \n [root@awesome\\\
          ]# fdisk -l \n Disk /dev/vda: 10.7 GB, 10737418240 bytes\n255 heads, 63\
          \ sectors/track, 1305 cylinders\nUnits = cylinders of 16065 \\* 512 = 8225280\
          \ bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size\
          \ (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x000c62bf\n\
          Device     Boot Start  End  Blocks   Id   System\n/dev/vda1  *    1    \
          \  1306 10484736 83  Linux\nDisk /dev/vdb: 32.2 GB, 32212254720 bytes\n\
          16 heads, 63 sectors/track, 62415 cylinders\nUnits = cylinders of 1008 \\\
          * 512 = 516096 bys\nSector size (logical/physical): 512 bytes / 512 bytes\n\
          I/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x00000000\n\
          \nDisk /dev/vdc: 10.7 GB, 10737418240 bytes\n16 heads, 63 sectors/track,\
          \ 20805 cylinders\nUnits = cylinders of 1008 \\* 512 = 516096 bytes\nSector\
          \ size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal):\
          \ 512 bytes / 512 bytes\nDisk identifier: 0x00000000\n \n \n Create a filesystem\
          \ on /dev/vdc \n \n [root@awesome /]# mkfs.ext4 /dev/vdc \n mke2fs 1.41.12\
          \ (17-May-2010) \n \n Mount the volume on your virtual machine. \n \n [root@awesome\
          \ /]# mkdir /data; mount /dev/vdc /data \n Limitations \n Tenjin is different\
          \ from Amazon EC2 or the NeCTAR Cloud in terms of features and specifications.\
          \ The specifications of Tenjin are similar to Raijin- our supercomputer.\
          \ It uses 56G Ethernet and SRIOV for low latency and high bandwidth network.\
          \ Introduction of these features have resulted in a few limitations that\
          \ are due to inherent nature of hardware and operating system design. \n\
          \ \n \n No Snapshots on Running Virtual Machines: We use SRIOV (Single Root\
          \ IO Virtualization) for fast 56G Ethernet (with RDMA support) and it does\
          \ not support snapshot feature on a running virtual machine. If you want\
          \ to snapshot, you will have to shutdown the virtual machine and then snapshot.\
          \ Snapshot on a live virtual machine will appear to have hung. We plan to\
          \ patch the dashboard to prevent this bug but it is quite low on priority\
          \ list. \n \n \n EthN interface increments on RHEL/CentOS-6 when using snapshot\
          \ as an image: \n \n \n To stop ethernet interfaces from incrementing by\
          \ one after each snapshot, please remove the following file before taking\
          \ the snapshot. This is not a limitation or a bug but just the way udev\
          \ rules work. \n [root@awesome /]# rm /etc/udev/rules.d/70-persistent-net.rules\
          \ \n \n \nNo Live Migration: Due to inherent nature of SRIOV design, we\
          \ cannot perform live migration of virtual machines between the hypervisors.\
          \ Cold migrations are fully supported. \n \n NCI uses the IP address range\
          \ supplied by the Australian National University. These IP addresses are\
          \ regularly scanned for security vulnerabilities and monitored for suspicious\
          \ network traffic and behavior. NCI reserves the right to shutdown and lock\
          \ your virtual machine in the case your virtual machine is not secure, has\
          \ been hacked and/or is involved in a suspicious behavior. NCI staff will\
          \ inform the virtual machine owner and the project CI with the reasons for\
          \ shutting down the virtual machine. \n NCI Policy for NFS Exports of global\
          \ files-systems to NCI\u2019s Cloud Infrastructure \n If your project has\
          \ global file-system allocation (e.g /g/data1, /g/data2 \u2026) and the\
          \ cloud instances (virtual machines) are managed by NCI staff, then please\
          \ contact help@nci.org.au and provide the details. \n If you have a virtual\
          \ machine on NeCTAR Cloud (public cloud) then NCI will not export the global\
          \ file-systems. This is due to inherent IP address reuse policy of the NeCTAR\
          \ cloud. \n If you manage your cloud instances at the NCI cloud, then following\
          \ policy would apply to the NFS exports. \n \n If you need Read-Only access,\
          \ then you only have to provide us with the IP address of the virtual machine.\
          \ NCI will export the project directories with root_squash. You might have\
          \ to create appropriate user and groups inside your virtual machine. \n\
          \ \n Once NCI has setup NFS exports for your virtual machines, you may need\
          \ to create the service account on your cloud instance with same UID and\
          \ GID as that of NCI LDAP. \n groupadd -g <gid in ldap> <Your NCI Project\
          \ ID> \n adduser -u <uid in ldap> <project_nfs user> \n Please refer to\
          \ Example at the end of this document. \n \n If you need Read-Write access,\
          \ you will need to request a service account. A service account is a normal\
          \ LDAP user account with no password. The service account for a project\
          \ is responsibility of the project chief investigator (CI). NCI will export\
          \ the file-system with NFS all_squash with anonuid and anongid set to proposed\
          \ service account. This effectively means that all the access to your project\
          \ directory from the cloud instance will be forced to the service account.\
          \ Therefore, the service account would need the appropriate directory permissions.\
          \ The default used for service accounts is project_nfs e.g. abc_nfs for\
          \ project \u201Cabc\u201D. \n \n In order to export the project directory,\
          \ we would also need the IP address of the cloud instance. \n Once everything\
          \ is setup, you would need to create the service account on your cloud instance\
          \ with same UID and GID as that of NCI LDAP. \n groupadd -g <gid in ldap>\
          \ <Your NCI Project ID> \n adduser -u <uid in ldap> <project_nfs user> \n\
          \ Example \n   Project: abc\n  GID of the project: 99999\n  Service Account:\
          \ abc\\_nfs\n  UID of Service Account: 88888\n  Export: /g/data1/abc\n \n\
          \ \n On your virtual machine (if it does not connect to NCI LDAP): \n \n\
          \ groupadd \u2013g 99999 abc \n adduser \u2013u 88888 abc\\_nfs \n \n Next\
          \ you need to mount NFS export on your cloud instance. Typical mount options\
          \ for gdata are:   \n \n hard,fg,defaults,nosuid,exec,rw,noatime,intr,rsize=32768,wsize=32768\
          \ \n Shell prompt command: \n mount -t nfs gdata-nfs.nci.org.au:/mnt/gdata1/abc\
          \ /data -o hard,fg,defaults,nosuid,exec,rw,noatime,intr,rsize=32768,wsize=32768\
          \ \n /etc/fstab entry: \n gdata-nfs.nci.org.au:/mnt/gdata1/abc    /data\
          \   nfs  hard,fg,defaults,nosuid,exec,rw,noatime,intr,rsize=32768,wsize=32768\
          \   0   0 \n Note: You need to make sure the abc_nfs user has the necessary\
          \ permissions to access /g/data1/abc folder. You can use ACLs to provide\
          \ fine grained access. Use man getfacl and man setfacl for more information.\
          \ Your project CI should be able to set the necessary permissions in the\
          \ root of your project subdirectory. "
        description: "<h1>Tenjin -- A quick start guide</h1>\n<h2>Introduction</h2>\n\
          <p>Allocation of resources on the Tenjin Cloud are available via a number\
          \ of ways:-</p>\n<ul>\n<li>\n<p>You are part of an NCI partner organization;</p>\n\
          </li>\n<li>\n<p>You are from an NCI supported Virtual Laboratory;</p>\n\
          </li>\n<li>\n<p>You have made a special arrangement with NCI.</p>\n</li>\n\
          </ul>\n<p>In all cases a request to <a href=\"mailto:help@nci.org.au\">help@nci.org.au</a>\
          \ will start the process.</p>\n<h2>Step by step how-to</h2>\n<p>Once access\
          \ and resources have been allocated, you will be able to get your system\
          \ set up by following this guide.</p>\n<ol>\n<li>\n<p>Login to <a href=\"\
          https://tenjin.nci.org.au\">https://tenjin.nci.org.au</a> with your NCI\
          \ credentials. Your OpenStack tenant would be same as your project ID. If\
          \ you are part of multiple projects, then please choose the appropriate\
          \ tenant.</p>\n</li>\n<li>\n<p>Click on the \u201CInstances Tab\u201D and\
          \ press \u201CLaunch Instance\u201D to start a virtual machine.</p>\n</li>\n\
          <li>\n<p>If you are using Tenjin for the first time, Click \u201CAccess\
          \ &amp; Security\u201D and create/add your KeyPair. On Linux or Mac, you\
          \ can \u201Ccat\u201D your public key and paste it here. You may give it\
          \ any name.</p>\n</li>\n</ol>\n<p>This is one time only operation. However\
          \ depending on your workflow/security model you may chose to have a number\
          \ of key pairs.</p>\n<ol>\n<li>Click \u201CDetails\u201D and select appropriate\
          \ Image Name and Flavor.</li>\n</ol>\n<p><img alt=\"\" src=\"./media/NCI-Tenjin-image-name&amp;flavour-selection.png\"\
          ></p>\n<p><strong>Flavors</strong> Explained</p>\n<p>NCI offers a number\
          \ of virtual machine flavors to suit the needs of a research group. The\
          \ name of the flavor gives you details of the number of cpus, memory and\
          \ local disk space.\n        E.g. 8c16m80d</p>\n<pre><code>       - CPUS:\
          \ 8\n\n       - Memory 16GB\n\n       - Local Disk: 80 GB\n</code></pre>\n\
          <p><strong>Local Disk and Cinder Volume</strong> usage guidance</p>\n<p>Local\
          \ disk is only for operating system and scratch. This disk is local to the\
          \ compute blade and it is NOT backed up. The main software engineering of\
          \ OpenStack Cloud requires you to have a virtual machine deployment process\
          \ that is reproducible. We strongly recommend using puppet or other alternates\
          \ to deploy the operating system.</p>\n<p>For persistent storage, NCI provides\
          \ cinder volume and projects should use cinder volume to store critical\
          \ data e.g. web catalogs and important data. It may also be noted while\
          \ cinder volume (based on Ceph) is replicated, we strongly suggest projects\
          \ to ask /pay for long term storage on NCI\u2019s tape drives. The data\
          \ on NCI\u2019s tape drives is backed up across two remote sites. For more\
          \ information please send an email to <a href=\"mailto:help@nci.org.au\"\
          >help@nci.org.au</a>.</p>\n<ol>\n<li>\n<p>Click \u201CAccess &amp; Security\u201D\
          \ and select the Key pair you want to use for logging into the virtual machine\
          \ once it is provisioned.</p>\n</li>\n<li>\n<p>Click \u201CNetworking\u201D\
          \ and select the IP address. Your project may have multiple IP address associated\
          \ depending upon the requirements.</p>\n</li>\n<li>\n<p>Click Launch.</p>\n\
          </li>\n<li>\n<p>Use \u201Cssh \u2013i /path/to/keypair root@IP.ADDRESS\u201D\
          \ to access the virtual machine.</p>\n</li>\n<li>\n<p>We do not recommend\
          \ putting in useful data on the VDA (root) and (VDB) ephemeral storage.\
          \ At the time of creation of the project, NCI gives 10GB (minimum) quota\
          \ for block storage (we use Ceph).</p>\n</li>\n<li>\n<p>Click \u201CVolumes\u201D\
          \ tab and create a volume.</p>\n</li>\n</ol>\n<p><img alt=\"\" src=\"./media/NCI-Tenjin-volumes-creation.png\"\
          ></p>\n<ol>\n<li>Attach the volume it to the virtual machine. It will most\
          \ probably get attached as /dev/vdc but it is always a good idea to check.</li>\n\
          </ol>\n<p>On your virtual machine the <em>fdisk \u2013l</em> command will\
          \ give you a clear idea.</p>\n<p><code>[root@awesome\\]# fdisk -l</code></p>\n\
          <pre><code>Disk /dev/vda: 10.7 GB, 10737418240 bytes\n255 heads, 63 sectors/track,\
          \ 1305 cylinders\nUnits = cylinders of 16065 \\* 512 = 8225280 bytes\nSector\
          \ size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal):\
          \ 512 bytes / 512 bytes\nDisk identifier: 0x000c62bf\nDevice     Boot Start\
          \  End  Blocks   Id   System\n/dev/vda1  *    1      1306 10484736 83  Linux\n\
          Disk /dev/vdb: 32.2 GB, 32212254720 bytes\n16 heads, 63 sectors/track, 62415\
          \ cylinders\nUnits = cylinders of 1008 \\* 512 = 516096 bys\nSector size\
          \ (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal):\
          \ 512 bytes / 512 bytes\nDisk identifier: 0x00000000\n\nDisk /dev/vdc: 10.7\
          \ GB, 10737418240 bytes\n16 heads, 63 sectors/track, 20805 cylinders\nUnits\
          \ = cylinders of 1008 \\* 512 = 516096 bytes\nSector size (logical/physical):\
          \ 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\
          Disk identifier: 0x00000000\n</code></pre>\n<ol>\n<li>Create a filesystem\
          \ on /dev/vdc</li>\n</ol>\n<p><code>[root@awesome /]# mkfs.ext4 /dev/vdc</code></p>\n\
          <p><code>mke2fs 1.41.12 (17-May-2010)</code></p>\n<ol>\n<li>Mount the volume\
          \ on your virtual machine.</li>\n</ol>\n<p><code>[root@awesome /]# mkdir\
          \ /data; mount /dev/vdc /data</code></p>\n<h2>Limitations</h2>\n<p>Tenjin\
          \ is different from Amazon EC2 or the NeCTAR Cloud in terms of features\
          \ and specifications. The specifications of Tenjin are similar to Raijin-\
          \ our supercomputer. It uses 56G Ethernet and SRIOV for low latency and\
          \ high bandwidth network. Introduction of these features have resulted in\
          \ a few limitations that are due to inherent nature of hardware and operating\
          \ system design.</p>\n<ol>\n<li>\n<p><strong>No Snapshots on Running Virtual\
          \ Machines:</strong> We use SRIOV (Single Root IO Virtualization) for fast\
          \ 56G Ethernet (with RDMA support) and it does not support snapshot feature\
          \ on a running virtual machine. If you want to snapshot, you will have to\
          \ shutdown the virtual machine and then snapshot. Snapshot on a live virtual\
          \ machine will appear to have hung. We plan to patch the dashboard to prevent\
          \ this bug but it is quite low on priority list.</p>\n</li>\n<li>\n<p><strong>EthN\
          \ interface increments on RHEL/CentOS-6 when using snapshot as an image:</strong></p>\n\
          </li>\n</ol>\n<p>To stop ethernet interfaces from incrementing by one after\
          \ each snapshot, please remove the following file before taking the snapshot.\
          \ This is not a limitation or a bug but just the way udev rules work.</p>\n\
          <p><code>[root@awesome /]# rm /etc/udev/rules.d/70-persistent-net.rules</code></p>\n\
          <ol>\n<li>\n<strong>No Live Migration:</strong> Due to inherent nature of\
          \ SRIOV design, we cannot perform live migration of virtual machines between\
          \ the hypervisors. Cold migrations are fully supported.</li>\n</ol>\n<p>NCI\
          \ uses the IP address range supplied by the Australian National University.\
          \ These IP addresses are regularly scanned for security vulnerabilities\
          \ and monitored for suspicious network traffic and behavior. NCI reserves\
          \ the right to shutdown and lock your virtual machine in the case your virtual\
          \ machine is not secure, has been hacked and/or is involved in a suspicious\
          \ behavior. NCI staff will inform the virtual machine owner and the project\
          \ CI with the reasons for shutting down the virtual machine.</p>\n<h2>NCI\
          \ Policy for NFS Exports of global files-systems to NCI\u2019s Cloud Infrastructure</h2>\n\
          <p>If your project has global file-system allocation (e.g /g/data1, /g/data2\
          \ \u2026) and the cloud instances (virtual machines) are managed by NCI\
          \ staff, then please contact <a href=\"mailto:help@nci.org.au\">help@nci.org.au</a>\
          \ and provide the details.</p>\n<p>If you have a virtual machine on NeCTAR\
          \ Cloud (public cloud) then NCI <em>will not</em> export the global file-systems.\
          \ This is due to inherent IP address reuse policy of the NeCTAR cloud.</p>\n\
          <p>If you manage your cloud instances at the NCI cloud, then following policy\
          \ would apply to the NFS exports.</p>\n<ol>\n<li>If you need Read-Only access,\
          \ then you only have to provide us with the IP address of the virtual machine.\
          \ NCI will export the project directories with root_squash. You might have\
          \ to create appropriate user and groups inside your virtual machine.</li>\n\
          </ol>\n<p>Once NCI has setup NFS exports for your virtual machines, you\
          \ may need to create the service account on your cloud instance with same\
          \ UID and GID as that of NCI LDAP.</p>\n<p><code>groupadd -g &lt;gid in\
          \ ldap&gt; &lt;Your NCI Project ID&gt;</code></p>\n<p><code>adduser -u &lt;uid\
          \ in ldap&gt; &lt;project_nfs user&gt;</code></p>\n<p>Please refer to Example\
          \ at the end of this document.</p>\n<ol>\n<li>If you need Read-Write access,\
          \ you will need to request a service account. A service account is a normal\
          \ LDAP user account with no password. The service account for a project\
          \ is responsibility of the project chief investigator (CI). NCI will export\
          \ the file-system with NFS all_squash with anonuid and anongid set to proposed\
          \ service account. This effectively means that all the access to your project\
          \ directory from the cloud instance will be forced to the service account.\
          \ Therefore, the service account would need the appropriate directory permissions.\
          \ The default used for service accounts is project_nfs e.g. abc_nfs for\
          \ project \u201Cabc\u201D.</li>\n</ol>\n<p>In order to export the project\
          \ directory, we would also need the IP address of the cloud instance.</p>\n\
          <p>Once everything is setup, you would need to create the service account\
          \ on your cloud instance with same UID and GID as that of NCI LDAP.</p>\n\
          <p><code>groupadd -g &lt;gid in ldap&gt; &lt;Your NCI Project ID&gt;</code></p>\n\
          <p><code>adduser -u &lt;uid in ldap&gt; &lt;project_nfs user&gt;</code></p>\n\
          <h3>Example</h3>\n<pre><code>  Project: abc\n  GID of the project: 99999\n\
          \  Service Account: abc\\_nfs\n  UID of Service Account: 88888\n  Export:\
          \ /g/data1/abc\n</code></pre>\n<ol>\n<li>On your virtual machine (if it\
          \ does not connect to NCI LDAP):</li>\n</ol>\n<p><code>groupadd \u2013g\
          \ 99999 abc</code></p>\n<p><code>adduser \u2013u 88888 abc\\_nfs</code></p>\n\
          <ol>\n<li>Next you need to mount NFS export on your cloud instance. Typical\
          \ mount options for gdata are:  </li>\n</ol>\n<p><code>hard,fg,defaults,nosuid,exec,rw,noatime,intr,rsize=32768,wsize=32768</code></p>\n\
          <p><strong>Shell prompt</strong> command:</p>\n<p><code>mount -t nfs gdata-nfs.nci.org.au:/mnt/gdata1/abc\
          \ /data -o hard,fg,defaults,nosuid,exec,rw,noatime,intr,rsize=32768,wsize=32768</code></p>\n\
          <p><strong>/etc/fstab</strong> entry:</p>\n<p><code>gdata-nfs.nci.org.au:/mnt/gdata1/abc\
          \    /data   nfs  hard,fg,defaults,nosuid,exec,rw,noatime,intr,rsize=32768,wsize=32768\
          \   0   0</code></p>\n<p><strong>Note:</strong> You need to make sure the\
          \ abc_nfs user has the necessary permissions to access /g/data1/abc folder.\
          \ You can use ACLs to provide fine grained access. Use man getfacl and man\
          \ setfacl for more information. Your project CI should be able to set the\
          \ necessary permissions in the root of your project subdirectory.</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000108747
        modified_at: '2016-01-31T17:30:52-05:00'
        modified_by: null
        position: 20
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: NCI Tenjin--A quick start guide
        updated_at: '2016-01-31T17:30:52-05:00'
        user_id: 6002464727
  html: "<h1>Tenjin -- A quick start guide</h1>\n<h2>Introduction</h2>\n<p>Allocation\
    \ of resources on the Tenjin Cloud are available via a number of ways:-</p>\n\
    <ul>\n<li>\n<p>You are part of an NCI partner organization;</p>\n</li>\n<li>\n\
    <p>You are from an NCI supported Virtual Laboratory;</p>\n</li>\n<li>\n<p>You\
    \ have made a special arrangement with NCI.</p>\n</li>\n</ul>\n<p>In all cases\
    \ a request to <a href=\"&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#104;&#101;&#108;&#112;&#64;&#110;&#99;&#105;&#46;&#111;&#114;&#103;&#46;&#97;&#117;\"\
    >&#104;&#101;&#108;&#112;&#64;&#110;&#99;&#105;&#46;&#111;&#114;&#103;&#46;&#97;&#117;</a>\
    \ will start the process.</p>\n<h2>Step by step how-to</h2>\n<p>Once access and\
    \ resources have been allocated, you will be able to get your system set up by\
    \ following this guide.</p>\n<ol>\n<li>\n<p>Login to <a href=\"https://tenjin.nci.org.au\"\
    >https://tenjin.nci.org.au</a> with your NCI credentials. Your OpenStack tenant\
    \ would be same as your project ID. If you are part of multiple projects, then\
    \ please choose the appropriate tenant.</p>\n</li>\n<li>\n<p>Click on the \u201C\
    Instances Tab\u201D and press \u201CLaunch Instance\u201D to start a virtual machine.</p>\n\
    </li>\n<li>\n<p>If you are using Tenjin for the first time, Click \u201CAccess\
    \ &amp; Security\u201D and create/add your KeyPair. On Linux or Mac, you can \u201C\
    cat\u201D your public key and paste it here. You may give it any name.</p>\n</li>\n\
    </ol>\n<p>This is one time only operation. However depending on your workflow/security\
    \ model you may chose to have a number of key pairs.</p>\n<ol>\n<li>Click \u201C\
    Details\u201D and select appropriate Image Name and Flavor.</li>\n</ol>\n<p><img\
    \ alt=\"\" src=\"./media/NCI-Tenjin-image-name&amp;flavour-selection.png\"></p>\n\
    <p><strong>Flavors</strong> Explained</p>\n<p>NCI offers a number of virtual machine\
    \ flavors to suit the needs of a research group. The name of the flavor gives\
    \ you details of the number of cpus, memory and local disk space.\n        E.g.\
    \ 8c16m80d</p>\n<pre><code>       - CPUS: 8\n\n       - Memory 16GB\n\n      \
    \ - Local Disk: 80 GB\n</code></pre>\n<p><strong>Local Disk and Cinder Volume</strong>\
    \ usage guidance</p>\n<p>Local disk is only for operating system and scratch.\
    \ This disk is local to the compute blade and it is NOT backed up. The main software\
    \ engineering of OpenStack Cloud requires you to have a virtual machine deployment\
    \ process that is reproducible. We strongly recommend using puppet or other alternates\
    \ to deploy the operating system.</p>\n<p>For persistent storage, NCI provides\
    \ cinder volume and projects should use cinder volume to store critical data e.g.\
    \ web catalogs and important data. It may also be noted while cinder volume (based\
    \ on Ceph) is replicated, we strongly suggest projects to ask /pay for long term\
    \ storage on NCI\u2019s tape drives. The data on NCI\u2019s tape drives is backed\
    \ up across two remote sites. For more information please send an email to <a\
    \ href=\"&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#104;&#101;&#108;&#112;&#64;&#110;&#99;&#105;&#46;&#111;&#114;&#103;&#46;&#97;&#117;\"\
    >&#104;&#101;&#108;&#112;&#64;&#110;&#99;&#105;&#46;&#111;&#114;&#103;&#46;&#97;&#117;</a>.</p>\n\
    <ol>\n<li>\n<p>Click \u201CAccess &amp; Security\u201D and select the Key pair\
    \ you want to use for logging into the virtual machine once it is provisioned.</p>\n\
    </li>\n<li>\n<p>Click \u201CNetworking\u201D and select the IP address. Your project\
    \ may have multiple IP address associated depending upon the requirements.</p>\n\
    </li>\n<li>\n<p>Click Launch.</p>\n</li>\n<li>\n<p>Use \u201Cssh \u2013i /path/to/keypair\
    \ root@IP.ADDRESS\u201D to access the virtual machine.</p>\n</li>\n<li>\n<p>We\
    \ do not recommend putting in useful data on the VDA (root) and (VDB) ephemeral\
    \ storage. At the time of creation of the project, NCI gives 10GB (minimum) quota\
    \ for block storage (we use Ceph).</p>\n</li>\n<li>\n<p>Click \u201CVolumes\u201D\
    \ tab and create a volume.</p>\n</li>\n</ol>\n<p><img alt=\"\" src=\"./media/NCI-Tenjin-volumes-creation.png\"\
    ></p>\n<ol>\n<li>Attach the volume it to the virtual machine. It will most probably\
    \ get attached as /dev/vdc but it is always a good idea to check.</li>\n</ol>\n\
    <p>On your virtual machine the <em>fdisk \u2013l</em> command will give you a\
    \ clear idea.</p>\n<p><code>[root@awesome\\]# fdisk -l</code></p>\n<pre><code>Disk\
    \ /dev/vda: 10.7 GB, 10737418240 bytes\n255 heads, 63 sectors/track, 1305 cylinders\n\
    Units = cylinders of 16065 \\* 512 = 8225280 bytes\nSector size (logical/physical):\
    \ 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk\
    \ identifier: 0x000c62bf\nDevice     Boot Start  End  Blocks   Id   System\n/dev/vda1\
    \  *    1      1306 10484736 83  Linux\nDisk /dev/vdb: 32.2 GB, 32212254720 bytes\n\
    16 heads, 63 sectors/track, 62415 cylinders\nUnits = cylinders of 1008 \\* 512\
    \ = 516096 bys\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size\
    \ (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x00000000\n\nDisk\
    \ /dev/vdc: 10.7 GB, 10737418240 bytes\n16 heads, 63 sectors/track, 20805 cylinders\n\
    Units = cylinders of 1008 \\* 512 = 516096 bytes\nSector size (logical/physical):\
    \ 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk\
    \ identifier: 0x00000000\n</code></pre>\n<ol>\n<li>Create a filesystem on /dev/vdc</li>\n\
    </ol>\n<p><code>[root@awesome /]# mkfs.ext4 /dev/vdc</code></p>\n<p><code>mke2fs\
    \ 1.41.12 (17-May-2010)</code></p>\n<ol>\n<li>Mount the volume on your virtual\
    \ machine.</li>\n</ol>\n<p><code>[root@awesome /]# mkdir /data; mount /dev/vdc\
    \ /data</code></p>\n<h2>Limitations</h2>\n<p>Tenjin is different from Amazon EC2\
    \ or the NeCTAR Cloud in terms of features and specifications. The specifications\
    \ of Tenjin are similar to Raijin- our supercomputer. It uses 56G Ethernet and\
    \ SRIOV for low latency and high bandwidth network. Introduction of these features\
    \ have resulted in a few limitations that are due to inherent nature of hardware\
    \ and operating system design.</p>\n<ol>\n<li>\n<p><strong>No Snapshots on Running\
    \ Virtual Machines:</strong> We use SRIOV (Single Root IO Virtualization) for\
    \ fast 56G Ethernet (with RDMA support) and it does not support snapshot feature\
    \ on a running virtual machine. If you want to snapshot, you will have to shutdown\
    \ the virtual machine and then snapshot. Snapshot on a live virtual machine will\
    \ appear to have hung. We plan to patch the dashboard to prevent this bug but\
    \ it is quite low on priority list.</p>\n</li>\n<li>\n<p><strong>EthN interface\
    \ increments on RHEL/CentOS-6 when using snapshot as an image:</strong></p>\n\
    </li>\n</ol>\n<p>To stop ethernet interfaces from incrementing by one after each\
    \ snapshot, please remove the following file before taking the snapshot. This\
    \ is not a limitation or a bug but just the way udev rules work.</p>\n<p><code>[root@awesome\
    \ /]# rm /etc/udev/rules.d/70-persistent-net.rules</code></p>\n<ol>\n<li><strong>No\
    \ Live Migration:</strong> Due to inherent nature of SRIOV design, we cannot perform\
    \ live migration of virtual machines between the hypervisors. Cold migrations\
    \ are fully supported.</li>\n</ol>\n<p>NCI uses the IP address range supplied\
    \ by the Australian National University. These IP addresses are regularly scanned\
    \ for security vulnerabilities and monitored for suspicious network traffic and\
    \ behavior. NCI reserves the right to shutdown and lock your virtual machine in\
    \ the case your virtual machine is not secure, has been hacked and/or is involved\
    \ in a suspicious behavior. NCI staff will inform the virtual machine owner and\
    \ the project CI with the reasons for shutting down the virtual machine.</p>\n\
    <h2>NCI Policy for NFS Exports of global files-systems to NCI\u2019s Cloud Infrastructure</h2>\n\
    <p>If your project has global file-system allocation (e.g /g/data1, /g/data2 \u2026\
    ) and the cloud instances (virtual machines) are managed by NCI staff, then please\
    \ contact <a href=\"&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#104;&#101;&#108;&#112;&#64;&#110;&#99;&#105;&#46;&#111;&#114;&#103;&#46;&#97;&#117;\"\
    >&#104;&#101;&#108;&#112;&#64;&#110;&#99;&#105;&#46;&#111;&#114;&#103;&#46;&#97;&#117;</a>\
    \ and provide the details.</p>\n<p>If you have a virtual machine on NeCTAR Cloud\
    \ (public cloud) then NCI <em>will not</em> export the global file-systems. This\
    \ is due to inherent IP address reuse policy of the NeCTAR cloud.</p>\n<p>If you\
    \ manage your cloud instances at the NCI cloud, then following policy would apply\
    \ to the NFS exports.</p>\n<ol>\n<li>If you need Read-Only access, then you only\
    \ have to provide us with the IP address of the virtual machine. NCI will export\
    \ the project directories with root_squash. You might have to create appropriate\
    \ user and groups inside your virtual machine.</li>\n</ol>\n<p>Once NCI has setup\
    \ NFS exports for your virtual machines, you may need to create the service account\
    \ on your cloud instance with same UID and GID as that of NCI LDAP.</p>\n<p><code>groupadd\
    \ -g &lt;gid in ldap&gt; &lt;Your NCI Project ID&gt;</code></p>\n<p><code>adduser\
    \ -u &lt;uid in ldap&gt; &lt;project_nfs user&gt;</code></p>\n<p>Please refer\
    \ to Example at the end of this document.</p>\n<ol>\n<li>If you need Read-Write\
    \ access, you will need to request a service account. A service account is a normal\
    \ LDAP user account with no password. The service account for a project is responsibility\
    \ of the project chief investigator (CI). NCI will export the file-system with\
    \ NFS all_squash with anonuid and anongid set to proposed service account. This\
    \ effectively means that all the access to your project directory from the cloud\
    \ instance will be forced to the service account. Therefore, the service account\
    \ would need the appropriate directory permissions. The default used for service\
    \ accounts is project_nfs e.g. abc_nfs for project \u201Cabc\u201D.</li>\n</ol>\n\
    <p>In order to export the project directory, we would also need the IP address\
    \ of the cloud instance.</p>\n<p>Once everything is setup, you would need to create\
    \ the service account on your cloud instance with same UID and GID as that of\
    \ NCI LDAP.</p>\n<p><code>groupadd -g &lt;gid in ldap&gt; &lt;Your NCI Project\
    \ ID&gt;</code></p>\n<p><code>adduser -u &lt;uid in ldap&gt; &lt;project_nfs user&gt;</code></p>\n\
    <h3>Example</h3>\n<pre><code>  Project: abc\n  GID of the project: 99999\n  Service\
    \ Account: abc\\_nfs\n  UID of Service Account: 88888\n  Export: /g/data1/abc\n\
    </code></pre>\n<ol>\n<li>On your virtual machine (if it does not connect to NCI\
    \ LDAP):</li>\n</ol>\n<p><code>groupadd \u2013g 99999 abc</code></p>\n<p><code>adduser\
    \ \u2013u 88888 abc\\_nfs</code></p>\n<ol>\n<li>Next you need to mount NFS export\
    \ on your cloud instance. Typical mount options for gdata are:  </li>\n</ol>\n\
    <p><code>hard,fg,defaults,nosuid,exec,rw,noatime,intr,rsize=32768,wsize=32768</code></p>\n\
    <p><strong>Shell prompt</strong> command:</p>\n<p><code>mount -t nfs gdata-nfs.nci.org.au:/mnt/gdata1/abc\
    \ /data -o hard,fg,defaults,nosuid,exec,rw,noatime,intr,rsize=32768,wsize=32768</code></p>\n\
    <p><strong>/etc/fstab</strong> entry:</p>\n<p><code>gdata-nfs.nci.org.au:/mnt/gdata1/abc\
    \    /data   nfs  hard,fg,defaults,nosuid,exec,rw,noatime,intr,rsize=32768,wsize=32768\
    \   0   0</code></p>\n<p><strong>Note:</strong> You need to make sure the abc_nfs\
    \ user has the necessary permissions to access /g/data1/abc folder. You can use\
    \ ACLs to provide fine grained access. Use man getfacl and man setfacl for more\
    \ information. Your project CI should be able to set the necessary permissions\
    \ in the root of your project subdirectory.</p>"
  parent: 24
  sha1: fd098fed933df16aa9dd9226f82317f0a2aac8ae
  title: NCI Tenjin--A quick start guide
111:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2016-01-31T17:30:53-05:00'
        desc_un_html: " Cluster as a Service (CAAS) \u2013 NCI SLURM Cluster Documentation\
          \ Source \n Installation plans \n NCI is looking at setting up a fully supported\
          \ instance on the NCI NRC Node. This should be ready by February 2016. \n\
          \ CAAS Description \n For the NeCTAR WP7.2 - CaaS project, NCI has created\
          \ version 1.0 of Dynamic Cluster, which is software that provides simple\
          \ to use provisioning of VMs for clusters in the cloud. \n The whole process\
          \ to provision a cluster is to instantiate a head-node, attach a volume\
          \ to head-node, login to head-node, mount volume as /data and provision\
          \ the cluster.  \n It has been designed to work with the NeCATR OpenStack\
          \ National Research Cloud. \n NCI CAAS software repository \n The software\
          \ is openly available from github here: \n https://github.com/NCI-Cloud/slurm-cluster.\
          \  \n This version requires configuration for desired set up. \n The documentation\
          \ is also available in pdf: \n https://github.com/NCI-Cloud/slurm-cluster/blob/master/SlurmClusterDocumentation.pdf "
        description: "<h1>Cluster as a Service (CAAS) \u2013 NCI SLURM Cluster Documentation\
          \ Source</h1>\n<h2>Installation plans</h2>\n<p>NCI is looking at setting\
          \ up a fully supported instance on the NCI NRC Node. This should be ready\
          \ by February 2016.</p>\n<h2>CAAS Description</h2>\n<p>For the NeCTAR WP7.2\
          \ - CaaS project, NCI has created version 1.0 of Dynamic Cluster, which\
          \ is software that provides simple to use provisioning of VMs for clusters\
          \ in the cloud.</p>\n<p>The whole process to provision a cluster is to instantiate\
          \ a head-node, attach a volume to head-node, login to head-node, mount volume\
          \ as /data and provision the cluster. </p>\n<p>It has been designed to work\
          \ with the NeCATR OpenStack National Research Cloud.</p>\n<h2>NCI CAAS software\
          \ repository</h2>\n<p>The software is openly available from github here:</p>\n\
          <p><a href=\"https://github.com/NCI-Cloud/slurm-cluster\">https://github.com/NCI-Cloud/slurm-cluster</a>.\
          \ </p>\n<p>This version requires configuration for desired set up.</p>\n\
          <p>The documentation is also available in pdf:</p>\n<p><a href=\"https://github.com/NCI-Cloud/slurm-cluster/blob/master/SlurmClusterDocumentation.pdf\"\
          >https://github.com/NCI-Cloud/slurm-cluster/blob/master/SlurmClusterDocumentation.pdf</a></p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000108748
        modified_at: '2016-01-31T17:30:53-05:00'
        modified_by: null
        position: 21
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Cluster as a Service (CAAS)--NCI SLURM Cluster Documentation
        updated_at: '2016-01-31T17:30:53-05:00'
        user_id: 6002464727
  html: "<h1>Cluster as a Service (CAAS) \u2013 NCI SLURM Cluster Documentation Source</h1>\n\
    <h2>Installation plans</h2>\n<p>NCI is looking at setting up a fully supported\
    \ instance on the NCI NRC Node. This should be ready by February 2016.</p>\n<h2>CAAS\
    \ Description</h2>\n<p>For the NeCTAR WP7.2 - CaaS project, NCI has created version\
    \ 1.0 of Dynamic Cluster, which is software that provides simple to use provisioning\
    \ of VMs for clusters in the cloud.</p>\n<p>The whole process to provision a cluster\
    \ is to instantiate a head-node, attach a volume to head-node, login to head-node,\
    \ mount volume as /data and provision the cluster. </p>\n<p>It has been designed\
    \ to work with the NeCATR OpenStack National Research Cloud.</p>\n<h2>NCI CAAS\
    \ software repository</h2>\n<p>The software is openly available from github here:</p>\n\
    <p><a href=\"https://github.com/NCI-Cloud/slurm-cluster\">https://github.com/NCI-Cloud/slurm-cluster</a>.\
    \ </p>\n<p>This version requires configuration for desired set up.</p>\n<p>The\
    \ documentation is also available in pdf:</p>\n<p><a href=\"https://github.com/NCI-Cloud/slurm-cluster/blob/master/SlurmClusterDocumentation.pdf\"\
    >https://github.com/NCI-Cloud/slurm-cluster/blob/master/SlurmClusterDocumentation.pdf</a></p>"
  parent: 24
  sha1: 9818146b3172be1f92ab57e2ea0d1faef112824c
  title: Cluster as a Service (CAAS)--NCI SLURM Cluster Documentation
112:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2016-01-31T17:30:48-05:00'
        desc_un_html: " Using MATLAB in NeCTAR -- A quick start guide \n Prerequisites\
          \ \n Please note that any Node that you wish to run MATLAB from will need\
          \ to meet the first of the following prerequisites. The NCI Node, principally\
          \ the Tenjin NeCTAR Partner Cloud, has met these requirements. NCI has included\
          \ the MATLAB software on the VDI images within Tenjin.\nEach researcher,\
          \ either individually, or as part of an institutional account will need\
          \ to meet the second \n \n \n An agreement with MathWorks that allows users\
          \ to use their own license on your infrastructure. \n \n \n A MathWorks\
          \ account with a MATLAB licence associated (to download and install MATLAB).\
          \ \n \n \n Setup \n \n \n Download the MATLAB installer to your local machine\
          \ from the MathWorks site and get the file installation key for your licence.\
          \ \n \n \n Create an instance in the usual. It's probably best to use a\
          \ flavour with at least a few cores and decent memory as MATLAB can be a\
          \ hog. \n \n \n If your code is mainly written for a single core, select\
          \ m2.small or m2.medium \n If your code will utilise more cores, and / or\
          \ memory, then select m2.large or one of the optimised m2 range. \n \n Copy\
          \ the MATLAB installer to the instance:   \n \n scp matlab\\_R2015b.iso\
          \ ec2-user@ipaddr \n \n SSH into the instance:  \n \n ssh ec2-user@<ipaddr>\
          \ \n \n Install build tools:  \n \n sudo yum groupinstall \"Development\
          \ Tools\"\\ \n \n Install needed X11 libraries:  \n \n sudo yum install\
          \ xauth libXrender libXtst\\ \n \n Mount MATLAB ISO:  \n \n mkdir MATLAB\
          \ && sudo mount -o loop matlab\\_R2015b.iso MATLAB\\ \n \n Install MATLAB:\
          \  \n \n cd MATLAB && sudo ./install -mode silent -agreeToLicense yes -fileInstallationKey\
          \ ... \n \n Log out:  \n \n exit \n \n Log back in with X-forwading enabled:\
          \  \n \n ssh -X ec2-user@&lt;ipaddr&gt;\\ \n \n Launch MATLAB:  \n \n /usr/local/MATLAB/R2015b/bin/matlab\
          \ -licmode online "
        description: '<h1>Using MATLAB in NeCTAR -- A quick start guide</h1>

          <h2>Prerequisites</h2>

          <p>Please note that any Node that you wish to run MATLAB from will need
          to meet the first of the following prerequisites. The NCI Node, principally
          the Tenjin NeCTAR Partner Cloud, has met these requirements. NCI has included
          the MATLAB software on the VDI images within Tenjin.

          Each researcher, either individually, or as part of an institutional account
          will need to meet the second</p>

          <ol>

          <li>

          <p>An agreement with MathWorks that allows users to use their own license
          on your infrastructure.</p>

          </li>

          <li>

          <p>A MathWorks account with a MATLAB licence associated (to download and
          install MATLAB).</p>

          </li>

          </ol>

          <h2>Setup</h2>

          <ol>

          <li>

          <p>Download the MATLAB installer to your local machine from the MathWorks
          site and get the file installation key for your licence.</p>

          </li>

          <li>

          <p>Create an instance in the usual. It''s probably best to use a flavour
          with at least a few cores and decent memory as MATLAB can be a hog.</p>

          </li>

          </ol>

          <p>If your code is mainly written for a single core, select m2.small or
          m2.medium</p>

          <p>If your code will utilise more cores, and / or memory, then select m2.large
          or one of the optimised m2 range.</p>

          <ol>

          <li>Copy the MATLAB installer to the instance:  </li>

          </ol>

          <p><code>scp matlab\_R2015b.iso ec2-user@ipaddr</code></p>

          <ol>

          <li>SSH into the instance: </li>

          </ol>

          <p><code>ssh ec2-user@&lt;ipaddr&gt;</code></p>

          <ol>

          <li>Install build tools: </li>

          </ol>

          <p><code>sudo yum groupinstall "Development Tools"\</code></p>

          <ol>

          <li>Install needed X11 libraries: </li>

          </ol>

          <p><code>sudo yum install xauth libXrender libXtst\</code></p>

          <ol>

          <li>Mount MATLAB ISO: </li>

          </ol>

          <p><code>mkdir MATLAB &amp;&amp; sudo mount -o loop matlab\_R2015b.iso MATLAB\</code></p>

          <ol>

          <li>Install MATLAB: </li>

          </ol>

          <p><code>cd MATLAB &amp;&amp; sudo ./install -mode silent -agreeToLicense
          yes -fileInstallationKey ...</code></p>

          <ol>

          <li>Log out: </li>

          </ol>

          <p><code>exit</code></p>

          <ol>

          <li>Log back in with X-forwading enabled: </li>

          </ol>

          <p><code>ssh -X ec2-user@&amp;lt;ipaddr&amp;gt;\</code></p>

          <ol>

          <li>Launch MATLAB: </li>

          </ol>

          <p><code>/usr/local/MATLAB/R2015b/bin/matlab -licmode online</code></p>'
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000108744
        modified_at: '2016-01-31T17:30:48-05:00'
        modified_by: null
        position: 17
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: NCI Using MATLAB in NeCTAR
        updated_at: '2016-01-31T17:30:48-05:00'
        user_id: 6002464727
  html: '<h1>Using MATLAB in NeCTAR -- A quick start guide</h1>

    <h2>Prerequisites</h2>

    <p>Please note that any Node that you wish to run MATLAB from will need to meet
    the first of the following prerequisites. The NCI Node, principally the Tenjin
    NeCTAR Partner Cloud, has met these requirements. NCI has included the MATLAB
    software on the VDI images within Tenjin.

    Each researcher, either individually, or as part of an institutional account will
    need to meet the second</p>

    <ol>

    <li>

    <p>An agreement with MathWorks that allows users to use their own license on your
    infrastructure.</p>

    </li>

    <li>

    <p>A MathWorks account with a MATLAB licence associated (to download and install
    MATLAB).</p>

    </li>

    </ol>

    <h2>Setup</h2>

    <ol>

    <li>

    <p>Download the MATLAB installer to your local machine from the MathWorks site
    and get the file installation key for your licence.</p>

    </li>

    <li>

    <p>Create an instance in the usual. It''s probably best to use a flavour with
    at least a few cores and decent memory as MATLAB can be a hog.</p>

    </li>

    </ol>

    <p>If your code is mainly written for a single core, select m2.small or m2.medium</p>

    <p>If your code will utilise more cores, and / or memory, then select m2.large
    or one of the optimised m2 range.</p>

    <ol>

    <li>Copy the MATLAB installer to the instance:  </li>

    </ol>

    <p><code>scp matlab\_R2015b.iso ec2-user@ipaddr</code></p>

    <ol>

    <li>SSH into the instance: </li>

    </ol>

    <p><code>ssh ec2-user@&lt;ipaddr&gt;</code></p>

    <ol>

    <li>Install build tools: </li>

    </ol>

    <p><code>sudo yum groupinstall "Development Tools"\</code></p>

    <ol>

    <li>Install needed X11 libraries: </li>

    </ol>

    <p><code>sudo yum install xauth libXrender libXtst\</code></p>

    <ol>

    <li>Mount MATLAB ISO: </li>

    </ol>

    <p><code>mkdir MATLAB &amp;&amp; sudo mount -o loop matlab\_R2015b.iso MATLAB\</code></p>

    <ol>

    <li>Install MATLAB: </li>

    </ol>

    <p><code>cd MATLAB &amp;&amp; sudo ./install -mode silent -agreeToLicense yes
    -fileInstallationKey ...</code></p>

    <ol>

    <li>Log out: </li>

    </ol>

    <p><code>exit</code></p>

    <ol>

    <li>Log back in with X-forwading enabled: </li>

    </ol>

    <p><code>ssh -X ec2-user@&amp;lt;ipaddr&amp;gt;\</code></p>

    <ol>

    <li>Launch MATLAB: </li>

    </ol>

    <p><code>/usr/local/MATLAB/R2015b/bin/matlab -licmode online</code></p>'
  parent: 24
  sha1: 6ad79aedf56d4f5b3f5d2f0a08e5e85b763e9ccb
  title: NCI Using MATLAB in NeCTAR
113:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2016-01-31T17:30:49-05:00'
        desc_un_html: " Remote Job Submission @ NCI \n Introduction \n NCI uses a\
          \ proprietary job scheduler by Altair for job scheduling on its current\
          \ supercomputer (Raijin) called PBSPro. Due to complex requirements of NCI,\
          \ Altair maintains a separate branch of PBSPro for NCI which has added features\
          \ requested by NCI. One of the features unique to NCI PBSPro branch is the\
          \ use of munge authentication between the PBS clients and the server. The\
          \ current version of upstream munge on RHEL 6/7 does not allow multiple\
          \ munge keys. While NCI has a patch for multiple munge keys, it has so far\
          \ not made it to the upstream munge repository. This has forced NCI to use\
          \ wrapper scripts. The added advantage of using wrapper scripts is the users\u2019\
          \ do not have to install PBSPro sclient on their virtual machine. \n Prerequisites\
          \ \n \n \n You should have access to NCI supercomputer. The current system\
          \ is called raijin. If you need more help, please visit http://nci.org.au\
          \ \n \n \n Your virtual machine is hosted at NCI NeCTAR partner cloud. \n\
          \ \n \n The virtual machine \u2018must\u2019 share filesystem with Raijin.\
          \ This essentially means that your virtual machine has mounted /g/dataN/ProjectID\
          \ folder. \n \n \n Installation \n \n Download/clone the wrapper scripts\
          \ from NCI cloud GitHub repository. E.g. use your $HOME/bin folder \n \n\
          \ git clone <https://github.com/NCI-Cloud/remote-job-submission-nci.git>\
          \ \n \n Add the repository to the $PATH e.g. for bash \n \n Export PATH=$PATH:$HOME/bin/remote-job-submission-nci\
          \ \n \n \n Create ssh key and enable passwordless ssh to NCI\u2019s supercomputer\
          \ using ssh-keygen \n \n \n Copy the key to the supercomputer. E.g. for\
          \ Raijin \n \n \n ssh-copy-id -i ~/.ssh/id\\_rsa.pub nciuserid@raijin.nci.org.au\
          \ \n \n Use qstat, qsub and qdel to manage your jobs. Please note that all\
          \ your scripts and data \u2018must\u2019 reside on NCI\u2019s global filesystem.\
          \ Data local to the virtual machine is not assessable to Raijin. \n "
        description: "<h1>Remote Job Submission @ NCI</h1>\n<h2>Introduction</h2>\n\
          <p>NCI uses a proprietary job scheduler by Altair for job scheduling on\
          \ its current supercomputer (Raijin) called PBSPro. Due to complex requirements\
          \ of NCI, Altair maintains a separate branch of PBSPro for NCI which has\
          \ added features requested by NCI. One of the features unique to NCI PBSPro\
          \ branch is the use of munge authentication between the PBS clients and\
          \ the server. The current version of upstream munge on RHEL 6/7 does not\
          \ allow multiple munge keys. While NCI has a patch for multiple munge keys,\
          \ it has so far not made it to the upstream munge repository. This has forced\
          \ NCI to use wrapper scripts. The added advantage of using wrapper scripts\
          \ is the users\u2019 do not have to install PBSPro sclient on their virtual\
          \ machine.</p>\n<h2>Prerequisites</h2>\n<ol>\n<li>\n<p>You should have access\
          \ to NCI supercomputer. The current system is called raijin. If you need\
          \ more help, please visit <a href=\"http://nci.org.au\">http://nci.org.au</a></p>\n\
          </li>\n<li>\n<p>Your virtual machine is hosted at NCI NeCTAR partner cloud.</p>\n\
          </li>\n<li>\n<p>The virtual machine \u2018must\u2019 share filesystem with\
          \ Raijin. This essentially means that your virtual machine has mounted /g/dataN/ProjectID\
          \ folder.</p>\n</li>\n</ol>\n<h2>Installation</h2>\n<ol>\n<li>Download/clone\
          \ the wrapper scripts from NCI cloud GitHub repository. E.g. use your $HOME/bin\
          \ folder</li>\n</ol>\n<p><code>git clone &lt;https://github.com/NCI-Cloud/remote-job-submission-nci.git&gt;</code></p>\n\
          <ol>\n<li>Add the repository to the $PATH e.g. for bash</li>\n</ol>\n<p><code>Export\
          \ PATH=$PATH:$HOME/bin/remote-job-submission-nci</code></p>\n<ol>\n<li>\n\
          <p>Create ssh key and enable passwordless ssh to NCI\u2019s supercomputer\
          \ using ssh-keygen</p>\n</li>\n<li>\n<p>Copy the key to the supercomputer.\
          \ E.g. for Raijin</p>\n</li>\n</ol>\n<p><code>ssh-copy-id -i ~/.ssh/id\\\
          _rsa.pub nciuserid@raijin.nci.org.au</code></p>\n<ol>\n<li>Use qstat, qsub\
          \ and qdel to manage your jobs. Please note that all your scripts and data\
          \ \u2018must\u2019 reside on NCI\u2019s global filesystem. Data local to\
          \ the virtual machine is not assessable to Raijin.</li>\n</ol>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000108745
        modified_at: '2016-01-31T17:30:49-05:00'
        modified_by: null
        position: 18
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: NCI Remote Job Submission
        updated_at: '2016-01-31T17:30:49-05:00'
        user_id: 6002464727
  html: "<h1>Remote Job Submission @ NCI</h1>\n<h2>Introduction</h2>\n<p>NCI uses\
    \ a proprietary job scheduler by Altair for job scheduling on its current supercomputer\
    \ (Raijin) called PBSPro. Due to complex requirements of NCI, Altair maintains\
    \ a separate branch of PBSPro for NCI which has added features requested by NCI.\
    \ One of the features unique to NCI PBSPro branch is the use of munge authentication\
    \ between the PBS clients and the server. The current version of upstream munge\
    \ on RHEL 6/7 does not allow multiple munge keys. While NCI has a patch for multiple\
    \ munge keys, it has so far not made it to the upstream munge repository. This\
    \ has forced NCI to use wrapper scripts. The added advantage of using wrapper\
    \ scripts is the users\u2019 do not have to install PBSPro sclient on their virtual\
    \ machine.</p>\n<h2>Prerequisites</h2>\n<ol>\n<li>\n<p>You should have access\
    \ to NCI supercomputer. The current system is called raijin. If you need more\
    \ help, please visit <a href=\"http://nci.org.au\">http://nci.org.au</a></p>\n\
    </li>\n<li>\n<p>Your virtual machine is hosted at NCI NeCTAR partner cloud.</p>\n\
    </li>\n<li>\n<p>The virtual machine \u2018must\u2019 share filesystem with Raijin.\
    \ This essentially means that your virtual machine has mounted /g/dataN/ProjectID\
    \ folder.</p>\n</li>\n</ol>\n<h2>Installation</h2>\n<ol>\n<li>Download/clone the\
    \ wrapper scripts from NCI cloud GitHub repository. E.g. use your $HOME/bin folder</li>\n\
    </ol>\n<p><code>git clone &lt;https://github.com/NCI-Cloud/remote-job-submission-nci.git&gt;</code></p>\n\
    <ol>\n<li>Add the repository to the $PATH e.g. for bash</li>\n</ol>\n<p><code>Export\
    \ PATH=$PATH:$HOME/bin/remote-job-submission-nci</code></p>\n<ol>\n<li>\n<p>Create\
    \ ssh key and enable passwordless ssh to NCI\u2019s supercomputer using ssh-keygen</p>\n\
    </li>\n<li>\n<p>Copy the key to the supercomputer. E.g. for Raijin</p>\n</li>\n\
    </ol>\n<p><code>ssh-copy-id -i ~/.ssh/id\\_rsa.pub nciuserid@raijin.nci.org.au</code></p>\n\
    <ol>\n<li>Use qstat, qsub and qdel to manage your jobs. Please note that all your\
    \ scripts and data \u2018must\u2019 reside on NCI\u2019s global filesystem. Data\
    \ local to the virtual machine is not assessable to Raijin.</li>\n</ol>"
  parent: 24
  sha1: f364031c15a303fe3fcb913d5b15113ebf1ea73f
  title: NCI Remote Job Submission
114:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2016-01-31T17:30:51-05:00'
        desc_un_html: " Dynamic Cluster as a Service (DCaaS) \u2013 eRSA Dynamic Cluster\
          \ Documentation Source \n Description \n Dynamic Cluster as a Service (DCaaS)\
          \ provides solutions for deploying dynamic compute clusters in the cloud.\
          \ \nSince clusters can be configured in a number of different ways, DCaaS\
          \ provides example solutions to enable cluster administrators to easily\
          \ set up a dynamic cluster in the cloud for different requirements, cluster\
          \ components and cloud middleware. \n All solutions are based on the Dynamic\
          \ Cluster software, which can dynamically provision cluster worker nodes\
          \ in the cloud, automatically scaling the size of the cluster to meet the\
          \ workload (the number of queued or running jobs). It can work with OpenStack\
          \ and AWS clouds and supports multiple cluster management systems (currently\
          \ Torque and SGE, but others can be added using a simple plugin mechanism).\
          \  \n Installations \n The DCaaS software is aimed at organisations such\
          \ as NeCTAR Nodes, universities or large research groups, to set up a managed\
          \ cluster in the cloud for their researchers. \n During 2015 eRSA ran a\
          \ pilot compute cluster in the cloud, called Emu, which used a prototype\
          \ version of the Dynamic Cluster software. An improved, production version\
          \ of this cluster, using the release version 1 of Dynamic Cluster and DCaaS,\
          \ is expected to be available in early 2016.  \n The ARC Centre of Excellence\
          \ in Particle Physics (CoEPP) has been using the prototype version of the\
          \ software since 2014, to run two clusters in the NeCTAR cloud which are\
          \ used to support CoEPP researchers and the ATLAS project at CERN. \n Dynamic\
          \ Cluster software repository \n The Dynamic Cluster software which automatically\
          \ adds and removes compute nodes in the cluster based on workload is openly\
          \ available from github here. This version requires configuration for desired\
          \ set up: \n https://github.com/eResearchSA/dynamiccluster \n The documentation\
          \ is also available in markdown through github\u2019s standard documentation\
          \ system: \n http://eresearchsa.github.io/dynamiccluster/ \n Dynamic Cluster\
          \ as a Service (DCaaS) installation \n Since clusters can be configured\
          \ in many different ways (and Dynamic Cluster is highly configurable to\
          \ support this), and setting up a cluster (even one not in the cloud) involves\
          \ a lot of other other things like choice of cluster management system,\
          \ authentication and authorisation systems, automated deployment scripts,\
          \ monitoring, etc that are independent of the Dynamic Cluster software,\
          \ a separate github project (Dynamic Cluster as a Service) has been created\
          \ which provides some example reference architectures and script/tools etc\
          \ to set up different types of clusters in the cloud for different requirements.\
          \ \n Version 1 of DCaaS supports two options for cluster setup: \n \n Basic\
          \ setup deploys a basic cluster for a single user via an OpenStack Heat\
          \ template. This could easily be extended to support multiple users. \n\
          \ Advanced setup is is modelled on the installation at eRSA, which allows\
          \ for multiple users, multiple availability zones and multiple project allocations.\
          \  \n \n The github repository is here: \n https://github.com/eResearchSA/dcaas\
          \ \n and the documentation is here: \n http://eresearchsa.github.io/dcaas/ "
        description: "<h1>Dynamic Cluster as a Service (DCaaS) \u2013 eRSA Dynamic\
          \ Cluster Documentation Source</h1>\n<h2>Description</h2>\n<p>Dynamic Cluster\
          \ as a Service (DCaaS) provides solutions for deploying dynamic compute\
          \ clusters in the cloud. \nSince clusters can be configured in a number\
          \ of different ways, DCaaS provides example solutions to enable cluster\
          \ administrators to easily set up a dynamic cluster in the cloud for different\
          \ requirements, cluster components and cloud middleware.</p>\n<p>All solutions\
          \ are based on the Dynamic Cluster software, which can dynamically provision\
          \ cluster worker nodes in the cloud, automatically scaling the size of the\
          \ cluster to meet the workload (the number of queued or running jobs). It\
          \ can work with OpenStack and AWS clouds and supports multiple cluster management\
          \ systems (currently Torque and SGE, but others can be added using a simple\
          \ plugin mechanism). </p>\n<h2>Installations</h2>\n<p>The DCaaS software\
          \ is aimed at organisations such as NeCTAR Nodes, universities or large\
          \ research groups, to set up a managed cluster in the cloud for their researchers.</p>\n\
          <p>During 2015 eRSA ran a pilot compute cluster in the cloud, called Emu,\
          \ which used a prototype version of the Dynamic Cluster software. An improved,\
          \ production version of this cluster, using the release version 1 of Dynamic\
          \ Cluster and DCaaS, is expected to be available in early 2016. </p>\n<p>The\
          \ ARC Centre of Excellence in Particle Physics (CoEPP) has been using the\
          \ prototype version of the software since 2014, to run two clusters in the\
          \ NeCTAR cloud which are used to support CoEPP researchers and the ATLAS\
          \ project at CERN.</p>\n<h2>Dynamic Cluster software repository</h2>\n<p>The\
          \ Dynamic Cluster software which automatically adds and removes compute\
          \ nodes in the cluster based on workload is openly available from github\
          \ here. This version requires configuration for desired set up:</p>\n<p><a\
          \ href=\"https://github.com/eResearchSA/dynamiccluster\">https://github.com/eResearchSA/dynamiccluster</a></p>\n\
          <p>The documentation is also available in markdown through github\u2019\
          s standard documentation system:</p>\n<p><a href=\"http://eresearchsa.github.io/dynamiccluster/\"\
          >http://eresearchsa.github.io/dynamiccluster/</a></p>\n<h2>Dynamic Cluster\
          \ as a Service (DCaaS) installation</h2>\n<p>Since clusters can be configured\
          \ in many different ways (and Dynamic Cluster is highly configurable to\
          \ support this), and setting up a cluster (even one not in the cloud) involves\
          \ a lot of other other things like choice of cluster management system,\
          \ authentication and authorisation systems, automated deployment scripts,\
          \ monitoring, etc that are independent of the Dynamic Cluster software,\
          \ a separate github project (Dynamic Cluster as a Service) has been created\
          \ which provides some example reference architectures and script/tools etc\
          \ to set up different types of clusters in the cloud for different requirements.</p>\n\
          <p>Version 1 of DCaaS supports two options for cluster setup:</p>\n<ul>\n\
          <li>Basic setup deploys a basic cluster for a single user via an OpenStack\
          \ Heat template. This could easily be extended to support multiple users.</li>\n\
          <li>Advanced setup is is modelled on the installation at eRSA, which allows\
          \ for multiple users, multiple availability zones and multiple project allocations.\
          \ </li>\n</ul>\n<p>The github repository is here:</p>\n<p><a href=\"https://github.com/eResearchSA/dcaas\"\
          >https://github.com/eResearchSA/dcaas</a></p>\n<p>and the documentation\
          \ is here:</p>\n<p><a href=\"http://eresearchsa.github.io/dcaas/\">http://eresearchsa.github.io/dcaas/</a></p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 2
        id: 6000108746
        modified_at: '2016-02-02T18:56:42-05:00'
        modified_by: null
        position: 19
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Dynamic Cluster as a Service (DCaaS)--eRSA Dynamic Cluster Documentation
        updated_at: '2016-02-02T18:56:42-05:00'
        user_id: 6002464727
  html: "<h1>Dynamic Cluster as a Service (DCaaS) \u2013 eRSA Dynamic Cluster Documentation\
    \ Source</h1>\n<h2>Description</h2>\n<p>Dynamic Cluster as a Service (DCaaS) provides\
    \ solutions for deploying dynamic compute clusters in the cloud. \nSince clusters\
    \ can be configured in a number of different ways, DCaaS provides example solutions\
    \ to enable cluster administrators to easily set up a dynamic cluster in the cloud\
    \ for different requirements, cluster components and cloud middleware.</p>\n<p>All\
    \ solutions are based on the Dynamic Cluster software, which can dynamically provision\
    \ cluster worker nodes in the cloud, automatically scaling the size of the cluster\
    \ to meet the workload (the number of queued or running jobs). It can work with\
    \ OpenStack and AWS clouds and supports multiple cluster management systems (currently\
    \ Torque and SGE, but others can be added using a simple plugin mechanism). </p>\n\
    <h2>Installations</h2>\n<p>The DCaaS software is aimed at organisations such as\
    \ NeCTAR Nodes, universities or large research groups, to set up a managed cluster\
    \ in the cloud for their researchers.</p>\n<p>During 2015 eRSA ran a pilot compute\
    \ cluster in the cloud, called Emu, which used a prototype version of the Dynamic\
    \ Cluster software. An improved, production version of this cluster, using the\
    \ release version 1 of Dynamic Cluster and DCaaS, is expected to be available\
    \ in early 2016. </p>\n<p>The ARC Centre of Excellence in Particle Physics (CoEPP)\
    \ has been using the prototype version of the software since 2014, to run two\
    \ clusters in the NeCTAR cloud which are used to support CoEPP researchers and\
    \ the ATLAS project at CERN.</p>\n<h2>Dynamic Cluster software repository</h2>\n\
    <p>The Dynamic Cluster software which automatically adds and removes compute nodes\
    \ in the cluster based on workload is openly available from github here. This\
    \ version requires configuration for desired set up:</p>\n<p><a href=\"https://github.com/eResearchSA/dynamiccluster\"\
    >https://github.com/eResearchSA/dynamiccluster</a></p>\n<p>The documentation is\
    \ also available in markdown through github\u2019s standard documentation system:</p>\n\
    <p><a href=\"http://eresearchsa.github.io/dynamiccluster/\">http://eresearchsa.github.io/dynamiccluster/</a></p>\n\
    <h2>Dynamic Cluster as a Service (DCaaS) installation</h2>\n<p>Since clusters\
    \ can be configured in many different ways (and Dynamic Cluster is highly configurable\
    \ to support this), and setting up a cluster (even one not in the cloud) involves\
    \ a lot of other other things like choice of cluster management system, authentication\
    \ and authorisation systems, automated deployment scripts, monitoring, etc that\
    \ are independent of the Dynamic Cluster software, a separate github project (Dynamic\
    \ Cluster as a Service) has been created which provides some example reference\
    \ architectures and script/tools etc to set up different types of clusters in\
    \ the cloud for different requirements.</p>\n<p>Version 1 of DCaaS supports two\
    \ options for cluster setup:</p>\n<ul>\n<li>Basic setup deploys a basic cluster\
    \ for a single user via an OpenStack Heat template. This could easily be extended\
    \ to support multiple users.</li>\n<li>Advanced setup is is modelled on the installation\
    \ at eRSA, which allows for multiple users, multiple availability zones and multiple\
    \ project allocations. </li>\n</ul>\n<p>The github repository is here:</p>\n<p><a\
    \ href=\"https://github.com/eResearchSA/dcaas\">https://github.com/eResearchSA/dcaas</a></p>\n\
    <p>and the documentation is here:</p>\n<p><a href=\"http://eresearchsa.github.io/dcaas/\"\
    >http://eresearchsa.github.io/dcaas/</a></p>"
  parent: 24
  sha1: 432ee39eebf4d71bfe842e348d44fc54749bb255
  title: Dynamic Cluster as a Service (DCaaS)--eRSA Dynamic Cluster Documentation
115:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2016-02-29T21:39:10-05:00'
        desc_un_html: " \n Bioinformatics using the Cloud Storage with NCBI data \n\
          \ Table of Contents \n \n Introduction \n NeCTAR Research Cloud storage\
          \ components review using the OpenStack Dashboard \n Attached Storage \n\
          \ root disk \n ephemeral \n External Storage - Volume and Object \n What\
          \ is volume or block-storage \n What is object storage \n File I/O best\
          \ practices \n Using the Openstack APIs to Manage NCBI Data \n \nDownloading\
          \ NCBI datasets directly to your instance  \n Summary \n \n Top of page\n\
          \ \n Introduction \n This guide is a reference on how to easily utilize\
          \ all the different storage components \nof the NeCTAR into a bioinformatics\
          \ framework so that you can work more efficiently.  For \nthe puposes of\
          \ developing our framework will use the NCBI-BLAST+\nas it is a popular\
          \ application across many areas of bioinformatics. The BLAST data sets can\
          \ be\nvery large and that present challenges to store and access that data\
          \ locally making \nit difficult to implement in the NeCTAR research clould.\
          \     \n Top of page \n NeCTAR Research Cloud storage components review\
          \ using the OpenStack Dashboard \n \n The NeCTAR is a federated research\
          \ cloud that uses OpenStack as the cloud operating system it \ncontrols\
          \ the compute, storage and networking resources across the different zones\
          \ that make up \nthe research cloud. The OpenStack dashboard lets user provision\
          \ resources for their instances \nthrough a web interface. The storage resources\
          \ can be classified as attached and external disks\neach of which has different\
          \ purpose that needs some basic explanation. \n \n Attached storage \n With\
          \ your instance you have access to limited diskspace with the  \"root disk\"\
          \ partition \"/\" and \n\"ephemeral disk\" partition that is accessed via\
          \ the /mnt directory of the default NeCTAR images. \nThe size of the the\
          \ \"root disk\" and \"ephemeral disk\" varies with the different hardware\
          \ templates \nor [flavors] (https://Support.Nectar.Org.Au/Support/Solutions/Articles/6000055380-Resources-Available-To-You)\
          \ \nthat are available when you are configuring your instance. So understanding\
          \ your research data \nrequirements is key so you can select the correct\
          \ flavor for your instance.\nHowever, as with everything including the research\
          \ cloud it does require a bit more insight of how a \nresearch might make\
          \ the best use of these storage components in a bioinformatic workflow.\
          \ Fortunately, NeCTAR is\na the ideal resource to allow researchers to improve\
          \ their technical knowledge of to how to use the research cloud\nfor their\
          \ computational work. \n Top of page\n \n What is the root disk \n The root\
          \ disk is an ephemeral disk that the operating system (OS) image is copied\
          \ to when you launch \na virtual machine. It is also where your home directory\
          \ is located in you virtual machine. When you \nsnapshot your instance it\
          \ is what is copied to create your snapshot image. \n Top of page\n  \n\
          \ What is ephemeral disk \n Ephemeral is a secondary ephemeral data disk.\
          \ That is an empty disk and exists only for the life \nof the instance.\
          \ When you terminate an instance all data in ephemeral is lost. With the\
          \ NeCTAR \ndefault images that have ephemeral storage are mounted with the\
          \ instance and located at /mnt \nbut you will need to change the ownership\
          \ of the /mnt directoryto be able to have read/write \naccess to do this\
          \ on a ubuntu instance use: \n $ sudo chown ubuntu /mnt \n on a fedora,\
          \ centos, scientific linux instances \n $ sudo chown ec2-user /mnt \n and\
          \ on a debian instance. \n $ sudo chown debian /mnt \n This ephemeral disk\
          \ space is where you should run you analysis as your home directory is too\
          \ small. \n Top of page \n \n External Storage - Volume and Object \n When\
          \ you apply for you NeCTAR allocation you are able \nto apply for object\
          \ and volume storage to use for research project.   \n \n Assuming that\
          \ your allocation request has either volume or object storage or both when\
          \ you configure your\nvolume or object storage you need to remember to do\
          \ select a sensible availability zones to use with your data. \n \n What\
          \ is volume or block-storage \n Persistent block-storage \nor volume storage\
          \ can live outside of you instance. This means that you read and write data\
          \ in the persistent volume storage \nand it can be moved around to different\
          \ instances but can only be mounted to one instance at any given time. \n\
          You can find more information about creating and attaching persistent volumes\
          \ through the NeCTAR dashboard on the NeCTAR support page. Once it is attached\
          \ to an instance the dashboard will show what the this: \n \n note the volume\
          \ names are hyperlinks that show the volume overview, \n \n The Attachments\
          \ show what device the that the volume is attached to in the is case  \n\
          \ /dev/vdd \n where /dev is the name of the device files and /vd* is the\
          \ name of the virtuo block device. \n The important commands to that you\
          \ need to know to configure the persistent volume storage once you have\
          \ attached to your instance. \nFor most NeCTAR research cloud users an ext4\
          \ filesystem is more than sufficient and the different filesystems are beyond\
          \ the scope of\nthis document. \n To to create an ext4 filesystem on the\
          \ device or persistent volume use \n $ sudo mkfs.ext4 /dev/vdd \n WARNING:\
          \ You only need to do this once as this reformats the device any data on\
          \ the device will be lost! \n Create a directory to mount the volume to\
          \ it can be anything but should be meaningful and consistent for your work.\
          \ \n $ sudo mkdir /volume_data \n To mount the persistent volume the command\
          \ is: \n $ sudo mount /dev/vdd /volume_data -t auto \n Lastly you will need\
          \ to change the ownership of the /volume_data directoryto be able to have\
          \ read/write \naccess to do this on a ubuntu instance use: \n $ sudo chown\
          \ ubuntu /volume_data \n on a fedora, centos, scientific linux instances\
          \ \n $ sudo chown ec2-user /volume_data \n and on a debian instance. \n\
          \ $ sudo chown debian /volume_data \n To unmount the volume from your instance\
          \ use these command umount\nNOTE: Do not umount the device if you are in\
          \ that directory so cd to your home directory first otherwise you it will\
          \ fail.\n$ cd \n$ sudo umount /volume_data \n Top of page\n \n What is object\
          \ storage \n What is object storage? \n \n A more useful definition can\
          \ be found on the NeCTAR support page. \n From the NeCTAR dashboard you\
          \ can create containers in the Object Store. \n   \n click the create container\
          \ button \n   \n Fill in the Container name and the click the create container\
          \ button. You can then choose if you want to make the object container public\
          \ or private. \n \n The private objects are only available within your NeCTAR\
          \ project. While object in public containers are exactly as the note states\
          \ in the window \nwhen you created your container  \n \n It is available\
          \ to anyone that knows the URL to that object including users who don't\
          \ have access to NeCTAR instances. \n You can upload object data from you\
          \ local computer to the container using the dashboard just select the Upload\
          \ Object button. To \ndownload an object to your local computer just select\
          \ the Download button. \n \n To download the object to your instance you\
          \ just neeed to use wget \n wget https://dashboard.rc.nectar.org.au/project/containers/blast/wgs.99.tar.gz\
          \ \n Top of page\n \n File I/O best practices \n Moving data to and from\
          \ you instance instance depending on the size of the files your are try\
          \ to move can be trival for small data but large \ndata sets can become\
          \ very difficult depending on many different things. Here are some things\
          \ to keep in mind with data I/O and the cloud. \n \n \n Compress your data\
          \ files if they are larger than 10Mb with gzip or some other compression\
          \ tool it should be installed in your instance.  \n \n \n If you have to\
          \ move a directory create tar files.  \n \n \n Don't try to move data over\
          \ a wireless network, plugin to an ethernet contection, preferably at your\
          \ local institution they have larger bandwidth. \n \n \n If you data move\
          \ still time out or are getting throttled contact your the local institutes\
          \ IT support to see if they can help. \n \n \n Ohio-(Only handle it once)\
          \ if you are uploading data to your instance try to move it directly to\
          \ your instance, NeCTAR is on a fast networks as most\n  nectar nodes are\
          \ housed within University or HPC data centers.  \n \n \n With smaller data\
          \ you can try any of the methods coverd on the NeCTAR support page it has\
          \ excellent instructions.  This will work for moving data to and from your\
          \ ephemeral or volume storage attached to your instances.  \n Top of page\n\
          \ \n Using the OpenStack APIs for Managing NCBI Data \n The National Center\
          \ for Biotechnology Information (NCBI) is located in Bethesda, Marylanl\
          \ and hosts the Basic Local Alignment Search Tool (BLAST) data and is available\
          \ directly from the NCBI FTP site ftp://ftp.ncbi.nlm.nih.gov. It is necessary\
          \ for researchs to be able to access these data sets easily as they are\
          \ required for many different Bioinformatic tools specifically BLAST. However\
          \ we will not present how to actually run BLAST but how to manage the NeCTAR\
          \ reseach cloud storage resources to enable researchers to utilize the NCBI\
          \ BLAST data sets effectively. \n Install the Python client tools \n First\
          \ you will need to update your instance and install a set of packages that\
          \ support the OpenStack APIs.\nThese are the commands for a ubuntu instance.\
          \ \n $ sudo apt-get update \n $ sudo apt-get install python-novaclient \n\
          \ $ sudo apt-get install python-keystoneclient \n $ sudo apt-get install\
          \ python-cinderclient \n $ sudo apt-get install python-swiftclient \n Top\
          \ of page \n Configuring your instance to use the Openstack API \n This\
          \ the basic procedure to configure within your instance to use the OpenStack\
          \ APIs with the Python clients.\nThe first step is to set or reset your\
          \ your password from the OpenStack dashboard through your user account settings.\
          \  \n   \n Select the Reset Password tab: \n   \n that takes you to the\
          \ Password Reset Form where you reset your password \n   \n This is your\
          \ new password it is case sensitive. We will use this in the OpenStack RC\
          \ file. \n   \n From the OpenStack dashboard under the Compute -> Access\
          \ & Security, select the Download OpenStack RC File\nthat will automatically\
          \ download a RC-file to your local machine. \n   \n The OpenStack RC File\
          \ that you just downloaded will have the name Project_name-openrc.sh\nYou\
          \ will need to edit the following lines in the Project_name-openrc.sh file.\
          \ \n   \n So that the new password is hardcoded into the Project_name-openrc.sh\
          \ file. \n   \n You will need to the copy that file and your ssh key file\
          \ either the ssh pem file or the ssh key file that is associated with your\
          \ instance\nfrom your local machine to your instance. Using any of the method\
          \ described in  NeCTAR support documents. You should move your key file\
          \ or pem file to your .ssh directory in your home directory on your instance.\
          \ \n On your instance you will need to source the Project_name-openrc.sh\
          \ file to configure your environment to authenticate access to the OpenStack\
          \ services. \n $ source Project_name-openrc.sh \n You will need to source\
          \ the script before you can run any of the commands otherwise the environment\
          \ is not set properly. \n note: If you see this  \n   \n you forget to source\
          \ the OpenStack RC file.  \n If you source your OpenStack RC file and see\
          \ this: \n   \n You did not edit the OpenStack RC file! \n Testing you API\
          \ authentication \n To test your access authentication you can use the command\
          \ \n $ nova list \n this should show the list of your current instances\
          \ that indicates your authentication access was successful! \n   \n Top\
          \ of page\n \n Downloading NCBI datasets directly to your instance \n The\
          \ data transferring program listed NeCTAR support documents\nwork nicely\
          \ from your local computer but can be difficult to implement in the cloud\
          \ because of gui's or poor performance.\nWhat we need is a program to allow\
          \ us to download from the NCBI ftp site directly to our instance's ephemeral\
          \ or volume storage that \nworks from the commandline.    \n NCBI has had\
          \ good success with the lftp program available from the image packages repository\
          \ has shown to \nwork nicely from the UNIX/Linux commandline. To install\
          \ it to your instance you can just use the package managment tools for ubuntu\
          \ the command is: \n $ sudo apt-get install lftp \n you can then use the\
          \ lftp command \n $ lftp ftp.ncbi.nlm.nih.gov \n Then you can use the same\
          \ ftp commands to navigate between the local and remote systems and download\
          \ with get and upload with put.\nThis figure shows how simple this process\
          \ is to get to the blast datasets  \n   \n Now you can use get to download\
          \ the data to your instance directly. \n Using the swift API create a new\
          \ container \n To list all the containers in your project. \n $ swift list\
          \ \n To create a new private container with the swift API from the command\
          \ line \n $ swift post container_name \n To create a new public container\
          \ the swift API use: \n `$ swift post -r .r:* container_name`` \n To upload\
          \ the data into the container. \n $ swift upload 'container_name' 'data_file'\
          \ \n   \n To see your new container  \n $ swift list \n and the objects\
          \ in your new container \n $ swift list 'container_name' \n   \n Top of\
          \ page\n \n Summary \n We have covered the difference between root, ephemeral,\
          \ volume and object storage available through the NeCTAR research cloud\
          \ \nand what programs are used to be able to store you data correctly so\
          \ that you can make effective use of you virtual machine. \n \n \n The root\
          \ storage is for the Operating system and you home directory. You should\
          \ install all applications there and your home directory\nis should not\
          \ store any data but small scripts and files. \n \n \n The ephemeral storage\
          \ is your workspace so all of you analysis should be done there and you\
          \ can store your local data there. Remember\nto get the right size hardware\
          \ flavor.  It needs to have enough disk space for analysis to run and store\
          \ any associated data.  It is your\nresponsibilty to maintain and will require\
          \ regular housekeeping.  Please delete files that are not needed and move\
          \ important results back to\neither your local machine or to volume/object\
          \ storage to share them with your group or the world. \n \n \n The volume\
          \ storage can be used for storing results, working data, or as a working\
          \ directory if needed. If you have multiple researcher who\nhave access\
          \ to your project then you can share data via the volume storage.  It is\
          \ also possible to attach more that one volume storage instance\nto your\
          \ compute instance as well so you can one for input data and have a second\
          \ for results.   \n \n \n The object storage should be used for static datasets\
          \ either reference ones like the NCBI-BLAST data sets or analysis results\
          \ you wish to share\nwith collaborators.  Static data can be downloaded\
          \ easly to your volume or ephemeral storage as part of you workflow or pipeline.\
          \ With an orginal\ncopy in object storage you can delete it from either\
          \ volume or ephemeral storage then with out having to get a new copy to\
          \ your instance.  \n \n \n NOTE: There are some unresolved issues with uploading\
          \ large data sets (>5GB) in to object storage. \nUnderstanding how to split/merge\
          \ files that are larger than 5GB and being able to manage them easily..\
          \ \n Top of page "
        description: "<p><a name=\"top\"></a></p>\n<h1>Bioinformatics using the Cloud\
          \ Storage with NCBI data</h1>\n<h2>Table of Contents</h2>\n<ul>\n<li><a\
          \ href=\"#intro\">Introduction</a></li>\n<li><a href=\"#dashboard\">NeCTAR\
          \ Research Cloud storage components review using the OpenStack Dashboard</a></li>\n\
          <li><a href=\"#attached\">Attached Storage</a></li>\n<li><a href=\"#root\"\
          >root disk</a></li>\n<li><a href=\"#ephemeral\">ephemeral</a></li>\n<li><a\
          \ href=\"#external\">External Storage - Volume and Object</a></li>\n<li><a\
          \ href=\"#volume\">What is volume or block-storage</a></li>\n<li><a href=\"\
          #object\">What is object storage</a></li>\n<li><a href=\"#io\">File I/O\
          \ best practices</a></li>\n<li><a href=\"#openstack\">Using the Openstack\
          \ APIs to Manage NCBI Data</a></li>\n<li>\n<a href=\"#ncbi\">Downloading\
          \ NCBI datasets directly to your instance</a> </li>\n<li><a href=\"#summary\"\
          >Summary</a></li>\n</ul>\n<p><a href=\"#top\">Top of page</a>\n<a name=\"\
          intro\"></a></p>\n<h2>Introduction</h2>\n<p>This guide is a reference on\
          \ how to easily utilize all the different storage components \nof the NeCTAR\
          \ into a bioinformatics framework so that you can work more efficiently.\
          \  For \nthe puposes of developing our framework will use the <a href=\"\
          http://blast.ncbi.nlm.nih.gov/Blast.cgi\">NCBI-BLAST+</a>\nas it is a popular\
          \ application across many areas of bioinformatics. The BLAST data sets can\
          \ be\nvery large and that present challenges to store and access that data\
          \ locally making \nit difficult to implement in the NeCTAR research clould.\
          \    </p>\n<p><a href=\"#top\">Top of page</a></p>\n<h2>NeCTAR Research\
          \ Cloud storage components review using the OpenStack Dashboard <a name=\"\
          dashboard\"></a>\n</h2>\n<p>The NeCTAR is a federated research cloud that\
          \ uses OpenStack as the cloud operating system it \ncontrols the compute,\
          \ storage and networking resources across the different zones that make\
          \ up \nthe research cloud. The OpenStack dashboard lets user <code>provision</code>\
          \ resources for their instances \nthrough a web interface. The storage resources\
          \ can be classified as attached and external disks\neach of which has different\
          \ purpose that needs some basic explanation.</p>\n<p><a name=\"attached\"\
          ></a></p>\n<h3>Attached storage</h3>\n<p>With your instance you have access\
          \ to limited diskspace with the  \"root disk\" partition \"/\" and \n\"\
          ephemeral disk\" partition that is accessed via the /mnt directory of the\
          \ default NeCTAR images. \nThe size of the the \"root disk\" and \"ephemeral\
          \ disk\" varies with the different hardware templates \nor [flavors] (https://Support.Nectar.Org.Au/Support/Solutions/Articles/6000055380-Resources-Available-To-You)\
          \ \nthat are available when you are configuring your instance. So understanding\
          \ your research data \nrequirements is key so you can select the correct\
          \ <code>flavor</code> for your instance.\nHowever, as with everything including\
          \ the research cloud it does require a bit more insight of how a \nresearch\
          \ might make the best use of these storage components in a bioinformatic\
          \ workflow. Fortunately, NeCTAR is\na the ideal resource to allow researchers\
          \ to improve their technical knowledge of to how to use the research cloud\n\
          for their computational work.</p>\n<p><a href=\"#top\">Top of page</a>\n\
          <a name=\"root\"></a></p>\n<h3>What is the root disk</h3>\n<p>The root disk\
          \ is an ephemeral disk that the operating system (OS) image is copied to\
          \ when you launch \na virtual machine. It is also where your home directory\
          \ is located in you virtual machine. When you \nsnapshot your instance it\
          \ is what is copied to create your snapshot image.</p>\n<p><a href=\"#top\"\
          >Top of page</a>\n <a name=\"ephemeral\"></a></p>\n<h3>What is ephemeral\
          \ disk</h3>\n<p>Ephemeral is a secondary ephemeral data disk. That is an\
          \ empty disk and exists only for the life \nof the instance. When you terminate\
          \ an instance all data in ephemeral is lost. With the NeCTAR \ndefault images\
          \ that have ephemeral storage are mounted with the instance and located\
          \ at <code>/mnt</code> \nbut you will need to change the ownership of the\
          \ <code>/mnt</code> directoryto be able to have read/write \naccess to do\
          \ this on a ubuntu instance use:</p>\n<p><code>$ sudo chown ubuntu /mnt</code></p>\n\
          <p>on a fedora, centos, scientific linux instances</p>\n<p><code>$ sudo\
          \ chown ec2-user /mnt</code></p>\n<p>and on a debian instance.</p>\n<p><code>$\
          \ sudo chown debian /mnt</code></p>\n<p>This ephemeral disk space is where\
          \ you should run you analysis as your <code>home</code> directory is too\
          \ small.</p>\n<p><a href=\"#top\">Top of page</a></p>\n<p><a name=\"external\"\
          ></a></p>\n<h2>External Storage - Volume and Object</h2>\n<p>When you apply\
          \ for you NeCTAR <a href=\"https://dashboard.rc.nectar.org.au\">allocation</a>\
          \ you are able \nto apply for object and volume storage to use for research\
          \ project.  </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_storage_request.png?raw=true\"\
          ></p>\n<p>Assuming that your allocation request has either volume or object\
          \ storage or both when you configure your\nvolume or object storage you\
          \ need to remember to do select a sensible <a href=\"https://support.nectar.org.au/solution/articles/6000055381-availability-zones\"\
          >availability zones</a> to use with your data.</p>\n<p><a name=\"volume\"\
          ></a></p>\n<h3>What is volume or block-storage</h3>\n<p>Persistent <a href=\"\
          http://docs.openstack.org/openstack-ops/content/user_facing_block_storage.html\"\
          >block-storage</a> \nor volume storage can live outside of you instance.\
          \ This means that you read and write data in the persistent volume storage\
          \ \nand it can be moved around to different instances but can only be mounted\
          \ to one instance at any given time. \nYou can find more information about\
          \ creating and attaching persistent volumes through the NeCTAR dashboard\
          \ on the NeCTAR <a href=\"https://support.nectar.org.au/solution/articles/6000055382-introduction-to-cloud-storage\"\
          >support</a> page. Once it is attached to an instance the dashboard will\
          \ show what the this:</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_vol_dash.png?raw=true\"\
          ></p>\n<p>note the volume names are hyperlinks that show the volume overview,</p>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_vol_overview.png?raw=true\"\
          ></p>\n<p>The Attachments show what device the that the volume is attached\
          \ to in the is case </p>\n<p><code>/dev/vdd</code></p>\n<p>where <code>/dev</code>\
          \ is the name of the device files and <code>/vd*</code> is the name of the\
          \ virtuo block device.</p>\n<p>The important commands to that you need to\
          \ know to configure the persistent volume storage once you have attached\
          \ to your instance. \nFor most NeCTAR research cloud users an ext4 filesystem\
          \ is more than sufficient and the different filesystems are beyond the scope\
          \ of\nthis document.</p>\n<p>To to create an ext4 filesystem on the device\
          \ or persistent volume use</p>\n<p><code>$ sudo mkfs.ext4 /dev/vdd</code></p>\n\
          <p>WARNING: You only need to do this once as this reformats the device any\
          \ data on the device will be lost!</p>\n<p>Create a directory to mount the\
          \ volume to it can be anything but should be meaningful and consistent for\
          \ your work.</p>\n<p><code>$ sudo mkdir /volume_data</code></p>\n<p>To mount\
          \ the persistent volume the command is:</p>\n<p><code>$ sudo mount /dev/vdd\
          \ /volume_data -t auto</code></p>\n<p>Lastly you will need to change the\
          \ ownership of the <code>/volume_data</code> directoryto be able to have\
          \ read/write \naccess to do this on a ubuntu instance use:</p>\n<p><code>$\
          \ sudo chown ubuntu /volume_data</code></p>\n<p>on a fedora, centos, scientific\
          \ linux instances</p>\n<p><code>$ sudo chown ec2-user /volume_data</code></p>\n\
          <p>and on a debian instance.</p>\n<p><code>$ sudo chown debian /volume_data</code></p>\n\
          <p>To unmount the volume from your instance use these command <code>umount</code>\n\
          NOTE: Do not umount the device if you are in that directory so <code>cd</code>\
          \ to your home directory first otherwise you it will fail.\n<code>$ cd</code><br>\n\
          <code>$ sudo umount /volume_data</code></p>\n<p><a href=\"#top\">Top of\
          \ page</a>\n<a name=\"object\"></a></p>\n<h3>What is object storage</h3>\n\
          <p>What is object storage?</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_obj_def.png?raw=true\"\
          ></p>\n<p>A more useful definition can be found on the NeCTAR <a href=\"\
          https://support.nectar.org.au/solution/articles/6000055382-introduction-to-cloud-storage\"\
          >support</a> page.</p>\n<p>From the NeCTAR dashboard you can create <code>containers</code>\
          \ in the Object Store.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_obj_1.png?raw=true\"\
          > </p>\n<p>click the create container button</p>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_obj_2.png?raw=true\"\
          > </p>\n<p>Fill in the Container name and the click the create container\
          \ button. You can then choose if you want to make the object container public\
          \ or private.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_obj_3.png?raw=true\"\
          ></p>\n<p>The private objects are only available within your NeCTAR project.\
          \ While object in public containers are exactly as the note states in the\
          \ window \nwhen you created your container </p>\n<p><img alt=\"\" src=\"\
          https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_obj_4.png?raw=true\"\
          ></p>\n<p>It is available to anyone that knows the URL to that object including\
          \ users who don't have access to NeCTAR instances.</p>\n<p>You can upload\
          \ object data from you local computer to the container using the dashboard\
          \ just select the <code>Upload Object</code> button. To \ndownload an object\
          \ to your local computer just select the <code>Download</code> button.</p>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_obj_5.png?raw=true\"\
          ></p>\n<p>To download the object to your instance you just neeed to use\
          \ <code>wget</code></p>\n<p><code>wget https://dashboard.rc.nectar.org.au/project/containers/blast/wgs.99.tar.gz</code></p>\n\
          <p><a href=\"#top\">Top of page</a>\n<a name=\"io\"></a></p>\n<h2>File I/O\
          \ best practices</h2>\n<p>Moving data to and from you instance instance\
          \ depending on the size of the files your are try to move can be trival\
          \ for small data but large \ndata sets can become very difficult depending\
          \ on many different things. Here are some things to keep in mind with data\
          \ I/O and the cloud.</p>\n<ul>\n<li>\n<p>Compress your data files if they\
          \ are larger than 10Mb with <a href=\"http://www.math.utah.edu/docs/info/gzip_4.html#SEC7\"\
          ><strong>gzip</strong></a> or some other compression tool it should be installed\
          \ in your instance. </p>\n</li>\n<li>\n<p>If you have to move a directory\
          \ create <a href=\"https://www.cs.colostate.edu/helpdocs/tar.html\"><strong>tar</strong></a>\
          \ files. </p>\n</li>\n<li>\n<p>Don't try to move data over a wireless network,\
          \ plugin to an ethernet contection, preferably at your local institution\
          \ they have larger bandwidth.</p>\n</li>\n<li>\n<p>If you data move still\
          \ time out or are getting throttled contact your the local institutes IT\
          \ support to see if they can help.</p>\n</li>\n<li>\n<p>Ohio-(Only handle\
          \ it once) if you are uploading data to your instance try to move it directly\
          \ to your instance, NeCTAR is on a fast networks as most\n  nectar nodes\
          \ are housed within University or HPC data centers. </p>\n</li>\n</ul>\n\
          <p>With smaller data you can try any of the methods coverd on the NeCTAR\
          \ <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
          >support</a> page it has excellent instructions.  This will work for moving\
          \ data to and from your ephemeral or volume storage attached to your instances.\
          \ </p>\n<p><a href=\"#top\">Top of page</a>\n<a name=\"openstack\"></a></p>\n\
          <h2>Using the OpenStack APIs for Managing NCBI Data</h2>\n<p>The National\
          \ Center for Biotechnology Information (<a href=\"http://www.ncbi.nlm.nih.gov/\"\
          ><strong>NCBI</strong></a>) is located in Bethesda, Marylanl and hosts the\
          \ Basic Local Alignment Search Tool (<a href=\"http://blast.ncbi.nlm.nih.gov/Blast.cgi\"\
          ><strong>BLAST</strong></a>) data and is available directly from the NCBI\
          \ FTP site <code>ftp://ftp.ncbi.nlm.nih.gov</code>. It is necessary for\
          \ researchs to be able to access these data sets easily as they are required\
          \ for many different Bioinformatic tools specifically BLAST. However we\
          \ will not present how to actually run BLAST but how to manage the NeCTAR\
          \ reseach cloud storage resources to enable researchers to utilize the NCBI\
          \ BLAST data sets effectively.</p>\n<h3>Install the Python client tools</h3>\n\
          <p>First you will need to update your instance and install a set of packages\
          \ that support the OpenStack APIs.\nThese are the commands for a ubuntu\
          \ instance.</p>\n<p><code>$ sudo apt-get update</code></p>\n<p><code>$ sudo\
          \ apt-get install python-novaclient</code></p>\n<p><code>$ sudo apt-get\
          \ install python-keystoneclient</code></p>\n<p><code>$ sudo apt-get install\
          \ python-cinderclient</code></p>\n<p><code>$ sudo apt-get install python-swiftclient</code></p>\n\
          <p><a href=\"#top\">Top of page</a></p>\n<h3>Configuring your instance to\
          \ use the Openstack API</h3>\n<p>This the basic procedure to configure within\
          \ your instance to use the OpenStack APIs with the Python clients.\nThe\
          \ first step is to set or reset your your password from the OpenStack dashboard\
          \ through your user account settings. </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_1.png?raw=true\"\
          > </p>\n<p>Select the Reset Password tab:</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_2.png?raw=true\"\
          > </p>\n<p>that takes you to the Password Reset Form where you reset your\
          \ password</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_3.png?raw=true\"\
          > </p>\n<p>This is your new password it is case sensitive. We will use this\
          \ in the OpenStack RC file.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_4.png?raw=true\"\
          > </p>\n<p>From the OpenStack dashboard under the Compute -&gt; Access &amp;\
          \ Security, select the <code>Download OpenStack RC File</code>\nthat will\
          \ automatically download a RC-file to your local machine.</p>\n<p><img alt=\"\
          \" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_5.png?raw=true\"\
          > </p>\n<p>The OpenStack RC File that you just downloaded will have the\
          \ name Project_name-openrc.sh\nYou will need to edit the following lines\
          \ in the Project_name-openrc.sh file.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_6.png?raw=true\"\
          > </p>\n<p>So that the new password is hardcoded into the Project_name-openrc.sh\
          \ file.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_7.png?raw=true\"\
          > </p>\n<p>You will need to the copy that file and your ssh key file either\
          \ the ssh <strong>pem file</strong> or the ssh <strong>key</strong> file\
          \ that is associated with your instance\nfrom your local machine to your\
          \ instance. Using any of the method described in  NeCTAR <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
          >support</a> documents. You should move your key file or pem file to your\
          \ <code>.ssh</code> directory in your home directory on your instance.</p>\n\
          <p>On your instance you will need to source the Project_name-openrc.sh file\
          \ to configure your environment to authenticate access to the OpenStack\
          \ services.</p>\n<p><code>$ source Project_name-openrc.sh</code></p>\n<p>You\
          \ will need to source the script before you can run any of the commands\
          \ otherwise the environment is not set properly.</p>\n<p>note: If you see\
          \ this </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_8.png?raw=true\"\
          > </p>\n<p>you forget to source the OpenStack RC file. </p>\n<p>If you source\
          \ your OpenStack RC file and see this:</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_9.png?raw=true\"\
          > </p>\n<p>You did not edit the OpenStack RC file!</p>\n<h3>Testing you\
          \ API authentication</h3>\n<p>To test your access authentication you can\
          \ use the command</p>\n<p><code>$ nova list</code></p>\n<p>this should show\
          \ the list of your current instances that indicates your authentication\
          \ access was successful!</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_10.png?raw=true\"\
          > </p>\n<p><a href=\"#top\">Top of page</a>\n<a name=\"ncbi\"></a></p>\n\
          <h3>Downloading NCBI datasets directly to your instance</h3>\n<p>The data\
          \ transferring program listed NeCTAR <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
          >support</a> documents\nwork nicely from your local computer but can be\
          \ difficult to implement in the cloud because of gui's or poor performance.\n\
          What we need is a program to allow us to download from the NCBI ftp site\
          \ directly to our instance's ephemeral or volume storage that \nworks from\
          \ the commandline.   </p>\n<p>NCBI has had good success with the <a href=\"\
          http://lftp.yar.ru/desc.html\"><strong>lftp</strong></a> program available\
          \ from the image packages repository has shown to \nwork nicely from the\
          \ UNIX/Linux commandline. To install it to your instance you can just use\
          \ the package managment tools for ubuntu the command is:</p>\n<p><code>$\
          \ sudo apt-get install lftp</code></p>\n<p>you can then use the <code>lftp</code>\
          \ command</p>\n<p><code>$ lftp ftp.ncbi.nlm.nih.gov</code></p>\n<p>Then\
          \ you can use the same <code>ftp</code> commands to navigate between the\
          \ local and remote systems and download with <code>get</code> and upload\
          \ with <code>put</code>.\nThis figure shows how simple this process is to\
          \ get to the blast datasets </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_11.png?raw=true\"\
          > </p>\n<p>Now you can use get to download the data to your instance directly.</p>\n\
          <h3>Using the swift API create a new container</h3>\n<p>To list all the\
          \ containers in your project.</p>\n<p><code>$ swift list</code></p>\n<p>To\
          \ create a new <strong>private</strong> container with the swift API from\
          \ the command line</p>\n<p><code>$ swift post container_name</code></p>\n\
          <p>To create a new <strong>public</strong> container the swift API use:</p>\n\
          <p>`$ swift post -r .r:* container_name``</p>\n<p>To upload the data into\
          \ the container.</p>\n<p><code>$ swift upload 'container_name' 'data_file'</code></p>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_12.png?raw=true\"\
          > </p>\n<p>To see your new container </p>\n<p><code>$ swift list</code></p>\n\
          <p>and the objects in your new container</p>\n<p><code>$ swift list 'container_name'</code></p>\n\
          <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/Pawsey_ncbi_api_13.png?raw=true\"\
          > </p>\n<p><a href=\"#top\">Top of page</a>\n<a name=\"summary\"></a></p>\n\
          <h2>Summary</h2>\n<p>We have covered the difference between root, ephemeral,\
          \ volume and object storage available through the NeCTAR research cloud\
          \ \nand what programs are used to be able to store you data correctly so\
          \ that you can make effective use of you virtual machine.</p>\n<ul>\n<li>\n\
          <p>The root storage is for the Operating system and you home directory.\
          \ You should install all applications there and your home directory\nis\
          \ should not store any data but small scripts and files.</p>\n</li>\n<li>\n\
          <p>The ephemeral storage is your workspace so all of you analysis should\
          \ be done there and you can store your local data there. Remember\nto get\
          \ the right size hardware flavor.  It needs to have enough disk space for\
          \ analysis to run and store any associated data.  It is your\nresponsibilty\
          \ to maintain and will require regular housekeeping.  Please <strong><em>delete</em></strong>\
          \ files that are not needed and move important results back to\neither your\
          \ local machine or to volume/object storage to share them with your group\
          \ or the world.</p>\n</li>\n<li>\n<p>The volume storage can be used for\
          \ storing results, working data, or as a working directory if needed. If\
          \ you have multiple researcher who\nhave access to your project then you\
          \ can share data via the volume storage.  It is also possible to attach\
          \ more that one volume storage instance\nto your compute instance as well\
          \ so you can one for input data and have a second for results.  </p>\n</li>\n\
          <li>\n<p>The object storage should be used for static datasets either reference\
          \ ones like the NCBI-BLAST data sets or analysis results you wish to share\n\
          with collaborators.  Static data can be downloaded easly to your volume\
          \ or ephemeral storage as part of you workflow or pipeline. With an orginal\n\
          copy in object storage you can delete it from either volume or ephemeral\
          \ storage then with out having to get a new copy to your instance. </p>\n\
          </li>\n</ul>\n<p>NOTE: There are some unresolved issues with uploading large\
          \ data sets (&gt;5GB) in to object storage. \nUnderstanding how to split/merge\
          \ files that are larger than 5GB and being able to manage them easily..</p>\n\
          <p><a href=\"#top\">Top of page</a></p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000115009
        modified_at: '2016-02-29T21:39:10-05:00'
        modified_by: null
        position: 22
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Pawsey NeCTAR Storage and NCBI data
        updated_at: '2016-02-29T21:39:10-05:00'
        user_id: 6002464727
  html: "<p><a name=\"top\"></a></p>\n<h1>Bioinformatics using the Cloud Storage with\
    \ NCBI data</h1>\n<h2>Table of Contents</h2>\n<ul>\n<li><a href=\"#intro\">Introduction</a></li>\n\
    <li><a href=\"#dashboard\">NeCTAR Research Cloud storage components review using\
    \ the OpenStack Dashboard</a></li>\n<li><a href=\"#attached\">Attached Storage</a></li>\n\
    <li><a href=\"#root\">root disk</a></li>\n<li><a href=\"#ephemeral\">ephemeral</a></li>\n\
    <li><a href=\"#external\">External Storage - Volume and Object</a></li>\n<li><a\
    \ href=\"#volume\">What is volume or block-storage</a></li>\n<li><a href=\"#object\"\
    >What is object storage</a></li>\n<li><a href=\"#io\">File I/O best practices</a></li>\n\
    <li><a href=\"#openstack\">Using the Openstack APIs to Manage NCBI Data</a></li>\n\
    <li><a href=\"#ncbi\">Downloading NCBI datasets directly to your instance</a>\
    \ </li>\n<li><a href=\"#summary\">Summary</a></li>\n</ul>\n<p><a href=\"#top\"\
    >Top of page</a>\n<a name=\"intro\"></a></p>\n<h2>Introduction</h2>\n<p>This guide\
    \ is a reference on how to easily utilize all the different storage components\
    \ \nof the NeCTAR into a bioinformatics framework so that you can work more efficiently.\
    \  For \nthe puposes of developing our framework will use the <a href=\"http://blast.ncbi.nlm.nih.gov/Blast.cgi\"\
    >NCBI-BLAST+</a>\nas it is a popular application across many areas of bioinformatics.\
    \ The BLAST data sets can be\nvery large and that present challenges to store\
    \ and access that data locally making \nit difficult to implement in the NeCTAR\
    \ research clould.    </p>\n<p><a href=\"#top\">Top of page</a></p>\n<h2>NeCTAR\
    \ Research Cloud storage components review using the OpenStack Dashboard <a name=\"\
    dashboard\"></a></h2>\n<p>The NeCTAR is a federated research cloud that uses OpenStack\
    \ as the cloud operating system it \ncontrols the compute, storage and networking\
    \ resources across the different zones that make up \nthe research cloud. The\
    \ OpenStack dashboard lets user <code>provision</code> resources for their instances\
    \ \nthrough a web interface. The storage resources can be classified as attached\
    \ and external disks\neach of which has different purpose that needs some basic\
    \ explanation.</p>\n<p><a name=\"attached\"></a></p>\n<h3>Attached storage</h3>\n\
    <p>With your instance you have access to limited diskspace with the  \"root disk\"\
    \ partition \"/\" and \n\"ephemeral disk\" partition that is accessed via the\
    \ /mnt directory of the default NeCTAR images. \nThe size of the the \"root disk\"\
    \ and \"ephemeral disk\" varies with the different hardware templates \nor [flavors]\
    \ (https://Support.Nectar.Org.Au/Support/Solutions/Articles/6000055380-Resources-Available-To-You)\
    \ \nthat are available when you are configuring your instance. So understanding\
    \ your research data \nrequirements is key so you can select the correct <code>flavor</code>\
    \ for your instance.\nHowever, as with everything including the research cloud\
    \ it does require a bit more insight of how a \nresearch might make the best use\
    \ of these storage components in a bioinformatic workflow. Fortunately, NeCTAR\
    \ is\na the ideal resource to allow researchers to improve their technical knowledge\
    \ of to how to use the research cloud\nfor their computational work.</p>\n<p><a\
    \ href=\"#top\">Top of page</a>\n<a name=\"root\"></a></p>\n<h3>What is the root\
    \ disk</h3>\n<p>The root disk is an ephemeral disk that the operating system (OS)\
    \ image is copied to when you launch \na virtual machine. It is also where your\
    \ home directory is located in you virtual machine. When you \nsnapshot your instance\
    \ it is what is copied to create your snapshot image.</p>\n<p><a href=\"#top\"\
    >Top of page</a>\n <a name=\"ephemeral\"></a></p>\n<h3>What is ephemeral disk</h3>\n\
    <p>Ephemeral is a secondary ephemeral data disk. That is an empty disk and exists\
    \ only for the life \nof the instance. When you terminate an instance all data\
    \ in ephemeral is lost. With the NeCTAR \ndefault images that have ephemeral storage\
    \ are mounted with the instance and located at <code>/mnt</code> \nbut you will\
    \ need to change the ownership of the <code>/mnt</code> directoryto be able to\
    \ have read/write \naccess to do this on a ubuntu instance use:</p>\n<p><code>$\
    \ sudo chown ubuntu /mnt</code></p>\n<p>on a fedora, centos, scientific linux\
    \ instances</p>\n<p><code>$ sudo chown ec2-user /mnt</code></p>\n<p>and on a debian\
    \ instance.</p>\n<p><code>$ sudo chown debian /mnt</code></p>\n<p>This ephemeral\
    \ disk space is where you should run you analysis as your <code>home</code> directory\
    \ is too small.</p>\n<p><a href=\"#top\">Top of page</a></p>\n<p><a name=\"external\"\
    ></a></p>\n<h2>External Storage - Volume and Object</h2>\n<p>When you apply for\
    \ you NeCTAR <a href=\"https://dashboard.rc.nectar.org.au\">allocation</a> you\
    \ are able \nto apply for object and volume storage to use for research project.\
    \  </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_storage_request.png?raw=true\"\
    ></p>\n<p>Assuming that your allocation request has either volume or object storage\
    \ or both when you configure your\nvolume or object storage you need to remember\
    \ to do select a sensible <a href=\"https://support.nectar.org.au/solution/articles/6000055381-availability-zones\"\
    >availability zones</a> to use with your data.</p>\n<p><a name=\"volume\"></a></p>\n\
    <h3>What is volume or block-storage</h3>\n<p>Persistent <a href=\"http://docs.openstack.org/openstack-ops/content/user_facing_block_storage.html\"\
    >block-storage</a> \nor volume storage can live outside of you instance. This\
    \ means that you read and write data in the persistent volume storage \nand it\
    \ can be moved around to different instances but can only be mounted to one instance\
    \ at any given time. \nYou can find more information about creating and attaching\
    \ persistent volumes through the NeCTAR dashboard on the NeCTAR <a href=\"https://support.nectar.org.au/solution/articles/6000055382-introduction-to-cloud-storage\"\
    >support</a> page. Once it is attached to an instance the dashboard will show\
    \ what the this:</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_vol_dash.png?raw=true\"\
    ></p>\n<p>note the volume names are hyperlinks that show the volume overview,</p>\n\
    <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_vol_overview.png?raw=true\"\
    ></p>\n<p>The Attachments show what device the that the volume is attached to\
    \ in the is case </p>\n<p><code>/dev/vdd</code></p>\n<p>where <code>/dev</code>\
    \ is the name of the device files and <code>/vd*</code> is the name of the virtuo\
    \ block device.</p>\n<p>The important commands to that you need to know to configure\
    \ the persistent volume storage once you have attached to your instance. \nFor\
    \ most NeCTAR research cloud users an ext4 filesystem is more than sufficient\
    \ and the different filesystems are beyond the scope of\nthis document.</p>\n\
    <p>To to create an ext4 filesystem on the device or persistent volume use</p>\n\
    <p><code>$ sudo mkfs.ext4 /dev/vdd</code></p>\n<p>WARNING: You only need to do\
    \ this once as this reformats the device any data on the device will be lost!</p>\n\
    <p>Create a directory to mount the volume to it can be anything but should be\
    \ meaningful and consistent for your work.</p>\n<p><code>$ sudo mkdir /volume_data</code></p>\n\
    <p>To mount the persistent volume the command is:</p>\n<p><code>$ sudo mount /dev/vdd\
    \ /volume_data -t auto</code></p>\n<p>Lastly you will need to change the ownership\
    \ of the <code>/volume_data</code> directoryto be able to have read/write \naccess\
    \ to do this on a ubuntu instance use:</p>\n<p><code>$ sudo chown ubuntu /volume_data</code></p>\n\
    <p>on a fedora, centos, scientific linux instances</p>\n<p><code>$ sudo chown\
    \ ec2-user /volume_data</code></p>\n<p>and on a debian instance.</p>\n<p><code>$\
    \ sudo chown debian /volume_data</code></p>\n<p>To unmount the volume from your\
    \ instance use these command <code>umount</code>\nNOTE: Do not umount the device\
    \ if you are in that directory so <code>cd</code> to your home directory first\
    \ otherwise you it will fail.\n<code>$ cd</code><br>\n<code>$ sudo umount /volume_data</code></p>\n\
    <p><a href=\"#top\">Top of page</a>\n<a name=\"object\"></a></p>\n<h3>What is\
    \ object storage</h3>\n<p>What is object storage?</p>\n<p><img alt=\"\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_obj_def.png?raw=true\"\
    ></p>\n<p>A more useful definition can be found on the NeCTAR <a href=\"https://support.nectar.org.au/solution/articles/6000055382-introduction-to-cloud-storage\"\
    >support</a> page.</p>\n<p>From the NeCTAR dashboard you can create <code>containers</code>\
    \ in the Object Store.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_obj_1.png?raw=true\"\
    > </p>\n<p>click the create container button</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_obj_2.png?raw=true\"\
    > </p>\n<p>Fill in the Container name and the click the create container button.\
    \ You can then choose if you want to make the object container public or private.</p>\n\
    <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_obj_3.png?raw=true\"\
    ></p>\n<p>The private objects are only available within your NeCTAR project. While\
    \ object in public containers are exactly as the note states in the window \n\
    when you created your container </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_obj_4.png?raw=true\"\
    ></p>\n<p>It is available to anyone that knows the URL to that object including\
    \ users who don't have access to NeCTAR instances.</p>\n<p>You can upload object\
    \ data from you local computer to the container using the dashboard just select\
    \ the <code>Upload Object</code> button. To \ndownload an object to your local\
    \ computer just select the <code>Download</code> button.</p>\n<p><img alt=\"\"\
    \ src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_obj_5.png?raw=true\"\
    ></p>\n<p>To download the object to your instance you just neeed to use <code>wget</code></p>\n\
    <p><code>wget https://dashboard.rc.nectar.org.au/project/containers/blast/wgs.99.tar.gz</code></p>\n\
    <p><a href=\"#top\">Top of page</a>\n<a name=\"io\"></a></p>\n<h2>File I/O best\
    \ practices</h2>\n<p>Moving data to and from you instance instance depending on\
    \ the size of the files your are try to move can be trival for small data but\
    \ large \ndata sets can become very difficult depending on many different things.\
    \ Here are some things to keep in mind with data I/O and the cloud.</p>\n<ul>\n\
    <li>\n<p>Compress your data files if they are larger than 10Mb with <a href=\"\
    http://www.math.utah.edu/docs/info/gzip_4.html#SEC7\"><strong>gzip</strong></a>\
    \ or some other compression tool it should be installed in your instance. </p>\n\
    </li>\n<li>\n<p>If you have to move a directory create <a href=\"https://www.cs.colostate.edu/helpdocs/tar.html\"\
    ><strong>tar</strong></a> files. </p>\n</li>\n<li>\n<p>Don't try to move data\
    \ over a wireless network, plugin to an ethernet contection, preferably at your\
    \ local institution they have larger bandwidth.</p>\n</li>\n<li>\n<p>If you data\
    \ move still time out or are getting throttled contact your the local institutes\
    \ IT support to see if they can help.</p>\n</li>\n<li>\n<p>Ohio-(Only handle it\
    \ once) if you are uploading data to your instance try to move it directly to\
    \ your instance, NeCTAR is on a fast networks as most\n  nectar nodes are housed\
    \ within University or HPC data centers. </p>\n</li>\n</ul>\n<p>With smaller data\
    \ you can try any of the methods coverd on the NeCTAR <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
    >support</a> page it has excellent instructions.  This will work for moving data\
    \ to and from your ephemeral or volume storage attached to your instances. </p>\n\
    <p><a href=\"#top\">Top of page</a>\n<a name=\"openstack\"></a></p>\n<h2>Using\
    \ the OpenStack APIs for Managing NCBI Data</h2>\n<p>The National Center for Biotechnology\
    \ Information (<a href=\"http://www.ncbi.nlm.nih.gov/\"><strong>NCBI</strong></a>)\
    \ is located in Bethesda, Marylanl and hosts the Basic Local Alignment Search\
    \ Tool (<a href=\"http://blast.ncbi.nlm.nih.gov/Blast.cgi\"><strong>BLAST</strong></a>)\
    \ data and is available directly from the NCBI FTP site <code>ftp://ftp.ncbi.nlm.nih.gov</code>.\
    \ It is necessary for researchs to be able to access these data sets easily as\
    \ they are required for many different Bioinformatic tools specifically BLAST.\
    \ However we will not present how to actually run BLAST but how to manage the\
    \ NeCTAR reseach cloud storage resources to enable researchers to utilize the\
    \ NCBI BLAST data sets effectively.</p>\n<h3>Install the Python client tools</h3>\n\
    <p>First you will need to update your instance and install a set of packages that\
    \ support the OpenStack APIs.\nThese are the commands for a ubuntu instance.</p>\n\
    <p><code>$ sudo apt-get update</code></p>\n<p><code>$ sudo apt-get install python-novaclient</code></p>\n\
    <p><code>$ sudo apt-get install python-keystoneclient</code></p>\n<p><code>$ sudo\
    \ apt-get install python-cinderclient</code></p>\n<p><code>$ sudo apt-get install\
    \ python-swiftclient</code></p>\n<p><a href=\"#top\">Top of page</a></p>\n<h3>Configuring\
    \ your instance to use the Openstack API</h3>\n<p>This the basic procedure to\
    \ configure within your instance to use the OpenStack APIs with the Python clients.\n\
    The first step is to set or reset your your password from the OpenStack dashboard\
    \ through your user account settings. </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_1.png?raw=true\"\
    > </p>\n<p>Select the Reset Password tab:</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_2.png?raw=true\"\
    > </p>\n<p>that takes you to the Password Reset Form where you reset your password</p>\n\
    <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_3.png?raw=true\"\
    > </p>\n<p>This is your new password it is case sensitive. We will use this in\
    \ the OpenStack RC file.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_4.png?raw=true\"\
    > </p>\n<p>From the OpenStack dashboard under the Compute -&gt; Access &amp; Security,\
    \ select the <code>Download OpenStack RC File</code>\nthat will automatically\
    \ download a RC-file to your local machine.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_5.png?raw=true\"\
    > </p>\n<p>The OpenStack RC File that you just downloaded will have the name Project_name-openrc.sh\n\
    You will need to edit the following lines in the Project_name-openrc.sh file.</p>\n\
    <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_6.png?raw=true\"\
    > </p>\n<p>So that the new password is hardcoded into the Project_name-openrc.sh\
    \ file.</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_7.png?raw=true\"\
    > </p>\n<p>You will need to the copy that file and your ssh key file either the\
    \ ssh <strong>pem file</strong> or the ssh <strong>key</strong> file that is associated\
    \ with your instance\nfrom your local machine to your instance. Using any of the\
    \ method described in  NeCTAR <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
    >support</a> documents. You should move your key file or pem file to your <code>.ssh</code>\
    \ directory in your home directory on your instance.</p>\n<p>On your instance\
    \ you will need to source the Project_name-openrc.sh file to configure your environment\
    \ to authenticate access to the OpenStack services.</p>\n<p><code>$ source Project_name-openrc.sh</code></p>\n\
    <p>You will need to source the script before you can run any of the commands otherwise\
    \ the environment is not set properly.</p>\n<p>note: If you see this </p>\n<p><img\
    \ alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_8.png?raw=true\"\
    > </p>\n<p>you forget to source the OpenStack RC file. </p>\n<p>If you source\
    \ your OpenStack RC file and see this:</p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_9.png?raw=true\"\
    > </p>\n<p>You did not edit the OpenStack RC file!</p>\n<h3>Testing you API authentication</h3>\n\
    <p>To test your access authentication you can use the command</p>\n<p><code>$\
    \ nova list</code></p>\n<p>this should show the list of your current instances\
    \ that indicates your authentication access was successful!</p>\n<p><img alt=\"\
    \" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_10.png?raw=true\"\
    > </p>\n<p><a href=\"#top\">Top of page</a>\n<a name=\"ncbi\"></a></p>\n<h3>Downloading\
    \ NCBI datasets directly to your instance</h3>\n<p>The data transferring program\
    \ listed NeCTAR <a href=\"https://support.nectar.org.au/support/solutions/articles/6000085114-transferring-data-to-your-vm\"\
    >support</a> documents\nwork nicely from your local computer but can be difficult\
    \ to implement in the cloud because of gui's or poor performance.\nWhat we need\
    \ is a program to allow us to download from the NCBI ftp site directly to our\
    \ instance's ephemeral or volume storage that \nworks from the commandline.  \
    \ </p>\n<p>NCBI has had good success with the <a href=\"http://lftp.yar.ru/desc.html\"\
    ><strong>lftp</strong></a> program available from the image packages repository\
    \ has shown to \nwork nicely from the UNIX/Linux commandline. To install it to\
    \ your instance you can just use the package managment tools for ubuntu the command\
    \ is:</p>\n<p><code>$ sudo apt-get install lftp</code></p>\n<p>you can then use\
    \ the <code>lftp</code> command</p>\n<p><code>$ lftp ftp.ncbi.nlm.nih.gov</code></p>\n\
    <p>Then you can use the same <code>ftp</code> commands to navigate between the\
    \ local and remote systems and download with <code>get</code> and upload with\
    \ <code>put</code>.\nThis figure shows how simple this process is to get to the\
    \ blast datasets </p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_11.png?raw=true\"\
    > </p>\n<p>Now you can use get to download the data to your instance directly.</p>\n\
    <h3>Using the swift API create a new container</h3>\n<p>To list all the containers\
    \ in your project.</p>\n<p><code>$ swift list</code></p>\n<p>To create a new <strong>private</strong>\
    \ container with the swift API from the command line</p>\n<p><code>$ swift post\
    \ container_name</code></p>\n<p>To create a new <strong>public</strong> container\
    \ the swift API use:</p>\n<p>`$ swift post -r .r:* container_name``</p>\n<p>To\
    \ upload the data into the container.</p>\n<p><code>$ swift upload 'container_name'\
    \ 'data_file'</code></p>\n<p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_12.png?raw=true\"\
    > </p>\n<p>To see your new container </p>\n<p><code>$ swift list</code></p>\n\
    <p>and the objects in your new container</p>\n<p><code>$ swift list 'container_name'</code></p>\n\
    <p><img alt=\"\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/Pawsey_ncbi_api_13.png?raw=true\"\
    > </p>\n<p><a href=\"#top\">Top of page</a>\n<a name=\"summary\"></a></p>\n<h2>Summary</h2>\n\
    <p>We have covered the difference between root, ephemeral, volume and object storage\
    \ available through the NeCTAR research cloud \nand what programs are used to\
    \ be able to store you data correctly so that you can make effective use of you\
    \ virtual machine.</p>\n<ul>\n<li>\n<p>The root storage is for the Operating system\
    \ and you home directory. You should install all applications there and your home\
    \ directory\nis should not store any data but small scripts and files.</p>\n</li>\n\
    <li>\n<p>The ephemeral storage is your workspace so all of you analysis should\
    \ be done there and you can store your local data there. Remember\nto get the\
    \ right size hardware flavor.  It needs to have enough disk space for analysis\
    \ to run and store any associated data.  It is your\nresponsibilty to maintain\
    \ and will require regular housekeeping.  Please <strong><em>delete</em></strong>\
    \ files that are not needed and move important results back to\neither your local\
    \ machine or to volume/object storage to share them with your group or the world.</p>\n\
    </li>\n<li>\n<p>The volume storage can be used for storing results, working data,\
    \ or as a working directory if needed. If you have multiple researcher who\nhave\
    \ access to your project then you can share data via the volume storage.  It is\
    \ also possible to attach more that one volume storage instance\nto your compute\
    \ instance as well so you can one for input data and have a second for results.\
    \  </p>\n</li>\n<li>\n<p>The object storage should be used for static datasets\
    \ either reference ones like the NCBI-BLAST data sets or analysis results you\
    \ wish to share\nwith collaborators.  Static data can be downloaded easly to your\
    \ volume or ephemeral storage as part of you workflow or pipeline. With an orginal\n\
    copy in object storage you can delete it from either volume or ephemeral storage\
    \ then with out having to get a new copy to your instance. </p>\n</li>\n</ul>\n\
    <p>NOTE: There are some unresolved issues with uploading large data sets (&gt;5GB)\
    \ in to object storage. \nUnderstanding how to split/merge files that are larger\
    \ than 5GB and being able to manage them easily..</p>\n<p><a href=\"#top\">Top\
    \ of page</a></p>"
  parent: 24
  sha1: e64ccf77ecc13bd9e9c89011d8ea0603f9c5b836
  title: Pawsey NeCTAR Storage and NCBI data
116:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2016-03-02T20:58:18-05:00'
        desc_un_html: " Introduction to MonARCH \n \n MonARCH (Monash Advanced Research\n\
          Computing Hybrid) is the next-generation HPC/HTC Cluster, designed from\
          \ the\nground up to address the emergent and future needs of the research\
          \ communities\nsupported by Monash. \n A key feature of MonARCH is that\
          \ it is provisioned through R@CMon, the Research\nCloud @ Monash facility.\
          \ Through the use of advanced cloud technology, MonARCH\nis able to configure\
          \ and grow dynamically. As with any HPC cluster, MonARCH\npresents a single\
          \ point-of-access to computational researchers to run\ncalculations on its\
          \ constituent servers. \n MonARCH aims to continually develop over time.\
          \ Currently, it consists of 35\nservers under two complementary hardware\
          \ specifications: \n \n high-core servers - two Haswell CPU sockets with\
          \ a total of 24 physical cores\n  (or 48 hyperthreaded cores) at 2.80 GHz\
          \ \n high-speed servers - two Haswell CPU sockets with a total of 16 physical\n\
          \  cores (or 32 hyperthreaded cores) at 3.20 GHz \n \n For data storage,\
          \ we have deployed a parallel file system service using Intel\nEnterprise\
          \ Lustre; providing over 300 TB usable storage with room for future\nexpansion.\
          \ \n The MonARCH service is operated by the Monash HPC team and continuing\
          \ technical\nand operational support from the R@CMon team, this includes\
          \ technical\nstaff from both the Monash eResearch Centre and Monash eSolutions.\
          \ \n If you have found the MonARCH useful for your research, we will be\
          \ very\ngrateful if you kindly acknowledge us with a text along the lines\
          \ of: \n \n This research was supported in part by the Monash eResearch\
          \ Centre and\neSolutions-Research Support Services through the use of the\
          \ MonARCH HPC\nCluster. \n \n How to Access MonARCH \n To access MonARCH\
          \ you will need to \n \n Create a username and password for the Monash HPC\
          \ systems \n Request access to the MonARCH resource \n Use SSH or Strudel\
          \ to access MonARCH \n \n Apply for access to Monash HPC systems and MonARCH\
          \ \n \n From a web browser, visit The Monash HPC Identity Management System\n\
          \ \n \n This web page will bootstrap your Monash HPC account using information\
          \ provided\nby your Institution and the AAF. \n Depending on your settings,\
          \ usually the next step will be to select your\ninstitution, in this example,\
          \ \"Monash University\". \n \n 2: You will be redirected to your institutions\
          \ secure Identity Provider\nservice. You should enter your institutional\
          \ username and password to\nauthenticate to your institution.  In the background,\
          \ your institution will\ntell us information like your Name and email address\
          \ (but never your password).\nDepending on your settings, you may be asked\
          \ to approve your institution\ntelling us this information. \n \n 3: The\
          \ next step is Username Selection. You will be presented with a list of\n\
          available usernames, It is important to note that this username is not\n\
          necessarily the same as your institute username. This username is for SSH\
          \ and\nSCP access to the MonARCH login node. \n In the example below, the\
          \ user's University username is \"authcate\" but their username\nfor MonARCH\
          \ is \"demo1\". \n \n 4: Apply to access MonARCH. Select the \"Use MonARCH\"\
          \ option. \n This will send a request to the MonARCH team to approve access\
          \ to the cluster. \n \n The above screen-grab shows that the application\
          \ is pending for approval. \n The application will the go through an approval\
          \ process. First the project\nleader will approve the application, then\
          \ the administrators will approve the\napplication While the approval process\
          \ is ongoing, if you click on the\n\"Applications\" button you should see\
          \ something like this: \n ![Screen show of HPC ID system in waiting for\
          \ admin state)(images/wait_admin.jpg) \n Once the application has been approved,\
          \ you'll receive an email and be able to\nmove onto the next step. \n 5:\
          \ Change your MonARCH cluster password. Note that this DOES NOT change your\n\
          Institutional password. Choose \"Personal\" and click \"Change Password\"\
          . \n Important: This DOES NOT change or affect your Institutional password.\
          \ This\npassword is for SSH and SCP access to the cluster. \n \n Accessing\
          \ MonARCH \n Using SSH \n You will need to use ssh (secure-shell) to login\
          \ to the head node. This program\nencrypts your interactions with the server.\
          \ How to get and use ssh depends upon\nyour desktop operating system. \n\
          \ Linux and MacOS \n Linux and MacOS both have SSH built in. Simply open\
          \ a terminal and type \n \n ssh username@monarch.erc.monash.edu.au \n \n\
          \ where username is the selected username from Step 3. In the above example,\n\
          the username is \"demo1\", so: \n \n ssh demo1@monarch.erc.monash.edu.au\
          \ \n \n Microsoft Windows \n ssh is not native to Windows, but you can download\
          \ several free versions. Many\nMonash PCs have a version of ssh installed\
          \ already on them. \n putty \n You can download putty from the putty website\
          \ Once\ninstalled you run putty: \n \n Start->All Programs->PuTTY->PuTTY\
          \ \n \n Select \u201CSession:\u201D on the left pane. \n In the text box\
          \ on the right pane labelled \"Host Name (or IP address)\"\nenter monarch.erc.monash.edu.au\
          \ \n Click open. You will be prompted for your username and password. These\
          \ are the\nusername and password you set for the Monash HPC ID system, not\
          \ your\ninstitutional username and password. \n SLURM \n Introduction \n\
          \ MonARCH uses the SLURM scheduler for running jobs.  The home page for\
          \ SLURM is http://slurm.schedmd.com/, and it is used in many computing systems,\
          \ such as MASSIVE and VLSCI.\nSLURM is an open-source workload manager designed\
          \ for Linux clusters of all sizes. It provides three key functions. \n \n\
          \ It allocates exclusive and/or non-exclusive access to resources (computer\
          \ nodes) to users for some duration of time so they can perform work. \n\
          \ It provides a framework for starting, executing, and monitoring work (typically\
          \ a parallel job) on a set of allocated nodes. \n It arbitrates contention\
          \ for resources by managing a queue of pending work. \n \n The following\
          \ material will explain how users can use SLURM.  At the bottom of the page\
          \ there is a PBS, SGE comparison section. \n SLURM Glossary \n It is important\
          \ to understand that some SLURM syntax have meanings which may differ from\
          \ syntax in other batch or resource schedulers. \n\n\n\nTerm\nDescription\n\
          \n\n\n\nResource\nA mix of CPUs, memory and time\n\n\nTask\nA task under\
          \ SLURM is a synonym for a process, and is often the number of MPI processes\
          \ that are required\n\n\nPartition\nSLURM groups nodes into sets called\
          \ partitions. Jobs are submitted to a partition to run. In other batch systems\
          \ the term queue is used\n\n\nAccount\nThe term account is used to describe\
          \ the entity to which used resources are charged to\n\n\nBatch jobs\nA chain\
          \ of commands in a script file\n\n\nSuccess\nA job completes and terminates\
          \ well (with exit status 0) (cancelled jobs are not considered successful)\n\
          \n\nFailure\nAnything that lacks success\n\n\nCPUs\nThe term CPU is used\
          \ to describe the smallest physical consumable, and for multi-core machines\
          \ this will be the core. For multi-core machines where hyper-threading is\
          \ enabled this will be a hardware thread.\n\n\nNode\nA node contains one\
          \ or more sockets\n\n\nSocket\nA socket contains one processor\n\n\nProcessor\n\
          A processor contains one or more cores\n\n\nCore\nA CPU core\n\n\n\n SLURM\
          \ Shell Commands \n Users submit jobs to the MonARCH using SLURM commands\
          \ called from the Unix shell (such as bash, or csh). Typically a user creates\
          \ a batch submission script that specifies what computing resources they\
          \ want from the cluster, as well as the commands to execute when the job\
          \ is running.  They then use sbatch filename to submit the job.  Users can\
          \ kill, pause and interrogate the jobs they are running.  Here is a list\
          \ of common commands: \n Commands to submit/delete a job in the queue \n\
          \n\n\nCommand\nDescription\n\n\n\n\nsbatch\nsbatch is used to submit a job\
          \ script for later execution. The script will typically contain one or more\
          \ srun commands to launch parallel tasks.\n\n\nscancel\nDeletes a job from\
          \ the queue, or stops it running.\n\n\n\n Commands to run an executable\
          \ \n\n\n\nCommand\nDescription\n\n\n\n\nsrun\nsrun should be used to execute\
          \ each program in your job script. It supersedes mpirun and is capable of\
          \ starting highly parallel jobs much faster than mpirun\n\n\n\n Examining\
          \ and Controlling the queue \n\n\n\nCommand\nDescription\n\n\n\n\nsinfo\n\
          reports the state of partitions and nodes managed by Slurm. It has a wide\
          \ variety of filtering, sorting, and formatting options.\n\n\nsqueue\nreports\
          \ the state of jobs or job steps. It has a wide variety of filtering, sorting,\
          \ and formatting options. By default, it reports the running jobs in priority\
          \ order and then the pending jobs in priority order.\n\n\nscontrol\nReport\
          \  or modify details of a job\n\n\nsinteractive\nIt is possible to run a\
          \ job as an interactive session using ' sinteractive '. The program hangs\
          \ until the session is scheduled to run, and then the user is logged into\
          \ the compute node. Exiting the shell (or logging out) ends the session\
          \ and the user is returned to the original node.\n\n\n\n Viewing job metrics\
          \ \n\n\n\nCommand\nDescription\n\n\n\n\nsacct\nThe command sacct shows metrics\
          \ from past jobs.\n\n\nsstat\nThe command sstat shows metrics from currently\
          \ running jobs when given a job number. Note, you need to launch jobs with\
          \ srun to get this information.\n\n\n\n More on Shell Commands \n Users\
          \ have several ways of getting information on shell commands. \n \n The\
          \ commands have man pages (via the unix manual). e.g. man sbatch \n The\
          \ commands have built-in help options, e.g. sbatch --help or sbatch --usage.\
          \ \n help print brief description \n usage  prints list of options \n There\
          \ are online manuals and information pages \n \n Most commands have options\
          \ in two formats: \n \n single letter e.g. -N 1 \n verbose  e.g. --nodes=1\
          \ \n \n Note the double dash -- in the verbose format. A non-\xAD\u2010\
          zero exit code indicates failure in a command. \n Some default behaviours\
          \ \n \n SLURM processes launched with srun are not run under a shell, so\
          \ none of the following are executed: \n ~/.profile \n ~/.baschrc \n ~/.login\
          \ \n ~/.cshrc, etc \n SLURM exports user environment by default (or --export=NONE)\
          \ \n SLURM runs in the current directory (no need to cd $PBS_O_WORKDIR)\
          \ \n SLURM combines stdout and stderr and outputs directly (and naming is\
          \ different). The SLURM stdout /stderr file will be appended,not overwritten\
          \ (if it exists) \n SLURM is case insensitive (e.g. project names are lower\
          \ case) \n Use #SBATCH instead of #PBS in batch scripts \n \n Batch Scripts\
          \ \n A job script has a header section which specifies the resources that\
          \ are\nrequired to run the job as well as the commands that must be executed.\
          \ An\nexample script is shown below. \n ```bash \n !/bin/bash \n SBATCH\
          \ --job-name=example \n SBATCH --account=director100 \n SBATCH --partition=workq\
          \ \n SBATCH --time=01:00:00 \n SBATCH --ntasks=32 \n SBATCH --ntasks-per-node=16\
          \ \n SBATCH --cpus-per-task=1 \n SBATCH --export=NONE \n module load intel\n\
          uname -a\nsrun uname -a\n``` \n Here are some of the SLURM directives you\
          \ can use in a batch script. \n\n\n\nSLURM directive\nDescription\n\n\n\n\
          \n--job-name=[job name]\nThe job name for the allocation, defaults to the\
          \ script name.\n\n\n--account=[account name]\nCharge resources used to this\
          \ account. A default account is configured for each user.\n\n\n--partition=[partition\
          \ name]\nRequest an allocation on the specified partition. If not specified\
          \ jobs will be submitted to the default partition.\n\n\n--time=[time spec]\n\
          The total walltime for the job allocation.\n\n\n--array=[job spec]\nSubmit\
          \ a job array with the defined indices.\n\n\n--dependency=[dependency list]\n\
          Specify a job dependency.\n\n\n--nodes=[total nodes]\nSpecify the total\
          \ number of nodes.\n\n\n--ntasks=[total tasks]\nSpecify the total number\
          \ of tasks.\n\n\n--ntasks-per-node=[ntasks]\nSpecify the number of tasks\
          \ per node.\n\n\n--cpus-per-task=[ncpus]\nSpecify the number of CPUs per\
          \ task.\n\n\n--ntasks-per-core=[ntasks]\nSpecify the number of tasks per\
          \ CPU core.\n\n\n--export=[variable\\\nALL\\\n\n\n\n NOTE: SLURM will copy\
          \ the entire environment from the shell where a job is\nsubmitted from.\
          \ This may break existing batch scripts that require a different\nenvironment\
          \ than say a login environment. To guard against this --export=NONE\ncan\
          \ be specified for each batch script. \n MonARCH Hardware Summary \n There\
          \ are two classes of compute nodes on MonARCH. They are broken into \"High\n\
          Speed\" and \"High Core Count\" flavours. \n \n \n config A: high-ish CPU\
          \ clock speed, lower-core count, standard RAM \n \n \n 16 physical cores\
          \ or 32 HT cores ==> two Intel Xeon E5-2667 v3 3.2GHz, 20M\n    Cache, 9.60GT/s\
          \ QPI, Turbo, HT, 8C/16T (135W) \n \n 128 GB RAM == 8 x 16GB RDIMM, 2133\
          \ MT/s, Dual Rank, x4 Data Width \n config B: lower CPU clock speed, high-core\
          \ count, higher RAM \n 24 physical cores or 48 HT cores ==> two Intel Xeon\
          \ E5-2680 v3 2.5GHz, 30M\n    Cache, 9.60GT/s QPI, Turbo, HT, 12C/24T (120W)\
          \ \n 256 GB RAM == 16 x 16GB RDIMM, 2133 MT/s, Dual Rank, x4 Data Width\
          \ \n \n MonARCH supports a wide range of software  packages. The Linux environment\
          \ module utility is used to load and unload different software packages.\
          \ When a module is loaded, it sets specific environment variables (e.g.,\
          \ PATH, LD_LIBRARY_PATH, etc.) to the appropriate pathnames where the software\
          \ is installed. \n Environment Modules \n There may be occasions where you\
          \ need to use different compilers and/or libraries from those found in your\
          \ usual environment, and you therefore need to adjust your environment variables\
          \ accordingly. The module command makes this easy. Some examples of its\
          \ use are: \n\n\n\nmodule avail\nShows what modules are available on the\
          \ system\n\n\n\n\nmodule whatis\nShows what they do\n\n\nmodule load openmpi-intel\n\
          Makes Intel MPI libraries and Intel Fortran compiler available\n\n\nmodule\
          \ list\nShows which module are loaded\n\n\nmodule purge\nUnloads all of\
          \ them\n\n\nmodule unload openmpi-intel intel\nUnloads Intel MPI and Intel\
          \ Fortran modules\n\n\nmodule display [modulefile]Software\nUse this command\
          \ to see exactly what a given modulefile will do to your environment, such\
          \ as what will be added to the PATH, MANPATH, etc. environment variables.\n\
          \n\n\n Here is an example of how to load the GNU C/C++ compiler. \n ```bash\
          \ \n $module load gcc/4.3.5\n``` \n That's all! Now here we put some extra\
          \ Linux commands to show that, by loading\nthe module, we override the default\
          \ System compiler. \n Load the gcc compiler, showing paths and versions:\
          \ \n ```bash \n \n show that we have the default compiler \n \n $which gcc\n\
          /usr/bin/gcc\n$gcc -v\nUsing built-in specs.\nTarget: x86_64-redhat-linux\n\
          Configured with: ../configure --prefix=/usr --mandir=/usr/share/man\n--infodir=/usr/share/info\n\
          --enable-shared --enable-threads=posix --enable-checking=release\n--with-system-zlib\
          \ --enable-__cxa_atexit\n--disable-libunwind-exceptions --enable-libgcj-multifile\n\
          --enable-languages=c,c++,objc,obj-c++,java,fortran,ada\n--enable-java-awt=gtk\
          \ --disable-dssi --enable-plugin\n--with-java-home=/usr/lib/jvm/java-1.4.2-gcj-1.4.2.0/jre\n\
          --with-cpu=generic --host=x86_64-redhat-linux\nThread model: posix\ngcc\
          \ version 4.1.2 20080704 (Red Hat 4.1.2-46) \n \n load a different compiler\
          \ \n \n $module load gcc/4.3.5 \n \n check that we have a new version \n\
          \ \n $which gcc\n/opt/sw/gcc-4.3.5/bin/gcc\n$gcc -v\nUsing built-in specs.\n\
          Target: x86_64-unknown-linux-gnu\nConfigured with: ../gcc-4.3.5/configure\
          \ --prefix=/opt/sw/gcc-4.3.5\nThread model: posix\ngcc version 4.3.5 (GCC)\n\
          ``` \n Suppose we wanted to know more about a module we wanted to load?\
          \ That can be done via the 'show' command 'module show' example \n ```bash\n\
          module show gcc/4.3.5 \n \n /opt/sw/Modules/modulefiles/gcc/4.3.5:\nmodule-whatis\
          \    GNU Compiler Collection is ...\nconflict     gcc/4.8.0\nconflict  \
          \   gcc/4.4.4\nconflict     gcc/4.5.3\nconflict     intel/10.0.025\nconflict\
          \     intelC/10.0.025\nprepend-path PATH /opt/sw/gcc-4.3.5/bin:/opt/sw/gcc-4.3.5/libexec/gcc/x86_64-unknown-linux-gnu/4.3.5\n\
          prepend-path     LD_LIBRARY_PATH /opt/sw/gcc-4.3.5/lib64:/opt/sw/gcc-4.3.5/lib\n\
          prepend-path     MANPATH /opt/sw/gcc-4.3.5/man \n \n ``` \n Suppose we wanted\
          \ to use the system compiler again. All you do is unload the module.\nUnload\
          \ the gcc compiler \n ```bash\nmodule unload gcc/4.3.5 \n ``` \n Here we\
          \ unload the compiler, checking that we have the right versions when finished.\
          \ \n Check that we load the correct compiler: \n ```bash \n \n unload compiler\
          \ \n \n $ module unload gcc/4.3.5 \n \n show that we have the default compiler\
          \ \n \n $which gcc\n/usr/bin/gcc\n$gcc -v\nUsing built-in specs.\nTarget:\
          \ x86_64-redhat-linux\nConfigured with: ../configure --prefix=/usr --mandir=/usr/share/man\
          \ --infodir=/usr/share/info --enable-shared --enable-threads=posix --enable-checking=release\
          \ --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions\
          \ --enable-libgcj-multifile --enable-languages=c,c++,objc,obj-c++,java,fortran,ada\
          \ --enable-java-awt=gtk --disable-dssi --enable-plugin --with-java-home=/usr/lib/jvm/java-1.4.2-gcj-1.4.2.0/jre\
          \ --with-cpu=generic --host=x86_64-redhat-linux\nThread model: posix\ngcc\
          \ version 4.1.2 20080704 (Red Hat 4.1.2-46)\n``` \n An advantage of using\
          \ the module command is that it warns you about conflicting packages.  You\
          \ can't load two different gcc compilers at the same time! \n bash\n$ module\
          \ load gcc/4.3.5\n$ module load gcc/4.2.3\ngcc/4.2.3(15):ERROR:150:    Module\
          \ 'gcc/4.2.3' conflicts with the currently loaded module(s) 'gcc/4.3.5'\n\
          gcc/4.2.3(15):ERROR:102:    Tcl command execution failed: conflict gcc/4.3.5\
          \ \n Note. Some modules load other modules! Also, if the software is licensed,\n\
          loading a module does not mean you will be allowed access to it.  Please\
          \  email\nmcc-help@monash.edu to gain access to proprietary software. Here,\
          \ loading the\nvasp module will not allow you access to it. \n Example of\
          \ 'module list': \n bash\nmodule list\nCurrently Loaded Modulefiles:\n \
          \ 1) gcc/4.3.5               3) mpfr/2.4.2              5) openmpi/1.6-gcc-4.5.3\
          \   7) vasp/5.3.2-2D\n  2) gmp/4.3.2               4) mpc/0.9          \
          \       6) fftw/3.2.2-openmp \n If you do not explicitly give a version\
          \ number, module will use the default module. \n Example of 'module display'\
          \ \n ```bash\nmodule display gcc \n \n /opt/sw/Modules/modulefiles/gcc/4.4.4:\
          \ \n             module-whatis     GNU Compiler Collection is ...\n    \
          \        module         load gmp mpfr\n            conflict     gcc/4.8.0\n\
          \            conflict     gcc/4.3.5\n            conflict     gcc/4.5.3\n\
          \            conflict     intel/10.0.025\n            conflict     intelC/10.0.025\n\
          \            prepend-path    PATH/opt/sw/gcc-4.4.4/bin:/opt/sw/gcc-4.4.4/libexec/gcc/x86_64-unknown-linux-gnu/4.4.4\n\
          \            prepend-path    LD_LIBRARY_PATH /opt/sw/gcc-4.4.4//lib64\n\
          \            prepend-path    MANPATH /opt/sw/gcc-4.4.4//man\n          \
          \  -------------------------------------------------------------------\n\
          \ \n ``` \n This is the output of 'module avail'.  You can interrogate any\
          \ module with the commands listed above.\nOutput of 'module avail' \n ```bash\n\
          module avail\n------------------------------ /usr/share/Modules/modulefiles\
          \ -------------------------------\ndot                    matlab-compiler/R2011a\
          \ module-info            null\nmatlab/R2011a-local    module-cvs       \
          \      modules                use.own \n ------------------------------\
          \ /opt/sw/Modules/modulefiles ----------------------------------\nFEniCS/1.0\
          \                         fluent/proto                       libctl/3.0.3(default)\n\
          Mesa/7.0.1(default)                freeglut/2.6.0                     libctl/3.1\n\
          Mesa/7.0.2                         freeimage/3.13.1                   libctl/3.2.1\n\
          Mesa/7.2                           freesurfer/5.0.0                   libxc/2.0.2\n\
          OpenBUGS/3.1.1                     fsc/1.1.2                          libxml2/2.7.2\n\
          OpenCV/2.2.0                       fsl/4.0.2                          macmolplt/7.4.2\n\
          Qt/3.3.8b                          fsl/4.1.0-test                     mallet/2.0.7\n\
          Qt/4.2.3                           fsl/4.1.5                          ...\n\
          ...\n``` "
        description: "<h1>Introduction to MonARCH</h1>\n<p><img alt=\"MonARCH Compute\
          \ Nodes\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/MonARCH.png?raw=true\"\
          ></p>\n<p>MonARCH (Monash Advanced Research\nComputing Hybrid) is the next-generation\
          \ HPC/HTC Cluster, designed from the\nground up to address the emergent\
          \ and future needs of the research communities\nsupported by Monash.</p>\n\
          <p>A key feature of MonARCH is that it is provisioned through R@CMon, the\
          \ Research\nCloud @ Monash facility. Through the use of advanced cloud technology,\
          \ MonARCH\nis able to configure and grow dynamically. As with any HPC cluster,\
          \ MonARCH\npresents a single point-of-access to computational researchers\
          \ to run\ncalculations on its constituent servers.</p>\n<p>MonARCH aims\
          \ to continually develop over time. Currently, it consists of 35\nservers\
          \ under two complementary hardware specifications:</p>\n<ul>\n<li>high-core\
          \ servers - two Haswell CPU sockets with a total of 24 physical cores\n\
          \  (or 48 hyperthreaded cores) at 2.80 GHz</li>\n<li>high-speed servers\
          \ - two Haswell CPU sockets with a total of 16 physical\n  cores (or 32\
          \ hyperthreaded cores) at 3.20 GHz</li>\n</ul>\n<p>For data storage, we\
          \ have deployed a parallel file system service using Intel\nEnterprise Lustre;\
          \ providing over 300 TB usable storage with room for future\nexpansion.</p>\n\
          <p>The MonARCH service is operated by the Monash HPC team and continuing\
          \ technical\nand operational support from the R@CMon team, this includes\
          \ technical\nstaff from both the Monash eResearch Centre and Monash eSolutions.</p>\n\
          <p>If you have found the MonARCH useful for your research, we will be very\n\
          grateful if you kindly acknowledge us with a text along the lines of:</p>\n\
          <blockquote>\n<p>This research was supported in part by the Monash eResearch\
          \ Centre and\neSolutions-Research Support Services through the use of the\
          \ MonARCH HPC\nCluster.</p>\n</blockquote>\n<h2>How to Access MonARCH</h2>\n\
          <p>To access MonARCH you will need to</p>\n<ul>\n<li>Create a username and\
          \ password for the Monash HPC systems</li>\n<li>Request access to the MonARCH\
          \ resource</li>\n<li>Use SSH or Strudel to access MonARCH</li>\n</ul>\n\
          <h3>Apply for access to Monash HPC systems and MonARCH</h3>\n<ol>\n<li>From\
          \ a web browser, visit <a href=\"https://hpc.erc.monash.edu.au/aafbootstrap\"\
          >The Monash HPC Identity Management System</a>\n</li>\n</ol>\n<p>This web\
          \ page will bootstrap your Monash HPC account using information provided\n\
          by your Institution and the AAF.</p>\n<p>Depending on your settings, usually\
          \ the next step will be to select your\ninstitution, in this example, \"\
          Monash University\".</p>\n<p><img alt=\"Screen shot of the AAF Discovery\
          \ Service\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/aaf_ds.jpg?raw=true\"\
          ></p>\n<p>2: You will be redirected to your institutions secure Identity\
          \ Provider\nservice. You should enter your institutional username and password\
          \ to\nauthenticate to your institution.  In the background, your institution\
          \ will\ntell us information like your Name and email address (but never\
          \ your password).\nDepending on your settings, you may be asked to approve\
          \ your institution\ntelling us this information.</p>\n<p><img alt=\"Screen\
          \ shot of the Monash AAF Identity Provider\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/monash_shib.jpg?raw=true\"\
          ></p>\n<p>3: The next step is Username Selection. You will be presented\
          \ with a list of\navailable usernames, It is important to note that this\
          \ username is not\nnecessarily the same as your institute username. This\
          \ username is for SSH and\nSCP access to the MonARCH login node.</p>\n<p>In\
          \ the example below, the user's University username is \"authcate\" but\
          \ their username\nfor MonARCH is \"demo1\".</p>\n<p><img alt=\"Screen shot\
          \ of HPC Id selecting a username\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/username_selection.jpg?raw=true\"\
          ></p>\n<p>4: Apply to access MonARCH. Select the <strong>\"Use MonARCH\"\
          </strong> option.</p>\n<p>This will send a request to the MonARCH team to\
          \ approve access to the cluster.</p>\n<p><img alt=\"Screen shot of HPC ID\
          \ system showing a pending application\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/application_pending.jpg?raw=true\"\
          ></p>\n<p>The above screen-grab shows that the application is pending for\
          \ approval.</p>\n<p>The application will the go through an approval process.\
          \ First the project\nleader will approve the application, then the administrators\
          \ will approve the\napplication While the approval process is ongoing, if\
          \ you click on the\n<strong>\"Applications\"</strong> button you should\
          \ see something like this:</p>\n<p>![Screen show of HPC ID system in waiting\
          \ for admin state)(images/wait_admin.jpg)</p>\n<p>Once the application has\
          \ been approved, you'll receive an email and be able to\nmove onto the next\
          \ step.</p>\n<p>5: Change your MonARCH cluster password. Note that this\
          \ <em>DOES NOT</em> change your\nInstitutional password. Choose <strong>\"\
          Personal\"</strong> and click <strong>\"Change Password\"</strong>.</p>\n\
          <p>Important: This <em>DOES NOT</em> change or affect your Institutional\
          \ password. This\npassword is for SSH and SCP access to the cluster.</p>\n\
          <p><img alt=\"Screen shot of the HPC Id system showing how to\nchange a\
          \ password\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR%20Documentation--DOCID16/Tools%20and%20Apps--DOCID24/images/set_password.jpg?raw=true\"\
          ></p>\n<h3>Accessing MonARCH</h3>\n<h4>Using SSH</h4>\n<p>You will need\
          \ to use ssh (secure-shell) to login to the head node. This program\nencrypts\
          \ your interactions with the server. How to get and use ssh depends upon\n\
          your desktop operating system.</p>\n<h5>Linux and MacOS</h5>\n<p>Linux and\
          \ MacOS both have SSH built in. Simply open a terminal and type</p>\n<blockquote>\n\
          <p>ssh <em>username</em>@monarch.erc.monash.edu.au</p>\n</blockquote>\n\
          <p>where <em>username</em> is the selected username from Step 3. In the\
          \ above example,\nthe username is \"demo1\", so:</p>\n<blockquote>\n<p>ssh\
          \ demo1@monarch.erc.monash.edu.au</p>\n</blockquote>\n<h5>Microsoft Windows</h5>\n\
          <p>ssh is not native to Windows, but you can download several free versions.\
          \ Many\nMonash PCs have a version of ssh installed already on them.</p>\n\
          <h6>putty</h6>\n<p>You can download putty from <a href=\"http://www.putty.org/\"\
          >the putty website</a> Once\ninstalled you run putty:</p>\n<blockquote>\n\
          <p>Start-&gt;All Programs-&gt;PuTTY-&gt;PuTTY</p>\n</blockquote>\n<p>Select\
          \ \u201CSession:\u201D on the left pane.</p>\n<p>In the text box on the\
          \ right pane labelled <strong>\"Host Name (or IP address)\"</strong>\nenter\
          \ <strong>monarch.erc.monash.edu.au</strong></p>\n<p>Click open. You will\
          \ be prompted for your username and password. These are the\nusername and\
          \ password you set for the Monash HPC ID system, not your\ninstitutional\
          \ username and password.</p>\n<h2>SLURM</h2>\n<h3>Introduction</h3>\n<p>MonARCH\
          \ uses the SLURM scheduler for running jobs.  The home page for SLURM is\
          \ <a href=\"http://slurm.schedmd.com/\">http://slurm.schedmd.com/</a>, and\
          \ it is used in many computing systems, such as MASSIVE and VLSCI.\nSLURM\
          \ is an open-source workload manager designed for Linux clusters of all\
          \ sizes. It provides three key functions.</p>\n<ul>\n<li>It allocates exclusive\
          \ and/or non-exclusive access to resources (computer nodes) to users for\
          \ some duration of time so they can perform work.</li>\n<li>It provides\
          \ a framework for starting, executing, and monitoring work (typically a\
          \ parallel job) on a set of allocated nodes.</li>\n<li>It arbitrates contention\
          \ for resources by managing a queue of pending work.</li>\n</ul>\n<p>The\
          \ following material will explain how users can use SLURM.  At the bottom\
          \ of the page there is a PBS, SGE comparison section.</p>\n<h3>SLURM Glossary</h3>\n\
          <p>It is important to understand that some SLURM syntax have meanings which\
          \ may differ from syntax in other batch or resource schedulers.</p>\n<table>\n\
          <thead>\n<tr>\n<th>Term</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
          <tr>\n<td>Resource</td>\n<td>A mix of CPUs, memory and time</td>\n</tr>\n\
          <tr>\n<td>Task</td>\n<td>A task under SLURM is a synonym for a process,\
          \ and is often the number of MPI processes that are required</td>\n</tr>\n\
          <tr>\n<td>Partition</td>\n<td>SLURM groups nodes into sets called partitions.\
          \ Jobs are submitted to a partition to run. In other batch systems the term\
          \ queue is used</td>\n</tr>\n<tr>\n<td>Account</td>\n<td>The term account\
          \ is used to describe the entity to which used resources are charged to</td>\n\
          </tr>\n<tr>\n<td>Batch jobs</td>\n<td>A chain of commands in a script file</td>\n\
          </tr>\n<tr>\n<td>Success</td>\n<td>A job completes and terminates well (with\
          \ exit status 0) (cancelled jobs are not considered successful)</td>\n</tr>\n\
          <tr>\n<td>Failure</td>\n<td>Anything that lacks success</td>\n</tr>\n<tr>\n\
          <td>CPUs</td>\n<td>The term CPU is used to describe the smallest physical\
          \ consumable, and for multi-core machines this will be the core. For multi-core\
          \ machines where hyper-threading is enabled this will be a hardware thread.</td>\n\
          </tr>\n<tr>\n<td>Node</td>\n<td>A node contains one or more sockets</td>\n\
          </tr>\n<tr>\n<td>Socket</td>\n<td>A socket contains one processor</td>\n\
          </tr>\n<tr>\n<td>Processor</td>\n<td>A processor contains one or more cores</td>\n\
          </tr>\n<tr>\n<td>Core</td>\n<td>A CPU core</td>\n</tr>\n</tbody>\n</table>\n\
          <h3>SLURM Shell Commands</h3>\n<p>Users submit jobs to the MonARCH using\
          \ SLURM commands called from the Unix shell (such as bash, or csh). Typically\
          \ a user creates a batch submission script that specifies what computing\
          \ resources they want from the cluster, as well as the commands to execute\
          \ when the job is running.  They then use sbatch <em>filename</em> to submit\
          \ the job.  Users can kill, pause and interrogate the jobs they are running.\
          \  Here is a list of common commands:</p>\n<h4>Commands to submit/delete\
          \ a job in the queue</h4>\n<table>\n<thead>\n<tr>\n<th>Command</th>\n<th>Description</th>\n\
          </tr>\n</thead>\n<tbody>\n<tr>\n<td>sbatch</td>\n<td>sbatch is used to submit\
          \ a job script for later execution. The script will typically contain one\
          \ or more srun commands to launch parallel tasks.</td>\n</tr>\n<tr>\n<td>scancel</td>\n\
          <td>Deletes a job from the queue, or stops it running.</td>\n</tr>\n</tbody>\n\
          </table>\n<h4>Commands to run an executable</h4>\n<table>\n<thead>\n<tr>\n\
          <th>Command</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n\
          <td>srun</td>\n<td>srun should be used to execute each program in your job\
          \ script. It supersedes mpirun and is capable of starting highly parallel\
          \ jobs much faster than mpirun</td>\n</tr>\n</tbody>\n</table>\n<h4>Examining\
          \ and Controlling the queue</h4>\n<table>\n<thead>\n<tr>\n<th>Command</th>\n\
          <th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>sinfo</td>\n<td>reports\
          \ the state of partitions and nodes managed by Slurm. It has a wide variety\
          \ of filtering, sorting, and formatting options.</td>\n</tr>\n<tr>\n<td>squeue</td>\n\
          <td>reports the state of jobs or job steps. It has a wide variety of filtering,\
          \ sorting, and formatting options. By default, it reports the running jobs\
          \ in priority order and then the pending jobs in priority order.</td>\n\
          </tr>\n<tr>\n<td>scontrol</td>\n<td>Report  or modify details of a job</td>\n\
          </tr>\n<tr>\n<td>sinteractive</td>\n<td>It is possible to run a job as an\
          \ interactive session using ' sinteractive '. The program hangs until the\
          \ session is scheduled to run, and then the user is logged into the compute\
          \ node. Exiting the shell (or logging out) ends the session and the user\
          \ is returned to the original node.</td>\n</tr>\n</tbody>\n</table>\n<h4>Viewing\
          \ job metrics</h4>\n<table>\n<thead>\n<tr>\n<th>Command</th>\n<th>Description</th>\n\
          </tr>\n</thead>\n<tbody>\n<tr>\n<td>sacct</td>\n<td>The command sacct shows\
          \ metrics from past jobs.</td>\n</tr>\n<tr>\n<td>sstat</td>\n<td>The command\
          \ sstat shows metrics from currently running jobs when given a job number.\
          \ Note, you need to launch jobs with srun to get this information.</td>\n\
          </tr>\n</tbody>\n</table>\n<h3>More on Shell Commands</h3>\n<p>Users have\
          \ several ways of getting information on shell commands.</p>\n<ul>\n<li>The\
          \ commands have man pages (via the unix manual). e.g. man sbatch</li>\n\
          <li>The commands have built-in help options, e.g. sbatch --help or sbatch\
          \ --usage.</li>\n<li>help print brief description</li>\n<li>usage  prints\
          \ list of options</li>\n<li>There are online manuals and information pages</li>\n\
          </ul>\n<p>Most commands have options in two formats:</p>\n<ul>\n<li>single\
          \ letter e.g. -N 1</li>\n<li>verbose  e.g. --nodes=1</li>\n</ul>\n<p>Note\
          \ the double dash -- in the verbose format. A non-\xAD\u2010zero exit code\
          \ indicates failure in a command.</p>\n<h4>Some default behaviours</h4>\n\
          <ul>\n<li>SLURM processes launched with srun are not run under a shell,\
          \ so none of the following are executed:</li>\n<li>~/.profile</li>\n<li>~/.baschrc</li>\n\
          <li>~/.login</li>\n<li>~/.cshrc, etc</li>\n<li>SLURM exports user environment\
          \ by default (or --export=NONE)</li>\n<li>SLURM runs in the current directory\
          \ (no need to cd $PBS_O_WORKDIR)</li>\n<li>SLURM combines stdout and stderr\
          \ and outputs directly (and naming is different). The SLURM stdout /stderr\
          \ file will be appended,not overwritten (if it exists)</li>\n<li>SLURM is\
          \ case insensitive (e.g. project names are lower case)</li>\n<li>Use #SBATCH\
          \ instead of #PBS in batch scripts</li>\n</ul>\n<h3>Batch Scripts</h3>\n\
          <p>A job script has a header section which specifies the resources that\
          \ are\nrequired to run the job as well as the commands that must be executed.\
          \ An\nexample script is shown below.</p>\n<p>```bash</p>\n<h1>!/bin/bash</h1>\n\
          <h1>SBATCH --job-name=example</h1>\n<h1>SBATCH --account=director100</h1>\n\
          <h1>SBATCH --partition=workq</h1>\n<h1>SBATCH --time=01:00:00</h1>\n<h1>SBATCH\
          \ --ntasks=32</h1>\n<h1>SBATCH --ntasks-per-node=16</h1>\n<h1>SBATCH --cpus-per-task=1</h1>\n\
          <h1>SBATCH --export=NONE</h1>\n<p>module load intel\nuname -a\nsrun uname\
          \ -a\n```</p>\n<p>Here are some of the SLURM directives you can use in a\
          \ batch script.</p>\n<table>\n<thead>\n<tr>\n<th>SLURM directive</th>\n\
          <th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>--job-name=[job\
          \ name]</td>\n<td>The job name for the allocation, defaults to the script\
          \ name.</td>\n</tr>\n<tr>\n<td>--account=[account name]</td>\n<td>Charge\
          \ resources used to this account. A default account is configured for each\
          \ user.</td>\n</tr>\n<tr>\n<td>--partition=[partition name]</td>\n<td>Request\
          \ an allocation on the specified partition. If not specified jobs will be\
          \ submitted to the default partition.</td>\n</tr>\n<tr>\n<td>--time=[time\
          \ spec]</td>\n<td>The total walltime for the job allocation.</td>\n</tr>\n\
          <tr>\n<td>--array=[job spec]</td>\n<td>Submit a job array with the defined\
          \ indices.</td>\n</tr>\n<tr>\n<td>--dependency=[dependency list]</td>\n\
          <td>Specify a job dependency.</td>\n</tr>\n<tr>\n<td>--nodes=[total nodes]</td>\n\
          <td>Specify the total number of nodes.</td>\n</tr>\n<tr>\n<td>--ntasks=[total\
          \ tasks]</td>\n<td>Specify the total number of tasks.</td>\n</tr>\n<tr>\n\
          <td>--ntasks-per-node=[ntasks]</td>\n<td>Specify the number of tasks per\
          \ node.</td>\n</tr>\n<tr>\n<td>--cpus-per-task=[ncpus]</td>\n<td>Specify\
          \ the number of CPUs per task.</td>\n</tr>\n<tr>\n<td>--ntasks-per-core=[ntasks]</td>\n\
          <td>Specify the number of tasks per CPU core.</td>\n</tr>\n<tr>\n<td>--export=[variable\\\
          </td>\n<td>ALL\\</td>\n</tr>\n</tbody>\n</table>\n<p>NOTE: SLURM will copy\
          \ the entire environment from the shell where a job is\nsubmitted from.\
          \ This may break existing batch scripts that require a different\nenvironment\
          \ than say a login environment. To guard against this --export=NONE\ncan\
          \ be specified for each batch script.</p>\n<h2>MonARCH Hardware Summary</h2>\n\
          <p>There are two classes of compute nodes on MonARCH. They are broken into\
          \ \"High\nSpeed\" and \"High Core Count\" flavours.</p>\n<ul>\n<li>\n<p>config\
          \ A: high-ish CPU clock speed, lower-core count, standard RAM</p>\n</li>\n\
          <li>\n<p>16 physical cores or 32 HT cores ==&gt; two Intel Xeon E5-2667\
          \ v3 3.2GHz, 20M\n    Cache, 9.60GT/s QPI, Turbo, HT, 8C/16T (135W)</p>\n\
          </li>\n<li>128 GB RAM == 8 x 16GB RDIMM, 2133 MT/s, Dual Rank, x4 Data Width</li>\n\
          <li>config B: lower CPU clock speed, high-core count, higher RAM</li>\n\
          <li>24 physical cores or 48 HT cores ==&gt; two Intel Xeon E5-2680 v3 2.5GHz,\
          \ 30M\n    Cache, 9.60GT/s QPI, Turbo, HT, 12C/24T (120W)</li>\n<li>256\
          \ GB RAM == 16 x 16GB RDIMM, 2133 MT/s, Dual Rank, x4 Data Width</li>\n\
          </ul>\n<p>MonARCH supports a wide range of software  packages. The Linux\
          \ environment module utility is used to load and unload different software\
          \ packages. When a module is loaded, it sets specific environment variables\
          \ (e.g., PATH, LD_LIBRARY_PATH, etc.) to the appropriate pathnames where\
          \ the software is installed.</p>\n<h2>Environment Modules</h2>\n<p>There\
          \ may be occasions where you need to use different compilers and/or libraries\
          \ from those found in your usual environment, and you therefore need to\
          \ adjust your environment variables accordingly. The module command makes\
          \ this easy. Some examples of its use are:</p>\n<table>\n<thead>\n<tr>\n\
          <th>module avail</th>\n<th>Shows what modules are available on the system</th>\n\
          </tr>\n</thead>\n<tbody>\n<tr>\n<td>module whatis</td>\n<td>Shows what they\
          \ do</td>\n</tr>\n<tr>\n<td>module load openmpi-intel</td>\n<td>Makes Intel\
          \ MPI libraries and Intel Fortran compiler available</td>\n</tr>\n<tr>\n\
          <td>module list</td>\n<td>Shows which module are loaded</td>\n</tr>\n<tr>\n\
          <td>module purge</td>\n<td>Unloads all of them</td>\n</tr>\n<tr>\n<td>module\
          \ unload openmpi-intel intel</td>\n<td>Unloads Intel MPI and Intel Fortran\
          \ modules</td>\n</tr>\n<tr>\n<td>module display [modulefile]Software</td>\n\
          <td>Use this command to see exactly what a given modulefile will do to your\
          \ environment, such as what will be added to the PATH, MANPATH, etc. environment\
          \ variables.</td>\n</tr>\n</tbody>\n</table>\n<p>Here is an example of how\
          \ to load the GNU C/C++ compiler.</p>\n<p>```bash</p>\n<p>$module load gcc/4.3.5\n\
          ```</p>\n<p>That's all! Now here we put some extra Linux commands to show\
          \ that, by loading\nthe module, we override the default System compiler.</p>\n\
          <p>Load the gcc compiler, showing paths and versions:</p>\n<p>```bash</p>\n\
          <h1></h1>\n<h1>show that we have the default compiler</h1>\n<h1></h1>\n\
          <p>$which gcc\n/usr/bin/gcc\n$gcc -v\nUsing built-in specs.\nTarget: x86_64-redhat-linux\n\
          Configured with: ../configure --prefix=/usr --mandir=/usr/share/man\n--infodir=/usr/share/info\n\
          --enable-shared --enable-threads=posix --enable-checking=release\n--with-system-zlib\
          \ --enable-__cxa_atexit\n--disable-libunwind-exceptions --enable-libgcj-multifile\n\
          --enable-languages=c,c++,objc,obj-c++,java,fortran,ada\n--enable-java-awt=gtk\
          \ --disable-dssi --enable-plugin\n--with-java-home=/usr/lib/jvm/java-1.4.2-gcj-1.4.2.0/jre\n\
          --with-cpu=generic --host=x86_64-redhat-linux\nThread model: posix\ngcc\
          \ version 4.1.2 20080704 (Red Hat 4.1.2-46)</p>\n<h1></h1>\n<h1>load a different\
          \ compiler</h1>\n<h1></h1>\n<p>$module load gcc/4.3.5</p>\n<h1></h1>\n<h1>check\
          \ that we have a new version</h1>\n<h1></h1>\n<p>$which gcc\n/opt/sw/gcc-4.3.5/bin/gcc\n\
          $gcc -v\nUsing built-in specs.\nTarget: x86_64-unknown-linux-gnu\nConfigured\
          \ with: ../gcc-4.3.5/configure --prefix=/opt/sw/gcc-4.3.5\nThread model:\
          \ posix\ngcc version 4.3.5 (GCC)\n```</p>\n<p>Suppose we wanted to know\
          \ more about a module we wanted to load? That can be done via the 'show'\
          \ command 'module show' example</p>\n<p>```bash\nmodule show gcc/4.3.5</p>\n\
          <hr>\n<p>/opt/sw/Modules/modulefiles/gcc/4.3.5:\nmodule-whatis    GNU Compiler\
          \ Collection is ...\nconflict     gcc/4.8.0\nconflict     gcc/4.4.4\nconflict\
          \     gcc/4.5.3\nconflict     intel/10.0.025\nconflict     intelC/10.0.025\n\
          prepend-path PATH /opt/sw/gcc-4.3.5/bin:/opt/sw/gcc-4.3.5/libexec/gcc/x86_64-unknown-linux-gnu/4.3.5\n\
          prepend-path     LD_LIBRARY_PATH /opt/sw/gcc-4.3.5/lib64:/opt/sw/gcc-4.3.5/lib\n\
          prepend-path     MANPATH /opt/sw/gcc-4.3.5/man</p>\n<hr>\n<p>```</p>\n<p>Suppose\
          \ we wanted to use the system compiler again. All you do is unload the module.\n\
          Unload the gcc compiler</p>\n<p>```bash\nmodule unload gcc/4.3.5</p>\n<p>```</p>\n\
          <p>Here we unload the compiler, checking that we have the right versions\
          \ when finished.</p>\n<p>Check that we load the correct compiler:</p>\n\
          <p>```bash</p>\n<h1></h1>\n<h1>unload compiler</h1>\n<h1></h1>\n<p>$ module\
          \ unload gcc/4.3.5</p>\n<h1></h1>\n<h1>show that we have the default compiler</h1>\n\
          <h1></h1>\n<p>$which gcc\n/usr/bin/gcc\n$gcc -v\nUsing built-in specs.\n\
          Target: x86_64-redhat-linux\nConfigured with: ../configure --prefix=/usr\
          \ --mandir=/usr/share/man --infodir=/usr/share/info --enable-shared --enable-threads=posix\
          \ --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions\
          \ --enable-libgcj-multifile --enable-languages=c,c++,objc,obj-c++,java,fortran,ada\
          \ --enable-java-awt=gtk --disable-dssi --enable-plugin --with-java-home=/usr/lib/jvm/java-1.4.2-gcj-1.4.2.0/jre\
          \ --with-cpu=generic --host=x86_64-redhat-linux\nThread model: posix\ngcc\
          \ version 4.1.2 20080704 (Red Hat 4.1.2-46)\n```</p>\n<p>An advantage of\
          \ using the module command is that it warns you about conflicting packages.\
          \  You can't load two different gcc compilers at the same time!</p>\n<p><code>bash\n\
          $ module load gcc/4.3.5\n$ module load gcc/4.2.3\ngcc/4.2.3(15):ERROR:150:\
          \    Module 'gcc/4.2.3' conflicts with the currently loaded module(s) 'gcc/4.3.5'\n\
          gcc/4.2.3(15):ERROR:102:    Tcl command execution failed: conflict gcc/4.3.5</code></p>\n\
          <p>Note. Some modules load other modules! Also, if the software is licensed,\n\
          loading a module does not mean you will be allowed access to it.  Please\
          \  email\nmcc-help@monash.edu to gain access to proprietary software. Here,\
          \ loading the\nvasp module will not allow you access to it.</p>\n<p>Example\
          \ of 'module list':</p>\n<p><code>bash\nmodule list\nCurrently Loaded Modulefiles:\n\
          \  1) gcc/4.3.5               3) mpfr/2.4.2              5) openmpi/1.6-gcc-4.5.3\
          \   7) vasp/5.3.2-2D\n  2) gmp/4.3.2               4) mpc/0.9          \
          \       6) fftw/3.2.2-openmp</code></p>\n<p>If you do not explicitly give\
          \ a version number, module will use the default module.</p>\n<p>Example\
          \ of 'module display'</p>\n<p>```bash\nmodule display gcc</p>\n<hr>\n<p>/opt/sw/Modules/modulefiles/gcc/4.4.4:</p>\n\
          <pre><code>            module-whatis     GNU Compiler Collection is ...\n\
          \            module         load gmp mpfr\n            conflict     gcc/4.8.0\n\
          \            conflict     gcc/4.3.5\n            conflict     gcc/4.5.3\n\
          \            conflict     intel/10.0.025\n            conflict     intelC/10.0.025\n\
          \            prepend-path    PATH/opt/sw/gcc-4.4.4/bin:/opt/sw/gcc-4.4.4/libexec/gcc/x86_64-unknown-linux-gnu/4.4.4\n\
          \            prepend-path    LD_LIBRARY_PATH /opt/sw/gcc-4.4.4//lib64\n\
          \            prepend-path    MANPATH /opt/sw/gcc-4.4.4//man\n          \
          \  -------------------------------------------------------------------\n\
          </code></pre>\n<p>```</p>\n<p>This is the output of 'module avail'.  You\
          \ can interrogate any module with the commands listed above.\nOutput of\
          \ 'module avail'</p>\n<p>```bash\nmodule avail\n------------------------------\
          \ /usr/share/Modules/modulefiles -------------------------------\ndot  \
          \                  matlab-compiler/R2011a module-info            null\n\
          matlab/R2011a-local    module-cvs             modules                use.own</p>\n\
          <p>------------------------------ /opt/sw/Modules/modulefiles ----------------------------------\n\
          FEniCS/1.0                         fluent/proto                       libctl/3.0.3(default)\n\
          Mesa/7.0.1(default)                freeglut/2.6.0                     libctl/3.1\n\
          Mesa/7.0.2                         freeimage/3.13.1                   libctl/3.2.1\n\
          Mesa/7.2                           freesurfer/5.0.0                   libxc/2.0.2\n\
          OpenBUGS/3.1.1                     fsc/1.1.2                          libxml2/2.7.2\n\
          OpenCV/2.2.0                       fsl/4.0.2                          macmolplt/7.4.2\n\
          Qt/3.3.8b                          fsl/4.1.0-test                     mallet/2.0.7\n\
          Qt/4.2.3                           fsl/4.1.5                          ...\n\
          ...\n```</p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 0
        id: 6000115468
        modified_at: '2016-03-02T20:58:18-05:00'
        modified_by: null
        position: 23
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Monash MonARCH User Documentation
        updated_at: '2016-03-02T20:58:18-05:00'
        user_id: 6002464727
  html: "<h1>Introduction to MonARCH</h1>\n<p><img alt=\"MonARCH Compute Nodes\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/MonARCH.png?raw=true\"\
    ></p>\n<p>MonARCH (Monash Advanced Research\nComputing Hybrid) is the next-generation\
    \ HPC/HTC Cluster, designed from the\nground up to address the emergent and future\
    \ needs of the research communities\nsupported by Monash.</p>\n<p>A key feature\
    \ of MonARCH is that it is provisioned through R@CMon, the Research\nCloud @ Monash\
    \ facility. Through the use of advanced cloud technology, MonARCH\nis able to\
    \ configure and grow dynamically. As with any HPC cluster, MonARCH\npresents a\
    \ single point-of-access to computational researchers to run\ncalculations on\
    \ its constituent servers.</p>\n<p>MonARCH aims to continually develop over time.\
    \ Currently, it consists of 35\nservers under two complementary hardware specifications:</p>\n\
    <ul>\n<li>high-core servers - two Haswell CPU sockets with a total of 24 physical\
    \ cores\n  (or 48 hyperthreaded cores) at 2.80 GHz</li>\n<li>high-speed servers\
    \ - two Haswell CPU sockets with a total of 16 physical\n  cores (or 32 hyperthreaded\
    \ cores) at 3.20 GHz</li>\n</ul>\n<p>For data storage, we have deployed a parallel\
    \ file system service using Intel\nEnterprise Lustre; providing over 300 TB usable\
    \ storage with room for future\nexpansion.</p>\n<p>The MonARCH service is operated\
    \ by the Monash HPC team and continuing technical\nand operational support from\
    \ the R@CMon team, this includes technical\nstaff from both the Monash eResearch\
    \ Centre and Monash eSolutions.</p>\n<p>If you have found the MonARCH useful for\
    \ your research, we will be very\ngrateful if you kindly acknowledge us with a\
    \ text along the lines of:</p>\n<blockquote>\n<p>This research was supported in\
    \ part by the Monash eResearch Centre and\neSolutions-Research Support Services\
    \ through the use of the MonARCH HPC\nCluster.</p>\n</blockquote>\n<h2>How to\
    \ Access MonARCH</h2>\n<p>To access MonARCH you will need to</p>\n<ul>\n<li>Create\
    \ a username and password for the Monash HPC systems</li>\n<li>Request access\
    \ to the MonARCH resource</li>\n<li>Use SSH or Strudel to access MonARCH</li>\n\
    </ul>\n<h3>Apply for access to Monash HPC systems and MonARCH</h3>\n<ol>\n<li>From\
    \ a web browser, visit <a href=\"https://hpc.erc.monash.edu.au/aafbootstrap\"\
    >The Monash HPC Identity Management System</a></li>\n</ol>\n<p>This web page will\
    \ bootstrap your Monash HPC account using information provided\nby your Institution\
    \ and the AAF.</p>\n<p>Depending on your settings, usually the next step will\
    \ be to select your\ninstitution, in this example, \"Monash University\".</p>\n\
    <p><img alt=\"Screen shot of the AAF Discovery Service\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/aaf_ds.jpg?raw=true\"\
    ></p>\n<p>2: You will be redirected to your institutions secure Identity Provider\n\
    service. You should enter your institutional username and password to\nauthenticate\
    \ to your institution.  In the background, your institution will\ntell us information\
    \ like your Name and email address (but never your password).\nDepending on your\
    \ settings, you may be asked to approve your institution\ntelling us this information.</p>\n\
    <p><img alt=\"Screen shot of the Monash AAF Identity Provider\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/monash_shib.jpg?raw=true\"\
    ></p>\n<p>3: The next step is Username Selection. You will be presented with a\
    \ list of\navailable usernames, It is important to note that this username is\
    \ not\nnecessarily the same as your institute username. This username is for SSH\
    \ and\nSCP access to the MonARCH login node.</p>\n<p>In the example below, the\
    \ user's University username is \"authcate\" but their username\nfor MonARCH is\
    \ \"demo1\".</p>\n<p><img alt=\"Screen shot of HPC Id selecting a username\" src=\"\
    https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/username_selection.jpg?raw=true\"\
    ></p>\n<p>4: Apply to access MonARCH. Select the <strong>\"Use MonARCH\"</strong>\
    \ option.</p>\n<p>This will send a request to the MonARCH team to approve access\
    \ to the cluster.</p>\n<p><img alt=\"Screen shot of HPC ID system showing a pending\
    \ application\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/application_pending.jpg?raw=true\"\
    ></p>\n<p>The above screen-grab shows that the application is pending for approval.</p>\n\
    <p>The application will the go through an approval process. First the project\n\
    leader will approve the application, then the administrators will approve the\n\
    application While the approval process is ongoing, if you click on the\n<strong>\"\
    Applications\"</strong> button you should see something like this:</p>\n<p>![Screen\
    \ show of HPC ID system in waiting for admin state)(images/wait_admin.jpg)</p>\n\
    <p>Once the application has been approved, you'll receive an email and be able\
    \ to\nmove onto the next step.</p>\n<p>5: Change your MonARCH cluster password.\
    \ Note that this <em>DOES NOT</em> change your\nInstitutional password. Choose\
    \ <strong>\"Personal\"</strong> and click <strong>\"Change Password\"</strong>.</p>\n\
    <p>Important: This <em>DOES NOT</em> change or affect your Institutional password.\
    \ This\npassword is for SSH and SCP access to the cluster.</p>\n<p><img alt=\"\
    Screen shot of the HPC Id system showing how to\nchange a password\" src=\"https://github.com/NeCTAR-RC/nectarcloud-tier0doco/blob/master/articles/NeCTAR\
    \ Documentation--DOCID16/Tools and Apps--DOCID24/images/set_password.jpg?raw=true\"\
    ></p>\n<h3>Accessing MonARCH</h3>\n<h4>Using SSH</h4>\n<p>You will need to use\
    \ ssh (secure-shell) to login to the head node. This program\nencrypts your interactions\
    \ with the server. How to get and use ssh depends upon\nyour desktop operating\
    \ system.</p>\n<h5>Linux and MacOS</h5>\n<p>Linux and MacOS both have SSH built\
    \ in. Simply open a terminal and type</p>\n<blockquote>\n<p>ssh <em>username</em>@monarch.erc.monash.edu.au</p>\n\
    </blockquote>\n<p>where <em>username</em> is the selected username from Step 3.\
    \ In the above example,\nthe username is \"demo1\", so:</p>\n<blockquote>\n<p>ssh\
    \ demo1@monarch.erc.monash.edu.au</p>\n</blockquote>\n<h5>Microsoft Windows</h5>\n\
    <p>ssh is not native to Windows, but you can download several free versions. Many\n\
    Monash PCs have a version of ssh installed already on them.</p>\n<h6>putty</h6>\n\
    <p>You can download putty from <a href=\"http://www.putty.org/\">the putty website</a>\
    \ Once\ninstalled you run putty:</p>\n<blockquote>\n<p>Start-&gt;All Programs-&gt;PuTTY-&gt;PuTTY</p>\n\
    </blockquote>\n<p>Select \u201CSession:\u201D on the left pane.</p>\n<p>In the\
    \ text box on the right pane labelled <strong>\"Host Name (or IP address)\"</strong>\n\
    enter <strong>monarch.erc.monash.edu.au</strong></p>\n<p>Click open. You will\
    \ be prompted for your username and password. These are the\nusername and password\
    \ you set for the Monash HPC ID system, not your\ninstitutional username and password.</p>\n\
    <h2>SLURM</h2>\n<h3>Introduction</h3>\n<p>MonARCH uses the SLURM scheduler for\
    \ running jobs.  The home page for SLURM is <a href=\"http://slurm.schedmd.com/\"\
    >http://slurm.schedmd.com/</a>, and it is used in many computing systems, such\
    \ as MASSIVE and VLSCI.\nSLURM is an open-source workload manager designed for\
    \ Linux clusters of all sizes. It provides three key functions.</p>\n<ul>\n<li>It\
    \ allocates exclusive and/or non-exclusive access to resources (computer nodes)\
    \ to users for some duration of time so they can perform work.</li>\n<li>It provides\
    \ a framework for starting, executing, and monitoring work (typically a parallel\
    \ job) on a set of allocated nodes.</li>\n<li>It arbitrates contention for resources\
    \ by managing a queue of pending work.</li>\n</ul>\n<p>The following material\
    \ will explain how users can use SLURM.  At the bottom of the page there is a\
    \ PBS, SGE comparison section.</p>\n<h3>SLURM Glossary</h3>\n<p>It is important\
    \ to understand that some SLURM syntax have meanings which may differ from syntax\
    \ in other batch or resource schedulers.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n\
    <th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Resource</td>\n<td>A\
    \ mix of CPUs, memory and time</td>\n</tr>\n<tr>\n<td>Task</td>\n<td>A task under\
    \ SLURM is a synonym for a process, and is often the number of MPI processes that\
    \ are required</td>\n</tr>\n<tr>\n<td>Partition</td>\n<td>SLURM groups nodes into\
    \ sets called partitions. Jobs are submitted to a partition to run. In other batch\
    \ systems the term queue is used</td>\n</tr>\n<tr>\n<td>Account</td>\n<td>The\
    \ term account is used to describe the entity to which used resources are charged\
    \ to</td>\n</tr>\n<tr>\n<td>Batch jobs</td>\n<td>A chain of commands in a script\
    \ file</td>\n</tr>\n<tr>\n<td>Success</td>\n<td>A job completes and terminates\
    \ well (with exit status 0) (cancelled jobs are not considered successful)</td>\n\
    </tr>\n<tr>\n<td>Failure</td>\n<td>Anything that lacks success</td>\n</tr>\n<tr>\n\
    <td>CPUs</td>\n<td>The term CPU is used to describe the smallest physical consumable,\
    \ and for multi-core machines this will be the core. For multi-core machines where\
    \ hyper-threading is enabled this will be a hardware thread.</td>\n</tr>\n<tr>\n\
    <td>Node</td>\n<td>A node contains one or more sockets</td>\n</tr>\n<tr>\n<td>Socket</td>\n\
    <td>A socket contains one processor</td>\n</tr>\n<tr>\n<td>Processor</td>\n<td>A\
    \ processor contains one or more cores</td>\n</tr>\n<tr>\n<td>Core</td>\n<td>A\
    \ CPU core</td>\n</tr>\n</tbody>\n</table>\n<h3>SLURM Shell Commands</h3>\n<p>Users\
    \ submit jobs to the MonARCH using SLURM commands called from the Unix shell (such\
    \ as bash, or csh). Typically a user creates a batch submission script that specifies\
    \ what computing resources they want from the cluster, as well as the commands\
    \ to execute when the job is running.  They then use sbatch <em>filename</em>\
    \ to submit the job.  Users can kill, pause and interrogate the jobs they are\
    \ running.  Here is a list of common commands:</p>\n<h4>Commands to submit/delete\
    \ a job in the queue</h4>\n<table>\n<thead>\n<tr>\n<th>Command</th>\n<th>Description</th>\n\
    </tr>\n</thead>\n<tbody>\n<tr>\n<td>sbatch</td>\n<td>sbatch is used to submit\
    \ a job script for later execution. The script will typically contain one or more\
    \ srun commands to launch parallel tasks.</td>\n</tr>\n<tr>\n<td>scancel</td>\n\
    <td>Deletes a job from the queue, or stops it running.</td>\n</tr>\n</tbody>\n\
    </table>\n<h4>Commands to run an executable</h4>\n<table>\n<thead>\n<tr>\n<th>Command</th>\n\
    <th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>srun</td>\n<td>srun\
    \ should be used to execute each program in your job script. It supersedes mpirun\
    \ and is capable of starting highly parallel jobs much faster than mpirun</td>\n\
    </tr>\n</tbody>\n</table>\n<h4>Examining and Controlling the queue</h4>\n<table>\n\
    <thead>\n<tr>\n<th>Command</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n\
    <tr>\n<td>sinfo</td>\n<td>reports the state of partitions and nodes managed by\
    \ Slurm. It has a wide variety of filtering, sorting, and formatting options.</td>\n\
    </tr>\n<tr>\n<td>squeue</td>\n<td>reports the state of jobs or job steps. It has\
    \ a wide variety of filtering, sorting, and formatting options. By default, it\
    \ reports the running jobs in priority order and then the pending jobs in priority\
    \ order.</td>\n</tr>\n<tr>\n<td>scontrol</td>\n<td>Report  or modify details of\
    \ a job</td>\n</tr>\n<tr>\n<td>sinteractive</td>\n<td>It is possible to run a\
    \ job as an interactive session using ' sinteractive '. The program hangs until\
    \ the session is scheduled to run, and then the user is logged into the compute\
    \ node. Exiting the shell (or logging out) ends the session and the user is returned\
    \ to the original node.</td>\n</tr>\n</tbody>\n</table>\n<h4>Viewing job metrics</h4>\n\
    <table>\n<thead>\n<tr>\n<th>Command</th>\n<th>Description</th>\n</tr>\n</thead>\n\
    <tbody>\n<tr>\n<td>sacct</td>\n<td>The command sacct shows metrics from past jobs.</td>\n\
    </tr>\n<tr>\n<td>sstat</td>\n<td>The command sstat shows metrics from currently\
    \ running jobs when given a job number. Note, you need to launch jobs with srun\
    \ to get this information.</td>\n</tr>\n</tbody>\n</table>\n<h3>More on Shell\
    \ Commands</h3>\n<p>Users have several ways of getting information on shell commands.</p>\n\
    <ul>\n<li>The commands have man pages (via the unix manual). e.g. man sbatch</li>\n\
    <li>The commands have built-in help options, e.g. sbatch --help or sbatch --usage.</li>\n\
    <li>help print brief description</li>\n<li>usage  prints list of options</li>\n\
    <li>There are online manuals and information pages</li>\n</ul>\n<p>Most commands\
    \ have options in two formats:</p>\n<ul>\n<li>single letter e.g. -N 1</li>\n<li>verbose\
    \  e.g. --nodes=1</li>\n</ul>\n<p>Note the double dash -- in the verbose format.\
    \ A non-\xAD\u2010zero exit code indicates failure in a command.</p>\n<h4>Some\
    \ default behaviours</h4>\n<ul>\n<li>SLURM processes launched with srun are not\
    \ run under a shell, so none of the following are executed:</li>\n<li>~/.profile</li>\n\
    <li>~/.baschrc</li>\n<li>~/.login</li>\n<li>~/.cshrc, etc</li>\n<li>SLURM exports\
    \ user environment by default (or --export=NONE)</li>\n<li>SLURM runs in the current\
    \ directory (no need to cd $PBS_O_WORKDIR)</li>\n<li>SLURM combines stdout and\
    \ stderr and outputs directly (and naming is different). The SLURM stdout /stderr\
    \ file will be appended,not overwritten (if it exists)</li>\n<li>SLURM is case\
    \ insensitive (e.g. project names are lower case)</li>\n<li>Use #SBATCH instead\
    \ of #PBS in batch scripts</li>\n</ul>\n<h3>Batch Scripts</h3>\n<p>A job script\
    \ has a header section which specifies the resources that are\nrequired to run\
    \ the job as well as the commands that must be executed. An\nexample script is\
    \ shown below.</p>\n<p>```bash</p>\n<h1>!/bin/bash</h1>\n<h1>SBATCH --job-name=example</h1>\n\
    <h1>SBATCH --account=director100</h1>\n<h1>SBATCH --partition=workq</h1>\n<h1>SBATCH\
    \ --time=01:00:00</h1>\n<h1>SBATCH --ntasks=32</h1>\n<h1>SBATCH --ntasks-per-node=16</h1>\n\
    <h1>SBATCH --cpus-per-task=1</h1>\n<h1>SBATCH --export=NONE</h1>\n<p>module load\
    \ intel\nuname -a\nsrun uname -a\n```</p>\n<p>Here are some of the SLURM directives\
    \ you can use in a batch script.</p>\n<table>\n<thead>\n<tr>\n<th>SLURM directive</th>\n\
    <th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>--job-name=[job name]</td>\n\
    <td>The job name for the allocation, defaults to the script name.</td>\n</tr>\n\
    <tr>\n<td>--account=[account name]</td>\n<td>Charge resources used to this account.\
    \ A default account is configured for each user.</td>\n</tr>\n<tr>\n<td>--partition=[partition\
    \ name]</td>\n<td>Request an allocation on the specified partition. If not specified\
    \ jobs will be submitted to the default partition.</td>\n</tr>\n<tr>\n<td>--time=[time\
    \ spec]</td>\n<td>The total walltime for the job allocation.</td>\n</tr>\n<tr>\n\
    <td>--array=[job spec]</td>\n<td>Submit a job array with the defined indices.</td>\n\
    </tr>\n<tr>\n<td>--dependency=[dependency list]</td>\n<td>Specify a job dependency.</td>\n\
    </tr>\n<tr>\n<td>--nodes=[total nodes]</td>\n<td>Specify the total number of nodes.</td>\n\
    </tr>\n<tr>\n<td>--ntasks=[total tasks]</td>\n<td>Specify the total number of\
    \ tasks.</td>\n</tr>\n<tr>\n<td>--ntasks-per-node=[ntasks]</td>\n<td>Specify the\
    \ number of tasks per node.</td>\n</tr>\n<tr>\n<td>--cpus-per-task=[ncpus]</td>\n\
    <td>Specify the number of CPUs per task.</td>\n</tr>\n<tr>\n<td>--ntasks-per-core=[ntasks]</td>\n\
    <td>Specify the number of tasks per CPU core.</td>\n</tr>\n<tr>\n<td>--export=[variable\\\
    </td>\n<td>ALL\\</td>\n</tr>\n</tbody>\n</table>\n<p>NOTE: SLURM will copy the\
    \ entire environment from the shell where a job is\nsubmitted from. This may break\
    \ existing batch scripts that require a different\nenvironment than say a login\
    \ environment. To guard against this --export=NONE\ncan be specified for each\
    \ batch script.</p>\n<h2>MonARCH Hardware Summary</h2>\n<p>There are two classes\
    \ of compute nodes on MonARCH. They are broken into \"High\nSpeed\" and \"High\
    \ Core Count\" flavours.</p>\n<ul>\n<li>\n<p>config A: high-ish CPU clock speed,\
    \ lower-core count, standard RAM</p>\n</li>\n<li>\n<p>16 physical cores or 32\
    \ HT cores ==&gt; two Intel Xeon E5-2667 v3 3.2GHz, 20M\n    Cache, 9.60GT/s QPI,\
    \ Turbo, HT, 8C/16T (135W)</p>\n</li>\n<li>128 GB RAM == 8 x 16GB RDIMM, 2133\
    \ MT/s, Dual Rank, x4 Data Width</li>\n<li>config B: lower CPU clock speed, high-core\
    \ count, higher RAM</li>\n<li>24 physical cores or 48 HT cores ==&gt; two Intel\
    \ Xeon E5-2680 v3 2.5GHz, 30M\n    Cache, 9.60GT/s QPI, Turbo, HT, 12C/24T (120W)</li>\n\
    <li>256 GB RAM == 16 x 16GB RDIMM, 2133 MT/s, Dual Rank, x4 Data Width</li>\n\
    </ul>\n<p>MonARCH supports a wide range of software  packages. The Linux environment\
    \ module utility is used to load and unload different software packages. When\
    \ a module is loaded, it sets specific environment variables (e.g., PATH, LD_LIBRARY_PATH,\
    \ etc.) to the appropriate pathnames where the software is installed.</p>\n<h2>Environment\
    \ Modules</h2>\n<p>There may be occasions where you need to use different compilers\
    \ and/or libraries from those found in your usual environment, and you therefore\
    \ need to adjust your environment variables accordingly. The module command makes\
    \ this easy. Some examples of its use are:</p>\n<table>\n<thead>\n<tr>\n<th>module\
    \ avail</th>\n<th>Shows what modules are available on the system</th>\n</tr>\n\
    </thead>\n<tbody>\n<tr>\n<td>module whatis</td>\n<td>Shows what they do</td>\n\
    </tr>\n<tr>\n<td>module load openmpi-intel</td>\n<td>Makes Intel MPI libraries\
    \ and Intel Fortran compiler available</td>\n</tr>\n<tr>\n<td>module list</td>\n\
    <td>Shows which module are loaded</td>\n</tr>\n<tr>\n<td>module purge</td>\n<td>Unloads\
    \ all of them</td>\n</tr>\n<tr>\n<td>module unload openmpi-intel intel</td>\n\
    <td>Unloads Intel MPI and Intel Fortran modules</td>\n</tr>\n<tr>\n<td>module\
    \ display [modulefile]Software</td>\n<td>Use this command to see exactly what\
    \ a given modulefile will do to your environment, such as what will be added to\
    \ the PATH, MANPATH, etc. environment variables.</td>\n</tr>\n</tbody>\n</table>\n\
    <p>Here is an example of how to load the GNU C/C++ compiler.</p>\n<p>```bash</p>\n\
    <p>$module load gcc/4.3.5\n```</p>\n<p>That's all! Now here we put some extra\
    \ Linux commands to show that, by loading\nthe module, we override the default\
    \ System compiler.</p>\n<p>Load the gcc compiler, showing paths and versions:</p>\n\
    <p>```bash</p>\n<h1></h1>\n<h1>show that we have the default compiler</h1>\n<h1></h1>\n\
    <p>$which gcc\n/usr/bin/gcc\n$gcc -v\nUsing built-in specs.\nTarget: x86_64-redhat-linux\n\
    Configured with: ../configure --prefix=/usr --mandir=/usr/share/man\n--infodir=/usr/share/info\n\
    --enable-shared --enable-threads=posix --enable-checking=release\n--with-system-zlib\
    \ --enable-__cxa_atexit\n--disable-libunwind-exceptions --enable-libgcj-multifile\n\
    --enable-languages=c,c++,objc,obj-c++,java,fortran,ada\n--enable-java-awt=gtk\
    \ --disable-dssi --enable-plugin\n--with-java-home=/usr/lib/jvm/java-1.4.2-gcj-1.4.2.0/jre\n\
    --with-cpu=generic --host=x86_64-redhat-linux\nThread model: posix\ngcc version\
    \ 4.1.2 20080704 (Red Hat 4.1.2-46)</p>\n<h1></h1>\n<h1>load a different compiler</h1>\n\
    <h1></h1>\n<p>$module load gcc/4.3.5</p>\n<h1></h1>\n<h1>check that we have a\
    \ new version</h1>\n<h1></h1>\n<p>$which gcc\n/opt/sw/gcc-4.3.5/bin/gcc\n$gcc\
    \ -v\nUsing built-in specs.\nTarget: x86_64-unknown-linux-gnu\nConfigured with:\
    \ ../gcc-4.3.5/configure --prefix=/opt/sw/gcc-4.3.5\nThread model: posix\ngcc\
    \ version 4.3.5 (GCC)\n```</p>\n<p>Suppose we wanted to know more about a module\
    \ we wanted to load? That can be done via the 'show' command 'module show' example</p>\n\
    <p>```bash\nmodule show gcc/4.3.5</p>\n<hr>\n<p>/opt/sw/Modules/modulefiles/gcc/4.3.5:\n\
    module-whatis    GNU Compiler Collection is ...\nconflict     gcc/4.8.0\nconflict\
    \     gcc/4.4.4\nconflict     gcc/4.5.3\nconflict     intel/10.0.025\nconflict\
    \     intelC/10.0.025\nprepend-path PATH /opt/sw/gcc-4.3.5/bin:/opt/sw/gcc-4.3.5/libexec/gcc/x86_64-unknown-linux-gnu/4.3.5\n\
    prepend-path     LD_LIBRARY_PATH /opt/sw/gcc-4.3.5/lib64:/opt/sw/gcc-4.3.5/lib\n\
    prepend-path     MANPATH /opt/sw/gcc-4.3.5/man</p>\n<hr>\n<p>```</p>\n<p>Suppose\
    \ we wanted to use the system compiler again. All you do is unload the module.\n\
    Unload the gcc compiler</p>\n<p>```bash\nmodule unload gcc/4.3.5</p>\n<p>```</p>\n\
    <p>Here we unload the compiler, checking that we have the right versions when\
    \ finished.</p>\n<p>Check that we load the correct compiler:</p>\n<p>```bash</p>\n\
    <h1></h1>\n<h1>unload compiler</h1>\n<h1></h1>\n<p>$ module unload gcc/4.3.5</p>\n\
    <h1></h1>\n<h1>show that we have the default compiler</h1>\n<h1></h1>\n<p>$which\
    \ gcc\n/usr/bin/gcc\n$gcc -v\nUsing built-in specs.\nTarget: x86_64-redhat-linux\n\
    Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info\
    \ --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib\
    \ --enable-__cxa_atexit --disable-libunwind-exceptions --enable-libgcj-multifile\
    \ --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk\
    \ --disable-dssi --enable-plugin --with-java-home=/usr/lib/jvm/java-1.4.2-gcj-1.4.2.0/jre\
    \ --with-cpu=generic --host=x86_64-redhat-linux\nThread model: posix\ngcc version\
    \ 4.1.2 20080704 (Red Hat 4.1.2-46)\n```</p>\n<p>An advantage of using the module\
    \ command is that it warns you about conflicting packages.  You can't load two\
    \ different gcc compilers at the same time!</p>\n<p><code>bash\n$ module load\
    \ gcc/4.3.5\n$ module load gcc/4.2.3\ngcc/4.2.3(15):ERROR:150:    Module 'gcc/4.2.3'\
    \ conflicts with the currently loaded module(s) 'gcc/4.3.5'\ngcc/4.2.3(15):ERROR:102:\
    \    Tcl command execution failed: conflict gcc/4.3.5</code></p>\n<p>Note. Some\
    \ modules load other modules! Also, if the software is licensed,\nloading a module\
    \ does not mean you will be allowed access to it.  Please  email\nmcc-help@monash.edu\
    \ to gain access to proprietary software. Here, loading the\nvasp module will\
    \ not allow you access to it.</p>\n<p>Example of 'module list':</p>\n<p><code>bash\n\
    module list\nCurrently Loaded Modulefiles:\n  1) gcc/4.3.5               3) mpfr/2.4.2\
    \              5) openmpi/1.6-gcc-4.5.3   7) vasp/5.3.2-2D\n  2) gmp/4.3.2   \
    \            4) mpc/0.9                 6) fftw/3.2.2-openmp</code></p>\n<p>If\
    \ you do not explicitly give a version number, module will use the default module.</p>\n\
    <p>Example of 'module display'</p>\n<p>```bash\nmodule display gcc</p>\n<hr>\n\
    <p>/opt/sw/Modules/modulefiles/gcc/4.4.4:</p>\n<pre><code>            module-whatis\
    \     GNU Compiler Collection is ...\n            module         load gmp mpfr\n\
    \            conflict     gcc/4.8.0\n            conflict     gcc/4.3.5\n    \
    \        conflict     gcc/4.5.3\n            conflict     intel/10.0.025\n   \
    \         conflict     intelC/10.0.025\n            prepend-path    PATH/opt/sw/gcc-4.4.4/bin:/opt/sw/gcc-4.4.4/libexec/gcc/x86_64-unknown-linux-gnu/4.4.4\n\
    \            prepend-path    LD_LIBRARY_PATH /opt/sw/gcc-4.4.4//lib64\n      \
    \      prepend-path    MANPATH /opt/sw/gcc-4.4.4//man\n            -------------------------------------------------------------------\n\
    </code></pre>\n<p>```</p>\n<p>This is the output of 'module avail'.  You can interrogate\
    \ any module with the commands listed above.\nOutput of 'module avail'</p>\n<p>```bash\n\
    module avail\n------------------------------ /usr/share/Modules/modulefiles -------------------------------\n\
    dot                    matlab-compiler/R2011a module-info            null\nmatlab/R2011a-local\
    \    module-cvs             modules                use.own</p>\n<p>------------------------------\
    \ /opt/sw/Modules/modulefiles ----------------------------------\nFEniCS/1.0 \
    \                        fluent/proto                       libctl/3.0.3(default)\n\
    Mesa/7.0.1(default)                freeglut/2.6.0                     libctl/3.1\n\
    Mesa/7.0.2                         freeimage/3.13.1                   libctl/3.2.1\n\
    Mesa/7.2                           freesurfer/5.0.0                   libxc/2.0.2\n\
    OpenBUGS/3.1.1                     fsc/1.1.2                          libxml2/2.7.2\n\
    OpenCV/2.2.0                       fsl/4.0.2                          macmolplt/7.4.2\n\
    Qt/3.3.8b                          fsl/4.1.0-test                     mallet/2.0.7\n\
    Qt/4.2.3                           fsl/4.1.5                          ...\n...\n\
    ```</p>"
  parent: 24
  sha1: 1a8335751e3a83a52007e82b2013efed4fb1c2b6
  title: Monash MonARCH User Documentation
117:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2016-03-21T05:10:38-04:00'
        desc_un_html: " VicNode and NeCTAR Cloud Storage - Use Cases, Patterns and\
          \ Tools \n Intro \n VicNode provides Victorian researchers and their collaborators\
          \ with the\nability to easily store and share research data through an affordable,\
          \ secure\nand sustainable service. It provides storage solutions to suit\
          \ a variety of\nresearch data storage needs. This documentation focuses\
          \ particularly on\nVicNode's cloud object storage offerings, however much\
          \ of it is relevant to\nNeCTAR Object Storage. Here you will find demos\
          \ of object storage client\ntools useful for completing common tasks, and\
          \ caveats regarding API usage and\ncompatibility. \n \n Contents \n \n VicNode\
          \ Overview \n VicNode Cloud Storage \n Accessing VicNode Cloud Storage \n\
          \ Common Use-cases and Client Tools \n Using rclone to synchronise folders\
          \ to/from object storage \n Sharing files over the Internet with Swift tempurls\
          \ \n Backing up files to object storage using Duplicity \n \n \n Overview\
          \ \n VicNode and the Research Cloud \n VicNode was established as part of\
          \ RDSI (the\nResearch Data Storage Initiative), a national network of research\
          \ data nodes\nand the sister project of NeCTAR. RDSI's focus is on accessibility,\n\
          dissemination, sharing and long-term curation of research datasets. VicNode's\n\
          storage services are hosted locally in Victoria at the datacentres of the\n\
          University of Melbourne and Monash University and are connected with high\n\
          bandwidth to the VeRNet and AARNet research networks, VicNode storage is\
          \ also\nclosely coupled to the Monash and Melbourne zones of the NeCTAR\
          \ Research Cloud. \n VicNode offers a variety of storage products utilising\
          \ different underlying technologies at each\noperating centre. Two types\
          \ of VicNode storage in particular are directly\nlinked to, and accessible\
          \ through, the Research Cloud: NeCTAR Volume Storage\nand NeCTAR Object\
          \ Storage. Implementation and access details of these are\ndiscussed in\
          \ the next section. \n Contents \n \n \n VicNode Cloud Storage \n Computational\
          \ \n VicNode's current Computational\nstorage product is delivered solely\
          \ as volume storage in the Monash and\nMelbourne zones of the NeCTAR Research\
          \ Cloud. This gives researchers persistent\nblock storage which can be used\
          \ like a virtual portable hard disk and\nhot-plugged (that is, attached\
          \ and detached) whilst a cloud server is active.\nVolumes can also be used\
          \ as bootable drives, thus making the whole cloud server\noperating system\
          \ and configuration persistent. \n Access to the underlying storage is standardised\
          \ through the NeCTAR Research\nCloud and OpenStack, but each operating centre\
          \ uses a different solution. At\nthe University of Melbourne, VicNode Computational\
          \ storage is delivered via\nhigh-availability NetApp servers, whereas at\
          \ Monash University it is built on\ntop of a cluster of commodity storage\
          \ servers all running the Ceph distributed\nstorage system. In both cases\
          \ rudimentary storage availability protection is\nprovided by RAID (in the\
          \ NetApp case) or replication (in the Ceph case), but no\nautomated/implicit\
          \ backups are made - backup of volume storage is the\nresponsibility of\
          \ the end-user and there are a number of options for this\nwithin and outside\
          \ of the Research Cloud. Note that because each operating\ncentre uses different\
          \ storage technologies their performance profiles may vary\nfor different\
          \ workloads. \n Object \n VicNode's other cloud storage offering is what\
          \ could be considered\nas the original and definitive cloud storage, that\
          \ is, object storage. Object\nstorage will be familiar to any regular Internet\
          \ or mobile users, though they\nmay not know it! The defining characteristic\
          \ of object storage is that it is\nbuilt for the Web and uses Web standards\
          \ like HTTP and techniques like REST\n(Representational State Transfer),\
          \ this contributes to making it massively\nscalable and ubiquitously accessible\
          \ online. Object storage is also very good\nat storing large and plentiful\
          \ data, that is, huge objects or many millions of\nobjects. It can do this\
          \ thanks to another of its defining characteristics, it\ndoes not allow\
          \ an arbitrarily hierarchical namespace - users can create\nbuckets/containers\
          \ and inside them place only objects, containers cannot be\nnested. So,\
          \ each container is a flat and unique namespace of objects. Both\nobjects\
          \ and the containers that hold them can also have user-defined metadata\n\
          associated with them in key-value pairs, and there are many special metadata\n\
          keys which enable and/or control some useful functionality of the storage,\n\
          e.g., access-controls. \n Because object storage is accessed as a web service\
          \ it is not a natural primary\nstorage type for end-user computing devices\
          \ (like your laptop). Though it is\ncommonly used by file sync-and-share\
          \ applications (anyone heard of Dropbox?) as\nthe central storage point\
          \ with just a small cache kept on end-user devices. \n Each VicNode operating\
          \ centre uses a different object storage solution, but\naccess to the underlying\
          \ storage is standardised through the NeCTAR Research\nCloud and both solutions\
          \ support the same basic end-user REST API interfaces -\nthe S3 and OpenStack\
          \ Swift APIs. The Monash University operating centre uses\nCeph Object Gateway\
          \ service whilst the University of Melbourne uses\nOpenStack Swift (as does\
          \ the NeCTAR Research Cloud). These are both clustered\nsoftware-defined\
          \ storage systems. The main difference between them (and they\nare quite\
          \ different under the hood) is that, following [CAP therom], Swift\nrelaxes\
          \ Consistency where Ceph relaxes Availability. Neither of these\nchoices\
          \ is black & white and if that means nothing to you then don't worry,\n\
          just know that VicNode's \"Object-Vault\" is the highly redundant OpenStack\
          \ Swift\nservice whilst VicNode's \"Object-Market\" uses faster disk and\
          \ will have a\ndisaster recovery solution utilising a tape backup (though\
          \ this is not yet\nimplemented). \n Contents \n \n \n Accessing VicNode\
          \ Cloud Storage \n To use VicNode's cloud volume and/or object storage you\
          \ must first have a\nVicNode allocation - apply to VicNode directly, or\
          \ if you are a University of\nMelbourne or Monash user you can contact your\
          \ local eResearch Support. \n Your VicNode storage quota will be associated\
          \ with a NeCTAR Research Cloud\nproject, so you will need to get an account\
          \ on the Research Cloud. If you\nare already a Research Cloud user then\
          \ you may have an existing project you\nare planning to use your VicNode\
          \ storage in, otherwise you will want to\napply for a project - if you are\
          \ applying for a new project and already\nhave a VicNode allocation you'd\
          \ like to use then mention this in the\nallocation request. \n Once you\
          \ have your VicNode cloud storage quota associated with a NeCTAR\nResearch\
          \ Cloud user and project you are ready to go! For the tools and\nexamples\
          \ in the subsequent sections you will also require your Research Cloud\n\
          API credentials. \n A note about Regions and endpoints \n In the context\
          \ of VicNode and NeCTAR there are at least three separate Object\nStorage\
          \ services. These are all integrated with the Research Cloud but some\n\
          are only accessible to VicNode users: \n \n NeCTAR Swift - This is a nationally\
          \ distributed Swift cluster with storage\n   nodes at seven Research Cloud\
          \ sites around Australia. Some sites also have\n   local Swift Proxies (the\
          \ user-facing API servers) which can be explicitly\n   used by configuring\
          \ your client tool/s to point to the correct storage URL\n   or Region.\
          \ The default storage policy for this cluster creates 3-copies of\n   all\
          \ objects. This cluster also provides storage for many other services on\n\
          \   the Research Cloud, e.g., the Glance Image Catalog where VM images and\n\
          \   snapshots are stored. All NeCTAR users are able to access and use NeCTAR\n\
          \   Swift. There is no need to specify any special storage URL or Region\
          \ for\n   this cluster as it is the default NeCTAR object storage service.\
          \ \n \n VicNode Swift Object Vault - See above for details. To use VicNode\
          \ Swift\n   you must tell you client tool/s to select either the \"VicNode\"\
          \ Region or\n   configure a storage URL of\n   \"https://vault.melbourne.vicnode.org.au:8888/v1//\"\
          \ \n \n \n VicNode Ceph Object Market - See above for details. Due to technical\n\
          \   limitations with NeCTAR Keystone, the VicNode Ceph Object store is not\n\
          \   currently listed in the Keystone service catalog and therefore cannot\
          \ be\n   referred to via Region. Instead, configure your client tool/s to\
          \ use a\n   storage URL of \"https://au-east.erc.monash.edu.au/swift/v1\"\
          . \n \n \n Example Swift python-swiftclient accessing VicNode Ceph Object:\
          \ \n swift --os-storage-url https://au-east.erc.monash.edu.au/swift/v1 stat\n\
          \ \n Example Swift python-swiftclient accessing VicNode Vault Object: \n\
          \ swift --os-region-name VicNode stat\nswift --os-storage-url https://vault.melbourne.vicnode.org.au:8888/v1/AUTH_d57de879288840e199bb1a48ae0c2c79\
          \ stat\n \n Example Swift python-openstackclient accessing VicNode Vault\
          \ Object: \n openstack --os-region-name VicNode object store account show\n\
          \ \n NB: currently python-openstackclient does not support specifying a\
          \ different\nSwift API endpoint other than by region name. \n Contents \n\
          \ \n \n Object Storage Use-cases and Client Tools \n This section includes\
          \ pointers and quickstart instructions for using various\nuseful object\
          \ storage client tools. These tools have been tested to work with\nVicNode\
          \ cloud storage. \n \n \n rclone \n rclone is described as \"rsync for cloud\
          \ storage\" (rysnc being a popular and\nwidely distributed tool for file\
          \ data-transfer and synchronisation).\nOf particular note is that rclone\
          \ supports a wide variety of cloud storage\ntypes (both as source and destination,\
          \ with local file-system too) and is\ncapable of delta synchronisation,\
          \ i.e., it is not necessary to transfer a\nfull copy of the dataset if part\
          \ of it has already been copied or only some\ndata on the source has changed,\
          \ which makes it suitable for working with\nlarge datasets. \n Install rclone\
          \ \n From http://rclone.org/, download and install the command line tool\n\
          for your system.  Go to http://rclone.org/downloads/ and choose: \n On Windows:\
          \ \n \n Download http://downloads.rclone.org/rclone-v1.25-windows-amd64.zip\
          \ \n Extract rclone.exe from the zip file and save it (e.g., as C:\\users\\\
          fred\\rclone.exe) \n All configuration and examples in the Linux section\
          \ are as below, run from within a cmd.exe shell \n \n On Macintosh: \n Not\
          \ yet tested (will be similar to below details for Linux but different\n\
          installation). \n On Linux: \n First download http://downloads.rclone.org/rclone-v1.25-linux-amd64.zip\
          \ \n Setup and use rclone \n From within a terminal session \n ubuntu@linux:~$\
          \ cd ~/Downloads\n \n unzip the downloaded archive \n ubuntu@linux:~/Downloads$\
          \ unzip rclone-v1.25-linux-amd64.zip\nArchive:  rclone-v1.25-linux-amd64.zip\n\
          \  creating: rclone-v1.25-linux-amd64/\n  inflating: rclone-v1.25-linux-amd64/README.txt\n\
          \  inflating: rclone-v1.25-linux-amd64/rclone\n  inflating: rclone-v1.25-linux-amd64/README.html\n\
          \  inflating: rclone-v1.25-linux-amd64/rclone.1\nubuntu@linux:~/Downloads$\
          \ cd rclone-v1.25-linux-amd64\n \n Copy the rclone program into the system\
          \ path \n ubuntu@linux:~/Downloads/rclone-v1.25-linux-amd64$ sudo cp rclone\
          \ /usr/local/bin\n[sudo] password for ubuntu:\n \n Also copy the manual\
          \ page so we can RTFM \n ubuntu@linux:~/Downloads/rclone-v1.25-linux-amd64$\
          \ sudo cp rclone.1 /usr/local/man/man1\n \n Test that rclone runs \n (You\
          \ can ignore the message that you haven't yet configured it) \n ubuntu@linux:~/Downloads/rclone-v1.25-linux-amd64$\
          \ rclone --version\n2015/11/26 20:57:41 Failed to load config file /home/ubuntu/.rclone.conf\
          \ - using defaults: open /home/ubuntu/.rclone.conf: no such file or directory\n\
          rclone v1.25\n \n Configure rclone to access your project's object storage\
          \ \n NB: here you will require the API credentials for your NeCTAR Research\
          \ Cloud\nuser and project, see Accessing VicNode Cloud Storage. \n Here\
          \ I will create a new configuration called \"backup\" accessing storage\n\
          belonging to the \"Monash_RSS-test\" project. \n \n Run rclone config\n\
          \ \n Press n to select the new remote option \n Enter a name of your choosing,\
          \ e.g., backup\n \n Choose the number corresponding to swift as the storage\
          \ type \n User name is your NeCTAR OS API username \n Enter your NeCTAR\
          \ OS API password at the key> prompt \n At the auth> prompt enter https://keystone.rc.nectar.org.au:5000/v2.0\n\
          \ \n At the tenant> prompt enter your OS API tenant/project name \n At the\
          \ region> prompt press enter \n Review and either correct the entries or\
          \ press y then q\n \n \n The file $HOME/.rclone.conf should now look something\
          \ like: \n [backup]\ntype = swift\nuser = john.smith@monash.edu\nkey = pvJDjLXPmDjxEmYyFiVG\n\
          auth = https://keystone.rc.nectar.org.au:5000/v2.0\ntenant = Monash_RSS-test\n\
          region =\n \n Test that rclone can access the object storage \n First list\
          \ the contents of the object location, if the object storage\nis new then\
          \ it will be empty, but this will verify that your\nconfiguration is correct:\
          \ \n ubuntu@linux:~$ rclone lsd backup:\n\nTransferred:            0 Bytes\
          \ (   0.00 kByte/s)\nErrors:                 0\nChecks:                \
          \ 0\nTransferred:            0\nElapsed time:        1.2s\n \n Create an\
          \ object storage container for your data \n Here I create a container \"\
          phd2015\" to hold my data: \n ubuntu@linux:~$ rclone mkdir backup:phd2015\n\
          \nTransferred:            0 Bytes (   0.00 kByte/s)\nErrors:           \
          \      0\nChecks:                 0\nTransferred:            0\nElapsed\
          \ time:        1.3s\n \n Make backups of local data to the object storage\
          \ container \n Here I have three directories on my local computer; \"PhD\"\
          , \"PhD-data\"\nand \"results\" and I'll make a backup copy of these in\
          \ my object\nstorage, appearing as \"phd2015/Phd\", \"phd2015/Phd-data\"\
          \ and\n\"phd2015/results\" respectively. \n ajft@fafnir:~/Downloads$ rclone\
          \ sync PhD backup:phd2015/PhD\n2015/11/26 21:26:17 Swift container phd2015\
          \ path PhD/: Building file list\n2015/11/26 21:26:19 Swift container phd2015\
          \ path PhD/: Waiting for checks to finish\n2015/11/26 21:26:19 Swift container\
          \ phd2015 path PhD/: Waiting for transfers to finish\n2015/11/26 21:26:20\
          \ Waiting for deletions to finish\n\nTransferred:         1852 Bytes ( \
          \  0.43 kByte/s)\nErrors:                 0\nChecks:                 0\n\
          Transferred:            2\nElapsed time:        4.2s\n\nubuntu@linux:~/Downloads$\
          \ rclone PhD-data backup:phd2015/PhD-data\n...\nubuntu@linux:~/Downloads$\
          \ rclone results backup:phd2015/PhD-results\n...\n \n (Note that as in the\
          \ third of these examples commands, the local source\nfolder and remote\
          \ destination object prefix can differ.) \n These three \"rclone sync\"\
          \ commands can be run daily (or more\nfrequently) to ensure that the copy\
          \ held in the object storage is up\nto date and matches the data on the\
          \ local computer. \n ubuntu@linux:~$ cat ~/sync-my-data\n#!/bin/sh\ncd $HOME/Documents\n\
          rclone sync PhD backup:phd2015/PhD\nrclone sync PhD-data backup:phd2015/PhD-data\n\
          rclone sync results backup:phd2015/PhD-results\n \n Viewing the data from\
          \ the NeCTAR dashboard \n (NB: this only applies to the NeCTAR Swift object\
          \ store as VicNode object\nstorage is implemented as a distinct service\
          \ with its own region.) \n After logging in to a the NeCTAR Dashboard it\
          \ is possible to view the files\nand containers.  You must select the correct\
          \ project first, then choose\n\"Object Store\" and \"Containers\", then\
          \ browse into your containers, e.g.,\n\"phd2015\" in the example above.\
          \ \n Contents \n \n \n Sharing files over the Internet with Swift tempurls\
          \ \n Object storage is great at both storing large amounts of unstructured\
          \ data\nand also disseminating it - once your data is in object storage\
          \ it is\nonly a small step to make it available over the Internet (using\
          \ standard\nprotocols that regular web-browsers understand). You can make\
          \ the contents\nof a container public or give specific access to other users\
          \ via container\nACLs. \n In this example we demonstrate how to use the\
          \ Swift tempurl feature to provide\ntemporary URL-authenticated access to\
          \ Swift objects. This feature allows you\nto easily share data with anyone\
          \ via URL, they needn't have a Swift user\naccount. Additionally, it's not\
          \ just GET access that can be allowed, but\nalso other HTTP methods like\
          \ PUT - so you can use this feature to allow other\npeople or services to\
          \ push data into your object storage. A typical example\nis a service such\
          \ as a website that allows users to download large objects\nfrom a non-public\
          \ object storage container by minting tempurls and presenting\nthem directly\
          \ to the user via their web-browser. \n How it works \n The tempurl functionality\
          \ works using a Hash-based Message\nAuthentication Code, this HMAC encodes:\
          \ \n \n The HTTP method being allowed, e.g., GET, PUT, HEAD, DELETE, POST\
          \ \n The expiry date (in Unix time) \n The path to the object (from the\
          \ object store's root URL) \n A secret key shared between the user/process\
          \ that generates the tempurl\n   and the object storage service that will\
          \ decode and accept/deny access\n   based on the other parameters \n \n\
          \ This encoding can be done with a few lines of Python or similar high-level\n\
          code, but luckily the Swift command line client already has a helper command\n\
          to do this. In older versions of python-swiftclient this was a separate\n\
          command called swift-temp-url, in newer versions this is a sub-command of\n\
          the main client, i.e., swift tempurl .... \n Set your Swift tempurl key\
          \ \n To use tempurl functionality it is first necessary to configure your\
          \ object\nstore account with a tempurl key - this is the shared secret mentioned\
          \ in\nstep 4 above that allows the server to verify whether a tempurl is\
          \ genuine.\nThis is done (as demonstrated below) using account metadata.\
          \ Both the\nOpenStack Swift and\nCeph Object Gateway Swift\nimplementations\
          \ of the Swift API allow users to set at least 2 tempurl keys,\nthis allows\
          \ users and applications to perform key rotation (but if you change\nthe\
          \ key used to generate a particular tempurl then that tempurl will\nbecome\
          \ invalid). \n On VicNode Object Market at Monash: \n $ swift --os-storage-url\
          \ https://au-east.erc.monash.edu.au/swift/v1 post --meta \"Temp-URL-Key:superfunhappytimes\"\
          \n \n On VicNode Object Vault at UoM: \n $ swift --os-region-name VicNode\
          \ post --meta \"Temp-URL-Key:codswallop\"\n \n NB: The OpenStack Swift API\
          \ will display the Temp-URL-Key metadata back via\nthe API when account\
          \ metadata is queried. The Ceph Swift API does not, so\nit is only possible\
          \ to set or add a new key if an existing one is forgotten\nor lost. \n Upload\
          \ the object (if doesn't already exist in the object store) \n Here we upload\
          \ the file experiment.tar.gz from the current directory to a\ncontainer\
          \ named share in our object storage account. \n $ swift upload share experiment.tar.gz\n\
          \ \n Generate a tempurl to share with collaborators \n We'll give them two\
          \ days (172800 seconds) to grab the data. \n $ swift --os-storage-url https://au-east.erc.monash.edu.au/swift/v1\
          \ tempurl GET 172800 /share/experiment.tar.gz superfunhappytimes\n/share/experiment.tar.gz?temp_url_sig=8592bd096a83ba05d3fd1e457dc1167dff62ba28&temp_url_expires=1454540180\n\
          \ \n The command outputs the sub-path and query components of the final\
          \ working\ntempurl URL. To get the final product we need to prepend the\
          \ service's Swift\nstorage URL. For the above example we would tell our\
          \ colleagues to grab the\nexperiment data from: \n \n https://au-east.erc.monash.edu.au/swift/v1/share/experiment.tar.gz?temp_url_sig=8592bd096a83ba05d3fd1e457dc1167dff62ba28&temp_url_expires=1454540180\
          \ \n \n With OpenStack Swift that URL also includes the account identifier,\
          \ e.g.,: \n \n https://vault.melbourne.vicnode.org.au:8888/v1/AUTH_cb6c6ea8eb634cc598b0d277b8677b4f/share/experiment.tar.gz?temp_url_sig=0b7408a830d9c03411804b019279135a714c6f28&temp_url_expires=1404626295\
          \ \n \n NB: The process of generating the tempurl is entirely local because\
          \ the\nSwift service just needs to know the tempurl key to decode the other\n\
          parameters and validate them on-demand. However, this means\nthere is no\
          \ validation that your new tempurl works, so we suggest you it\nthem before\
          \ distributing, e.g., by pasting into your web-browser address\nbar. \n\
          \ Contents \n \n \n Backing up files to object storage using Duplicity \n\
          \ Duplicity is a backup utility that can make secure and bandwidth efficient\n\
          back-ups from your computer to various remote storage types including Swift\n\
          and S3. Duplicity uses librsync and GnuPG to make differential and secure\n\
          back-ups. In this example we will configure Duplicity to back-up using the\n\
          Swift API. \n First you'll need to create a container that Duplicity will\
          \ use as the backup\ntarget location. In this example we assume a container\
          \ named \"ubuntu\" already\nexists in the project's object store. You can\
          \ optionally\nencrypt your back-ups locally before they are transferred\
          \ to cloud storage,\nthough we do not cover that in this example. \n Configure\
          \ Duplicity to use Swift API \n On a 14.04 (Trusty) Ubuntu LTS system \n\
          \ apt-get install duplicity\n \n Create a credentials file \n The credentials\
          \ file contains a subset of the variables from your openrc.sh\nResearch\
          \ Cloud API credentials file. \n cat backup.sh\n#!/bin/bash\nexport SWIFT_AUTHVERSION=2\n\
          export SWIFT_AUTHURL=https://keystone.rc.nectar.org.au:5000/v2.0/\nexport\
          \ SWIFT_USERNAME=\"Monash_RSS-test:adrian.tritschler@monash.edu\"\nexport\
          \ SWIFT_PASSWORD=xxxxxxxxx\n \n Source the credentials, then run a backup\
          \ \n $ . backup.sh\n$ duplicity --no-encryption /home/ajft/src swift://ubuntu\n\
          Synchronizing remote metadata to local cache...\nDeleting local /home/ajft/.cache/duplicity/97fd3f05cdb92feaf3607d5ff406f22c/duplicity-full-signatures.20160106T001707Z.sigtar.gz\
          \ (not authoritative at backend).\nDeleting local /home/ajft/.cache/duplicity/97fd3f05cdb92feaf3607d5ff406f22c/duplicity-full.20160106T001707Z.manifest\
          \ (not authoritative at backend).\nLast full backup date: none\nNo signatures\
          \ found, switching to full backup.\n--------------[ Backup Statistics ]--------------\n\
          StartTime 1452040911.64 (Wed Jan  6 11:41:51 2016)\nEndTime 1452040911.68\
          \ (Wed Jan  6 11:41:51 2016)\nElapsedTime 0.04 (0.04 seconds)\nSourceFiles\
          \ 109\nSourceFileSize 458449 (448 KB)\nNewFiles 109\nNewFileSize 458449\
          \ (448 KB)\nDeletedFiles 0\nChangedFiles 0\nChangedFileSize 0 (0 bytes)\n\
          ChangedDeltaSize 0 (0 bytes)\nDeltaEntries 109\nRawDeltaSize 257745 (252\
          \ KB)\nTotalDestinationSizeChange 175413 (171 KB)\nErrors 0\n \n Verify\
          \ that Duplicity has created the initial back-up \n You can now see the\
          \ files that Duplicity has created by listing the contents\nof the target\
          \ container, e.g., using the Dashboard to browse or the Swift\ncommand-line\
          \ client (python-swiftclient). \n $ swift list --lh ubuntu\n9.6K 2016-01-06\
          \ 00:41:52 duplicity-full-signatures.20160106T004151Z.sigtar.gz\n 179 2016-01-06\
          \ 00:41:53 duplicity-full.20160106T004151Z.manifest\n171K 2016-01-06 00:41:52\
          \ duplicity-full.20160106T004151Z.vol1.difftar.gz\n181K\n \n Contents "
        description: "<h1>VicNode and NeCTAR Cloud Storage - Use Cases, Patterns and\
          \ Tools</h1>\n<h2>Intro</h2>\n<p><a href=\"http://vicnode.org.au\">VicNode</a>\
          \ provides Victorian researchers and their collaborators with the\nability\
          \ to easily store and share research data through an affordable, secure\n\
          and sustainable service. It provides storage solutions to suit a variety\
          \ of\nresearch data storage needs. This documentation focuses particularly\
          \ on\n<strong>VicNode's cloud object storage offerings</strong>, however\
          \ much of it is relevant to\n<a href=\"https://support.nectar.org.au/support/solutions/folders/6000190146\"\
          >NeCTAR Object Storage</a>. Here you will find demos of object storage client\n\
          tools useful for completing common tasks, and caveats regarding API usage\
          \ and\ncompatibility.</p>\n<p><a name=\"toc\"></a></p>\n<h3>Contents</h3>\n\
          <ul>\n<li><a href=\"#overview\">VicNode Overview</a></li>\n<li><a href=\"\
          #vicnode%20storage\">VicNode Cloud Storage</a></li>\n<li><a href=\"#accessing\"\
          >Accessing VicNode Cloud Storage</a></li>\n<li><a href=\"#use-cases%20and%20tools\"\
          >Common Use-cases and Client Tools</a></li>\n<li><a href=\"#rclone\">Using\
          \ rclone to synchronise folders to/from object storage</a></li>\n<li><a\
          \ href=\"#tempurl\">Sharing files over the Internet with Swift tempurls</a></li>\n\
          <li><a href=\"#duplicity\">Backing up files to object storage using Duplicity</a></li>\n\
          </ul>\n<p><a name=\"overview\"></a></p>\n<h2>Overview</h2>\n<h3>VicNode\
          \ and the Research Cloud</h3>\n<p>VicNode was established as part of RDSI\
          \ (the\nResearch Data Storage Initiative), a national network of research\
          \ data nodes\nand the sister project of NeCTAR. RDSI's focus is on accessibility,\n\
          dissemination, sharing and long-term curation of research datasets. VicNode's\n\
          storage services are hosted locally in Victoria at the datacentres of the\n\
          University of Melbourne and Monash University and are connected with high\n\
          bandwidth to the VeRNet and AARNet research networks, VicNode storage is\
          \ also\nclosely coupled to the Monash and Melbourne zones of the NeCTAR\
          \ Research Cloud.</p>\n<p>VicNode offers a variety of <a href=\"http://vicnode.org.au/products/\"\
          \ title=\"VicNode Storage Products\">storage products</a> utilising different\
          \ underlying technologies at each\noperating centre. Two types of VicNode\
          \ storage in particular are directly\nlinked to, and accessible through,\
          \ the Research Cloud: <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055382-introduction-to-cloud-storage\"\
          >NeCTAR Volume Storage</a>\nand <a href=\"https://support.nectar.org.au/support/solutions/folders/6000190146\"\
          >NeCTAR Object Storage</a>. Implementation and access details of these are\n\
          discussed in the next section.</p>\n<p><a href=\"#toc\">Contents</a></p>\n\
          <p><a name=\"vicnode%20storage\"></a></p>\n<hr>\n<h3>VicNode Cloud Storage</h3>\n\
          <h4>Computational</h4>\n<p>VicNode's current Computational\nstorage product\
          \ is delivered solely as volume storage in the Monash and\nMelbourne zones\
          \ of the NeCTAR Research Cloud. This gives researchers persistent\nblock\
          \ storage which can be used like a virtual portable hard disk and\nhot-plugged\
          \ (that is, attached and detached) whilst a cloud server is active.\nVolumes\
          \ can also be used as bootable drives, thus making the whole cloud server\n\
          operating system and configuration persistent.</p>\n<p>Access to the underlying\
          \ storage is standardised through the NeCTAR Research\nCloud and OpenStack,\
          \ but each operating centre uses a different solution. At\nthe University\
          \ of Melbourne, VicNode Computational storage is delivered via\nhigh-availability\
          \ NetApp servers, whereas at Monash University it is built on\ntop of a\
          \ cluster of commodity storage servers all running the Ceph distributed\n\
          storage system. In both cases rudimentary storage availability protection\
          \ is\nprovided by RAID (in the NetApp case) or replication (in the Ceph\
          \ case), but no\nautomated/implicit backups are made - backup of volume\
          \ storage is the\nresponsibility of the end-user and there are a number\
          \ of options for this\nwithin and outside of the Research Cloud. Note that\
          \ because each operating\ncentre uses different storage technologies their\
          \ performance profiles may vary\nfor different workloads.</p>\n<h4>Object</h4>\n\
          <p>VicNode's other cloud storage offering is what could be considered\n\
          as the original and definitive cloud storage, that is, object storage. Object\n\
          storage will be familiar to any regular Internet or mobile users, though\
          \ they\nmay not know it! The defining characteristic of object storage is\
          \ that it is\nbuilt for the Web and uses Web standards like HTTP and techniques\
          \ like REST\n(Representational State Transfer), this contributes to making\
          \ it massively\nscalable and ubiquitously accessible online. Object storage\
          \ is also very good\nat storing large and plentiful data, that is, huge\
          \ objects or many millions of\nobjects. It can do this thanks to another\
          \ of its defining characteristics, it\ndoes not allow an arbitrarily hierarchical\
          \ namespace - users can create\nbuckets/containers and inside them place\
          \ only objects, containers cannot be\nnested. So, each container is a flat\
          \ and unique namespace of objects. Both\nobjects and the containers that\
          \ hold them can also have user-defined metadata\nassociated with them in\
          \ key-value pairs, and there are many special metadata\nkeys which enable\
          \ and/or control some useful functionality of the storage,\ne.g., access-controls.</p>\n\
          <p>Because object storage is accessed as a web service it is not a natural\
          \ primary\nstorage type for end-user computing devices (like your laptop).\
          \ Though it is\ncommonly used by file sync-and-share applications (anyone\
          \ heard of Dropbox?) as\nthe central storage point with just a small cache\
          \ kept on end-user devices.</p>\n<p>Each VicNode operating centre uses a\
          \ different object storage solution, but\naccess to the underlying storage\
          \ is standardised through the NeCTAR Research\nCloud and both solutions\
          \ support the same basic end-user REST API interfaces -\nthe S3 and OpenStack\
          \ Swift APIs. The Monash University operating centre uses\n<a href=\"http://docs.ceph.com/docs/master/radosgw/\"\
          >Ceph Object Gateway</a> service whilst the University of Melbourne uses\n\
          <a href=\"http://swift.openstack.org\">OpenStack Swift</a> (as does the\
          \ NeCTAR Research Cloud). These are both clustered\nsoftware-defined storage\
          \ systems. The main difference between them (and they\nare quite different\
          \ under the hood) is that, following [CAP therom], Swift\nrelaxes <em>Consistency</em>\
          \ where Ceph relaxes <em>Availability</em>. Neither of these\nchoices is\
          \ black &amp; white and if that means nothing to you then don't worry,\n\
          just know that VicNode's \"Object-Vault\" is the highly redundant OpenStack\
          \ Swift\nservice whilst VicNode's \"Object-Market\" uses faster disk and\
          \ will have a\ndisaster recovery solution utilising a tape backup (though\
          \ this is not yet\nimplemented).</p>\n<p><a href=\"#toc\">Contents</a></p>\n\
          <hr>\n<p><a name=\"accessing\"></a></p>\n<h4>Accessing VicNode Cloud Storage</h4>\n\
          <p>To use VicNode's cloud volume and/or object storage you must first have\
          \ a\nVicNode allocation - apply to VicNode directly, or if you are a University\
          \ of\nMelbourne or Monash user you can contact your local eResearch Support.</p>\n\
          <p>Your VicNode storage quota will be associated with a NeCTAR Research\
          \ Cloud\nproject, so you will need to <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
          >get an account</a> on the Research Cloud. If you\nare already a Research\
          \ Cloud user then you may have an existing project you\nare planning to\
          \ use your VicNode storage in, otherwise you will want to\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
          >apply for a project</a> - if you are applying for a new project and already\n\
          have a VicNode allocation you'd like to use then mention this in the\nallocation\
          \ request.</p>\n<p>Once you have your VicNode cloud storage quota associated\
          \ with a NeCTAR\nResearch Cloud user and project you are ready to go! For\
          \ the tools and\nexamples in the subsequent sections you will also require\
          \ your Research Cloud\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000078065-api\"\
          >API credentials</a>.</p>\n<h5>A note about Regions and endpoints</h5>\n\
          <p>In the context of VicNode and NeCTAR there are at least three separate\
          \ Object\nStorage services. These are all integrated with the Research Cloud\
          \ but some\nare only accessible to VicNode users:</p>\n<ol>\n<li>NeCTAR\
          \ Swift - This is a nationally distributed Swift cluster with storage\n\
          \   nodes at seven Research Cloud sites around Australia. Some sites also\
          \ have\n   local Swift Proxies (the user-facing API servers) which can be\
          \ explicitly\n   used by configuring your client tool/s to point to the\
          \ correct storage URL\n   or Region. The default storage policy for this\
          \ cluster creates 3-copies of\n   all objects. This cluster also provides\
          \ storage for many other services on\n   the Research Cloud, e.g., the Glance\
          \ Image Catalog where VM images and\n   snapshots are stored. All NeCTAR\
          \ users are able to access and use NeCTAR\n   Swift. There is no need to\
          \ specify any special storage URL or Region for\n   this cluster as it is\
          \ the default NeCTAR object storage service.</li>\n<li>\n<p>VicNode Swift\
          \ Object Vault - See above for details. To use VicNode Swift\n   you must\
          \ tell you client tool/s to select either the \"VicNode\" Region or\n  \
          \ configure a storage URL of\n   \"https://vault.melbourne.vicnode.org.au:8888/v1//\"\
          </p>\n</li>\n<li>\n<p>VicNode Ceph Object Market - See above for details.\
          \ Due to technical\n   limitations with NeCTAR Keystone, the VicNode Ceph\
          \ Object store is not\n   currently listed in the Keystone service catalog\
          \ and therefore cannot be\n   referred to via Region. Instead, configure\
          \ your client tool/s to use a\n   storage URL of \"https://au-east.erc.monash.edu.au/swift/v1\"\
          .</p>\n</li>\n</ol>\n<p>Example Swift python-swiftclient accessing VicNode\
          \ Ceph Object:</p>\n<pre><code>swift --os-storage-url https://au-east.erc.monash.edu.au/swift/v1\
          \ stat\n</code></pre>\n<p>Example Swift python-swiftclient accessing VicNode\
          \ Vault Object:</p>\n<pre><code>swift --os-region-name VicNode stat\nswift\
          \ --os-storage-url https://vault.melbourne.vicnode.org.au:8888/v1/AUTH_d57de879288840e199bb1a48ae0c2c79\
          \ stat\n</code></pre>\n<p>Example Swift python-openstackclient accessing\
          \ VicNode Vault Object:</p>\n<pre><code>openstack --os-region-name VicNode\
          \ object store account show\n</code></pre>\n<p>NB: currently python-openstackclient\
          \ does not support specifying a different\nSwift API endpoint other than\
          \ by region name.</p>\n<p><a href=\"#toc\">Contents</a></p>\n<hr>\n<p><a\
          \ name=\"use-cases%20and%20tools\"></a></p>\n<h2>Object Storage Use-cases\
          \ and Client Tools</h2>\n<p>This section includes pointers and quickstart\
          \ instructions for using various\nuseful object storage client tools. These\
          \ tools have been tested to work with\nVicNode cloud storage.</p>\n<hr>\n\
          <p><a name=\"rclone\"></a></p>\n<h2>rclone</h2>\n<p><a href=\"http://rclone.org/\"\
          >rclone</a> is described as \"rsync for cloud storage\" (rysnc being a popular\
          \ and\nwidely distributed tool for file data-transfer and synchronisation).\n\
          Of particular note is that <a href=\"http://rclone.org/\">rclone</a> supports\
          \ a wide variety of cloud storage\ntypes (both as source and destination,\
          \ with local file-system too) and is\ncapable of <em>delta synchronisation</em>,\
          \ i.e., it is not necessary to transfer a\nfull copy of the dataset if part\
          \ of it has already been copied or only some\ndata on the source has changed,\
          \ which makes it suitable for working with\nlarge datasets.</p>\n<h3>Install\
          \ rclone</h3>\n<p>From http://rclone.org/, download and install the command\
          \ line tool\nfor your system.  Go to http://rclone.org/downloads/ and choose:</p>\n\
          <p>On Windows:</p>\n<ul>\n<li>Download http://downloads.rclone.org/rclone-v1.25-windows-amd64.zip</li>\n\
          <li>Extract rclone.exe from the zip file and save it (e.g., as C:\\users\\\
          fred\\rclone.exe)</li>\n<li>All configuration and examples in the Linux\
          \ section are as below, run from within a cmd.exe shell</li>\n</ul>\n<p>On\
          \ Macintosh:</p>\n<p>Not yet tested (will be similar to below details for\
          \ Linux but different\ninstallation).</p>\n<p>On Linux:</p>\n<p>First download\
          \ http://downloads.rclone.org/rclone-v1.25-linux-amd64.zip</p>\n<h3>Setup\
          \ and use rclone</h3>\n<h4>From within a terminal session</h4>\n<pre><code>ubuntu@linux:~$\
          \ cd ~/Downloads\n</code></pre>\n<p>unzip the downloaded archive</p>\n<pre><code>ubuntu@linux:~/Downloads$\
          \ unzip rclone-v1.25-linux-amd64.zip\nArchive:  rclone-v1.25-linux-amd64.zip\n\
          \  creating: rclone-v1.25-linux-amd64/\n  inflating: rclone-v1.25-linux-amd64/README.txt\n\
          \  inflating: rclone-v1.25-linux-amd64/rclone\n  inflating: rclone-v1.25-linux-amd64/README.html\n\
          \  inflating: rclone-v1.25-linux-amd64/rclone.1\nubuntu@linux:~/Downloads$\
          \ cd rclone-v1.25-linux-amd64\n</code></pre>\n<h4>Copy the rclone program\
          \ into the system path</h4>\n<pre><code>ubuntu@linux:~/Downloads/rclone-v1.25-linux-amd64$\
          \ sudo cp rclone /usr/local/bin\n[sudo] password for ubuntu:\n</code></pre>\n\
          <h4>Also copy the manual page so we can RTFM</h4>\n<pre><code>ubuntu@linux:~/Downloads/rclone-v1.25-linux-amd64$\
          \ sudo cp rclone.1 /usr/local/man/man1\n</code></pre>\n<h4>Test that rclone\
          \ runs</h4>\n<p>(You can ignore the message that you haven't yet configured\
          \ it)</p>\n<pre><code>ubuntu@linux:~/Downloads/rclone-v1.25-linux-amd64$\
          \ rclone --version\n2015/11/26 20:57:41 Failed to load config file /home/ubuntu/.rclone.conf\
          \ - using defaults: open /home/ubuntu/.rclone.conf: no such file or directory\n\
          rclone v1.25\n</code></pre>\n<h4>Configure rclone to access your project's\
          \ object storage</h4>\n<p>NB: here you will require the API credentials\
          \ for your NeCTAR Research Cloud\nuser and project, see <a href=\"#accessing\"\
          >Accessing VicNode Cloud Storage</a>.</p>\n<p>Here I will create a new configuration\
          \ called \"backup\" accessing storage\nbelonging to the \"Monash_RSS-test\"\
          \ project.</p>\n<ul>\n<li>Run <strong>rclone config</strong>\n</li>\n<li>Press\
          \ <strong>n</strong> to select the new remote option</li>\n<li>Enter a name\
          \ of your choosing, e.g., <strong>backup</strong>\n</li>\n<li>Choose the\
          \ number corresponding to <strong>swift</strong> as the storage type</li>\n\
          <li>User name is your NeCTAR OS API username</li>\n<li>Enter your NeCTAR\
          \ OS API password at the <strong>key&gt;</strong> prompt</li>\n<li>At the\
          \ <strong>auth&gt;</strong> prompt enter <strong>https://keystone.rc.nectar.org.au:5000/v2.0</strong>\n\
          </li>\n<li>At the <strong>tenant&gt;</strong> prompt enter your OS API tenant/project\
          \ name</li>\n<li>At the <strong>region&gt;</strong> prompt press enter</li>\n\
          <li>Review and either correct the entries or press <strong>y</strong> then\
          \ <strong>q</strong>\n</li>\n</ul>\n<p>The file $HOME/.rclone.conf should\
          \ now look something like:</p>\n<pre><code>[backup]\ntype = swift\nuser\
          \ = john.smith@monash.edu\nkey = pvJDjLXPmDjxEmYyFiVG\nauth = https://keystone.rc.nectar.org.au:5000/v2.0\n\
          tenant = Monash_RSS-test\nregion =\n</code></pre>\n<h4>Test that rclone\
          \ can access the object storage</h4>\n<p>First list the contents of the\
          \ object location, if the object storage\nis new then it will be empty,\
          \ but this will verify that your\nconfiguration is correct:</p>\n<pre><code>ubuntu@linux:~$\
          \ rclone lsd backup:\n\nTransferred:            0 Bytes (   0.00 kByte/s)\n\
          Errors:                 0\nChecks:                 0\nTransferred:     \
          \       0\nElapsed time:        1.2s\n</code></pre>\n<h4>Create an object\
          \ storage container for your data</h4>\n<p>Here I create a container \"\
          phd2015\" to hold my data:</p>\n<pre><code>ubuntu@linux:~$ rclone mkdir\
          \ backup:phd2015\n\nTransferred:            0 Bytes (   0.00 kByte/s)\n\
          Errors:                 0\nChecks:                 0\nTransferred:     \
          \       0\nElapsed time:        1.3s\n</code></pre>\n<h4>Make backups of\
          \ local data to the object storage container</h4>\n<p>Here I have three\
          \ directories on my local computer; \"PhD\", \"PhD-data\"\nand \"results\"\
          \ and I'll make a backup copy of these in my object\nstorage, appearing\
          \ as \"phd2015/Phd\", \"phd2015/Phd-data\" and\n\"phd2015/results\" respectively.</p>\n\
          <pre><code>ajft@fafnir:~/Downloads$ rclone sync PhD backup:phd2015/PhD\n\
          2015/11/26 21:26:17 Swift container phd2015 path PhD/: Building file list\n\
          2015/11/26 21:26:19 Swift container phd2015 path PhD/: Waiting for checks\
          \ to finish\n2015/11/26 21:26:19 Swift container phd2015 path PhD/: Waiting\
          \ for transfers to finish\n2015/11/26 21:26:20 Waiting for deletions to\
          \ finish\n\nTransferred:         1852 Bytes (   0.43 kByte/s)\nErrors: \
          \                0\nChecks:                 0\nTransferred:            2\n\
          Elapsed time:        4.2s\n\nubuntu@linux:~/Downloads$ rclone PhD-data backup:phd2015/PhD-data\n\
          ...\nubuntu@linux:~/Downloads$ rclone results backup:phd2015/PhD-results\n\
          ...\n</code></pre>\n<p>(Note that as in the third of these examples commands,\
          \ the local source\nfolder and remote destination object prefix can differ.)</p>\n\
          <p>These three \"rclone sync\" commands can be run daily (or more\nfrequently)\
          \ to ensure that the copy held in the object storage is up\nto date and\
          \ matches the data on the local computer.</p>\n<pre><code>ubuntu@linux:~$\
          \ cat ~/sync-my-data\n#!/bin/sh\ncd $HOME/Documents\nrclone sync PhD backup:phd2015/PhD\n\
          rclone sync PhD-data backup:phd2015/PhD-data\nrclone sync results backup:phd2015/PhD-results\n\
          </code></pre>\n<h4>Viewing the data from the NeCTAR dashboard</h4>\n<p>(NB:\
          \ this only applies to the NeCTAR Swift object store as VicNode object\n\
          storage is implemented as a distinct service with its own <em>region</em>.)</p>\n\
          <p>After logging in to a the <a href=\"https://support.nectar.org.au/support/solutions/articles/6000076111-nectar-dashboard\"\
          >NeCTAR Dashboard</a> it is possible to view the files\nand containers.\
          \  You must select the correct project first, then choose\n\"Object Store\"\
          \ and \"Containers\", then browse into your containers, e.g.,\n\"phd2015\"\
          \ in the example above.</p>\n<p><a href=\"#toc\">Contents</a></p>\n<hr>\n\
          <p><a name=\"tempurl\"></a></p>\n<h2>Sharing files over the Internet with\
          \ Swift tempurls</h2>\n<p>Object storage is great at both storing large\
          \ amounts of unstructured data\nand also disseminating it - once your data\
          \ is in object storage it is\nonly a small step to make it available over\
          \ the Internet (using standard\nprotocols that regular web-browsers understand).\
          \ You can make the contents\nof a container public or give specific access\
          \ to other users via container\nACLs.</p>\n<p>In this example we demonstrate\
          \ how to use the Swift tempurl feature to provide\ntemporary URL-authenticated\
          \ access to Swift objects. This feature allows you\nto easily share data\
          \ with anyone via URL, they needn't have a Swift user\naccount. Additionally,\
          \ it's not just GET access that can be allowed, but\nalso other HTTP methods\
          \ like PUT - so you can use this feature to allow other\npeople or services\
          \ to push data into your object storage. A typical example\nis a service\
          \ such as a website that allows users to download large objects\nfrom a\
          \ non-public object storage container by minting tempurls and presenting\n\
          them directly to the user via their web-browser.</p>\n<h3>How it works</h3>\n\
          <p>The tempurl functionality works using a Hash-based Message\nAuthentication\
          \ Code, this <a href=\"https://en.wikipedia.org/wiki/Hash-based_message_authentication_code\"\
          >HMAC</a> encodes:</p>\n<ol>\n<li>The HTTP method being allowed, e.g., GET,\
          \ PUT, HEAD, DELETE, POST</li>\n<li>The expiry date (in Unix time)</li>\n\
          <li>The path to the object (from the object store's root URL)</li>\n<li>A\
          \ secret key shared between the user/process that generates the tempurl\n\
          \   and the object storage service that will decode and accept/deny access\n\
          \   based on the other parameters</li>\n</ol>\n<p>This encoding can be done\
          \ with a few lines of Python or similar high-level\ncode, but luckily the\
          \ Swift command line client already has a helper command\nto do this. In\
          \ older versions of python-swiftclient this was a separate\ncommand called\
          \ <em>swift-temp-url</em>, in newer versions this is a sub-command of\n\
          the main client, i.e., <em>swift tempurl ...</em>.</p>\n<h3>Set your Swift\
          \ tempurl key</h3>\n<p>To use tempurl functionality it is first necessary\
          \ to configure your object\nstore account with a tempurl key - this is the\
          \ shared secret mentioned in\nstep 4 above that allows the server to verify\
          \ whether a tempurl is genuine.\nThis is done (as demonstrated below) using\
          \ account metadata. Both the\nOpenStack <a href=\"http://docs.ceph.com/docs/master/radosgw/swift/\"\
          >Swift</a> and\n<a href=\"http://docs.ceph.com/docs/master/radosgw/swift/\"\
          >Ceph Object Gateway Swift</a>\nimplementations of the Swift API allow users\
          \ to set at least 2 tempurl keys,\nthis allows users and applications to\
          \ perform key rotation (but if you change\nthe key used to generate a particular\
          \ tempurl then that tempurl will\nbecome invalid).</p>\n<p>On VicNode Object\
          \ Market at Monash:</p>\n<pre><code>$ swift --os-storage-url https://au-east.erc.monash.edu.au/swift/v1\
          \ post --meta \"Temp-URL-Key:superfunhappytimes\"\n</code></pre>\n<p>On\
          \ VicNode Object Vault at UoM:</p>\n<pre><code>$ swift --os-region-name\
          \ VicNode post --meta \"Temp-URL-Key:codswallop\"\n</code></pre>\n<p>NB:\
          \ The OpenStack Swift API will display the Temp-URL-Key metadata back via\n\
          the API when account metadata is queried. The Ceph Swift API does not, so\n\
          it is only possible to set or add a new key if an existing one is forgotten\n\
          or lost.</p>\n<h3>Upload the object (if doesn't already exist in the object\
          \ store)</h3>\n<p>Here we upload the file <em>experiment.tar.gz</em> from\
          \ the current directory to a\ncontainer named <em>share</em> in our object\
          \ storage account.</p>\n<pre><code>$ swift upload share experiment.tar.gz\n\
          </code></pre>\n<h3>Generate a tempurl to share with collaborators</h3>\n\
          <p>We'll give them two days (172800 seconds) to grab the data.</p>\n<pre><code>$\
          \ swift --os-storage-url https://au-east.erc.monash.edu.au/swift/v1 tempurl\
          \ GET 172800 /share/experiment.tar.gz superfunhappytimes\n/share/experiment.tar.gz?temp_url_sig=8592bd096a83ba05d3fd1e457dc1167dff62ba28&amp;temp_url_expires=1454540180\n\
          </code></pre>\n<p>The command outputs the sub-path and query components\
          \ of the final working\ntempurl URL. To get the final product we need to\
          \ prepend the service's Swift\nstorage URL. For the above example we would\
          \ tell our colleagues to grab the\nexperiment data from:</p>\n<blockquote>\n\
          <p>https://au-east.erc.monash.edu.au/swift/v1/share/experiment.tar.gz?temp_url_sig=8592bd096a83ba05d3fd1e457dc1167dff62ba28&amp;temp_url_expires=1454540180</p>\n\
          </blockquote>\n<p>With OpenStack Swift that URL also includes the account\
          \ identifier, e.g.,:</p>\n<blockquote>\n<p>https://vault.melbourne.vicnode.org.au:8888/v1/AUTH_cb6c6ea8eb634cc598b0d277b8677b4f/share/experiment.tar.gz?temp_url_sig=0b7408a830d9c03411804b019279135a714c6f28&amp;temp_url_expires=1404626295</p>\n\
          </blockquote>\n<p>NB: The process of generating the tempurl is entirely\
          \ local because the\nSwift service just needs to know the tempurl key to\
          \ decode the other\nparameters and validate them on-demand. However, this\
          \ means\nthere is no validation that your new tempurl works, so we suggest\
          \ you it\nthem before distributing, e.g., by pasting into your web-browser\
          \ address\nbar.</p>\n<p><a href=\"#toc\">Contents</a></p>\n<hr>\n<p><a name=\"\
          duplicity\"></a></p>\n<h2>Backing up files to object storage using Duplicity</h2>\n\
          <p><a href=\"http://duplicity.nongnu.org\">Duplicity</a> is a backup utility\
          \ that can make secure and bandwidth efficient\nback-ups from your computer\
          \ to various remote storage types including Swift\nand S3. Duplicity uses\
          \ librsync and GnuPG to make differential and secure\nback-ups. In this\
          \ example we will configure Duplicity to back-up using the\nSwift API.</p>\n\
          <p>First you'll need to create a container that Duplicity will use as the\
          \ backup\ntarget location. In this example we assume a container named \"\
          ubuntu\" already\nexists in the project's object store. You can optionally\n\
          <a href=\"https://dmsimard.com/2014/08/12/send-your-encrypted-duplicity-backups-to-a-swift-object-storage/\"\
          >encrypt your back-ups</a> locally before they are transferred to cloud\
          \ storage,\nthough we do not cover that in this example.</p>\n<h3>Configure\
          \ Duplicity to use Swift API</h3>\n<h4>On a 14.04 (Trusty) Ubuntu LTS system</h4>\n\
          <pre><code>apt-get install duplicity\n</code></pre>\n<h4>Create a credentials\
          \ file</h4>\n<p>The credentials file contains a subset of the variables\
          \ from your openrc.sh\nResearch Cloud <a href=\"https://support.nectar.org.au/support/solutions/articles/6000078065-api\"\
          >API credentials</a> file.</p>\n<pre><code>cat backup.sh\n#!/bin/bash\n\
          export SWIFT_AUTHVERSION=2\nexport SWIFT_AUTHURL=https://keystone.rc.nectar.org.au:5000/v2.0/\n\
          export SWIFT_USERNAME=\"Monash_RSS-test:adrian.tritschler@monash.edu\"\n\
          export SWIFT_PASSWORD=xxxxxxxxx\n</code></pre>\n<h4>Source the credentials,\
          \ then run a backup</h4>\n<pre><code>$ . backup.sh\n$ duplicity --no-encryption\
          \ /home/ajft/src swift://ubuntu\nSynchronizing remote metadata to local\
          \ cache...\nDeleting local /home/ajft/.cache/duplicity/97fd3f05cdb92feaf3607d5ff406f22c/duplicity-full-signatures.20160106T001707Z.sigtar.gz\
          \ (not authoritative at backend).\nDeleting local /home/ajft/.cache/duplicity/97fd3f05cdb92feaf3607d5ff406f22c/duplicity-full.20160106T001707Z.manifest\
          \ (not authoritative at backend).\nLast full backup date: none\nNo signatures\
          \ found, switching to full backup.\n--------------[ Backup Statistics ]--------------\n\
          StartTime 1452040911.64 (Wed Jan  6 11:41:51 2016)\nEndTime 1452040911.68\
          \ (Wed Jan  6 11:41:51 2016)\nElapsedTime 0.04 (0.04 seconds)\nSourceFiles\
          \ 109\nSourceFileSize 458449 (448 KB)\nNewFiles 109\nNewFileSize 458449\
          \ (448 KB)\nDeletedFiles 0\nChangedFiles 0\nChangedFileSize 0 (0 bytes)\n\
          ChangedDeltaSize 0 (0 bytes)\nDeltaEntries 109\nRawDeltaSize 257745 (252\
          \ KB)\nTotalDestinationSizeChange 175413 (171 KB)\nErrors 0\n</code></pre>\n\
          <h4>Verify that Duplicity has created the initial back-up</h4>\n<p>You can\
          \ now see the files that Duplicity has created by listing the contents\n\
          of the target container, e.g., using the Dashboard to browse or the Swift\n\
          command-line client (python-swiftclient).</p>\n<pre><code>$ swift list --lh\
          \ ubuntu\n9.6K 2016-01-06 00:41:52 duplicity-full-signatures.20160106T004151Z.sigtar.gz\n\
          \ 179 2016-01-06 00:41:53 duplicity-full.20160106T004151Z.manifest\n171K\
          \ 2016-01-06 00:41:52 duplicity-full.20160106T004151Z.vol1.difftar.gz\n\
          181K\n</code></pre>\n<p><a href=\"#toc\">Contents</a></p>"
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:07-04:00'
          customer_folders: []
          description: Tools and Apps
          id: 6000190153
          is_default: false
          language_id: 6
          name: Tools and Apps
          parent_id: 6000190153
          position: 3
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190153
        hits: 10
        id: 6000118791
        modified_at: '2016-04-04T03:01:26-04:00'
        modified_by: null
        position: 24
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: VicNode and NeCTAR Cloud Storage - Use Cases, Patterns and Tools
        updated_at: '2016-04-04T03:01:26-04:00'
        user_id: 6002464727
  html: "<h1>VicNode and NeCTAR Cloud Storage - Use Cases, Patterns and Tools</h1>\n\
    <h2>Intro</h2>\n<p><a href=\"http://vicnode.org.au\">VicNode</a> provides Victorian\
    \ researchers and their collaborators with the\nability to easily store and share\
    \ research data through an affordable, secure\nand sustainable service. It provides\
    \ storage solutions to suit a variety of\nresearch data storage needs. This documentation\
    \ focuses particularly on\n<strong>VicNode's cloud object storage offerings</strong>,\
    \ however much of it is relevant to\n<a href=\"https://support.nectar.org.au/support/solutions/folders/6000190146\"\
    >NeCTAR Object Storage</a>. Here you will find demos of object storage client\n\
    tools useful for completing common tasks, and caveats regarding API usage and\n\
    compatibility.</p>\n<p><a name=\"toc\"/></p>\n<h3>Contents</h3>\n<ul>\n<li><a\
    \ href=\"#overview\">VicNode Overview</a></li>\n<li><a href=\"#vicnode storage\"\
    >VicNode Cloud Storage</a></li>\n<li><a href=\"#accessing\">Accessing VicNode\
    \ Cloud Storage</a></li>\n<li><a href=\"#use-cases and tools\">Common Use-cases\
    \ and Client Tools</a></li>\n<li><a href=\"#rclone\">Using rclone to synchronise\
    \ folders to/from object storage</a></li>\n<li><a href=\"#tempurl\">Sharing files\
    \ over the Internet with Swift tempurls</a></li>\n<li><a href=\"#duplicity\">Backing\
    \ up files to object storage using Duplicity</a></li>\n</ul>\n<p><a name=\"overview\"\
    /></p>\n<h2>Overview</h2>\n<h3>VicNode and the Research Cloud</h3>\n<p>VicNode\
    \ was established as part of RDSI (the\nResearch Data Storage Initiative), a national\
    \ network of research data nodes\nand the sister project of NeCTAR. RDSI's focus\
    \ is on accessibility,\ndissemination, sharing and long-term curation of research\
    \ datasets. VicNode's\nstorage services are hosted locally in Victoria at the\
    \ datacentres of the\nUniversity of Melbourne and Monash University and are connected\
    \ with high\nbandwidth to the VeRNet and AARNet research networks, VicNode storage\
    \ is also\nclosely coupled to the Monash and Melbourne zones of the NeCTAR Research\
    \ Cloud.</p>\n<p>VicNode offers a variety of <a href=\"http://vicnode.org.au/products/\"\
    \ title=\"VicNode Storage Products\">storage products</a> utilising different\
    \ underlying technologies at each\noperating centre. Two types of VicNode storage\
    \ in particular are directly\nlinked to, and accessible through, the Research\
    \ Cloud: <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055382-introduction-to-cloud-storage\"\
    >NeCTAR Volume Storage</a>\nand <a href=\"https://support.nectar.org.au/support/solutions/folders/6000190146\"\
    >NeCTAR Object Storage</a>. Implementation and access details of these are\ndiscussed\
    \ in the next section.</p>\n<p><a href=\"#toc\">Contents</a></p>\n<p><a name=\"\
    vicnode storage\"/></p>\n<hr>\n<h3>VicNode Cloud Storage</h3>\n<h4>Computational</h4>\n\
    <p>VicNode's current Computational\nstorage product is delivered solely as volume\
    \ storage in the Monash and\nMelbourne zones of the NeCTAR Research Cloud. This\
    \ gives researchers persistent\nblock storage which can be used like a virtual\
    \ portable hard disk and\nhot-plugged (that is, attached and detached) whilst\
    \ a cloud server is active.\nVolumes can also be used as bootable drives, thus\
    \ making the whole cloud server\noperating system and configuration persistent.</p>\n\
    <p>Access to the underlying storage is standardised through the NeCTAR Research\n\
    Cloud and OpenStack, but each operating centre uses a different solution. At\n\
    the University of Melbourne, VicNode Computational storage is delivered via\n\
    high-availability NetApp servers, whereas at Monash University it is built on\n\
    top of a cluster of commodity storage servers all running the Ceph distributed\n\
    storage system. In both cases rudimentary storage availability protection is\n\
    provided by RAID (in the NetApp case) or replication (in the Ceph case), but no\n\
    automated/implicit backups are made - backup of volume storage is the\nresponsibility\
    \ of the end-user and there are a number of options for this\nwithin and outside\
    \ of the Research Cloud. Note that because each operating\ncentre uses different\
    \ storage technologies their performance profiles may vary\nfor different workloads.</p>\n\
    <h4>Object</h4>\n<p>VicNode's other cloud storage offering is what could be considered\n\
    as the original and definitive cloud storage, that is, object storage. Object\n\
    storage will be familiar to any regular Internet or mobile users, though they\n\
    may not know it! The defining characteristic of object storage is that it is\n\
    built for the Web and uses Web standards like HTTP and techniques like REST\n\
    (Representational State Transfer), this contributes to making it massively\nscalable\
    \ and ubiquitously accessible online. Object storage is also very good\nat storing\
    \ large and plentiful data, that is, huge objects or many millions of\nobjects.\
    \ It can do this thanks to another of its defining characteristics, it\ndoes not\
    \ allow an arbitrarily hierarchical namespace - users can create\nbuckets/containers\
    \ and inside them place only objects, containers cannot be\nnested. So, each container\
    \ is a flat and unique namespace of objects. Both\nobjects and the containers\
    \ that hold them can also have user-defined metadata\nassociated with them in\
    \ key-value pairs, and there are many special metadata\nkeys which enable and/or\
    \ control some useful functionality of the storage,\ne.g., access-controls.</p>\n\
    <p>Because object storage is accessed as a web service it is not a natural primary\n\
    storage type for end-user computing devices (like your laptop). Though it is\n\
    commonly used by file sync-and-share applications (anyone heard of Dropbox?) as\n\
    the central storage point with just a small cache kept on end-user devices.</p>\n\
    <p>Each VicNode operating centre uses a different object storage solution, but\n\
    access to the underlying storage is standardised through the NeCTAR Research\n\
    Cloud and both solutions support the same basic end-user REST API interfaces -\n\
    the S3 and OpenStack Swift APIs. The Monash University operating centre uses\n\
    <a href=\"http://docs.ceph.com/docs/master/radosgw/\">Ceph Object Gateway</a>\
    \ service whilst the University of Melbourne uses\n<a href=\"http://swift.openstack.org\"\
    >OpenStack Swift</a> (as does the NeCTAR Research Cloud). These are both clustered\n\
    software-defined storage systems. The main difference between them (and they\n\
    are quite different under the hood) is that, following [CAP therom], Swift\nrelaxes\
    \ <em>Consistency</em> where Ceph relaxes <em>Availability</em>. Neither of these\n\
    choices is black &amp; white and if that means nothing to you then don't worry,\n\
    just know that VicNode's \"Object-Vault\" is the highly redundant OpenStack Swift\n\
    service whilst VicNode's \"Object-Market\" uses faster disk and will have a\n\
    disaster recovery solution utilising a tape backup (though this is not yet\nimplemented).</p>\n\
    <p><a href=\"#toc\">Contents</a></p>\n<hr>\n<p><a name=\"accessing\"/></p>\n<h4>Accessing\
    \ VicNode Cloud Storage</h4>\n<p>To use VicNode's cloud volume and/or object storage\
    \ you must first have a\nVicNode allocation - apply to VicNode directly, or if\
    \ you are a University of\nMelbourne or Monash user you can contact your local\
    \ eResearch Support.</p>\n<p>Your VicNode storage quota will be associated with\
    \ a NeCTAR Research Cloud\nproject, so you will need to <a href=\"https://support.nectar.org.au/support/solutions/articles/6000055377-getting-an-account\"\
    >get an account</a> on the Research Cloud. If you\nare already a Research Cloud\
    \ user then you may have an existing project you\nare planning to use your VicNode\
    \ storage in, otherwise you will want to\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000068044-managing-an-allocation\"\
    >apply for a project</a> - if you are applying for a new project and already\n\
    have a VicNode allocation you'd like to use then mention this in the\nallocation\
    \ request.</p>\n<p>Once you have your VicNode cloud storage quota associated with\
    \ a NeCTAR\nResearch Cloud user and project you are ready to go! For the tools\
    \ and\nexamples in the subsequent sections you will also require your Research\
    \ Cloud\n<a href=\"https://support.nectar.org.au/support/solutions/articles/6000078065-api\"\
    >API credentials</a>.</p>\n<h5>A note about Regions and endpoints</h5>\n<p>In\
    \ the context of VicNode and NeCTAR there are at least three separate Object\n\
    Storage services. These are all integrated with the Research Cloud but some\n\
    are only accessible to VicNode users:</p>\n<ol>\n<li>NeCTAR Swift - This is a\
    \ nationally distributed Swift cluster with storage\n   nodes at seven Research\
    \ Cloud sites around Australia. Some sites also have\n   local Swift Proxies (the\
    \ user-facing API servers) which can be explicitly\n   used by configuring your\
    \ client tool/s to point to the correct storage URL\n   or Region. The default\
    \ storage policy for this cluster creates 3-copies of\n   all objects. This cluster\
    \ also provides storage for many other services on\n   the Research Cloud, e.g.,\
    \ the Glance Image Catalog where VM images and\n   snapshots are stored. All NeCTAR\
    \ users are able to access and use NeCTAR\n   Swift. There is no need to specify\
    \ any special storage URL or Region for\n   this cluster as it is the default\
    \ NeCTAR object storage service.</li>\n<li>\n<p>VicNode Swift Object Vault - See\
    \ above for details. To use VicNode Swift\n   you must tell you client tool/s\
    \ to select either the \"VicNode\" Region or\n   configure a storage URL of\n\
    \   \"https://vault.melbourne.vicnode.org.au:8888/v1/<ACCOUNT>/\"</p>\n</li>\n\
    <li>\n<p>VicNode Ceph Object Market - See above for details. Due to technical\n\
    \   limitations with NeCTAR Keystone, the VicNode Ceph Object store is not\n \
    \  currently listed in the Keystone service catalog and therefore cannot be\n\
    \   referred to via Region. Instead, configure your client tool/s to use a\n \
    \  storage URL of \"https://au-east.erc.monash.edu.au/swift/v1\".</p>\n</li>\n\
    </ol>\n<p>Example Swift python-swiftclient accessing VicNode Ceph Object:</p>\n\
    <pre><code>swift --os-storage-url https://au-east.erc.monash.edu.au/swift/v1 stat\n\
    </code></pre>\n<p>Example Swift python-swiftclient accessing VicNode Vault Object:</p>\n\
    <pre><code>swift --os-region-name VicNode stat\nswift --os-storage-url https://vault.melbourne.vicnode.org.au:8888/v1/AUTH_d57de879288840e199bb1a48ae0c2c79\
    \ stat\n</code></pre>\n<p>Example Swift python-openstackclient accessing VicNode\
    \ Vault Object:</p>\n<pre><code>openstack --os-region-name VicNode object store\
    \ account show\n</code></pre>\n<p>NB: currently python-openstackclient does not\
    \ support specifying a different\nSwift API endpoint other than by region name.</p>\n\
    <p><a href=\"#toc\">Contents</a></p>\n<hr>\n<p><a name=\"use-cases and tools\"\
    /></p>\n<h2>Object Storage Use-cases and Client Tools</h2>\n<p>This section includes\
    \ pointers and quickstart instructions for using various\nuseful object storage\
    \ client tools. These tools have been tested to work with\nVicNode cloud storage.</p>\n\
    <hr>\n<p><a name=\"rclone\"/></p>\n<h2>rclone</h2>\n<p><a href=\"http://rclone.org/\"\
    >rclone</a> is described as \"rsync for cloud storage\" (rysnc being a popular\
    \ and\nwidely distributed tool for file data-transfer and synchronisation).\n\
    Of particular note is that <a href=\"http://rclone.org/\">rclone</a> supports\
    \ a wide variety of cloud storage\ntypes (both as source and destination, with\
    \ local file-system too) and is\ncapable of <em>delta synchronisation</em>, i.e.,\
    \ it is not necessary to transfer a\nfull copy of the dataset if part of it has\
    \ already been copied or only some\ndata on the source has changed, which makes\
    \ it suitable for working with\nlarge datasets.</p>\n<h3>Install rclone</h3>\n\
    <p>From http://rclone.org/, download and install the command line tool\nfor your\
    \ system.  Go to http://rclone.org/downloads/ and choose:</p>\n<p>On Windows:</p>\n\
    <ul>\n<li>Download http://downloads.rclone.org/rclone-v1.25-windows-amd64.zip</li>\n\
    <li>Extract rclone.exe from the zip file and save it (e.g., as C:\\users\\fred\\\
    rclone.exe)</li>\n<li>All configuration and examples in the Linux section are\
    \ as below, run from within a cmd.exe shell</li>\n</ul>\n<p>On Macintosh:</p>\n\
    <p>Not yet tested (will be similar to below details for Linux but different\n\
    installation).</p>\n<p>On Linux:</p>\n<p>First download http://downloads.rclone.org/rclone-v1.25-linux-amd64.zip</p>\n\
    <h3>Setup and use rclone</h3>\n<h4>From within a terminal session</h4>\n<pre><code>ubuntu@linux:~$\
    \ cd ~/Downloads\n</code></pre>\n<p>unzip the downloaded archive</p>\n<pre><code>ubuntu@linux:~/Downloads$\
    \ unzip rclone-v1.25-linux-amd64.zip\nArchive:  rclone-v1.25-linux-amd64.zip\n\
    \  creating: rclone-v1.25-linux-amd64/\n  inflating: rclone-v1.25-linux-amd64/README.txt\n\
    \  inflating: rclone-v1.25-linux-amd64/rclone\n  inflating: rclone-v1.25-linux-amd64/README.html\n\
    \  inflating: rclone-v1.25-linux-amd64/rclone.1\nubuntu@linux:~/Downloads$ cd\
    \ rclone-v1.25-linux-amd64\n</code></pre>\n<h4>Copy the rclone program into the\
    \ system path</h4>\n<pre><code>ubuntu@linux:~/Downloads/rclone-v1.25-linux-amd64$\
    \ sudo cp rclone /usr/local/bin\n[sudo] password for ubuntu:\n</code></pre>\n\
    <h4>Also copy the manual page so we can RTFM</h4>\n<pre><code>ubuntu@linux:~/Downloads/rclone-v1.25-linux-amd64$\
    \ sudo cp rclone.1 /usr/local/man/man1\n</code></pre>\n<h4>Test that rclone runs</h4>\n\
    <p>(You can ignore the message that you haven't yet configured it)</p>\n<pre><code>ubuntu@linux:~/Downloads/rclone-v1.25-linux-amd64$\
    \ rclone --version\n2015/11/26 20:57:41 Failed to load config file /home/ubuntu/.rclone.conf\
    \ - using defaults: open /home/ubuntu/.rclone.conf: no such file or directory\n\
    rclone v1.25\n</code></pre>\n<h4>Configure rclone to access your project's object\
    \ storage</h4>\n<p>NB: here you will require the API credentials for your NeCTAR\
    \ Research Cloud\nuser and project, see <a href=\"#accessing\">Accessing VicNode\
    \ Cloud Storage</a>.</p>\n<p>Here I will create a new configuration called \"\
    backup\" accessing storage\nbelonging to the \"Monash_RSS-test\" project.</p>\n\
    <ul>\n<li>Run <strong>rclone config</strong></li>\n<li>Press <strong>n</strong>\
    \ to select the new remote option</li>\n<li>Enter a name of your choosing, e.g.,\
    \ <strong>backup</strong></li>\n<li>Choose the number corresponding to <strong>swift</strong>\
    \ as the storage type</li>\n<li>User name is your NeCTAR OS API username</li>\n\
    <li>Enter your NeCTAR OS API password at the <strong>key&gt;</strong> prompt</li>\n\
    <li>At the <strong>auth&gt;</strong> prompt enter <strong>https://keystone.rc.nectar.org.au:5000/v2.0</strong></li>\n\
    <li>At the <strong>tenant&gt;</strong> prompt enter your OS API tenant/project\
    \ name</li>\n<li>At the <strong>region&gt;</strong> prompt press enter</li>\n\
    <li>Review and either correct the entries or press <strong>y</strong> then <strong>q</strong></li>\n\
    </ul>\n<p>The file $HOME/.rclone.conf should now look something like:</p>\n<pre><code>[backup]\n\
    type = swift\nuser = john.smith@monash.edu\nkey = pvJDjLXPmDjxEmYyFiVG\nauth =\
    \ https://keystone.rc.nectar.org.au:5000/v2.0\ntenant = Monash_RSS-test\nregion\
    \ =\n</code></pre>\n<h4>Test that rclone can access the object storage</h4>\n\
    <p>First list the contents of the object location, if the object storage\nis new\
    \ then it will be empty, but this will verify that your\nconfiguration is correct:</p>\n\
    <pre><code>ubuntu@linux:~$ rclone lsd backup:\n\nTransferred:            0 Bytes\
    \ (   0.00 kByte/s)\nErrors:                 0\nChecks:                 0\nTransferred:\
    \            0\nElapsed time:        1.2s\n</code></pre>\n<h4>Create an object\
    \ storage container for your data</h4>\n<p>Here I create a container \"phd2015\"\
    \ to hold my data:</p>\n<pre><code>ubuntu@linux:~$ rclone mkdir backup:phd2015\n\
    \nTransferred:            0 Bytes (   0.00 kByte/s)\nErrors:                 0\n\
    Checks:                 0\nTransferred:            0\nElapsed time:        1.3s\n\
    </code></pre>\n<h4>Make backups of local data to the object storage container</h4>\n\
    <p>Here I have three directories on my local computer; \"PhD\", \"PhD-data\"\n\
    and \"results\" and I'll make a backup copy of these in my object\nstorage, appearing\
    \ as \"phd2015/Phd\", \"phd2015/Phd-data\" and\n\"phd2015/results\" respectively.</p>\n\
    <pre><code>ajft@fafnir:~/Downloads$ rclone sync PhD backup:phd2015/PhD\n2015/11/26\
    \ 21:26:17 Swift container phd2015 path PhD/: Building file list\n2015/11/26 21:26:19\
    \ Swift container phd2015 path PhD/: Waiting for checks to finish\n2015/11/26\
    \ 21:26:19 Swift container phd2015 path PhD/: Waiting for transfers to finish\n\
    2015/11/26 21:26:20 Waiting for deletions to finish\n\nTransferred:         1852\
    \ Bytes (   0.43 kByte/s)\nErrors:                 0\nChecks:                \
    \ 0\nTransferred:            2\nElapsed time:        4.2s\n\nubuntu@linux:~/Downloads$\
    \ rclone PhD-data backup:phd2015/PhD-data\n...\nubuntu@linux:~/Downloads$ rclone\
    \ results backup:phd2015/PhD-results\n...\n</code></pre>\n<p>(Note that as in\
    \ the third of these examples commands, the local source\nfolder and remote destination\
    \ object prefix can differ.)</p>\n<p>These three \"rclone sync\" commands can\
    \ be run daily (or more\nfrequently) to ensure that the copy held in the object\
    \ storage is up\nto date and matches the data on the local computer.</p>\n<pre><code>ubuntu@linux:~$\
    \ cat ~/sync-my-data\n#!/bin/sh\ncd $HOME/Documents\nrclone sync PhD backup:phd2015/PhD\n\
    rclone sync PhD-data backup:phd2015/PhD-data\nrclone sync results backup:phd2015/PhD-results\n\
    </code></pre>\n<h4>Viewing the data from the NeCTAR dashboard</h4>\n<p>(NB: this\
    \ only applies to the NeCTAR Swift object store as VicNode object\nstorage is\
    \ implemented as a distinct service with its own <em>region</em>.)</p>\n<p>After\
    \ logging in to a the <a href=\"https://support.nectar.org.au/support/solutions/articles/6000076111-nectar-dashboard\"\
    >NeCTAR Dashboard</a> it is possible to view the files\nand containers.  You must\
    \ select the correct project first, then choose\n\"Object Store\" and \"Containers\"\
    , then browse into your containers, e.g.,\n\"phd2015\" in the example above.</p>\n\
    <p><a href=\"#toc\">Contents</a></p>\n<hr>\n<p><a name=\"tempurl\"/></p>\n<h2>Sharing\
    \ files over the Internet with Swift tempurls</h2>\n<p>Object storage is great\
    \ at both storing large amounts of unstructured data\nand also disseminating it\
    \ - once your data is in object storage it is\nonly a small step to make it available\
    \ over the Internet (using standard\nprotocols that regular web-browsers understand).\
    \ You can make the contents\nof a container public or give specific access to\
    \ other users via container\nACLs.</p>\n<p>In this example we demonstrate how\
    \ to use the Swift tempurl feature to provide\ntemporary URL-authenticated access\
    \ to Swift objects. This feature allows you\nto easily share data with anyone\
    \ via URL, they needn't have a Swift user\naccount. Additionally, it's not just\
    \ GET access that can be allowed, but\nalso other HTTP methods like PUT - so you\
    \ can use this feature to allow other\npeople or services to push data into your\
    \ object storage. A typical example\nis a service such as a website that allows\
    \ users to download large objects\nfrom a non-public object storage container\
    \ by minting tempurls and presenting\nthem directly to the user via their web-browser.</p>\n\
    <h3>How it works</h3>\n<p>The tempurl functionality works using a Hash-based Message\n\
    Authentication Code, this <a href=\"https://en.wikipedia.org/wiki/Hash-based_message_authentication_code\"\
    >HMAC</a> encodes:</p>\n<ol>\n<li>The HTTP method being allowed, e.g., GET, PUT,\
    \ HEAD, DELETE, POST</li>\n<li>The expiry date (in Unix time)</li>\n<li>The path\
    \ to the object (from the object store's root URL)</li>\n<li>A secret key shared\
    \ between the user/process that generates the tempurl\n   and the object storage\
    \ service that will decode and accept/deny access\n   based on the other parameters</li>\n\
    </ol>\n<p>This encoding can be done with a few lines of Python or similar high-level\n\
    code, but luckily the Swift command line client already has a helper command\n\
    to do this. In older versions of python-swiftclient this was a separate\ncommand\
    \ called <em>swift-temp-url</em>, in newer versions this is a sub-command of\n\
    the main client, i.e., <em>swift tempurl ...</em>.</p>\n<h3>Set your Swift tempurl\
    \ key</h3>\n<p>To use tempurl functionality it is first necessary to configure\
    \ your object\nstore account with a tempurl key - this is the shared secret mentioned\
    \ in\nstep 4 above that allows the server to verify whether a tempurl is genuine.\n\
    This is done (as demonstrated below) using account metadata. Both the\nOpenStack\
    \ <a href=\"http://docs.ceph.com/docs/master/radosgw/swift/\">Swift</a> and\n\
    <a href=\"http://docs.ceph.com/docs/master/radosgw/swift/\">Ceph Object Gateway\
    \ Swift</a>\nimplementations of the Swift API allow users to set at least 2 tempurl\
    \ keys,\nthis allows users and applications to perform key rotation (but if you\
    \ change\nthe key used to generate a particular tempurl then that tempurl will\n\
    become invalid).</p>\n<p>On VicNode Object Market at Monash:</p>\n<pre><code>$\
    \ swift --os-storage-url https://au-east.erc.monash.edu.au/swift/v1 post --meta\
    \ \"Temp-URL-Key:superfunhappytimes\"\n</code></pre>\n<p>On VicNode Object Vault\
    \ at UoM:</p>\n<pre><code>$ swift --os-region-name VicNode post --meta \"Temp-URL-Key:codswallop\"\
    \n</code></pre>\n<p>NB: The OpenStack Swift API will display the Temp-URL-Key\
    \ metadata back via\nthe API when account metadata is queried. The Ceph Swift\
    \ API does not, so\nit is only possible to set or add a new key if an existing\
    \ one is forgotten\nor lost.</p>\n<h3>Upload the object (if doesn't already exist\
    \ in the object store)</h3>\n<p>Here we upload the file <em>experiment.tar.gz</em>\
    \ from the current directory to a\ncontainer named <em>share</em> in our object\
    \ storage account.</p>\n<pre><code>$ swift upload share experiment.tar.gz\n</code></pre>\n\
    <h3>Generate a tempurl to share with collaborators</h3>\n<p>We'll give them two\
    \ days (172800 seconds) to grab the data.</p>\n<pre><code>$ swift --os-storage-url\
    \ https://au-east.erc.monash.edu.au/swift/v1 tempurl GET 172800 /share/experiment.tar.gz\
    \ superfunhappytimes\n/share/experiment.tar.gz?temp_url_sig=8592bd096a83ba05d3fd1e457dc1167dff62ba28&amp;temp_url_expires=1454540180\n\
    </code></pre>\n<p>The command outputs the sub-path and query components of the\
    \ final working\ntempurl URL. To get the final product we need to prepend the\
    \ service's Swift\nstorage URL. For the above example we would tell our colleagues\
    \ to grab the\nexperiment data from:</p>\n<blockquote>\n<p>https://au-east.erc.monash.edu.au/swift/v1/share/experiment.tar.gz?temp_url_sig=8592bd096a83ba05d3fd1e457dc1167dff62ba28&amp;temp_url_expires=1454540180</p>\n\
    </blockquote>\n<p>With OpenStack Swift that URL also includes the account identifier,\
    \ e.g.,:</p>\n<blockquote>\n<p>https://vault.melbourne.vicnode.org.au:8888/v1/AUTH_cb6c6ea8eb634cc598b0d277b8677b4f/share/experiment.tar.gz?temp_url_sig=0b7408a830d9c03411804b019279135a714c6f28&amp;temp_url_expires=1404626295</p>\n\
    </blockquote>\n<p>NB: The process of generating the tempurl is entirely local\
    \ because the\nSwift service just needs to know the tempurl key to decode the\
    \ other\nparameters and validate them on-demand. However, this means\nthere is\
    \ no validation that your new tempurl works, so we suggest you it\nthem before\
    \ distributing, e.g., by pasting into your web-browser address\nbar.</p>\n<p><a\
    \ href=\"#toc\">Contents</a></p>\n<hr>\n<p><a name=\"duplicity\"/></p>\n<h2>Backing\
    \ up files to object storage using Duplicity</h2>\n<p><a href=\"http://duplicity.nongnu.org\"\
    >Duplicity</a> is a backup utility that can make secure and bandwidth efficient\n\
    back-ups from your computer to various remote storage types including Swift\n\
    and S3. Duplicity uses librsync and GnuPG to make differential and secure\nback-ups.\
    \ In this example we will configure Duplicity to back-up using the\nSwift API.</p>\n\
    <p>First you'll need to create a container that Duplicity will use as the backup\n\
    target location. In this example we assume a container named \"ubuntu\" already\n\
    exists in the project's object store. You can optionally\n<a href=\"https://dmsimard.com/2014/08/12/send-your-encrypted-duplicity-backups-to-a-swift-object-storage/\"\
    >encrypt your back-ups</a> locally before they are transferred to cloud storage,\n\
    though we do not cover that in this example.</p>\n<h3>Configure Duplicity to use\
    \ Swift API</h3>\n<h4>On a 14.04 (Trusty) Ubuntu LTS system</h4>\n<pre><code>apt-get\
    \ install duplicity\n</code></pre>\n<h4>Create a credentials file</h4>\n<p>The\
    \ credentials file contains a subset of the variables from your openrc.sh\nResearch\
    \ Cloud <a href=\"https://support.nectar.org.au/support/solutions/articles/6000078065-api\"\
    >API credentials</a> file.</p>\n<pre><code>cat backup.sh\n#!/bin/bash\nexport\
    \ SWIFT_AUTHVERSION=2\nexport SWIFT_AUTHURL=https://keystone.rc.nectar.org.au:5000/v2.0/\n\
    export SWIFT_USERNAME=\"Monash_RSS-test:adrian.tritschler@monash.edu\"\nexport\
    \ SWIFT_PASSWORD=xxxxxxxxx\n</code></pre>\n<h4>Source the credentials, then run\
    \ a backup</h4>\n<pre><code>$ . backup.sh\n$ duplicity --no-encryption /home/ajft/src\
    \ swift://ubuntu\nSynchronizing remote metadata to local cache...\nDeleting local\
    \ /home/ajft/.cache/duplicity/97fd3f05cdb92feaf3607d5ff406f22c/duplicity-full-signatures.20160106T001707Z.sigtar.gz\
    \ (not authoritative at backend).\nDeleting local /home/ajft/.cache/duplicity/97fd3f05cdb92feaf3607d5ff406f22c/duplicity-full.20160106T001707Z.manifest\
    \ (not authoritative at backend).\nLast full backup date: none\nNo signatures\
    \ found, switching to full backup.\n--------------[ Backup Statistics ]--------------\n\
    StartTime 1452040911.64 (Wed Jan  6 11:41:51 2016)\nEndTime 1452040911.68 (Wed\
    \ Jan  6 11:41:51 2016)\nElapsedTime 0.04 (0.04 seconds)\nSourceFiles 109\nSourceFileSize\
    \ 458449 (448 KB)\nNewFiles 109\nNewFileSize 458449 (448 KB)\nDeletedFiles 0\n\
    ChangedFiles 0\nChangedFileSize 0 (0 bytes)\nChangedDeltaSize 0 (0 bytes)\nDeltaEntries\
    \ 109\nRawDeltaSize 257745 (252 KB)\nTotalDestinationSizeChange 175413 (171 KB)\n\
    Errors 0\n</code></pre>\n<h4>Verify that Duplicity has created the initial back-up</h4>\n\
    <p>You can now see the files that Duplicity has created by listing the contents\n\
    of the target container, e.g., using the Dashboard to browse or the Swift\ncommand-line\
    \ client (python-swiftclient).</p>\n<pre><code>$ swift list --lh ubuntu\n9.6K\
    \ 2016-01-06 00:41:52 duplicity-full-signatures.20160106T004151Z.sigtar.gz\n 179\
    \ 2016-01-06 00:41:53 duplicity-full.20160106T004151Z.manifest\n171K 2016-01-06\
    \ 00:41:52 duplicity-full.20160106T004151Z.vol1.difftar.gz\n181K\n</code></pre>\n\
    <p><a href=\"#toc\">Contents</a></p>"
  parent: 24
  sha1: 797b91c0937e7c35f50ae33e35e4d94523b89a99
  title: VicNode and NeCTAR Cloud Storage - Use Cases, Patterns and Tools
118:
  freshdesk:
    fd_attributes:
      article:
        art_type: 1
        created_at: '2016-04-03T22:07:35-04:00'
        desc_un_html: " Research Cloud Networking \n \n Background \n By default each\
          \ instance/server on the NeCTAR Research gets assigned a single\npublic\
          \ IPv4 address on boot. Each Node of the RC provides and manages the\naddress\
          \ space associated with instances launched and running in their zones...\
          \ \n \n Contents \n \n Background \n Research Cloud Address Ranges \n \n\
          \ \n Research Cloud Address Ranges \n Insert list of IP ranges per Node/zone\
          \ here \n Test FD docbot code block handling \n backticks: \n $ echo \"\
          hi\"\nhi \n backticks with syntax qualifier: \n bash\n$ echo \"hi\"\nhi\
          \ \n 4-spaces: \n $ echo \"hi\"\nhi\n \n tabs: \n $ echo \"hi\"\nhi\n \n\
          \ in-line html: \n \n$ echo \"hi\"\nhi\n "
        description: '<h1>Research Cloud Networking</h1>

          <p><a name="background"></a></p>

          <h2>Background</h2>

          <p>By default each instance/server on the NeCTAR Research gets assigned
          a single

          public IPv4 address on boot. Each Node of the RC provides and manages the

          address space associated with instances launched and running in their zones...</p>

          <p><a name="toc"></a></p>

          <h2>Contents</h2>

          <ul>

          <li><a href="#background">Background</a></li>

          <li><a href="#ranges">Research Cloud Address Ranges</a></li>

          </ul>

          <p><a name="ranges"></a></p>

          <h2>Research Cloud Address Ranges</h2>

          <p>Insert list of IP ranges per Node/zone here</p>

          <h2>Test FD docbot code block handling</h2>

          <p>backticks:</p>

          <p><code>$ echo "hi"

          hi</code></p>

          <p>backticks with syntax qualifier:</p>

          <p><code>bash

          $ echo "hi"

          hi</code></p>

          <p>4-spaces:</p>

          <pre><code>$ echo "hi"

          hi

          </code></pre>

          <p>tabs:</p>

          <pre><code>$ echo "hi"

          hi

          </code></pre>

          <p>in-line html:</p>

          <pre><code>

          $ echo "hi"

          hi

          </code></pre>'
        folder:
          category_id: 6000122278
          created_at: '2015-09-03T01:28:09-04:00'
          customer_folders: []
          description: NeCTAR Fundamentals
          id: 6000190155
          is_default: false
          language_id: 6
          name: NeCTAR Fundamentals
          parent_id: 6000190155
          position: 2
          updated_at: '2015-10-08T21:02:18-04:00'
          visibility: 1
        folder_id: 6000190155
        hits: 0
        id: 6000121047
        modified_at: '2016-04-03T22:07:35-04:00'
        modified_by: null
        position: 5
        seo_data: {}
        status: 2
        tags: []
        thumbs_down: 0
        thumbs_up: 0
        title: Research Cloud Networking
        updated_at: '2016-04-03T22:07:35-04:00'
        user_id: 6002464727
  html: '<h1>Research Cloud Networking</h1>

    <p><a name="background"></p>

    <h2>Background</h2>

    <p>By default each instance/server on the NeCTAR Research gets assigned a single

    public IPv4 address on boot. Each Node of the RC provides and manages the

    address space associated with instances launched and running in their zones...</p>

    <p><a name="toc"/></p>

    <h2>Contents</h2>

    <ul>

    <li><a href="#background">Background</a></li>

    <li><a href="#ranges">Research Cloud Address Ranges</a></li>

    </ul>

    <p><a name="ranges"/></p>

    <h2>Research Cloud Address Ranges</h2>

    <p>Insert list of IP ranges per Node/zone here</p>

    <h2>Test FD docbot code block handling</h2>

    <p>backticks:</p>

    <p><code>$ echo "hi"

    hi</code></p>

    <p>backticks with syntax qualifier:</p>

    <p><code>bash

    $ echo "hi"

    hi</code></p>

    <p>4-spaces:</p>

    <pre><code>$ echo "hi"

    hi

    </code></pre>

    <p>tabs:</p>

    <pre><code>$ echo "hi"

    hi

    </code></pre>

    <p>in-line html:</p>

    <pre><code>

    $ echo "hi"

    hi

    </code></pre>'
  parent: 26
  sha1: d7245f956c0dcc04f227efa033801ea5359bcf1a
  title: Research Cloud Networking
